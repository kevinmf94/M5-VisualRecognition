[32m[03/29 15:27:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 15:27:46 d2.data.build]: [0mRemoved 729 images with no usable annotations. 5082 images left.
[32m[03/29 15:27:46 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 12949        | Pedestrian | 18823        |
|            |              |            |              |
|   total    | 31772        |            |              |[0m
[32m[03/29 15:27:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 15:27:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 15:27:46 d2.data.common]: [0mSerializing 5082 elements to byte tensors and concatenating them all ...
[32m[03/29 15:27:46 d2.data.common]: [0mSerialized dataset takes 15.09 MiB
[32m[03/29 15:27:47 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 15:27:47 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 9960         | Pedestrian | 10725        |
|            |              |            |              |
|   total    | 20685        |            |              |[0m
[32m[03/29 15:27:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 15:27:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 15:27:47 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 15:27:47 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 15:27:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 15:27:59 d2.utils.events]: [0m eta: 0:01:11  iter: 19  total_loss: 2.083  loss_cls: 0.8904  loss_box_reg: 0.5043  loss_mask: 0.6864  loss_rpn_cls: 0.04854  loss_rpn_loc: 0.03157  total_val_loss: 2.171  val_loss_cls: 0.8852  val_loss_box_reg: 0.516  val_loss_mask: 0.6819  val_loss_rpn_cls: 0.1028  val_loss_rpn_loc: 0.05068  time: 0.2536  data_time: 0.0597  lr: 0.00019981  max_mem: 4282M
[32m[03/29 15:28:08 d2.utils.events]: [0m eta: 0:01:05  iter: 39  total_loss: 1.582  loss_cls: 0.4084  loss_box_reg: 0.516  loss_mask: 0.5801  loss_rpn_cls: 0.0381  loss_rpn_loc: 0.03436  total_val_loss: 1.425  val_loss_cls: 0.3755  val_loss_box_reg: 0.4718  val_loss_mask: 0.5474  val_loss_rpn_cls: 0.05698  val_loss_rpn_loc: 0.02594  time: 0.2534  data_time: 0.0105  lr: 0.00039961  max_mem: 4464M
[32m[03/29 15:28:18 d2.utils.events]: [0m eta: 0:01:00  iter: 59  total_loss: 1.198  loss_cls: 0.2632  loss_box_reg: 0.4831  loss_mask: 0.382  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.02199  total_val_loss: 1.165  val_loss_cls: 0.2731  val_loss_box_reg: 0.4349  val_loss_mask: 0.4287  val_loss_rpn_cls: 0.04961  val_loss_rpn_loc: 0.02725  time: 0.2516  data_time: 0.0082  lr: 0.00059941  max_mem: 4464M
[32m[03/29 15:28:27 d2.utils.events]: [0m eta: 0:00:55  iter: 79  total_loss: 0.8716  loss_cls: 0.1626  loss_box_reg: 0.3549  loss_mask: 0.2923  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.02128  total_val_loss: 1.14  val_loss_cls: 0.236  val_loss_box_reg: 0.47  val_loss_mask: 0.3733  val_loss_rpn_cls: 0.05002  val_loss_rpn_loc: 0.03496  time: 0.2506  data_time: 0.0101  lr: 0.00079921  max_mem: 4464M
[32m[03/29 15:28:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 15:28:38 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 15:28:38 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 15:28:38 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 15:28:38 d2.utils.events]: [0m eta: 0:00:51  iter: 99  total_loss: 1.01  loss_cls: 0.1929  loss_box_reg: 0.4157  loss_mask: 0.2918  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.03461  total_val_loss: 0.8236  val_loss_cls: 0.1679  val_loss_box_reg: 0.2805  val_loss_mask: 0.2849  val_loss_rpn_cls: 0.03697  val_loss_rpn_loc: 0.02656  time: 0.2566  data_time: 0.0088  lr: 0.00099901  max_mem: 4464M
[32m[03/29 15:28:48 d2.utils.events]: [0m eta: 0:00:47  iter: 119  total_loss: 0.7779  loss_cls: 0.1334  loss_box_reg: 0.2716  loss_mask: 0.2588  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.03601  total_val_loss: 0.8565  val_loss_cls: 0.164  val_loss_box_reg: 0.295  val_loss_mask: 0.2635  val_loss_rpn_cls: 0.05115  val_loss_rpn_loc: 0.02932  time: 0.2605  data_time: 0.0117  lr: 0.0011988  max_mem: 4464M
[32m[03/29 15:28:58 d2.utils.events]: [0m eta: 0:00:41  iter: 139  total_loss: 0.6817  loss_cls: 0.1459  loss_box_reg: 0.2582  loss_mask: 0.2451  loss_rpn_cls: 0.01915  loss_rpn_loc: 0.02788  total_val_loss: 0.7948  val_loss_cls: 0.1609  val_loss_box_reg: 0.2869  val_loss_mask: 0.2681  val_loss_rpn_cls: 0.03565  val_loss_rpn_loc: 0.0394  time: 0.2616  data_time: 0.0103  lr: 0.0013986  max_mem: 4630M
[32m[03/29 15:29:08 d2.utils.events]: [0m eta: 0:00:36  iter: 159  total_loss: 0.6498  loss_cls: 0.1201  loss_box_reg: 0.2439  loss_mask: 0.2569  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.03957  total_val_loss: 0.6961  val_loss_cls: 0.1261  val_loss_box_reg: 0.2035  val_loss_mask: 0.2419  val_loss_rpn_cls: 0.03232  val_loss_rpn_loc: 0.04047  time: 0.2626  data_time: 0.0159  lr: 0.0015984  max_mem: 4686M
[32m[03/29 15:29:18 d2.utils.events]: [0m eta: 0:00:31  iter: 179  total_loss: 0.6884  loss_cls: 0.1233  loss_box_reg: 0.2422  loss_mask: 0.2291  loss_rpn_cls: 0.008288  loss_rpn_loc: 0.02746  total_val_loss: 0.6748  val_loss_cls: 0.142  val_loss_box_reg: 0.2258  val_loss_mask: 0.1971  val_loss_rpn_cls: 0.03269  val_loss_rpn_loc: 0.03079  time: 0.2631  data_time: 0.0127  lr: 0.0017982  max_mem: 4686M
[32m[03/29 15:29:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 15:29:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 15:29:29 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 15:29:29 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 15:29:29 d2.utils.events]: [0m eta: 0:00:26  iter: 199  total_loss: 0.6963  loss_cls: 0.1375  loss_box_reg: 0.2492  loss_mask: 0.239  loss_rpn_cls: 0.01091  loss_rpn_loc: 0.03779  total_val_loss: 0.8271  val_loss_cls: 0.1699  val_loss_box_reg: 0.287  val_loss_mask: 0.2416  val_loss_rpn_cls: 0.04113  val_loss_rpn_loc: 0.0436  time: 0.2650  data_time: 0.0080  lr: 0.001998  max_mem: 4686M
[32m[03/29 15:29:39 d2.utils.events]: [0m eta: 0:00:21  iter: 219  total_loss: 0.7288  loss_cls: 0.139  loss_box_reg: 0.2276  loss_mask: 0.2358  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.03897  total_val_loss: 0.7289  val_loss_cls: 0.1519  val_loss_box_reg: 0.1937  val_loss_mask: 0.2577  val_loss_rpn_cls: 0.03069  val_loss_rpn_loc: 0.03843  time: 0.2644  data_time: 0.0080  lr: 0.0021978  max_mem: 4686M
[32m[03/29 15:29:48 d2.utils.events]: [0m eta: 0:00:16  iter: 239  total_loss: 0.6537  loss_cls: 0.1222  loss_box_reg: 0.2289  loss_mask: 0.2327  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.04159  total_val_loss: 0.6885  val_loss_cls: 0.1384  val_loss_box_reg: 0.2346  val_loss_mask: 0.2419  val_loss_rpn_cls: 0.03973  val_loss_rpn_loc: 0.03292  time: 0.2644  data_time: 0.0110  lr: 0.0023976  max_mem: 4686M
[32m[03/29 15:29:58 d2.utils.events]: [0m eta: 0:00:10  iter: 259  total_loss: 0.6243  loss_cls: 0.1043  loss_box_reg: 0.2013  loss_mask: 0.2445  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.02754  total_val_loss: 0.6226  val_loss_cls: 0.1328  val_loss_box_reg: 0.1517  val_loss_mask: 0.2479  val_loss_rpn_cls: 0.02815  val_loss_rpn_loc: 0.02255  time: 0.2635  data_time: 0.0075  lr: 0.0025974  max_mem: 4686M
[32m[03/29 15:30:08 d2.utils.events]: [0m eta: 0:00:05  iter: 279  total_loss: 0.5481  loss_cls: 0.1148  loss_box_reg: 0.2074  loss_mask: 0.2243  loss_rpn_cls: 0.008366  loss_rpn_loc: 0.02021  total_val_loss: 0.8344  val_loss_cls: 0.1586  val_loss_box_reg: 0.2634  val_loss_mask: 0.2743  val_loss_rpn_cls: 0.05112  val_loss_rpn_loc: 0.05656  time: 0.2630  data_time: 0.0099  lr: 0.0027972  max_mem: 4686M
[32m[03/29 15:30:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 15:30:26 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 15:30:26 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 15:30:26 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 15:30:27 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 0.6072  loss_cls: 0.1056  loss_box_reg: 0.2102  loss_mask: 0.2324  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.03274  total_val_loss: 0.7345  val_loss_cls: 0.1623  val_loss_box_reg: 0.2285  val_loss_mask: 0.2748  val_loss_rpn_cls: 0.0287  val_loss_rpn_loc: 0.02703  time: 0.2633  data_time: 0.0078  lr: 0.002997  max_mem: 4686M
[32m[03/29 15:30:27 d2.engine.hooks]: [0mOverall training speed: 298 iterations in 0:01:18 (0.2633 s / it)
[32m[03/29 15:30:27 d2.engine.hooks]: [0mTotal training time: 0:02:36 (0:01:18 on hooks)
[32m[03/29 15:30:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 15:30:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 15:30:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 15:30:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 15:30:28 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 15:30:28 d2.evaluation.coco_evaluation]: [0m'kittimots_test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[5m[31mWARNING[0m [32m[03/29 15:30:28 d2.data.datasets.coco]: [0mUsing previously cached COCO format annotations at './output/kittimots_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[32m[03/29 15:30:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 15:30:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 15:30:29 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 15:30:29 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 15:30:30 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.0478 s / img. ETA=0:03:06
[32m[03/29 15:30:35 d2.evaluation.evaluator]: [0mInference done 105/3489. 0.0471 s / img. ETA=0:03:00
[32m[03/29 15:30:40 d2.evaluation.evaluator]: [0mInference done 171/3489. 0.0497 s / img. ETA=0:03:28
[32m[03/29 15:30:45 d2.evaluation.evaluator]: [0mInference done 249/3489. 0.0500 s / img. ETA=0:03:24
[32m[03/29 15:30:50 d2.evaluation.evaluator]: [0mInference done 327/3489. 0.0501 s / img. ETA=0:03:21
[32m[03/29 15:30:55 d2.evaluation.evaluator]: [0mInference done 397/3489. 0.0507 s / img. ETA=0:03:21
[32m[03/29 15:31:00 d2.evaluation.evaluator]: [0mInference done 477/3489. 0.0510 s / img. ETA=0:03:15
[32m[03/29 15:31:05 d2.evaluation.evaluator]: [0mInference done 559/3489. 0.0512 s / img. ETA=0:03:08
[32m[03/29 15:31:10 d2.evaluation.evaluator]: [0mInference done 633/3489. 0.0514 s / img. ETA=0:03:05
[32m[03/29 15:31:15 d2.evaluation.evaluator]: [0mInference done 712/3489. 0.0514 s / img. ETA=0:02:59
[32m[03/29 15:31:20 d2.evaluation.evaluator]: [0mInference done 798/3489. 0.0513 s / img. ETA=0:02:52
[32m[03/29 15:31:25 d2.evaluation.evaluator]: [0mInference done 885/3489. 0.0512 s / img. ETA=0:02:45
[32m[03/29 15:31:30 d2.evaluation.evaluator]: [0mInference done 950/3489. 0.0516 s / img. ETA=0:02:43
[32m[03/29 15:31:35 d2.evaluation.evaluator]: [0mInference done 1010/3489. 0.0520 s / img. ETA=0:02:42
[32m[03/29 15:31:40 d2.evaluation.evaluator]: [0mInference done 1071/3489. 0.0523 s / img. ETA=0:02:40
[32m[03/29 15:31:45 d2.evaluation.evaluator]: [0mInference done 1143/3489. 0.0523 s / img. ETA=0:02:36
[32m[03/29 15:31:50 d2.evaluation.evaluator]: [0mInference done 1216/3489. 0.0524 s / img. ETA=0:02:32
[32m[03/29 15:31:55 d2.evaluation.evaluator]: [0mInference done 1302/3489. 0.0522 s / img. ETA=0:02:25
[32m[03/29 15:32:00 d2.evaluation.evaluator]: [0mInference done 1387/3489. 0.0521 s / img. ETA=0:02:18
[32m[03/29 15:32:05 d2.evaluation.evaluator]: [0mInference done 1463/3489. 0.0521 s / img. ETA=0:02:13
[32m[03/29 15:32:11 d2.evaluation.evaluator]: [0mInference done 1543/3489. 0.0520 s / img. ETA=0:02:07
[32m[03/29 15:32:16 d2.evaluation.evaluator]: [0mInference done 1621/3489. 0.0520 s / img. ETA=0:02:02
[32m[03/29 15:32:21 d2.evaluation.evaluator]: [0mInference done 1694/3489. 0.0520 s / img. ETA=0:01:58
[32m[03/29 15:32:26 d2.evaluation.evaluator]: [0mInference done 1762/3489. 0.0520 s / img. ETA=0:01:54
[32m[03/29 15:32:31 d2.evaluation.evaluator]: [0mInference done 1815/3489. 0.0523 s / img. ETA=0:01:52
[32m[03/29 15:32:36 d2.evaluation.evaluator]: [0mInference done 1871/3489. 0.0525 s / img. ETA=0:01:49
[32m[03/29 15:32:41 d2.evaluation.evaluator]: [0mInference done 1933/3489. 0.0526 s / img. ETA=0:01:45
[32m[03/29 15:32:46 d2.evaluation.evaluator]: [0mInference done 1990/3489. 0.0528 s / img. ETA=0:01:42
[32m[03/29 15:32:51 d2.evaluation.evaluator]: [0mInference done 2061/3489. 0.0528 s / img. ETA=0:01:38
[32m[03/29 15:32:56 d2.evaluation.evaluator]: [0mInference done 2128/3489. 0.0528 s / img. ETA=0:01:33
[32m[03/29 15:33:01 d2.evaluation.evaluator]: [0mInference done 2191/3489. 0.0529 s / img. ETA=0:01:29
[32m[03/29 15:33:06 d2.evaluation.evaluator]: [0mInference done 2254/3489. 0.0530 s / img. ETA=0:01:25
[32m[03/29 15:33:11 d2.evaluation.evaluator]: [0mInference done 2317/3489. 0.0530 s / img. ETA=0:01:21
[32m[03/29 15:33:16 d2.evaluation.evaluator]: [0mInference done 2387/3489. 0.0530 s / img. ETA=0:01:17
[32m[03/29 15:33:21 d2.evaluation.evaluator]: [0mInference done 2458/3489. 0.0530 s / img. ETA=0:01:12
[32m[03/29 15:33:26 d2.evaluation.evaluator]: [0mInference done 2535/3489. 0.0530 s / img. ETA=0:01:06
[32m[03/29 15:33:31 d2.evaluation.evaluator]: [0mInference done 2615/3489. 0.0529 s / img. ETA=0:01:00
[32m[03/29 15:33:36 d2.evaluation.evaluator]: [0mInference done 2689/3489. 0.0529 s / img. ETA=0:00:55
[32m[03/29 15:33:41 d2.evaluation.evaluator]: [0mInference done 2758/3489. 0.0529 s / img. ETA=0:00:50
[32m[03/29 15:33:46 d2.evaluation.evaluator]: [0mInference done 2822/3489. 0.0530 s / img. ETA=0:00:46
[32m[03/29 15:33:51 d2.evaluation.evaluator]: [0mInference done 2891/3489. 0.0529 s / img. ETA=0:00:41
[32m[03/29 15:33:56 d2.evaluation.evaluator]: [0mInference done 2970/3489. 0.0529 s / img. ETA=0:00:36
[32m[03/29 15:34:01 d2.evaluation.evaluator]: [0mInference done 3040/3489. 0.0529 s / img. ETA=0:00:31
[32m[03/29 15:34:06 d2.evaluation.evaluator]: [0mInference done 3108/3489. 0.0529 s / img. ETA=0:00:26
[32m[03/29 15:34:11 d2.evaluation.evaluator]: [0mInference done 3179/3489. 0.0529 s / img. ETA=0:00:21
[32m[03/29 15:34:16 d2.evaluation.evaluator]: [0mInference done 3251/3489. 0.0529 s / img. ETA=0:00:16
[32m[03/29 15:34:21 d2.evaluation.evaluator]: [0mInference done 3333/3489. 0.0528 s / img. ETA=0:00:10
[32m[03/29 15:34:26 d2.evaluation.evaluator]: [0mInference done 3423/3489. 0.0528 s / img. ETA=0:00:04
[32m[03/29 15:34:30 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:00.959316 (0.069162 s / img per device, on 1 devices)
[32m[03/29 15:34:30 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:03 (0.052690 s / img per device, on 1 devices)
[32m[03/29 15:34:31 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 15:34:31 d2.evaluation.coco_evaluation]: [0mSaving results to ./output/coco_instances_results.json
[32m[03/29 15:34:32 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 0.98 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.26 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.850
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.670
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.721
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825
[32m[03/29 15:34:33 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 56.768 | 84.973 | 67.045 | 40.978 | 65.078 | 70.918 |
[32m[03/29 15:34:33 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.432 | Pedestrian | 53.104 |
Loading and preparing results...
DONE (t=0.75s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 1.46 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.27 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.824
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.817
[32m[03/29 15:34:37 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.705 | 82.376 | 59.296 | 32.754 | 60.693 | 76.447 |
[32m[03/29 15:34:37 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.209 | Pedestrian | 42.201 |
[32m[03/29 15:34:37 d2.engine.defaults]: [0mEvaluation results for kittimots_test in csv format:
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: 56.7681,84.9734,67.0446,40.9778,65.0782,70.9178
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 15:34:37 d2.evaluation.testing]: [0mcopypaste: 52.7048,82.3763,59.2964,32.7545,60.6932,76.4467
evaluated
0015/000152
Time inference:  0.0666880365461111
0016/000027
Time inference:  0.06578799523413181
0019/000115
Time inference:  0.065667275339365
0019/000222
Time inference:  0.06613264977931976
0019/000324
Time inference:  0.06505510304123163
0019/000570
Time inference:  0.06541920732706785
0019/001035
Time inference:  0.06345717888325453
0020/000630
Time inference:  0.06583277229219675
0020/000688
Time inference:  0.06570769287645817
