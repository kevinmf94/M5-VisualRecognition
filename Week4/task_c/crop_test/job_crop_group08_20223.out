Test [0.100000, 0.100000]
[32m[03/28 19:41:58 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 19:41:59 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 19:41:59 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 16900        | Pedestrian | 690          |
|            |              |            |              |
|   total    | 17590        |            |              |[0m
[32m[03/28 19:41:59 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 19:41:59 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 19:41:59 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 19:41:59 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 19:41:59 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 19:41:59 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 9960         | Pedestrian | 10725        |
|            |              |            |              |
|   total    | 20685        |            |              |[0m
[32m[03/28 19:41:59 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 19:41:59 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 19:41:59 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 19:41:59 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 19:41:59 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 19:42:24 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.903  loss_cls: 0.77  loss_box_reg: 0.5335  loss_mask: 0.6591  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.01358  total_val_loss: 1.86  val_loss_cls: 0.7311  val_loss_box_reg: 0.3816  val_loss_mask: 0.69  val_loss_rpn_cls: 0.05428  val_loss_rpn_loc: 0.01284  time: 0.8468  data_time: 0.0313  lr: 0.00019981  max_mem: 4741M
[32m[03/28 19:42:48 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.959  loss_cls: 0.1898  loss_box_reg: 0.3326  loss_mask: 0.3818  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.008513  total_val_loss: 0.8957  val_loss_cls: 0.1646  val_loss_box_reg: 0.3273  val_loss_mask: 0.4353  val_loss_rpn_cls: 0.02362  val_loss_rpn_loc: 0.009041  time: 0.8514  data_time: 0.0071  lr: 0.00039961  max_mem: 4742M
[32m[03/28 19:43:13 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.6679  loss_cls: 0.07884  loss_box_reg: 0.3169  loss_mask: 0.1946  loss_rpn_cls: 0.008363  loss_rpn_loc: 0.007676  total_val_loss: 1.059  val_loss_cls: 0.2036  val_loss_box_reg: 0.5  val_loss_mask: 0.3393  val_loss_rpn_cls: 0.03284  val_loss_rpn_loc: 0.01416  time: 0.8563  data_time: 0.0069  lr: 0.00059941  max_mem: 4742M
[32m[03/28 19:43:37 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.509  loss_cls: 0.06259  loss_box_reg: 0.232  loss_mask: 0.1888  loss_rpn_cls: 0.009394  loss_rpn_loc: 0.006512  total_val_loss: 0.9523  val_loss_cls: 0.1891  val_loss_box_reg: 0.3718  val_loss_mask: 0.3175  val_loss_rpn_cls: 0.0252  val_loss_rpn_loc: 0.0157  time: 0.8608  data_time: 0.0117  lr: 0.00079921  max_mem: 4742M
[32m[03/28 19:44:02 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 19:44:02 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 19:44:02 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 19:44:02 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 19:44:02 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.3903  loss_cls: 0.05066  loss_box_reg: 0.1623  loss_mask: 0.1267  loss_rpn_cls: 0.007414  loss_rpn_loc: 0.009925  total_val_loss: 1.134  val_loss_cls: 0.2893  val_loss_box_reg: 0.3617  val_loss_mask: 0.362  val_loss_rpn_cls: 0.01855  val_loss_rpn_loc: 0.01263  time: 0.8612  data_time: 0.0061  lr: 0.00099901  max_mem: 4742M
[32m[03/28 19:44:26 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.2695  loss_cls: 0.03275  loss_box_reg: 0.05938  loss_mask: 0.1558  loss_rpn_cls: 0.004565  loss_rpn_loc: 0.003808  total_val_loss: 0.9763  val_loss_cls: 0.241  val_loss_box_reg: 0.3032  val_loss_mask: 0.3585  val_loss_rpn_cls: 0.02459  val_loss_rpn_loc: 0.01647  time: 0.8616  data_time: 0.0058  lr: 0.0011988  max_mem: 4742M
[32m[03/28 19:44:50 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3037  loss_cls: 0.04181  loss_box_reg: 0.08539  loss_mask: 0.1401  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.007173  total_val_loss: 0.7423  val_loss_cls: 0.1656  val_loss_box_reg: 0.1986  val_loss_mask: 0.3099  val_loss_rpn_cls: 0.02407  val_loss_rpn_loc: 0.01298  time: 0.8617  data_time: 0.0059  lr: 0.0013986  max_mem: 4742M
[32m[03/28 19:45:15 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3126  loss_cls: 0.04893  loss_box_reg: 0.09645  loss_mask: 0.1341  loss_rpn_cls: 0.007519  loss_rpn_loc: 0.01172  total_val_loss: 0.9795  val_loss_cls: 0.2251  val_loss_box_reg: 0.3021  val_loss_mask: 0.3362  val_loss_rpn_cls: 0.0241  val_loss_rpn_loc: 0.01467  time: 0.8627  data_time: 0.0064  lr: 0.0015984  max_mem: 4742M
[32m[03/28 19:45:39 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3649  loss_cls: 0.06061  loss_box_reg: 0.1414  loss_mask: 0.168  loss_rpn_cls: 0.00653  loss_rpn_loc: 0.01268  total_val_loss: 0.8741  val_loss_cls: 0.1887  val_loss_box_reg: 0.2907  val_loss_mask: 0.3258  val_loss_rpn_cls: 0.02172  val_loss_rpn_loc: 0.01431  time: 0.8631  data_time: 0.0061  lr: 0.0017982  max_mem: 4742M
[32m[03/28 19:46:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 19:46:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 19:46:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 19:46:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 19:46:04 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4044  loss_cls: 0.05881  loss_box_reg: 0.1287  loss_mask: 0.1604  loss_rpn_cls: 0.005753  loss_rpn_loc: 0.01109  total_val_loss: 0.7029  val_loss_cls: 0.1509  val_loss_box_reg: 0.2518  val_loss_mask: 0.2975  val_loss_rpn_cls: 0.02085  val_loss_rpn_loc: 0.01553  time: 0.8633  data_time: 0.0062  lr: 0.001998  max_mem: 4742M
[32m[03/28 19:46:04 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8633 s / it)
[32m[03/28 19:46:04 d2.engine.hooks]: [0mTotal training time: 0:04:01 (0:01:10 on hooks)
[32m[03/28 19:46:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 19:46:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 19:46:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 19:46:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 19:46:05 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 19:46:05 d2.evaluation.coco_evaluation]: [0m'kittimots_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[03/28 19:46:05 d2.data.datasets.coco]: [0mConverting annotations of dataset 'kittimots_val' to COCO format ...)
[32m[03/28 19:46:05 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[03/28 19:46:05 d2.data.datasets.coco]: [0mConversion finished, #images: 3489, #annotations: 20685
[32m[03/28 19:46:05 d2.data.datasets.coco]: [0mCaching COCO format annotations at './output_0.100000_0.100000/kittimots_val_coco_format.json' ...
[32m[03/28 19:46:06 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 19:46:06 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 19:46:07 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 19:46:07 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 19:46:10 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2274 s / img. ETA=0:14:24
[32m[03/28 19:46:15 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2296 s / img. ETA=0:14:22
[32m[03/28 19:46:20 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2295 s / img. ETA=0:14:10
[32m[03/28 19:46:25 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2306 s / img. ETA=0:14:05
[32m[03/28 19:46:31 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2312 s / img. ETA=0:14:10
[32m[03/28 19:46:36 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2334 s / img. ETA=0:14:30
[32m[03/28 19:46:41 d2.evaluation.evaluator]: [0mInference done 127/3489. 0.2352 s / img. ETA=0:14:56
[32m[03/28 19:46:46 d2.evaluation.evaluator]: [0mInference done 141/3489. 0.2371 s / img. ETA=0:15:28
[32m[03/28 19:46:51 d2.evaluation.evaluator]: [0mInference done 155/3489. 0.2391 s / img. ETA=0:15:54
[32m[03/28 19:46:56 d2.evaluation.evaluator]: [0mInference done 169/3489. 0.2406 s / img. ETA=0:16:14
[32m[03/28 19:47:02 d2.evaluation.evaluator]: [0mInference done 184/3489. 0.2411 s / img. ETA=0:16:24
[32m[03/28 19:47:07 d2.evaluation.evaluator]: [0mInference done 200/3489. 0.2416 s / img. ETA=0:16:25
[32m[03/28 19:47:12 d2.evaluation.evaluator]: [0mInference done 219/3489. 0.2414 s / img. ETA=0:16:09
[32m[03/28 19:47:17 d2.evaluation.evaluator]: [0mInference done 238/3489. 0.2407 s / img. ETA=0:15:55
[32m[03/28 19:47:22 d2.evaluation.evaluator]: [0mInference done 256/3489. 0.2409 s / img. ETA=0:15:49
[32m[03/28 19:47:27 d2.evaluation.evaluator]: [0mInference done 274/3489. 0.2407 s / img. ETA=0:15:41
[32m[03/28 19:47:32 d2.evaluation.evaluator]: [0mInference done 291/3489. 0.2409 s / img. ETA=0:15:38
[32m[03/28 19:47:37 d2.evaluation.evaluator]: [0mInference done 307/3489. 0.2410 s / img. ETA=0:15:37
[32m[03/28 19:47:42 d2.evaluation.evaluator]: [0mInference done 323/3489. 0.2413 s / img. ETA=0:15:36
[32m[03/28 19:47:47 d2.evaluation.evaluator]: [0mInference done 339/3489. 0.2415 s / img. ETA=0:15:35
[32m[03/28 19:47:52 d2.evaluation.evaluator]: [0mInference done 354/3489. 0.2418 s / img. ETA=0:15:36
[32m[03/28 19:47:58 d2.evaluation.evaluator]: [0mInference done 371/3489. 0.2420 s / img. ETA=0:15:31
[32m[03/28 19:48:03 d2.evaluation.evaluator]: [0mInference done 388/3489. 0.2421 s / img. ETA=0:15:27
[32m[03/28 19:48:08 d2.evaluation.evaluator]: [0mInference done 406/3489. 0.2420 s / img. ETA=0:15:19
[32m[03/28 19:48:13 d2.evaluation.evaluator]: [0mInference done 423/3489. 0.2421 s / img. ETA=0:15:15
[32m[03/28 19:48:18 d2.evaluation.evaluator]: [0mInference done 444/3489. 0.2416 s / img. ETA=0:15:01
[32m[03/28 19:48:23 d2.evaluation.evaluator]: [0mInference done 465/3489. 0.2410 s / img. ETA=0:14:48
[32m[03/28 19:48:29 d2.evaluation.evaluator]: [0mInference done 486/3489. 0.2405 s / img. ETA=0:14:36
[32m[03/28 19:48:34 d2.evaluation.evaluator]: [0mInference done 507/3489. 0.2401 s / img. ETA=0:14:23
[32m[03/28 19:48:39 d2.evaluation.evaluator]: [0mInference done 528/3489. 0.2395 s / img. ETA=0:14:11
[32m[03/28 19:48:44 d2.evaluation.evaluator]: [0mInference done 549/3489. 0.2391 s / img. ETA=0:14:00
[32m[03/28 19:48:49 d2.evaluation.evaluator]: [0mInference done 569/3489. 0.2390 s / img. ETA=0:13:52
[32m[03/28 19:48:54 d2.evaluation.evaluator]: [0mInference done 586/3489. 0.2391 s / img. ETA=0:13:49
[32m[03/28 19:48:59 d2.evaluation.evaluator]: [0mInference done 604/3489. 0.2393 s / img. ETA=0:13:44
[32m[03/28 19:49:05 d2.evaluation.evaluator]: [0mInference done 622/3489. 0.2393 s / img. ETA=0:13:39
[32m[03/28 19:49:10 d2.evaluation.evaluator]: [0mInference done 640/3489. 0.2394 s / img. ETA=0:13:34
[32m[03/28 19:49:15 d2.evaluation.evaluator]: [0mInference done 659/3489. 0.2394 s / img. ETA=0:13:28
[32m[03/28 19:49:20 d2.evaluation.evaluator]: [0mInference done 679/3489. 0.2391 s / img. ETA=0:13:20
[32m[03/28 19:49:25 d2.evaluation.evaluator]: [0mInference done 700/3489. 0.2389 s / img. ETA=0:13:10
[32m[03/28 19:49:30 d2.evaluation.evaluator]: [0mInference done 720/3489. 0.2387 s / img. ETA=0:13:02
[32m[03/28 19:49:35 d2.evaluation.evaluator]: [0mInference done 740/3489. 0.2385 s / img. ETA=0:12:55
[32m[03/28 19:49:41 d2.evaluation.evaluator]: [0mInference done 761/3489. 0.2382 s / img. ETA=0:12:46
[32m[03/28 19:49:46 d2.evaluation.evaluator]: [0mInference done 782/3489. 0.2379 s / img. ETA=0:12:37
[32m[03/28 19:49:51 d2.evaluation.evaluator]: [0mInference done 803/3489. 0.2376 s / img. ETA=0:12:28
[32m[03/28 19:49:56 d2.evaluation.evaluator]: [0mInference done 825/3489. 0.2373 s / img. ETA=0:12:19
[32m[03/28 19:50:01 d2.evaluation.evaluator]: [0mInference done 846/3489. 0.2371 s / img. ETA=0:12:11
[32m[03/28 19:50:06 d2.evaluation.evaluator]: [0mInference done 867/3489. 0.2369 s / img. ETA=0:12:03
[32m[03/28 19:50:11 d2.evaluation.evaluator]: [0mInference done 888/3489. 0.2367 s / img. ETA=0:11:55
[32m[03/28 19:50:16 d2.evaluation.evaluator]: [0mInference done 906/3489. 0.2367 s / img. ETA=0:11:50
[32m[03/28 19:50:21 d2.evaluation.evaluator]: [0mInference done 921/3489. 0.2370 s / img. ETA=0:11:49
[32m[03/28 19:50:26 d2.evaluation.evaluator]: [0mInference done 935/3489. 0.2372 s / img. ETA=0:11:49
[32m[03/28 19:50:32 d2.evaluation.evaluator]: [0mInference done 950/3489. 0.2374 s / img. ETA=0:11:47
[32m[03/28 19:50:37 d2.evaluation.evaluator]: [0mInference done 965/3489. 0.2376 s / img. ETA=0:11:46
[32m[03/28 19:50:42 d2.evaluation.evaluator]: [0mInference done 979/3489. 0.2378 s / img. ETA=0:11:45
[32m[03/28 19:50:47 d2.evaluation.evaluator]: [0mInference done 993/3489. 0.2379 s / img. ETA=0:11:44
[32m[03/28 19:50:52 d2.evaluation.evaluator]: [0mInference done 1008/3489. 0.2381 s / img. ETA=0:11:43
[32m[03/28 19:50:58 d2.evaluation.evaluator]: [0mInference done 1023/3489. 0.2383 s / img. ETA=0:11:41
[32m[03/28 19:51:03 d2.evaluation.evaluator]: [0mInference done 1037/3489. 0.2384 s / img. ETA=0:11:39
[32m[03/28 19:51:08 d2.evaluation.evaluator]: [0mInference done 1052/3489. 0.2386 s / img. ETA=0:11:38
[32m[03/28 19:51:13 d2.evaluation.evaluator]: [0mInference done 1067/3489. 0.2387 s / img. ETA=0:11:36
[32m[03/28 19:51:19 d2.evaluation.evaluator]: [0mInference done 1082/3489. 0.2388 s / img. ETA=0:11:33
[32m[03/28 19:51:24 d2.evaluation.evaluator]: [0mInference done 1101/3489. 0.2388 s / img. ETA=0:11:27
[32m[03/28 19:51:29 d2.evaluation.evaluator]: [0mInference done 1119/3489. 0.2388 s / img. ETA=0:11:22
[32m[03/28 19:51:34 d2.evaluation.evaluator]: [0mInference done 1134/3489. 0.2390 s / img. ETA=0:11:19
[32m[03/28 19:51:39 d2.evaluation.evaluator]: [0mInference done 1149/3489. 0.2391 s / img. ETA=0:11:17
[32m[03/28 19:51:45 d2.evaluation.evaluator]: [0mInference done 1164/3489. 0.2392 s / img. ETA=0:11:14
[32m[03/28 19:51:50 d2.evaluation.evaluator]: [0mInference done 1179/3489. 0.2395 s / img. ETA=0:11:12
[32m[03/28 19:51:55 d2.evaluation.evaluator]: [0mInference done 1194/3489. 0.2396 s / img. ETA=0:11:09
[32m[03/28 19:52:00 d2.evaluation.evaluator]: [0mInference done 1210/3489. 0.2397 s / img. ETA=0:11:05
[32m[03/28 19:52:05 d2.evaluation.evaluator]: [0mInference done 1227/3489. 0.2397 s / img. ETA=0:11:00
[32m[03/28 19:52:10 d2.evaluation.evaluator]: [0mInference done 1244/3489. 0.2398 s / img. ETA=0:10:55
[32m[03/28 19:52:15 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2397 s / img. ETA=0:10:48
[32m[03/28 19:52:20 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2395 s / img. ETA=0:10:39
[32m[03/28 19:52:25 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2393 s / img. ETA=0:10:31
[32m[03/28 19:52:31 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2391 s / img. ETA=0:10:23
[32m[03/28 19:52:36 d2.evaluation.evaluator]: [0mInference done 1351/3489. 0.2389 s / img. ETA=0:10:15
[32m[03/28 19:52:41 d2.evaluation.evaluator]: [0mInference done 1372/3489. 0.2388 s / img. ETA=0:10:08
[32m[03/28 19:52:46 d2.evaluation.evaluator]: [0mInference done 1393/3489. 0.2387 s / img. ETA=0:10:00
[32m[03/28 19:52:51 d2.evaluation.evaluator]: [0mInference done 1414/3489. 0.2385 s / img. ETA=0:09:53
[32m[03/28 19:52:56 d2.evaluation.evaluator]: [0mInference done 1435/3489. 0.2384 s / img. ETA=0:09:46
[32m[03/28 19:53:01 d2.evaluation.evaluator]: [0mInference done 1456/3489. 0.2383 s / img. ETA=0:09:38
[32m[03/28 19:53:06 d2.evaluation.evaluator]: [0mInference done 1477/3489. 0.2381 s / img. ETA=0:09:31
[32m[03/28 19:53:12 d2.evaluation.evaluator]: [0mInference done 1499/3489. 0.2380 s / img. ETA=0:09:24
[32m[03/28 19:53:17 d2.evaluation.evaluator]: [0mInference done 1520/3489. 0.2378 s / img. ETA=0:09:16
[32m[03/28 19:53:22 d2.evaluation.evaluator]: [0mInference done 1541/3489. 0.2377 s / img. ETA=0:09:09
[32m[03/28 19:53:27 d2.evaluation.evaluator]: [0mInference done 1562/3489. 0.2376 s / img. ETA=0:09:03
[32m[03/28 19:53:32 d2.evaluation.evaluator]: [0mInference done 1583/3489. 0.2375 s / img. ETA=0:08:56
[32m[03/28 19:53:37 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2375 s / img. ETA=0:08:50
[32m[03/28 19:53:42 d2.evaluation.evaluator]: [0mInference done 1620/3489. 0.2375 s / img. ETA=0:08:45
[32m[03/28 19:53:48 d2.evaluation.evaluator]: [0mInference done 1637/3489. 0.2376 s / img. ETA=0:08:41
[32m[03/28 19:53:53 d2.evaluation.evaluator]: [0mInference done 1656/3489. 0.2376 s / img. ETA=0:08:35
[32m[03/28 19:53:58 d2.evaluation.evaluator]: [0mInference done 1673/3489. 0.2377 s / img. ETA=0:08:31
[32m[03/28 19:54:03 d2.evaluation.evaluator]: [0mInference done 1687/3489. 0.2378 s / img. ETA=0:08:28
[32m[03/28 19:54:08 d2.evaluation.evaluator]: [0mInference done 1701/3489. 0.2379 s / img. ETA=0:08:25
[32m[03/28 19:54:13 d2.evaluation.evaluator]: [0mInference done 1716/3489. 0.2380 s / img. ETA=0:08:22
[32m[03/28 19:54:19 d2.evaluation.evaluator]: [0mInference done 1731/3489. 0.2381 s / img. ETA=0:08:19
[32m[03/28 19:54:24 d2.evaluation.evaluator]: [0mInference done 1746/3489. 0.2382 s / img. ETA=0:08:16
[32m[03/28 19:54:29 d2.evaluation.evaluator]: [0mInference done 1760/3489. 0.2383 s / img. ETA=0:08:13
[32m[03/28 19:54:34 d2.evaluation.evaluator]: [0mInference done 1774/3489. 0.2384 s / img. ETA=0:08:10
[32m[03/28 19:54:39 d2.evaluation.evaluator]: [0mInference done 1788/3489. 0.2385 s / img. ETA=0:08:07
[32m[03/28 19:54:44 d2.evaluation.evaluator]: [0mInference done 1802/3489. 0.2386 s / img. ETA=0:08:04
[32m[03/28 19:54:49 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2387 s / img. ETA=0:08:01
[32m[03/28 19:54:54 d2.evaluation.evaluator]: [0mInference done 1830/3489. 0.2387 s / img. ETA=0:07:58
[32m[03/28 19:55:00 d2.evaluation.evaluator]: [0mInference done 1844/3489. 0.2388 s / img. ETA=0:07:55
[32m[03/28 19:55:05 d2.evaluation.evaluator]: [0mInference done 1858/3489. 0.2389 s / img. ETA=0:07:52
[32m[03/28 19:55:10 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2390 s / img. ETA=0:07:48
[32m[03/28 19:55:15 d2.evaluation.evaluator]: [0mInference done 1886/3489. 0.2391 s / img. ETA=0:07:45
[32m[03/28 19:55:20 d2.evaluation.evaluator]: [0mInference done 1900/3489. 0.2391 s / img. ETA=0:07:42
[32m[03/28 19:55:25 d2.evaluation.evaluator]: [0mInference done 1914/3489. 0.2393 s / img. ETA=0:07:39
[32m[03/28 19:55:30 d2.evaluation.evaluator]: [0mInference done 1928/3489. 0.2393 s / img. ETA=0:07:36
[32m[03/28 19:55:35 d2.evaluation.evaluator]: [0mInference done 1942/3489. 0.2394 s / img. ETA=0:07:32
[32m[03/28 19:55:40 d2.evaluation.evaluator]: [0mInference done 1956/3489. 0.2395 s / img. ETA=0:07:29
[32m[03/28 19:55:45 d2.evaluation.evaluator]: [0mInference done 1970/3489. 0.2396 s / img. ETA=0:07:26
[32m[03/28 19:55:50 d2.evaluation.evaluator]: [0mInference done 1984/3489. 0.2397 s / img. ETA=0:07:22
[32m[03/28 19:55:56 d2.evaluation.evaluator]: [0mInference done 2000/3489. 0.2397 s / img. ETA=0:07:18
[32m[03/28 19:56:01 d2.evaluation.evaluator]: [0mInference done 2017/3489. 0.2397 s / img. ETA=0:07:13
[32m[03/28 19:56:06 d2.evaluation.evaluator]: [0mInference done 2033/3489. 0.2398 s / img. ETA=0:07:09
[32m[03/28 19:56:11 d2.evaluation.evaluator]: [0mInference done 2048/3489. 0.2399 s / img. ETA=0:07:05
[32m[03/28 19:56:16 d2.evaluation.evaluator]: [0mInference done 2063/3489. 0.2399 s / img. ETA=0:07:01
[32m[03/28 19:56:22 d2.evaluation.evaluator]: [0mInference done 2077/3489. 0.2400 s / img. ETA=0:06:57
[32m[03/28 19:56:27 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2401 s / img. ETA=0:06:54
[32m[03/28 19:56:32 d2.evaluation.evaluator]: [0mInference done 2105/3489. 0.2402 s / img. ETA=0:06:50
[32m[03/28 19:56:37 d2.evaluation.evaluator]: [0mInference done 2119/3489. 0.2403 s / img. ETA=0:06:47
[32m[03/28 19:56:42 d2.evaluation.evaluator]: [0mInference done 2133/3489. 0.2404 s / img. ETA=0:06:43
[32m[03/28 19:56:47 d2.evaluation.evaluator]: [0mInference done 2147/3489. 0.2405 s / img. ETA=0:06:40
[32m[03/28 19:56:52 d2.evaluation.evaluator]: [0mInference done 2161/3489. 0.2405 s / img. ETA=0:06:36
[32m[03/28 19:56:57 d2.evaluation.evaluator]: [0mInference done 2175/3489. 0.2406 s / img. ETA=0:06:32
[32m[03/28 19:57:02 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2407 s / img. ETA=0:06:29
[32m[03/28 19:57:07 d2.evaluation.evaluator]: [0mInference done 2203/3489. 0.2408 s / img. ETA=0:06:25
[32m[03/28 19:57:12 d2.evaluation.evaluator]: [0mInference done 2217/3489. 0.2409 s / img. ETA=0:06:21
[32m[03/28 19:57:17 d2.evaluation.evaluator]: [0mInference done 2230/3489. 0.2410 s / img. ETA=0:06:18
[32m[03/28 19:57:23 d2.evaluation.evaluator]: [0mInference done 2244/3489. 0.2411 s / img. ETA=0:06:14
[32m[03/28 19:57:28 d2.evaluation.evaluator]: [0mInference done 2259/3489. 0.2412 s / img. ETA=0:06:10
[32m[03/28 19:57:33 d2.evaluation.evaluator]: [0mInference done 2273/3489. 0.2413 s / img. ETA=0:06:07
[32m[03/28 19:57:38 d2.evaluation.evaluator]: [0mInference done 2288/3489. 0.2413 s / img. ETA=0:06:02
[32m[03/28 19:57:43 d2.evaluation.evaluator]: [0mInference done 2302/3489. 0.2414 s / img. ETA=0:05:59
[32m[03/28 19:57:48 d2.evaluation.evaluator]: [0mInference done 2316/3489. 0.2415 s / img. ETA=0:05:55
[32m[03/28 19:57:54 d2.evaluation.evaluator]: [0mInference done 2330/3489. 0.2415 s / img. ETA=0:05:51
[32m[03/28 19:57:59 d2.evaluation.evaluator]: [0mInference done 2344/3489. 0.2416 s / img. ETA=0:05:47
[32m[03/28 19:58:04 d2.evaluation.evaluator]: [0mInference done 2359/3489. 0.2417 s / img. ETA=0:05:43
[32m[03/28 19:58:09 d2.evaluation.evaluator]: [0mInference done 2377/3489. 0.2417 s / img. ETA=0:05:38
[32m[03/28 19:58:14 d2.evaluation.evaluator]: [0mInference done 2395/3489. 0.2417 s / img. ETA=0:05:32
[32m[03/28 19:58:20 d2.evaluation.evaluator]: [0mInference done 2411/3489. 0.2417 s / img. ETA=0:05:27
[32m[03/28 19:58:25 d2.evaluation.evaluator]: [0mInference done 2429/3489. 0.2417 s / img. ETA=0:05:22
[32m[03/28 19:58:30 d2.evaluation.evaluator]: [0mInference done 2444/3489. 0.2418 s / img. ETA=0:05:17
[32m[03/28 19:58:35 d2.evaluation.evaluator]: [0mInference done 2459/3489. 0.2418 s / img. ETA=0:05:13
[32m[03/28 19:58:40 d2.evaluation.evaluator]: [0mInference done 2473/3489. 0.2419 s / img. ETA=0:05:09
[32m[03/28 19:58:45 d2.evaluation.evaluator]: [0mInference done 2488/3489. 0.2420 s / img. ETA=0:05:05
[32m[03/28 19:58:50 d2.evaluation.evaluator]: [0mInference done 2509/3489. 0.2418 s / img. ETA=0:04:58
[32m[03/28 19:58:56 d2.evaluation.evaluator]: [0mInference done 2529/3489. 0.2418 s / img. ETA=0:04:51
[32m[03/28 19:59:01 d2.evaluation.evaluator]: [0mInference done 2549/3489. 0.2417 s / img. ETA=0:04:45
[32m[03/28 19:59:06 d2.evaluation.evaluator]: [0mInference done 2568/3489. 0.2417 s / img. ETA=0:04:39
[32m[03/28 19:59:11 d2.evaluation.evaluator]: [0mInference done 2589/3489. 0.2416 s / img. ETA=0:04:32
[32m[03/28 19:59:16 d2.evaluation.evaluator]: [0mInference done 2609/3489. 0.2415 s / img. ETA=0:04:26
[32m[03/28 19:59:21 d2.evaluation.evaluator]: [0mInference done 2630/3489. 0.2414 s / img. ETA=0:04:19
[32m[03/28 19:59:26 d2.evaluation.evaluator]: [0mInference done 2652/3489. 0.2413 s / img. ETA=0:04:12
[32m[03/28 19:59:31 d2.evaluation.evaluator]: [0mInference done 2671/3489. 0.2412 s / img. ETA=0:04:06
[32m[03/28 19:59:36 d2.evaluation.evaluator]: [0mInference done 2691/3489. 0.2412 s / img. ETA=0:04:00
[32m[03/28 19:59:42 d2.evaluation.evaluator]: [0mInference done 2711/3489. 0.2411 s / img. ETA=0:03:53
[32m[03/28 19:59:47 d2.evaluation.evaluator]: [0mInference done 2731/3489. 0.2410 s / img. ETA=0:03:47
[32m[03/28 19:59:52 d2.evaluation.evaluator]: [0mInference done 2751/3489. 0.2410 s / img. ETA=0:03:41
[32m[03/28 19:59:57 d2.evaluation.evaluator]: [0mInference done 2771/3489. 0.2409 s / img. ETA=0:03:35
[32m[03/28 20:00:02 d2.evaluation.evaluator]: [0mInference done 2791/3489. 0.2408 s / img. ETA=0:03:28
[32m[03/28 20:00:07 d2.evaluation.evaluator]: [0mInference done 2811/3489. 0.2408 s / img. ETA=0:03:22
[32m[03/28 20:00:12 d2.evaluation.evaluator]: [0mInference done 2831/3489. 0.2407 s / img. ETA=0:03:16
[32m[03/28 20:00:18 d2.evaluation.evaluator]: [0mInference done 2851/3489. 0.2407 s / img. ETA=0:03:10
[32m[03/28 20:00:23 d2.evaluation.evaluator]: [0mInference done 2871/3489. 0.2406 s / img. ETA=0:03:04
[32m[03/28 20:00:28 d2.evaluation.evaluator]: [0mInference done 2891/3489. 0.2405 s / img. ETA=0:02:58
[32m[03/28 20:00:33 d2.evaluation.evaluator]: [0mInference done 2912/3489. 0.2404 s / img. ETA=0:02:51
[32m[03/28 20:00:38 d2.evaluation.evaluator]: [0mInference done 2933/3489. 0.2403 s / img. ETA=0:02:45
[32m[03/28 20:00:43 d2.evaluation.evaluator]: [0mInference done 2954/3489. 0.2403 s / img. ETA=0:02:38
[32m[03/28 20:00:48 d2.evaluation.evaluator]: [0mInference done 2975/3489. 0.2402 s / img. ETA=0:02:32
[32m[03/28 20:00:53 d2.evaluation.evaluator]: [0mInference done 2995/3489. 0.2401 s / img. ETA=0:02:26
[32m[03/28 20:00:58 d2.evaluation.evaluator]: [0mInference done 3015/3489. 0.2401 s / img. ETA=0:02:20
[32m[03/28 20:01:03 d2.evaluation.evaluator]: [0mInference done 3035/3489. 0.2400 s / img. ETA=0:02:14
[32m[03/28 20:01:09 d2.evaluation.evaluator]: [0mInference done 3055/3489. 0.2399 s / img. ETA=0:02:08
[32m[03/28 20:01:14 d2.evaluation.evaluator]: [0mInference done 3075/3489. 0.2399 s / img. ETA=0:02:02
[32m[03/28 20:01:19 d2.evaluation.evaluator]: [0mInference done 3094/3489. 0.2399 s / img. ETA=0:01:56
[32m[03/28 20:01:24 d2.evaluation.evaluator]: [0mInference done 3114/3489. 0.2398 s / img. ETA=0:01:50
[32m[03/28 20:01:29 d2.evaluation.evaluator]: [0mInference done 3133/3489. 0.2398 s / img. ETA=0:01:44
[32m[03/28 20:01:34 d2.evaluation.evaluator]: [0mInference done 3153/3489. 0.2397 s / img. ETA=0:01:38
[32m[03/28 20:01:39 d2.evaluation.evaluator]: [0mInference done 3173/3489. 0.2397 s / img. ETA=0:01:32
[32m[03/28 20:01:44 d2.evaluation.evaluator]: [0mInference done 3194/3489. 0.2396 s / img. ETA=0:01:26
[32m[03/28 20:01:50 d2.evaluation.evaluator]: [0mInference done 3214/3489. 0.2396 s / img. ETA=0:01:20
[32m[03/28 20:01:55 d2.evaluation.evaluator]: [0mInference done 3234/3489. 0.2395 s / img. ETA=0:01:14
[32m[03/28 20:02:00 d2.evaluation.evaluator]: [0mInference done 3254/3489. 0.2395 s / img. ETA=0:01:08
[32m[03/28 20:02:05 d2.evaluation.evaluator]: [0mInference done 3275/3489. 0.2394 s / img. ETA=0:01:02
[32m[03/28 20:02:10 d2.evaluation.evaluator]: [0mInference done 3297/3489. 0.2393 s / img. ETA=0:00:56
[32m[03/28 20:02:15 d2.evaluation.evaluator]: [0mInference done 3319/3489. 0.2392 s / img. ETA=0:00:49
[32m[03/28 20:02:20 d2.evaluation.evaluator]: [0mInference done 3341/3489. 0.2391 s / img. ETA=0:00:43
[32m[03/28 20:02:26 d2.evaluation.evaluator]: [0mInference done 3363/3489. 0.2391 s / img. ETA=0:00:36
[32m[03/28 20:02:31 d2.evaluation.evaluator]: [0mInference done 3385/3489. 0.2390 s / img. ETA=0:00:30
[32m[03/28 20:02:36 d2.evaluation.evaluator]: [0mInference done 3406/3489. 0.2389 s / img. ETA=0:00:24
[32m[03/28 20:02:41 d2.evaluation.evaluator]: [0mInference done 3427/3489. 0.2388 s / img. ETA=0:00:17
[32m[03/28 20:02:46 d2.evaluation.evaluator]: [0mInference done 3448/3489. 0.2388 s / img. ETA=0:00:11
[32m[03/28 20:02:51 d2.evaluation.evaluator]: [0mInference done 3468/3489. 0.2387 s / img. ETA=0:00:06
[32m[03/28 20:02:56 d2.evaluation.evaluator]: [0mInference done 3489/3489. 0.2387 s / img. ETA=0:00:00
[32m[03/28 20:02:57 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:48.295588 (0.289407 s / img per device, on 1 devices)
[32m[03/28 20:02:57 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:51 (0.238693 s / img per device, on 1 devices)
[32m[03/28 20:02:59 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 20:02:59 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.100000/coco_instances_results.json
[32m[03/28 20:03:00 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.70 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.63 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784
[32m[03/28 20:03:03 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.932 | 74.163 | 39.568 | 28.957 | 48.204 | 56.753 |
[32m[03/28 20:03:03 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.873 | Pedestrian | 22.992 |
Loading and preparing results...
DONE (t=2.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.70 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.66 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766
[32m[03/28 20:03:14 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.800 | 70.292 | 38.526 | 22.295 | 48.956 | 69.617 |
[32m[03/28 20:03:14 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.916 | Pedestrian | 18.685 |
[32m[03/28 20:03:14 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: 42.9321,74.1628,39.5677,28.9570,48.2039,56.7532
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:03:14 d2.evaluation.testing]: [0mcopypaste: 40.8005,70.2924,38.5256,22.2947,48.9564,69.6174
evaluated
Test [0.100000, 0.200000]
[32m[03/28 20:03:15 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:03:15 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:03:15 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:03:15 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:03:15 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:03:15 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:03:16 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:03:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:03:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:03:16 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:03:16 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:03:16 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 20:03:41 d2.utils.events]: [0m eta: 0:02:30  iter: 19  total_loss: 1.952  loss_cls: 0.8871  loss_box_reg: 0.2982  loss_mask: 0.6601  loss_rpn_cls: 0.02178  loss_rpn_loc: 0.008324  total_val_loss: 2.092  val_loss_cls: 0.8923  val_loss_box_reg: 0.4863  val_loss_mask: 0.6815  val_loss_rpn_cls: 0.03809  val_loss_rpn_loc: 0.01392  time: 0.8460  data_time: 0.0311  lr: 0.00019981  max_mem: 4742M
[32m[03/28 20:04:05 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 1.005  loss_cls: 0.2136  loss_box_reg: 0.3963  loss_mask: 0.3743  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.009038  total_val_loss: 1.167  val_loss_cls: 0.255  val_loss_box_reg: 0.4052  val_loss_mask: 0.5025  val_loss_rpn_cls: 0.03469  val_loss_rpn_loc: 0.01287  time: 0.8525  data_time: 0.0065  lr: 0.00039961  max_mem: 4742M
[32m[03/28 20:04:30 d2.utils.events]: [0m eta: 0:02:00  iter: 59  total_loss: 0.6864  loss_cls: 0.103  loss_box_reg: 0.3296  loss_mask: 0.1963  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01061  total_val_loss: 1.203  val_loss_cls: 0.2238  val_loss_box_reg: 0.552  val_loss_mask: 0.4235  val_loss_rpn_cls: 0.03717  val_loss_rpn_loc: 0.01524  time: 0.8611  data_time: 0.0073  lr: 0.00059941  max_mem: 4742M
[32m[03/28 20:04:54 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.4827  loss_cls: 0.04938  loss_box_reg: 0.1892  loss_mask: 0.197  loss_rpn_cls: 0.006974  loss_rpn_loc: 0.004603  total_val_loss: 0.933  val_loss_cls: 0.1848  val_loss_box_reg: 0.3856  val_loss_mask: 0.3416  val_loss_rpn_cls: 0.02037  val_loss_rpn_loc: 0.01346  time: 0.8644  data_time: 0.0062  lr: 0.00079921  max_mem: 4744M
[32m[03/28 20:05:19 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:05:19 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:05:19 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:05:19 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:05:19 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4724  loss_cls: 0.05879  loss_box_reg: 0.1687  loss_mask: 0.2083  loss_rpn_cls: 0.007204  loss_rpn_loc: 0.005968  total_val_loss: 0.6652  val_loss_cls: 0.1371  val_loss_box_reg: 0.2533  val_loss_mask: 0.3454  val_loss_rpn_cls: 0.02173  val_loss_rpn_loc: 0.01122  time: 0.8654  data_time: 0.0071  lr: 0.00099901  max_mem: 4744M
[32m[03/28 20:05:44 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.3572  loss_cls: 0.0651  loss_box_reg: 0.109  loss_mask: 0.1512  loss_rpn_cls: 0.006986  loss_rpn_loc: 0.008843  total_val_loss: 0.8305  val_loss_cls: 0.143  val_loss_box_reg: 0.2002  val_loss_mask: 0.284  val_loss_rpn_cls: 0.02325  val_loss_rpn_loc: 0.01714  time: 0.8668  data_time: 0.0070  lr: 0.0011988  max_mem: 4744M
[32m[03/28 20:06:08 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.3976  loss_cls: 0.06239  loss_box_reg: 0.1337  loss_mask: 0.1558  loss_rpn_cls: 0.006189  loss_rpn_loc: 0.009446  total_val_loss: 0.7724  val_loss_cls: 0.1633  val_loss_box_reg: 0.2682  val_loss_mask: 0.2814  val_loss_rpn_cls: 0.0143  val_loss_rpn_loc: 0.0135  time: 0.8673  data_time: 0.0070  lr: 0.0013986  max_mem: 4744M
[32m[03/28 20:06:33 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.2627  loss_cls: 0.02661  loss_box_reg: 0.06459  loss_mask: 0.1371  loss_rpn_cls: 0.005295  loss_rpn_loc: 0.006463  total_val_loss: 0.9964  val_loss_cls: 0.2205  val_loss_box_reg: 0.3578  val_loss_mask: 0.3594  val_loss_rpn_cls: 0.01317  val_loss_rpn_loc: 0.01248  time: 0.8677  data_time: 0.0064  lr: 0.0015984  max_mem: 4744M
[32m[03/28 20:06:57 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3904  loss_cls: 0.04938  loss_box_reg: 0.1014  loss_mask: 0.1511  loss_rpn_cls: 0.00775  loss_rpn_loc: 0.008209  total_val_loss: 0.9084  val_loss_cls: 0.193  val_loss_box_reg: 0.2888  val_loss_mask: 0.3555  val_loss_rpn_cls: 0.01407  val_loss_rpn_loc: 0.01356  time: 0.8669  data_time: 0.0067  lr: 0.0017982  max_mem: 4744M
[32m[03/28 20:07:22 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:07:22 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:07:23 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:07:23 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:07:23 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3121  loss_cls: 0.03863  loss_box_reg: 0.07407  loss_mask: 0.1349  loss_rpn_cls: 0.006122  loss_rpn_loc: 0.006326  total_val_loss: 0.6478  val_loss_cls: 0.1212  val_loss_box_reg: 0.2076  val_loss_mask: 0.2957  val_loss_rpn_cls: 0.01719  val_loss_rpn_loc: 0.01173  time: 0.8671  data_time: 0.0060  lr: 0.001998  max_mem: 4744M
[32m[03/28 20:07:23 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8671 s / it)
[32m[03/28 20:07:23 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:11 on hooks)
[32m[03/28 20:07:23 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:07:23 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:07:24 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:07:24 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 20:07:24 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 20:07:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:07:24 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:07:24 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 20:07:24 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 20:07:27 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2253 s / img. ETA=0:13:45
[32m[03/28 20:07:32 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2302 s / img. ETA=0:13:55
[32m[03/28 20:07:37 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2307 s / img. ETA=0:13:49
[32m[03/28 20:07:43 d2.evaluation.evaluator]: [0mInference done 75/3489. 0.2293 s / img. ETA=0:13:36
[32m[03/28 20:07:48 d2.evaluation.evaluator]: [0mInference done 96/3489. 0.2292 s / img. ETA=0:13:38
[32m[03/28 20:07:53 d2.evaluation.evaluator]: [0mInference done 115/3489. 0.2302 s / img. ETA=0:13:48
[32m[03/28 20:07:58 d2.evaluation.evaluator]: [0mInference done 132/3489. 0.2322 s / img. ETA=0:14:07
[32m[03/28 20:08:03 d2.evaluation.evaluator]: [0mInference done 148/3489. 0.2342 s / img. ETA=0:14:26
[32m[03/28 20:08:08 d2.evaluation.evaluator]: [0mInference done 164/3489. 0.2363 s / img. ETA=0:14:44
[32m[03/28 20:08:13 d2.evaluation.evaluator]: [0mInference done 181/3489. 0.2374 s / img. ETA=0:14:51
[32m[03/28 20:08:18 d2.evaluation.evaluator]: [0mInference done 199/3489. 0.2377 s / img. ETA=0:14:49
[32m[03/28 20:08:24 d2.evaluation.evaluator]: [0mInference done 220/3489. 0.2371 s / img. ETA=0:14:37
[32m[03/28 20:08:29 d2.evaluation.evaluator]: [0mInference done 240/3489. 0.2366 s / img. ETA=0:14:27
[32m[03/28 20:08:34 d2.evaluation.evaluator]: [0mInference done 260/3489. 0.2364 s / img. ETA=0:14:20
[32m[03/28 20:08:39 d2.evaluation.evaluator]: [0mInference done 279/3489. 0.2363 s / img. ETA=0:14:15
[32m[03/28 20:08:44 d2.evaluation.evaluator]: [0mInference done 299/3489. 0.2362 s / img. ETA=0:14:08
[32m[03/28 20:08:49 d2.evaluation.evaluator]: [0mInference done 317/3489. 0.2364 s / img. ETA=0:14:06
[32m[03/28 20:08:54 d2.evaluation.evaluator]: [0mInference done 336/3489. 0.2366 s / img. ETA=0:14:02
[32m[03/28 20:08:59 d2.evaluation.evaluator]: [0mInference done 354/3489. 0.2369 s / img. ETA=0:14:01
[32m[03/28 20:09:05 d2.evaluation.evaluator]: [0mInference done 373/3489. 0.2369 s / img. ETA=0:13:57
[32m[03/28 20:09:10 d2.evaluation.evaluator]: [0mInference done 392/3489. 0.2370 s / img. ETA=0:13:52
[32m[03/28 20:09:15 d2.evaluation.evaluator]: [0mInference done 411/3489. 0.2371 s / img. ETA=0:13:49
[32m[03/28 20:09:20 d2.evaluation.evaluator]: [0mInference done 431/3489. 0.2369 s / img. ETA=0:13:42
[32m[03/28 20:09:25 d2.evaluation.evaluator]: [0mInference done 452/3489. 0.2365 s / img. ETA=0:13:32
[32m[03/28 20:09:30 d2.evaluation.evaluator]: [0mInference done 473/3489. 0.2361 s / img. ETA=0:13:22
[32m[03/28 20:09:35 d2.evaluation.evaluator]: [0mInference done 494/3489. 0.2357 s / img. ETA=0:13:13
[32m[03/28 20:09:41 d2.evaluation.evaluator]: [0mInference done 515/3489. 0.2356 s / img. ETA=0:13:05
[32m[03/28 20:09:46 d2.evaluation.evaluator]: [0mInference done 537/3489. 0.2351 s / img. ETA=0:12:55
[32m[03/28 20:09:51 d2.evaluation.evaluator]: [0mInference done 558/3489. 0.2350 s / img. ETA=0:12:48
[32m[03/28 20:09:56 d2.evaluation.evaluator]: [0mInference done 578/3489. 0.2349 s / img. ETA=0:12:42
[32m[03/28 20:10:01 d2.evaluation.evaluator]: [0mInference done 597/3489. 0.2351 s / img. ETA=0:12:38
[32m[03/28 20:10:06 d2.evaluation.evaluator]: [0mInference done 616/3489. 0.2351 s / img. ETA=0:12:33
[32m[03/28 20:10:11 d2.evaluation.evaluator]: [0mInference done 635/3489. 0.2352 s / img. ETA=0:12:29
[32m[03/28 20:10:16 d2.evaluation.evaluator]: [0mInference done 654/3489. 0.2353 s / img. ETA=0:12:24
[32m[03/28 20:10:21 d2.evaluation.evaluator]: [0mInference done 674/3489. 0.2352 s / img. ETA=0:12:19
[32m[03/28 20:10:27 d2.evaluation.evaluator]: [0mInference done 695/3489. 0.2351 s / img. ETA=0:12:12
[32m[03/28 20:10:32 d2.evaluation.evaluator]: [0mInference done 716/3489. 0.2349 s / img. ETA=0:12:05
[32m[03/28 20:10:37 d2.evaluation.evaluator]: [0mInference done 737/3489. 0.2348 s / img. ETA=0:11:58
[32m[03/28 20:10:42 d2.evaluation.evaluator]: [0mInference done 758/3489. 0.2346 s / img. ETA=0:11:51
[32m[03/28 20:10:47 d2.evaluation.evaluator]: [0mInference done 780/3489. 0.2344 s / img. ETA=0:11:44
[32m[03/28 20:10:52 d2.evaluation.evaluator]: [0mInference done 802/3489. 0.2342 s / img. ETA=0:11:36
[32m[03/28 20:10:58 d2.evaluation.evaluator]: [0mInference done 824/3489. 0.2340 s / img. ETA=0:11:29
[32m[03/28 20:11:03 d2.evaluation.evaluator]: [0mInference done 846/3489. 0.2337 s / img. ETA=0:11:21
[32m[03/28 20:11:08 d2.evaluation.evaluator]: [0mInference done 868/3489. 0.2336 s / img. ETA=0:11:14
[32m[03/28 20:11:13 d2.evaluation.evaluator]: [0mInference done 890/3489. 0.2334 s / img. ETA=0:11:07
[32m[03/28 20:11:18 d2.evaluation.evaluator]: [0mInference done 910/3489. 0.2334 s / img. ETA=0:11:02
[32m[03/28 20:11:24 d2.evaluation.evaluator]: [0mInference done 928/3489. 0.2336 s / img. ETA=0:10:59
[32m[03/28 20:11:29 d2.evaluation.evaluator]: [0mInference done 946/3489. 0.2339 s / img. ETA=0:10:56
[32m[03/28 20:11:34 d2.evaluation.evaluator]: [0mInference done 964/3489. 0.2341 s / img. ETA=0:10:53
[32m[03/28 20:11:39 d2.evaluation.evaluator]: [0mInference done 981/3489. 0.2344 s / img. ETA=0:10:51
[32m[03/28 20:11:45 d2.evaluation.evaluator]: [0mInference done 998/3489. 0.2347 s / img. ETA=0:10:49
[32m[03/28 20:11:50 d2.evaluation.evaluator]: [0mInference done 1015/3489. 0.2349 s / img. ETA=0:10:46
[32m[03/28 20:11:55 d2.evaluation.evaluator]: [0mInference done 1032/3489. 0.2352 s / img. ETA=0:10:43
[32m[03/28 20:12:00 d2.evaluation.evaluator]: [0mInference done 1049/3489. 0.2354 s / img. ETA=0:10:41
[32m[03/28 20:12:05 d2.evaluation.evaluator]: [0mInference done 1066/3489. 0.2356 s / img. ETA=0:10:38
[32m[03/28 20:12:11 d2.evaluation.evaluator]: [0mInference done 1084/3489. 0.2357 s / img. ETA=0:10:34
[32m[03/28 20:12:16 d2.evaluation.evaluator]: [0mInference done 1104/3489. 0.2357 s / img. ETA=0:10:28
[32m[03/28 20:12:21 d2.evaluation.evaluator]: [0mInference done 1123/3489. 0.2357 s / img. ETA=0:10:24
[32m[03/28 20:12:26 d2.evaluation.evaluator]: [0mInference done 1140/3489. 0.2360 s / img. ETA=0:10:21
[32m[03/28 20:12:31 d2.evaluation.evaluator]: [0mInference done 1158/3489. 0.2361 s / img. ETA=0:10:17
[32m[03/28 20:12:36 d2.evaluation.evaluator]: [0mInference done 1175/3489. 0.2362 s / img. ETA=0:10:14
[32m[03/28 20:12:41 d2.evaluation.evaluator]: [0mInference done 1193/3489. 0.2364 s / img. ETA=0:10:10
[32m[03/28 20:12:47 d2.evaluation.evaluator]: [0mInference done 1211/3489. 0.2365 s / img. ETA=0:10:05
[32m[03/28 20:12:52 d2.evaluation.evaluator]: [0mInference done 1230/3489. 0.2365 s / img. ETA=0:10:01
[32m[03/28 20:12:57 d2.evaluation.evaluator]: [0mInference done 1249/3489. 0.2366 s / img. ETA=0:09:56
[32m[03/28 20:13:02 d2.evaluation.evaluator]: [0mInference done 1270/3489. 0.2365 s / img. ETA=0:09:50
[32m[03/28 20:13:07 d2.evaluation.evaluator]: [0mInference done 1291/3489. 0.2364 s / img. ETA=0:09:43
[32m[03/28 20:13:12 d2.evaluation.evaluator]: [0mInference done 1313/3489. 0.2363 s / img. ETA=0:09:36
[32m[03/28 20:13:17 d2.evaluation.evaluator]: [0mInference done 1335/3489. 0.2361 s / img. ETA=0:09:29
[32m[03/28 20:13:23 d2.evaluation.evaluator]: [0mInference done 1357/3489. 0.2360 s / img. ETA=0:09:22
[32m[03/28 20:13:28 d2.evaluation.evaluator]: [0mInference done 1379/3489. 0.2358 s / img. ETA=0:09:15
[32m[03/28 20:13:33 d2.evaluation.evaluator]: [0mInference done 1401/3489. 0.2357 s / img. ETA=0:09:09
[32m[03/28 20:13:38 d2.evaluation.evaluator]: [0mInference done 1422/3489. 0.2356 s / img. ETA=0:09:03
[32m[03/28 20:13:43 d2.evaluation.evaluator]: [0mInference done 1443/3489. 0.2355 s / img. ETA=0:08:56
[32m[03/28 20:13:48 d2.evaluation.evaluator]: [0mInference done 1464/3489. 0.2353 s / img. ETA=0:08:50
[32m[03/28 20:13:53 d2.evaluation.evaluator]: [0mInference done 1486/3489. 0.2352 s / img. ETA=0:08:44
[32m[03/28 20:13:59 d2.evaluation.evaluator]: [0mInference done 1508/3489. 0.2351 s / img. ETA=0:08:37
[32m[03/28 20:14:04 d2.evaluation.evaluator]: [0mInference done 1530/3489. 0.2350 s / img. ETA=0:08:31
[32m[03/28 20:14:09 d2.evaluation.evaluator]: [0mInference done 1551/3489. 0.2349 s / img. ETA=0:08:25
[32m[03/28 20:14:14 d2.evaluation.evaluator]: [0mInference done 1573/3489. 0.2348 s / img. ETA=0:08:18
[32m[03/28 20:14:19 d2.evaluation.evaluator]: [0mInference done 1594/3489. 0.2348 s / img. ETA=0:08:12
[32m[03/28 20:14:24 d2.evaluation.evaluator]: [0mInference done 1613/3489. 0.2348 s / img. ETA=0:08:08
[32m[03/28 20:14:29 d2.evaluation.evaluator]: [0mInference done 1632/3489. 0.2348 s / img. ETA=0:08:03
[32m[03/28 20:14:35 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2348 s / img. ETA=0:07:58
[32m[03/28 20:14:40 d2.evaluation.evaluator]: [0mInference done 1671/3489. 0.2348 s / img. ETA=0:07:53
[32m[03/28 20:14:45 d2.evaluation.evaluator]: [0mInference done 1689/3489. 0.2349 s / img. ETA=0:07:49
[32m[03/28 20:14:50 d2.evaluation.evaluator]: [0mInference done 1706/3489. 0.2350 s / img. ETA=0:07:45
[32m[03/28 20:14:55 d2.evaluation.evaluator]: [0mInference done 1724/3489. 0.2351 s / img. ETA=0:07:41
[32m[03/28 20:15:00 d2.evaluation.evaluator]: [0mInference done 1741/3489. 0.2354 s / img. ETA=0:07:37
[32m[03/28 20:15:06 d2.evaluation.evaluator]: [0mInference done 1758/3489. 0.2355 s / img. ETA=0:07:33
[32m[03/28 20:15:11 d2.evaluation.evaluator]: [0mInference done 1774/3489. 0.2357 s / img. ETA=0:07:30
[32m[03/28 20:15:16 d2.evaluation.evaluator]: [0mInference done 1790/3489. 0.2359 s / img. ETA=0:07:27
[32m[03/28 20:15:21 d2.evaluation.evaluator]: [0mInference done 1806/3489. 0.2360 s / img. ETA=0:07:24
[32m[03/28 20:15:26 d2.evaluation.evaluator]: [0mInference done 1822/3489. 0.2361 s / img. ETA=0:07:20
[32m[03/28 20:15:31 d2.evaluation.evaluator]: [0mInference done 1838/3489. 0.2363 s / img. ETA=0:07:17
[32m[03/28 20:15:37 d2.evaluation.evaluator]: [0mInference done 1854/3489. 0.2364 s / img. ETA=0:07:13
[32m[03/28 20:15:42 d2.evaluation.evaluator]: [0mInference done 1871/3489. 0.2365 s / img. ETA=0:07:10
[32m[03/28 20:15:47 d2.evaluation.evaluator]: [0mInference done 1887/3489. 0.2366 s / img. ETA=0:07:06
[32m[03/28 20:15:52 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2367 s / img. ETA=0:07:02
[32m[03/28 20:15:57 d2.evaluation.evaluator]: [0mInference done 1919/3489. 0.2368 s / img. ETA=0:06:59
[32m[03/28 20:16:02 d2.evaluation.evaluator]: [0mInference done 1935/3489. 0.2370 s / img. ETA=0:06:55
[32m[03/28 20:16:07 d2.evaluation.evaluator]: [0mInference done 1951/3489. 0.2371 s / img. ETA=0:06:52
[32m[03/28 20:16:12 d2.evaluation.evaluator]: [0mInference done 1967/3489. 0.2372 s / img. ETA=0:06:48
[32m[03/28 20:16:17 d2.evaluation.evaluator]: [0mInference done 1983/3489. 0.2373 s / img. ETA=0:06:44
[32m[03/28 20:16:23 d2.evaluation.evaluator]: [0mInference done 2001/3489. 0.2374 s / img. ETA=0:06:40
[32m[03/28 20:16:28 d2.evaluation.evaluator]: [0mInference done 2020/3489. 0.2374 s / img. ETA=0:06:35
[32m[03/28 20:16:33 d2.evaluation.evaluator]: [0mInference done 2038/3489. 0.2374 s / img. ETA=0:06:30
[32m[03/28 20:16:38 d2.evaluation.evaluator]: [0mInference done 2055/3489. 0.2375 s / img. ETA=0:06:26
[32m[03/28 20:16:43 d2.evaluation.evaluator]: [0mInference done 2072/3489. 0.2376 s / img. ETA=0:06:22
[32m[03/28 20:16:49 d2.evaluation.evaluator]: [0mInference done 2088/3489. 0.2377 s / img. ETA=0:06:18
[32m[03/28 20:16:54 d2.evaluation.evaluator]: [0mInference done 2105/3489. 0.2378 s / img. ETA=0:06:14
[32m[03/28 20:16:59 d2.evaluation.evaluator]: [0mInference done 2121/3489. 0.2379 s / img. ETA=0:06:10
[32m[03/28 20:17:04 d2.evaluation.evaluator]: [0mInference done 2137/3489. 0.2381 s / img. ETA=0:06:06
[32m[03/28 20:17:09 d2.evaluation.evaluator]: [0mInference done 2153/3489. 0.2382 s / img. ETA=0:06:02
[32m[03/28 20:17:14 d2.evaluation.evaluator]: [0mInference done 2169/3489. 0.2382 s / img. ETA=0:05:58
[32m[03/28 20:17:19 d2.evaluation.evaluator]: [0mInference done 2185/3489. 0.2384 s / img. ETA=0:05:54
[32m[03/28 20:17:25 d2.evaluation.evaluator]: [0mInference done 2202/3489. 0.2385 s / img. ETA=0:05:50
[32m[03/28 20:17:30 d2.evaluation.evaluator]: [0mInference done 2218/3489. 0.2386 s / img. ETA=0:05:46
[32m[03/28 20:17:35 d2.evaluation.evaluator]: [0mInference done 2235/3489. 0.2387 s / img. ETA=0:05:42
[32m[03/28 20:17:40 d2.evaluation.evaluator]: [0mInference done 2252/3489. 0.2387 s / img. ETA=0:05:38
[32m[03/28 20:17:45 d2.evaluation.evaluator]: [0mInference done 2270/3489. 0.2387 s / img. ETA=0:05:33
[32m[03/28 20:17:50 d2.evaluation.evaluator]: [0mInference done 2288/3489. 0.2388 s / img. ETA=0:05:28
[32m[03/28 20:17:55 d2.evaluation.evaluator]: [0mInference done 2305/3489. 0.2388 s / img. ETA=0:05:24
[32m[03/28 20:18:00 d2.evaluation.evaluator]: [0mInference done 2322/3489. 0.2389 s / img. ETA=0:05:19
[32m[03/28 20:18:06 d2.evaluation.evaluator]: [0mInference done 2339/3489. 0.2390 s / img. ETA=0:05:15
[32m[03/28 20:18:11 d2.evaluation.evaluator]: [0mInference done 2356/3489. 0.2390 s / img. ETA=0:05:10
[32m[03/28 20:18:16 d2.evaluation.evaluator]: [0mInference done 2375/3489. 0.2390 s / img. ETA=0:05:05
[32m[03/28 20:18:21 d2.evaluation.evaluator]: [0mInference done 2395/3489. 0.2390 s / img. ETA=0:04:59
[32m[03/28 20:18:26 d2.evaluation.evaluator]: [0mInference done 2414/3489. 0.2390 s / img. ETA=0:04:54
[32m[03/28 20:18:31 d2.evaluation.evaluator]: [0mInference done 2433/3489. 0.2390 s / img. ETA=0:04:49
[32m[03/28 20:18:36 d2.evaluation.evaluator]: [0mInference done 2450/3489. 0.2390 s / img. ETA=0:04:44
[32m[03/28 20:18:42 d2.evaluation.evaluator]: [0mInference done 2467/3489. 0.2391 s / img. ETA=0:04:40
[32m[03/28 20:18:47 d2.evaluation.evaluator]: [0mInference done 2483/3489. 0.2392 s / img. ETA=0:04:36
[32m[03/28 20:18:52 d2.evaluation.evaluator]: [0mInference done 2503/3489. 0.2391 s / img. ETA=0:04:30
[32m[03/28 20:18:57 d2.evaluation.evaluator]: [0mInference done 2523/3489. 0.2391 s / img. ETA=0:04:25
[32m[03/28 20:19:02 d2.evaluation.evaluator]: [0mInference done 2543/3489. 0.2390 s / img. ETA=0:04:19
[32m[03/28 20:19:07 d2.evaluation.evaluator]: [0mInference done 2563/3489. 0.2390 s / img. ETA=0:04:13
[32m[03/28 20:19:12 d2.evaluation.evaluator]: [0mInference done 2584/3489. 0.2389 s / img. ETA=0:04:07
[32m[03/28 20:19:17 d2.evaluation.evaluator]: [0mInference done 2605/3489. 0.2388 s / img. ETA=0:04:01
[32m[03/28 20:19:22 d2.evaluation.evaluator]: [0mInference done 2626/3489. 0.2388 s / img. ETA=0:03:55
[32m[03/28 20:19:27 d2.evaluation.evaluator]: [0mInference done 2648/3489. 0.2387 s / img. ETA=0:03:49
[32m[03/28 20:19:33 d2.evaluation.evaluator]: [0mInference done 2669/3489. 0.2386 s / img. ETA=0:03:43
[32m[03/28 20:19:38 d2.evaluation.evaluator]: [0mInference done 2689/3489. 0.2385 s / img. ETA=0:03:38
[32m[03/28 20:19:43 d2.evaluation.evaluator]: [0mInference done 2710/3489. 0.2385 s / img. ETA=0:03:32
[32m[03/28 20:19:48 d2.evaluation.evaluator]: [0mInference done 2731/3489. 0.2384 s / img. ETA=0:03:26
[32m[03/28 20:19:53 d2.evaluation.evaluator]: [0mInference done 2751/3489. 0.2384 s / img. ETA=0:03:20
[32m[03/28 20:19:58 d2.evaluation.evaluator]: [0mInference done 2772/3489. 0.2383 s / img. ETA=0:03:14
[32m[03/28 20:20:04 d2.evaluation.evaluator]: [0mInference done 2793/3489. 0.2382 s / img. ETA=0:03:09
[32m[03/28 20:20:09 d2.evaluation.evaluator]: [0mInference done 2814/3489. 0.2382 s / img. ETA=0:03:03
[32m[03/28 20:20:14 d2.evaluation.evaluator]: [0mInference done 2834/3489. 0.2381 s / img. ETA=0:02:57
[32m[03/28 20:20:19 d2.evaluation.evaluator]: [0mInference done 2855/3489. 0.2382 s / img. ETA=0:02:52
[32m[03/28 20:20:24 d2.evaluation.evaluator]: [0mInference done 2876/3489. 0.2381 s / img. ETA=0:02:46
[32m[03/28 20:20:29 d2.evaluation.evaluator]: [0mInference done 2897/3489. 0.2380 s / img. ETA=0:02:40
[32m[03/28 20:20:35 d2.evaluation.evaluator]: [0mInference done 2918/3489. 0.2380 s / img. ETA=0:02:34
[32m[03/28 20:20:40 d2.evaluation.evaluator]: [0mInference done 2940/3489. 0.2379 s / img. ETA=0:02:28
[32m[03/28 20:20:45 d2.evaluation.evaluator]: [0mInference done 2961/3489. 0.2378 s / img. ETA=0:02:22
[32m[03/28 20:20:50 d2.evaluation.evaluator]: [0mInference done 2982/3489. 0.2378 s / img. ETA=0:02:16
[32m[03/28 20:20:55 d2.evaluation.evaluator]: [0mInference done 3002/3489. 0.2377 s / img. ETA=0:02:11
[32m[03/28 20:21:00 d2.evaluation.evaluator]: [0mInference done 3022/3489. 0.2377 s / img. ETA=0:02:06
[32m[03/28 20:21:05 d2.evaluation.evaluator]: [0mInference done 3043/3489. 0.2376 s / img. ETA=0:02:00
[32m[03/28 20:21:10 d2.evaluation.evaluator]: [0mInference done 3064/3489. 0.2376 s / img. ETA=0:01:54
[32m[03/28 20:21:15 d2.evaluation.evaluator]: [0mInference done 3084/3489. 0.2375 s / img. ETA=0:01:49
[32m[03/28 20:21:20 d2.evaluation.evaluator]: [0mInference done 3105/3489. 0.2375 s / img. ETA=0:01:43
[32m[03/28 20:21:25 d2.evaluation.evaluator]: [0mInference done 3125/3489. 0.2374 s / img. ETA=0:01:37
[32m[03/28 20:21:31 d2.evaluation.evaluator]: [0mInference done 3146/3489. 0.2374 s / img. ETA=0:01:32
[32m[03/28 20:21:36 d2.evaluation.evaluator]: [0mInference done 3167/3489. 0.2373 s / img. ETA=0:01:26
[32m[03/28 20:21:41 d2.evaluation.evaluator]: [0mInference done 3188/3489. 0.2373 s / img. ETA=0:01:20
[32m[03/28 20:21:46 d2.evaluation.evaluator]: [0mInference done 3209/3489. 0.2372 s / img. ETA=0:01:15
[32m[03/28 20:21:51 d2.evaluation.evaluator]: [0mInference done 3229/3489. 0.2372 s / img. ETA=0:01:09
[32m[03/28 20:21:56 d2.evaluation.evaluator]: [0mInference done 3250/3489. 0.2371 s / img. ETA=0:01:04
[32m[03/28 20:22:01 d2.evaluation.evaluator]: [0mInference done 3271/3489. 0.2371 s / img. ETA=0:00:58
[32m[03/28 20:22:06 d2.evaluation.evaluator]: [0mInference done 3292/3489. 0.2370 s / img. ETA=0:00:52
[32m[03/28 20:22:11 d2.evaluation.evaluator]: [0mInference done 3314/3489. 0.2370 s / img. ETA=0:00:46
[32m[03/28 20:22:17 d2.evaluation.evaluator]: [0mInference done 3336/3489. 0.2369 s / img. ETA=0:00:40
[32m[03/28 20:22:22 d2.evaluation.evaluator]: [0mInference done 3358/3489. 0.2368 s / img. ETA=0:00:34
[32m[03/28 20:22:27 d2.evaluation.evaluator]: [0mInference done 3380/3489. 0.2368 s / img. ETA=0:00:29
[32m[03/28 20:22:32 d2.evaluation.evaluator]: [0mInference done 3402/3489. 0.2367 s / img. ETA=0:00:23
[32m[03/28 20:22:37 d2.evaluation.evaluator]: [0mInference done 3423/3489. 0.2366 s / img. ETA=0:00:17
[32m[03/28 20:22:42 d2.evaluation.evaluator]: [0mInference done 3444/3489. 0.2366 s / img. ETA=0:00:11
[32m[03/28 20:22:47 d2.evaluation.evaluator]: [0mInference done 3465/3489. 0.2365 s / img. ETA=0:00:06
[32m[03/28 20:22:52 d2.evaluation.evaluator]: [0mInference done 3486/3489. 0.2365 s / img. ETA=0:00:00
[32m[03/28 20:22:53 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:27.240318 (0.266142 s / img per device, on 1 devices)
[32m[03/28 20:22:53 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:43 (0.236489 s / img per device, on 1 devices)
[32m[03/28 20:22:55 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 20:22:55 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.200000/coco_instances_results.json
[32m[03/28 20:22:56 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.43 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.51 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[32m[03/28 20:22:58 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.349 | 77.281 | 43.443 | 31.137 | 53.358 | 56.354 |
[32m[03/28 20:22:58 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.690 | Pedestrian | 30.008 |
Loading and preparing results...
DONE (t=1.72s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.21 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.54 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.238
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722
[32m[03/28 20:23:07 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.987 | 73.584 | 41.597 | 23.842 | 50.843 | 67.531 |
[32m[03/28 20:23:07 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.660 | Pedestrian | 23.314 |
[32m[03/28 20:23:07 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: 45.3491,77.2809,43.4425,31.1370,53.3584,56.3537
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:23:07 d2.evaluation.testing]: [0mcopypaste: 42.9872,73.5837,41.5968,23.8425,50.8432,67.5313
evaluated
Test [0.100000, 0.500000]
[32m[03/28 20:23:08 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:23:08 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:23:08 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:23:08 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:23:08 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:23:08 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:23:09 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:23:09 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:23:09 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:23:09 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:23:09 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:23:09 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 20:23:34 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.735  loss_cls: 0.7624  loss_box_reg: 0.2965  loss_mask: 0.6714  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.008785  total_val_loss: 1.938  val_loss_cls: 0.7232  val_loss_box_reg: 0.4779  val_loss_mask: 0.6862  val_loss_rpn_cls: 0.04221  val_loss_rpn_loc: 0.01125  time: 0.8441  data_time: 0.0299  lr: 0.00019981  max_mem: 4744M
[32m[03/28 20:23:58 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.9087  loss_cls: 0.1771  loss_box_reg: 0.3671  loss_mask: 0.3615  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.008954  total_val_loss: 1.391  val_loss_cls: 0.3067  val_loss_box_reg: 0.513  val_loss_mask: 0.5616  val_loss_rpn_cls: 0.03214  val_loss_rpn_loc: 0.0161  time: 0.8550  data_time: 0.0066  lr: 0.00039961  max_mem: 4744M
[32m[03/28 20:24:23 d2.utils.events]: [0m eta: 0:02:00  iter: 59  total_loss: 0.6087  loss_cls: 0.08353  loss_box_reg: 0.284  loss_mask: 0.2074  loss_rpn_cls: 0.007226  loss_rpn_loc: 0.007945  total_val_loss: 1.148  val_loss_cls: 0.2252  val_loss_box_reg: 0.4401  val_loss_mask: 0.4925  val_loss_rpn_cls: 0.03334  val_loss_rpn_loc: 0.01552  time: 0.8575  data_time: 0.0068  lr: 0.00059941  max_mem: 4744M
[32m[03/28 20:24:47 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.585  loss_cls: 0.0769  loss_box_reg: 0.2567  loss_mask: 0.1835  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.008827  total_val_loss: 0.9094  val_loss_cls: 0.1637  val_loss_box_reg: 0.3456  val_loss_mask: 0.3707  val_loss_rpn_cls: 0.02824  val_loss_rpn_loc: 0.01098  time: 0.8624  data_time: 0.0063  lr: 0.00079921  max_mem: 4744M
[32m[03/28 20:25:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:25:12 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:25:12 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:25:12 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:25:13 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4189  loss_cls: 0.06008  loss_box_reg: 0.1701  loss_mask: 0.1664  loss_rpn_cls: 0.008771  loss_rpn_loc: 0.009706  total_val_loss: 0.963  val_loss_cls: 0.2169  val_loss_box_reg: 0.3342  val_loss_mask: 0.3688  val_loss_rpn_cls: 0.02513  val_loss_rpn_loc: 0.01242  time: 0.8640  data_time: 0.0064  lr: 0.00099901  max_mem: 4745M
[32m[03/28 20:25:37 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.3546  loss_cls: 0.0428  loss_box_reg: 0.1178  loss_mask: 0.1762  loss_rpn_cls: 0.007951  loss_rpn_loc: 0.007549  total_val_loss: 0.5968  val_loss_cls: 0.1162  val_loss_box_reg: 0.2142  val_loss_mask: 0.2547  val_loss_rpn_cls: 0.01984  val_loss_rpn_loc: 0.01245  time: 0.8648  data_time: 0.0069  lr: 0.0011988  max_mem: 4747M
[32m[03/28 20:26:02 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.4328  loss_cls: 0.06605  loss_box_reg: 0.1441  loss_mask: 0.1641  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.01357  total_val_loss: 0.9639  val_loss_cls: 0.1981  val_loss_box_reg: 0.2216  val_loss_mask: 0.403  val_loss_rpn_cls: 0.01595  val_loss_rpn_loc: 0.01589  time: 0.8659  data_time: 0.0066  lr: 0.0013986  max_mem: 4747M
[32m[03/28 20:26:26 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3296  loss_cls: 0.05594  loss_box_reg: 0.0978  loss_mask: 0.1464  loss_rpn_cls: 0.005882  loss_rpn_loc: 0.008401  total_val_loss: 0.9622  val_loss_cls: 0.1861  val_loss_box_reg: 0.2408  val_loss_mask: 0.4437  val_loss_rpn_cls: 0.02178  val_loss_rpn_loc: 0.01214  time: 0.8660  data_time: 0.0070  lr: 0.0015984  max_mem: 4747M
[32m[03/28 20:26:50 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3552  loss_cls: 0.05345  loss_box_reg: 0.1172  loss_mask: 0.1484  loss_rpn_cls: 0.004532  loss_rpn_loc: 0.006518  total_val_loss: 0.8327  val_loss_cls: 0.2216  val_loss_box_reg: 0.2844  val_loss_mask: 0.2955  val_loss_rpn_cls: 0.02096  val_loss_rpn_loc: 0.01454  time: 0.8652  data_time: 0.0061  lr: 0.0017982  max_mem: 4747M
[32m[03/28 20:27:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:27:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:27:16 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:27:16 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:27:16 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3989  loss_cls: 0.05591  loss_box_reg: 0.152  loss_mask: 0.1447  loss_rpn_cls: 0.0067  loss_rpn_loc: 0.007006  total_val_loss: 0.6384  val_loss_cls: 0.1187  val_loss_box_reg: 0.191  val_loss_mask: 0.3117  val_loss_rpn_cls: 0.01224  val_loss_rpn_loc: 0.01032  time: 0.8666  data_time: 0.0062  lr: 0.001998  max_mem: 4747M
[32m[03/28 20:27:16 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8666 s / it)
[32m[03/28 20:27:16 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/28 20:27:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:27:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:27:16 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:27:16 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 20:27:16 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 20:27:17 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:27:17 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:27:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 20:27:17 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 20:27:20 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2266 s / img. ETA=0:14:14
[32m[03/28 20:27:26 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2298 s / img. ETA=0:14:14
[32m[03/28 20:27:31 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2314 s / img. ETA=0:14:10
[32m[03/28 20:27:36 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2308 s / img. ETA=0:14:00
[32m[03/28 20:27:41 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2314 s / img. ETA=0:14:02
[32m[03/28 20:27:46 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2322 s / img. ETA=0:14:11
[32m[03/28 20:27:51 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2342 s / img. ETA=0:14:33
[32m[03/28 20:27:57 d2.evaluation.evaluator]: [0mInference done 146/3489. 0.2366 s / img. ETA=0:14:54
[32m[03/28 20:28:02 d2.evaluation.evaluator]: [0mInference done 162/3489. 0.2385 s / img. ETA=0:15:10
[32m[03/28 20:28:07 d2.evaluation.evaluator]: [0mInference done 178/3489. 0.2399 s / img. ETA=0:15:20
[32m[03/28 20:28:12 d2.evaluation.evaluator]: [0mInference done 196/3489. 0.2404 s / img. ETA=0:15:19
[32m[03/28 20:28:17 d2.evaluation.evaluator]: [0mInference done 216/3489. 0.2396 s / img. ETA=0:15:06
[32m[03/28 20:28:23 d2.evaluation.evaluator]: [0mInference done 236/3489. 0.2389 s / img. ETA=0:14:56
[32m[03/28 20:28:28 d2.evaluation.evaluator]: [0mInference done 255/3489. 0.2388 s / img. ETA=0:14:50
[32m[03/28 20:28:33 d2.evaluation.evaluator]: [0mInference done 274/3489. 0.2387 s / img. ETA=0:14:44
[32m[03/28 20:28:38 d2.evaluation.evaluator]: [0mInference done 292/3489. 0.2389 s / img. ETA=0:14:40
[32m[03/28 20:28:43 d2.evaluation.evaluator]: [0mInference done 310/3489. 0.2391 s / img. ETA=0:14:37
[32m[03/28 20:28:48 d2.evaluation.evaluator]: [0mInference done 328/3489. 0.2392 s / img. ETA=0:14:32
[32m[03/28 20:28:53 d2.evaluation.evaluator]: [0mInference done 345/3489. 0.2394 s / img. ETA=0:14:30
[32m[03/28 20:28:58 d2.evaluation.evaluator]: [0mInference done 363/3489. 0.2395 s / img. ETA=0:14:26
[32m[03/28 20:29:03 d2.evaluation.evaluator]: [0mInference done 381/3489. 0.2396 s / img. ETA=0:14:22
[32m[03/28 20:29:09 d2.evaluation.evaluator]: [0mInference done 400/3489. 0.2397 s / img. ETA=0:14:17
[32m[03/28 20:29:14 d2.evaluation.evaluator]: [0mInference done 418/3489. 0.2398 s / img. ETA=0:14:13
[32m[03/28 20:29:19 d2.evaluation.evaluator]: [0mInference done 439/3489. 0.2393 s / img. ETA=0:14:02
[32m[03/28 20:29:24 d2.evaluation.evaluator]: [0mInference done 460/3489. 0.2389 s / img. ETA=0:13:52
[32m[03/28 20:29:29 d2.evaluation.evaluator]: [0mInference done 481/3489. 0.2386 s / img. ETA=0:13:42
[32m[03/28 20:29:34 d2.evaluation.evaluator]: [0mInference done 502/3489. 0.2382 s / img. ETA=0:13:32
[32m[03/28 20:29:39 d2.evaluation.evaluator]: [0mInference done 523/3489. 0.2378 s / img. ETA=0:13:23
[32m[03/28 20:29:44 d2.evaluation.evaluator]: [0mInference done 544/3489. 0.2376 s / img. ETA=0:13:13
[32m[03/28 20:29:49 d2.evaluation.evaluator]: [0mInference done 564/3489. 0.2374 s / img. ETA=0:13:06
[32m[03/28 20:29:54 d2.evaluation.evaluator]: [0mInference done 583/3489. 0.2374 s / img. ETA=0:13:01
[32m[03/28 20:30:00 d2.evaluation.evaluator]: [0mInference done 602/3489. 0.2375 s / img. ETA=0:12:56
[32m[03/28 20:30:05 d2.evaluation.evaluator]: [0mInference done 620/3489. 0.2375 s / img. ETA=0:12:53
[32m[03/28 20:30:10 d2.evaluation.evaluator]: [0mInference done 638/3489. 0.2376 s / img. ETA=0:12:48
[32m[03/28 20:30:15 d2.evaluation.evaluator]: [0mInference done 657/3489. 0.2375 s / img. ETA=0:12:43
[32m[03/28 20:30:20 d2.evaluation.evaluator]: [0mInference done 677/3489. 0.2374 s / img. ETA=0:12:36
[32m[03/28 20:30:25 d2.evaluation.evaluator]: [0mInference done 698/3489. 0.2372 s / img. ETA=0:12:28
[32m[03/28 20:30:30 d2.evaluation.evaluator]: [0mInference done 718/3489. 0.2371 s / img. ETA=0:12:21
[32m[03/28 20:30:35 d2.evaluation.evaluator]: [0mInference done 739/3489. 0.2369 s / img. ETA=0:12:14
[32m[03/28 20:30:40 d2.evaluation.evaluator]: [0mInference done 760/3489. 0.2366 s / img. ETA=0:12:06
[32m[03/28 20:30:45 d2.evaluation.evaluator]: [0mInference done 782/3489. 0.2363 s / img. ETA=0:11:58
[32m[03/28 20:30:50 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2361 s / img. ETA=0:11:50
[32m[03/28 20:30:56 d2.evaluation.evaluator]: [0mInference done 826/3489. 0.2359 s / img. ETA=0:11:42
[32m[03/28 20:31:01 d2.evaluation.evaluator]: [0mInference done 847/3489. 0.2357 s / img. ETA=0:11:35
[32m[03/28 20:31:06 d2.evaluation.evaluator]: [0mInference done 868/3489. 0.2356 s / img. ETA=0:11:28
[32m[03/28 20:31:11 d2.evaluation.evaluator]: [0mInference done 890/3489. 0.2354 s / img. ETA=0:11:20
[32m[03/28 20:31:16 d2.evaluation.evaluator]: [0mInference done 909/3489. 0.2354 s / img. ETA=0:11:16
[32m[03/28 20:31:21 d2.evaluation.evaluator]: [0mInference done 927/3489. 0.2356 s / img. ETA=0:11:13
[32m[03/28 20:31:26 d2.evaluation.evaluator]: [0mInference done 944/3489. 0.2359 s / img. ETA=0:11:10
[32m[03/28 20:31:31 d2.evaluation.evaluator]: [0mInference done 961/3489. 0.2361 s / img. ETA=0:11:07
[32m[03/28 20:31:37 d2.evaluation.evaluator]: [0mInference done 978/3489. 0.2364 s / img. ETA=0:11:05
[32m[03/28 20:31:42 d2.evaluation.evaluator]: [0mInference done 994/3489. 0.2367 s / img. ETA=0:11:03
[32m[03/28 20:31:47 d2.evaluation.evaluator]: [0mInference done 1010/3489. 0.2370 s / img. ETA=0:11:00
[32m[03/28 20:31:52 d2.evaluation.evaluator]: [0mInference done 1027/3489. 0.2372 s / img. ETA=0:10:58
[32m[03/28 20:31:57 d2.evaluation.evaluator]: [0mInference done 1043/3489. 0.2374 s / img. ETA=0:10:55
[32m[03/28 20:32:02 d2.evaluation.evaluator]: [0mInference done 1060/3489. 0.2376 s / img. ETA=0:10:52
[32m[03/28 20:32:08 d2.evaluation.evaluator]: [0mInference done 1077/3489. 0.2378 s / img. ETA=0:10:49
[32m[03/28 20:32:13 d2.evaluation.evaluator]: [0mInference done 1095/3489. 0.2379 s / img. ETA=0:10:44
[32m[03/28 20:32:18 d2.evaluation.evaluator]: [0mInference done 1113/3489. 0.2379 s / img. ETA=0:10:40
[32m[03/28 20:32:23 d2.evaluation.evaluator]: [0mInference done 1130/3489. 0.2380 s / img. ETA=0:10:36
[32m[03/28 20:32:28 d2.evaluation.evaluator]: [0mInference done 1147/3489. 0.2382 s / img. ETA=0:10:33
[32m[03/28 20:32:33 d2.evaluation.evaluator]: [0mInference done 1164/3489. 0.2383 s / img. ETA=0:10:30
[32m[03/28 20:32:38 d2.evaluation.evaluator]: [0mInference done 1181/3489. 0.2385 s / img. ETA=0:10:26
[32m[03/28 20:32:43 d2.evaluation.evaluator]: [0mInference done 1198/3489. 0.2387 s / img. ETA=0:10:23
[32m[03/28 20:32:48 d2.evaluation.evaluator]: [0mInference done 1215/3489. 0.2388 s / img. ETA=0:10:19
[32m[03/28 20:32:54 d2.evaluation.evaluator]: [0mInference done 1233/3489. 0.2389 s / img. ETA=0:10:14
[32m[03/28 20:32:59 d2.evaluation.evaluator]: [0mInference done 1251/3489. 0.2389 s / img. ETA=0:10:10
[32m[03/28 20:33:04 d2.evaluation.evaluator]: [0mInference done 1272/3489. 0.2388 s / img. ETA=0:10:03
[32m[03/28 20:33:09 d2.evaluation.evaluator]: [0mInference done 1294/3489. 0.2386 s / img. ETA=0:09:55
[32m[03/28 20:33:14 d2.evaluation.evaluator]: [0mInference done 1316/3489. 0.2384 s / img. ETA=0:09:48
[32m[03/28 20:33:19 d2.evaluation.evaluator]: [0mInference done 1337/3489. 0.2383 s / img. ETA=0:09:41
[32m[03/28 20:33:24 d2.evaluation.evaluator]: [0mInference done 1359/3489. 0.2381 s / img. ETA=0:09:34
[32m[03/28 20:33:29 d2.evaluation.evaluator]: [0mInference done 1380/3489. 0.2380 s / img. ETA=0:09:27
[32m[03/28 20:33:34 d2.evaluation.evaluator]: [0mInference done 1402/3489. 0.2378 s / img. ETA=0:09:21
[32m[03/28 20:33:40 d2.evaluation.evaluator]: [0mInference done 1423/3489. 0.2376 s / img. ETA=0:09:14
[32m[03/28 20:33:45 d2.evaluation.evaluator]: [0mInference done 1444/3489. 0.2375 s / img. ETA=0:09:08
[32m[03/28 20:33:50 d2.evaluation.evaluator]: [0mInference done 1465/3489. 0.2374 s / img. ETA=0:09:01
[32m[03/28 20:33:55 d2.evaluation.evaluator]: [0mInference done 1487/3489. 0.2373 s / img. ETA=0:08:55
[32m[03/28 20:34:00 d2.evaluation.evaluator]: [0mInference done 1509/3489. 0.2371 s / img. ETA=0:08:48
[32m[03/28 20:34:05 d2.evaluation.evaluator]: [0mInference done 1530/3489. 0.2371 s / img. ETA=0:08:42
[32m[03/28 20:34:10 d2.evaluation.evaluator]: [0mInference done 1551/3489. 0.2370 s / img. ETA=0:08:35
[32m[03/28 20:34:16 d2.evaluation.evaluator]: [0mInference done 1573/3489. 0.2368 s / img. ETA=0:08:29
[32m[03/28 20:34:21 d2.evaluation.evaluator]: [0mInference done 1594/3489. 0.2367 s / img. ETA=0:08:23
[32m[03/28 20:34:26 d2.evaluation.evaluator]: [0mInference done 1613/3489. 0.2367 s / img. ETA=0:08:18
[32m[03/28 20:34:31 d2.evaluation.evaluator]: [0mInference done 1631/3489. 0.2368 s / img. ETA=0:08:13
[32m[03/28 20:34:36 d2.evaluation.evaluator]: [0mInference done 1650/3489. 0.2368 s / img. ETA=0:08:08
[32m[03/28 20:34:41 d2.evaluation.evaluator]: [0mInference done 1668/3489. 0.2368 s / img. ETA=0:08:04
[32m[03/28 20:34:46 d2.evaluation.evaluator]: [0mInference done 1685/3489. 0.2369 s / img. ETA=0:08:00
[32m[03/28 20:34:51 d2.evaluation.evaluator]: [0mInference done 1701/3489. 0.2370 s / img. ETA=0:07:56
[32m[03/28 20:34:57 d2.evaluation.evaluator]: [0mInference done 1718/3489. 0.2372 s / img. ETA=0:07:53
[32m[03/28 20:35:02 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2373 s / img. ETA=0:07:49
[32m[03/28 20:35:07 d2.evaluation.evaluator]: [0mInference done 1751/3489. 0.2375 s / img. ETA=0:07:45
[32m[03/28 20:35:12 d2.evaluation.evaluator]: [0mInference done 1766/3489. 0.2376 s / img. ETA=0:07:42
[32m[03/28 20:35:17 d2.evaluation.evaluator]: [0mInference done 1782/3489. 0.2378 s / img. ETA=0:07:39
[32m[03/28 20:35:22 d2.evaluation.evaluator]: [0mInference done 1798/3489. 0.2379 s / img. ETA=0:07:35
[32m[03/28 20:35:28 d2.evaluation.evaluator]: [0mInference done 1814/3489. 0.2381 s / img. ETA=0:07:32
[32m[03/28 20:35:33 d2.evaluation.evaluator]: [0mInference done 1830/3489. 0.2382 s / img. ETA=0:07:28
[32m[03/28 20:35:38 d2.evaluation.evaluator]: [0mInference done 1846/3489. 0.2383 s / img. ETA=0:07:25
[32m[03/28 20:35:43 d2.evaluation.evaluator]: [0mInference done 1862/3489. 0.2385 s / img. ETA=0:07:21
[32m[03/28 20:35:48 d2.evaluation.evaluator]: [0mInference done 1878/3489. 0.2386 s / img. ETA=0:07:18
[32m[03/28 20:35:54 d2.evaluation.evaluator]: [0mInference done 1894/3489. 0.2387 s / img. ETA=0:07:14
[32m[03/28 20:35:59 d2.evaluation.evaluator]: [0mInference done 1910/3489. 0.2388 s / img. ETA=0:07:10
[32m[03/28 20:36:04 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2389 s / img. ETA=0:07:07
[32m[03/28 20:36:09 d2.evaluation.evaluator]: [0mInference done 1942/3489. 0.2391 s / img. ETA=0:07:03
[32m[03/28 20:36:14 d2.evaluation.evaluator]: [0mInference done 1958/3489. 0.2392 s / img. ETA=0:06:59
[32m[03/28 20:36:19 d2.evaluation.evaluator]: [0mInference done 1974/3489. 0.2393 s / img. ETA=0:06:55
[32m[03/28 20:36:24 d2.evaluation.evaluator]: [0mInference done 1990/3489. 0.2394 s / img. ETA=0:06:51
[32m[03/28 20:36:30 d2.evaluation.evaluator]: [0mInference done 2008/3489. 0.2394 s / img. ETA=0:06:47
[32m[03/28 20:36:35 d2.evaluation.evaluator]: [0mInference done 2026/3489. 0.2394 s / img. ETA=0:06:42
[32m[03/28 20:36:40 d2.evaluation.evaluator]: [0mInference done 2043/3489. 0.2395 s / img. ETA=0:06:38
[32m[03/28 20:36:45 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2396 s / img. ETA=0:06:34
[32m[03/28 20:36:50 d2.evaluation.evaluator]: [0mInference done 2075/3489. 0.2397 s / img. ETA=0:06:30
[32m[03/28 20:36:55 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2398 s / img. ETA=0:06:26
[32m[03/28 20:37:00 d2.evaluation.evaluator]: [0mInference done 2107/3489. 0.2399 s / img. ETA=0:06:22
[32m[03/28 20:37:06 d2.evaluation.evaluator]: [0mInference done 2123/3489. 0.2400 s / img. ETA=0:06:18
[32m[03/28 20:37:11 d2.evaluation.evaluator]: [0mInference done 2138/3489. 0.2401 s / img. ETA=0:06:14
[32m[03/28 20:37:16 d2.evaluation.evaluator]: [0mInference done 2154/3489. 0.2403 s / img. ETA=0:06:10
[32m[03/28 20:37:21 d2.evaluation.evaluator]: [0mInference done 2170/3489. 0.2404 s / img. ETA=0:06:06
[32m[03/28 20:37:26 d2.evaluation.evaluator]: [0mInference done 2186/3489. 0.2405 s / img. ETA=0:06:02
[32m[03/28 20:37:31 d2.evaluation.evaluator]: [0mInference done 2202/3489. 0.2406 s / img. ETA=0:05:58
[32m[03/28 20:37:37 d2.evaluation.evaluator]: [0mInference done 2218/3489. 0.2407 s / img. ETA=0:05:54
[32m[03/28 20:37:42 d2.evaluation.evaluator]: [0mInference done 2234/3489. 0.2408 s / img. ETA=0:05:50
[32m[03/28 20:37:47 d2.evaluation.evaluator]: [0mInference done 2251/3489. 0.2409 s / img. ETA=0:05:46
[32m[03/28 20:37:52 d2.evaluation.evaluator]: [0mInference done 2268/3489. 0.2409 s / img. ETA=0:05:41
[32m[03/28 20:37:57 d2.evaluation.evaluator]: [0mInference done 2284/3489. 0.2410 s / img. ETA=0:05:37
[32m[03/28 20:38:02 d2.evaluation.evaluator]: [0mInference done 2300/3489. 0.2411 s / img. ETA=0:05:33
[32m[03/28 20:38:07 d2.evaluation.evaluator]: [0mInference done 2316/3489. 0.2412 s / img. ETA=0:05:29
[32m[03/28 20:38:13 d2.evaluation.evaluator]: [0mInference done 2332/3489. 0.2413 s / img. ETA=0:05:24
[32m[03/28 20:38:18 d2.evaluation.evaluator]: [0mInference done 2349/3489. 0.2413 s / img. ETA=0:05:20
[32m[03/28 20:38:23 d2.evaluation.evaluator]: [0mInference done 2366/3489. 0.2413 s / img. ETA=0:05:15
[32m[03/28 20:38:28 d2.evaluation.evaluator]: [0mInference done 2385/3489. 0.2413 s / img. ETA=0:05:10
[32m[03/28 20:38:33 d2.evaluation.evaluator]: [0mInference done 2404/3489. 0.2413 s / img. ETA=0:05:04
[32m[03/28 20:38:38 d2.evaluation.evaluator]: [0mInference done 2422/3489. 0.2413 s / img. ETA=0:04:59
[32m[03/28 20:38:43 d2.evaluation.evaluator]: [0mInference done 2440/3489. 0.2413 s / img. ETA=0:04:54
[32m[03/28 20:38:48 d2.evaluation.evaluator]: [0mInference done 2456/3489. 0.2414 s / img. ETA=0:04:50
[32m[03/28 20:38:54 d2.evaluation.evaluator]: [0mInference done 2472/3489. 0.2415 s / img. ETA=0:04:46
[32m[03/28 20:38:59 d2.evaluation.evaluator]: [0mInference done 2488/3489. 0.2415 s / img. ETA=0:04:42
[32m[03/28 20:39:04 d2.evaluation.evaluator]: [0mInference done 2509/3489. 0.2415 s / img. ETA=0:04:35
[32m[03/28 20:39:09 d2.evaluation.evaluator]: [0mInference done 2529/3489. 0.2414 s / img. ETA=0:04:30
[32m[03/28 20:39:14 d2.evaluation.evaluator]: [0mInference done 2549/3489. 0.2413 s / img. ETA=0:04:24
[32m[03/28 20:39:19 d2.evaluation.evaluator]: [0mInference done 2568/3489. 0.2413 s / img. ETA=0:04:18
[32m[03/28 20:39:24 d2.evaluation.evaluator]: [0mInference done 2589/3489. 0.2412 s / img. ETA=0:04:12
[32m[03/28 20:39:29 d2.evaluation.evaluator]: [0mInference done 2610/3489. 0.2411 s / img. ETA=0:04:06
[32m[03/28 20:39:34 d2.evaluation.evaluator]: [0mInference done 2631/3489. 0.2410 s / img. ETA=0:04:00
[32m[03/28 20:39:40 d2.evaluation.evaluator]: [0mInference done 2653/3489. 0.2409 s / img. ETA=0:03:53
[32m[03/28 20:39:45 d2.evaluation.evaluator]: [0mInference done 2673/3489. 0.2408 s / img. ETA=0:03:48
[32m[03/28 20:39:50 d2.evaluation.evaluator]: [0mInference done 2693/3489. 0.2408 s / img. ETA=0:03:42
[32m[03/28 20:39:55 d2.evaluation.evaluator]: [0mInference done 2713/3489. 0.2407 s / img. ETA=0:03:36
[32m[03/28 20:40:00 d2.evaluation.evaluator]: [0mInference done 2733/3489. 0.2407 s / img. ETA=0:03:30
[32m[03/28 20:40:05 d2.evaluation.evaluator]: [0mInference done 2753/3489. 0.2406 s / img. ETA=0:03:25
[32m[03/28 20:40:10 d2.evaluation.evaluator]: [0mInference done 2773/3489. 0.2405 s / img. ETA=0:03:19
[32m[03/28 20:40:15 d2.evaluation.evaluator]: [0mInference done 2793/3489. 0.2405 s / img. ETA=0:03:13
[32m[03/28 20:40:20 d2.evaluation.evaluator]: [0mInference done 2813/3489. 0.2404 s / img. ETA=0:03:08
[32m[03/28 20:40:25 d2.evaluation.evaluator]: [0mInference done 2833/3489. 0.2403 s / img. ETA=0:03:02
[32m[03/28 20:40:30 d2.evaluation.evaluator]: [0mInference done 2853/3489. 0.2403 s / img. ETA=0:02:56
[32m[03/28 20:40:36 d2.evaluation.evaluator]: [0mInference done 2874/3489. 0.2402 s / img. ETA=0:02:50
[32m[03/28 20:40:41 d2.evaluation.evaluator]: [0mInference done 2894/3489. 0.2401 s / img. ETA=0:02:45
[32m[03/28 20:40:46 d2.evaluation.evaluator]: [0mInference done 2915/3489. 0.2401 s / img. ETA=0:02:39
[32m[03/28 20:40:51 d2.evaluation.evaluator]: [0mInference done 2936/3489. 0.2400 s / img. ETA=0:02:33
[32m[03/28 20:40:56 d2.evaluation.evaluator]: [0mInference done 2957/3489. 0.2399 s / img. ETA=0:02:27
[32m[03/28 20:41:01 d2.evaluation.evaluator]: [0mInference done 2978/3489. 0.2398 s / img. ETA=0:02:21
[32m[03/28 20:41:06 d2.evaluation.evaluator]: [0mInference done 2998/3489. 0.2398 s / img. ETA=0:02:15
[32m[03/28 20:41:11 d2.evaluation.evaluator]: [0mInference done 3018/3489. 0.2397 s / img. ETA=0:02:10
[32m[03/28 20:41:16 d2.evaluation.evaluator]: [0mInference done 3038/3489. 0.2397 s / img. ETA=0:02:04
[32m[03/28 20:41:21 d2.evaluation.evaluator]: [0mInference done 3057/3489. 0.2396 s / img. ETA=0:01:59
[32m[03/28 20:41:27 d2.evaluation.evaluator]: [0mInference done 3077/3489. 0.2396 s / img. ETA=0:01:53
[32m[03/28 20:41:32 d2.evaluation.evaluator]: [0mInference done 3096/3489. 0.2395 s / img. ETA=0:01:48
[32m[03/28 20:41:37 d2.evaluation.evaluator]: [0mInference done 3116/3489. 0.2395 s / img. ETA=0:01:42
[32m[03/28 20:41:42 d2.evaluation.evaluator]: [0mInference done 3136/3489. 0.2395 s / img. ETA=0:01:37
[32m[03/28 20:41:47 d2.evaluation.evaluator]: [0mInference done 3156/3489. 0.2394 s / img. ETA=0:01:31
[32m[03/28 20:41:52 d2.evaluation.evaluator]: [0mInference done 3176/3489. 0.2394 s / img. ETA=0:01:26
[32m[03/28 20:41:57 d2.evaluation.evaluator]: [0mInference done 3197/3489. 0.2393 s / img. ETA=0:01:20
[32m[03/28 20:42:02 d2.evaluation.evaluator]: [0mInference done 3218/3489. 0.2392 s / img. ETA=0:01:14
[32m[03/28 20:42:08 d2.evaluation.evaluator]: [0mInference done 3238/3489. 0.2392 s / img. ETA=0:01:08
[32m[03/28 20:42:13 d2.evaluation.evaluator]: [0mInference done 3259/3489. 0.2391 s / img. ETA=0:01:03
[32m[03/28 20:42:18 d2.evaluation.evaluator]: [0mInference done 3280/3489. 0.2391 s / img. ETA=0:00:57
[32m[03/28 20:42:23 d2.evaluation.evaluator]: [0mInference done 3302/3489. 0.2390 s / img. ETA=0:00:51
[32m[03/28 20:42:28 d2.evaluation.evaluator]: [0mInference done 3324/3489. 0.2389 s / img. ETA=0:00:45
[32m[03/28 20:42:33 d2.evaluation.evaluator]: [0mInference done 3346/3489. 0.2388 s / img. ETA=0:00:39
[32m[03/28 20:42:38 d2.evaluation.evaluator]: [0mInference done 3368/3489. 0.2388 s / img. ETA=0:00:33
[32m[03/28 20:42:44 d2.evaluation.evaluator]: [0mInference done 3390/3489. 0.2387 s / img. ETA=0:00:27
[32m[03/28 20:42:49 d2.evaluation.evaluator]: [0mInference done 3411/3489. 0.2386 s / img. ETA=0:00:21
[32m[03/28 20:42:54 d2.evaluation.evaluator]: [0mInference done 3432/3489. 0.2386 s / img. ETA=0:00:15
[32m[03/28 20:42:59 d2.evaluation.evaluator]: [0mInference done 3453/3489. 0.2385 s / img. ETA=0:00:09
[32m[03/28 20:43:04 d2.evaluation.evaluator]: [0mInference done 3474/3489. 0.2384 s / img. ETA=0:00:04
[32m[03/28 20:43:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:48.700651 (0.272302 s / img per device, on 1 devices)
[32m[03/28 20:43:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:50 (0.238399 s / img per device, on 1 devices)
[32m[03/28 20:43:09 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 20:43:10 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.500000/coco_instances_results.json
[32m[03/28 20:43:11 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.43 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.54 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.795
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.309
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.760
[32m[03/28 20:43:13 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.860 | 79.521 | 54.632 | 30.893 | 60.615 | 61.509 |
[32m[03/28 20:43:13 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 59.156 | Pedestrian | 40.564 |
Loading and preparing results...
DONE (t=1.86s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.19 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[32m[03/28 20:43:22 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.275 | 76.154 | 44.887 | 22.891 | 54.648 | 69.720 |
[32m[03/28 20:43:22 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.089 | Pedestrian | 28.460 |
[32m[03/28 20:43:23 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: 49.8598,79.5208,54.6321,30.8926,60.6147,61.5085
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:43:23 d2.evaluation.testing]: [0mcopypaste: 45.2747,76.1540,44.8872,22.8910,54.6480,69.7196
evaluated
Test [0.100000, 0.700000]
[32m[03/28 20:43:23 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:43:24 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:43:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:43:24 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:43:24 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:43:24 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:43:24 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:43:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:43:24 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:43:24 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:43:24 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:43:25 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 20:43:49 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.941  loss_cls: 0.8543  loss_box_reg: 0.3355  loss_mask: 0.6601  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.005647  total_val_loss: 2.038  val_loss_cls: 0.819  val_loss_box_reg: 0.4729  val_loss_mask: 0.6681  val_loss_rpn_cls: 0.03157  val_loss_rpn_loc: 0.01568  time: 0.8395  data_time: 0.0313  lr: 0.00019981  max_mem: 4747M
[32m[03/28 20:44:13 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.8154  loss_cls: 0.1578  loss_box_reg: 0.2624  loss_mask: 0.337  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.004006  total_val_loss: 1.074  val_loss_cls: 0.2283  val_loss_box_reg: 0.4528  val_loss_mask: 0.4337  val_loss_rpn_cls: 0.03191  val_loss_rpn_loc: 0.01087  time: 0.8482  data_time: 0.0066  lr: 0.00039961  max_mem: 4747M
[32m[03/28 20:44:38 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.5728  loss_cls: 0.07519  loss_box_reg: 0.2867  loss_mask: 0.2188  loss_rpn_cls: 0.009748  loss_rpn_loc: 0.007104  total_val_loss: 1.218  val_loss_cls: 0.2836  val_loss_box_reg: 0.4525  val_loss_mask: 0.4259  val_loss_rpn_cls: 0.03476  val_loss_rpn_loc: 0.0144  time: 0.8514  data_time: 0.0061  lr: 0.00059941  max_mem: 4747M
[32m[03/28 20:45:02 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.6598  loss_cls: 0.08753  loss_box_reg: 0.3095  loss_mask: 0.1914  loss_rpn_cls: 0.00779  loss_rpn_loc: 0.008334  total_val_loss: 0.9014  val_loss_cls: 0.1534  val_loss_box_reg: 0.3069  val_loss_mask: 0.4252  val_loss_rpn_cls: 0.04093  val_loss_rpn_loc: 0.01091  time: 0.8550  data_time: 0.0067  lr: 0.00079921  max_mem: 4747M
[32m[03/28 20:45:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:45:26 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:45:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:45:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:45:27 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.484  loss_cls: 0.06604  loss_box_reg: 0.2192  loss_mask: 0.1579  loss_rpn_cls: 0.004729  loss_rpn_loc: 0.01078  total_val_loss: 1.071  val_loss_cls: 0.2739  val_loss_box_reg: 0.3364  val_loss_mask: 0.3947  val_loss_rpn_cls: 0.02042  val_loss_rpn_loc: 0.01523  time: 0.8577  data_time: 0.0072  lr: 0.00099901  max_mem: 4747M
[32m[03/28 20:45:51 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3936  loss_cls: 0.04946  loss_box_reg: 0.09982  loss_mask: 0.157  loss_rpn_cls: 0.005455  loss_rpn_loc: 0.007809  total_val_loss: 0.8523  val_loss_cls: 0.2096  val_loss_box_reg: 0.2954  val_loss_mask: 0.3061  val_loss_rpn_cls: 0.01804  val_loss_rpn_loc: 0.01845  time: 0.8594  data_time: 0.0079  lr: 0.0011988  max_mem: 4747M
[32m[03/28 20:46:16 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.2993  loss_cls: 0.04264  loss_box_reg: 0.08233  loss_mask: 0.1502  loss_rpn_cls: 0.007127  loss_rpn_loc: 0.008936  total_val_loss: 0.6075  val_loss_cls: 0.1345  val_loss_box_reg: 0.2256  val_loss_mask: 0.2508  val_loss_rpn_cls: 0.01857  val_loss_rpn_loc: 0.01312  time: 0.8612  data_time: 0.0075  lr: 0.0013986  max_mem: 4747M
[32m[03/28 20:46:41 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3903  loss_cls: 0.06508  loss_box_reg: 0.149  loss_mask: 0.1421  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01421  total_val_loss: 0.7006  val_loss_cls: 0.1458  val_loss_box_reg: 0.2268  val_loss_mask: 0.303  val_loss_rpn_cls: 0.01447  val_loss_rpn_loc: 0.01475  time: 0.8631  data_time: 0.0064  lr: 0.0015984  max_mem: 4747M
[32m[03/28 20:47:05 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3545  loss_cls: 0.05355  loss_box_reg: 0.08083  loss_mask: 0.1795  loss_rpn_cls: 0.004273  loss_rpn_loc: 0.006366  total_val_loss: 0.5254  val_loss_cls: 0.09577  val_loss_box_reg: 0.1601  val_loss_mask: 0.2911  val_loss_rpn_cls: 0.01771  val_loss_rpn_loc: 0.009966  time: 0.8634  data_time: 0.0077  lr: 0.0017982  max_mem: 4747M
[32m[03/28 20:47:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:47:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:47:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:47:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:47:31 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3437  loss_cls: 0.04221  loss_box_reg: 0.07406  loss_mask: 0.1849  loss_rpn_cls: 0.00619  loss_rpn_loc: 0.006623  total_val_loss: 0.9067  val_loss_cls: 0.1652  val_loss_box_reg: 0.302  val_loss_mask: 0.3123  val_loss_rpn_cls: 0.02352  val_loss_rpn_loc: 0.01605  time: 0.8630  data_time: 0.0069  lr: 0.001998  max_mem: 4747M
[32m[03/28 20:47:31 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8630 s / it)
[32m[03/28 20:47:31 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/28 20:47:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:47:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:47:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:47:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 20:47:31 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 20:47:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:47:32 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:47:32 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 20:47:32 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 20:47:35 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2281 s / img. ETA=0:14:29
[32m[03/28 20:47:40 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2327 s / img. ETA=0:14:46
[32m[03/28 20:47:46 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2311 s / img. ETA=0:14:23
[32m[03/28 20:47:51 d2.evaluation.evaluator]: [0mInference done 73/3489. 0.2297 s / img. ETA=0:14:06
[32m[03/28 20:47:56 d2.evaluation.evaluator]: [0mInference done 93/3489. 0.2301 s / img. ETA=0:14:10
[32m[03/28 20:48:01 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2325 s / img. ETA=0:14:28
[32m[03/28 20:48:06 d2.evaluation.evaluator]: [0mInference done 127/3489. 0.2343 s / img. ETA=0:14:51
[32m[03/28 20:48:11 d2.evaluation.evaluator]: [0mInference done 143/3489. 0.2366 s / img. ETA=0:15:10
[32m[03/28 20:48:17 d2.evaluation.evaluator]: [0mInference done 159/3489. 0.2385 s / img. ETA=0:15:25
[32m[03/28 20:48:22 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2400 s / img. ETA=0:15:35
[32m[03/28 20:48:27 d2.evaluation.evaluator]: [0mInference done 191/3489. 0.2409 s / img. ETA=0:15:40
[32m[03/28 20:48:32 d2.evaluation.evaluator]: [0mInference done 210/3489. 0.2405 s / img. ETA=0:15:31
[32m[03/28 20:48:37 d2.evaluation.evaluator]: [0mInference done 229/3489. 0.2402 s / img. ETA=0:15:21
[32m[03/28 20:48:42 d2.evaluation.evaluator]: [0mInference done 247/3489. 0.2404 s / img. ETA=0:15:16
[32m[03/28 20:48:47 d2.evaluation.evaluator]: [0mInference done 265/3489. 0.2404 s / img. ETA=0:15:11
[32m[03/28 20:48:52 d2.evaluation.evaluator]: [0mInference done 282/3489. 0.2407 s / img. ETA=0:15:09
[32m[03/28 20:48:57 d2.evaluation.evaluator]: [0mInference done 300/3489. 0.2408 s / img. ETA=0:15:04
[32m[03/28 20:49:03 d2.evaluation.evaluator]: [0mInference done 317/3489. 0.2414 s / img. ETA=0:15:03
[32m[03/28 20:49:08 d2.evaluation.evaluator]: [0mInference done 335/3489. 0.2415 s / img. ETA=0:14:59
[32m[03/28 20:49:13 d2.evaluation.evaluator]: [0mInference done 351/3489. 0.2420 s / img. ETA=0:14:59
[32m[03/28 20:49:18 d2.evaluation.evaluator]: [0mInference done 369/3489. 0.2421 s / img. ETA=0:14:54
[32m[03/28 20:49:23 d2.evaluation.evaluator]: [0mInference done 386/3489. 0.2424 s / img. ETA=0:14:52
[32m[03/28 20:49:28 d2.evaluation.evaluator]: [0mInference done 403/3489. 0.2427 s / img. ETA=0:14:48
[32m[03/28 20:49:33 d2.evaluation.evaluator]: [0mInference done 420/3489. 0.2428 s / img. ETA=0:14:44
[32m[03/28 20:49:39 d2.evaluation.evaluator]: [0mInference done 440/3489. 0.2427 s / img. ETA=0:14:34
[32m[03/28 20:49:44 d2.evaluation.evaluator]: [0mInference done 461/3489. 0.2421 s / img. ETA=0:14:22
[32m[03/28 20:49:49 d2.evaluation.evaluator]: [0mInference done 481/3489. 0.2416 s / img. ETA=0:14:13
[32m[03/28 20:49:54 d2.evaluation.evaluator]: [0mInference done 502/3489. 0.2411 s / img. ETA=0:14:02
[32m[03/28 20:49:59 d2.evaluation.evaluator]: [0mInference done 523/3489. 0.2406 s / img. ETA=0:13:51
[32m[03/28 20:50:04 d2.evaluation.evaluator]: [0mInference done 545/3489. 0.2400 s / img. ETA=0:13:40
[32m[03/28 20:50:09 d2.evaluation.evaluator]: [0mInference done 564/3489. 0.2399 s / img. ETA=0:13:33
[32m[03/28 20:50:14 d2.evaluation.evaluator]: [0mInference done 582/3489. 0.2401 s / img. ETA=0:13:29
[32m[03/28 20:50:20 d2.evaluation.evaluator]: [0mInference done 600/3489. 0.2402 s / img. ETA=0:13:25
[32m[03/28 20:50:25 d2.evaluation.evaluator]: [0mInference done 618/3489. 0.2403 s / img. ETA=0:13:21
[32m[03/28 20:50:30 d2.evaluation.evaluator]: [0mInference done 635/3489. 0.2405 s / img. ETA=0:13:17
[32m[03/28 20:50:35 d2.evaluation.evaluator]: [0mInference done 653/3489. 0.2405 s / img. ETA=0:13:12
[32m[03/28 20:50:40 d2.evaluation.evaluator]: [0mInference done 672/3489. 0.2404 s / img. ETA=0:13:06
[32m[03/28 20:50:45 d2.evaluation.evaluator]: [0mInference done 692/3489. 0.2402 s / img. ETA=0:12:58
[32m[03/28 20:50:50 d2.evaluation.evaluator]: [0mInference done 712/3489. 0.2399 s / img. ETA=0:12:50
[32m[03/28 20:50:55 d2.evaluation.evaluator]: [0mInference done 732/3489. 0.2397 s / img. ETA=0:12:43
[32m[03/28 20:51:00 d2.evaluation.evaluator]: [0mInference done 752/3489. 0.2395 s / img. ETA=0:12:36
[32m[03/28 20:51:05 d2.evaluation.evaluator]: [0mInference done 773/3489. 0.2392 s / img. ETA=0:12:27
[32m[03/28 20:51:10 d2.evaluation.evaluator]: [0mInference done 794/3489. 0.2389 s / img. ETA=0:12:19
[32m[03/28 20:51:15 d2.evaluation.evaluator]: [0mInference done 815/3489. 0.2387 s / img. ETA=0:12:11
[32m[03/28 20:51:20 d2.evaluation.evaluator]: [0mInference done 836/3489. 0.2384 s / img. ETA=0:12:03
[32m[03/28 20:51:25 d2.evaluation.evaluator]: [0mInference done 857/3489. 0.2382 s / img. ETA=0:11:55
[32m[03/28 20:51:30 d2.evaluation.evaluator]: [0mInference done 878/3489. 0.2380 s / img. ETA=0:11:48
[32m[03/28 20:51:36 d2.evaluation.evaluator]: [0mInference done 900/3489. 0.2377 s / img. ETA=0:11:39
[32m[03/28 20:51:41 d2.evaluation.evaluator]: [0mInference done 916/3489. 0.2380 s / img. ETA=0:11:37
[32m[03/28 20:51:46 d2.evaluation.evaluator]: [0mInference done 933/3489. 0.2383 s / img. ETA=0:11:35
[32m[03/28 20:51:51 d2.evaluation.evaluator]: [0mInference done 949/3489. 0.2385 s / img. ETA=0:11:32
[32m[03/28 20:51:56 d2.evaluation.evaluator]: [0mInference done 965/3489. 0.2387 s / img. ETA=0:11:29
[32m[03/28 20:52:01 d2.evaluation.evaluator]: [0mInference done 981/3489. 0.2390 s / img. ETA=0:11:27
[32m[03/28 20:52:07 d2.evaluation.evaluator]: [0mInference done 997/3489. 0.2393 s / img. ETA=0:11:25
[32m[03/28 20:52:12 d2.evaluation.evaluator]: [0mInference done 1013/3489. 0.2395 s / img. ETA=0:11:22
[32m[03/28 20:52:17 d2.evaluation.evaluator]: [0mInference done 1029/3489. 0.2397 s / img. ETA=0:11:19
[32m[03/28 20:52:22 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2400 s / img. ETA=0:11:17
[32m[03/28 20:52:27 d2.evaluation.evaluator]: [0mInference done 1061/3489. 0.2402 s / img. ETA=0:11:14
[32m[03/28 20:52:32 d2.evaluation.evaluator]: [0mInference done 1077/3489. 0.2403 s / img. ETA=0:11:11
[32m[03/28 20:52:37 d2.evaluation.evaluator]: [0mInference done 1094/3489. 0.2404 s / img. ETA=0:11:07
[32m[03/28 20:52:42 d2.evaluation.evaluator]: [0mInference done 1112/3489. 0.2404 s / img. ETA=0:11:02
[32m[03/28 20:52:47 d2.evaluation.evaluator]: [0mInference done 1129/3489. 0.2406 s / img. ETA=0:10:58
[32m[03/28 20:52:53 d2.evaluation.evaluator]: [0mInference done 1145/3489. 0.2408 s / img. ETA=0:10:55
[32m[03/28 20:52:58 d2.evaluation.evaluator]: [0mInference done 1161/3489. 0.2410 s / img. ETA=0:10:52
[32m[03/28 20:53:03 d2.evaluation.evaluator]: [0mInference done 1177/3489. 0.2411 s / img. ETA=0:10:48
[32m[03/28 20:53:08 d2.evaluation.evaluator]: [0mInference done 1193/3489. 0.2413 s / img. ETA=0:10:45
[32m[03/28 20:53:13 d2.evaluation.evaluator]: [0mInference done 1210/3489. 0.2414 s / img. ETA=0:10:41
[32m[03/28 20:53:18 d2.evaluation.evaluator]: [0mInference done 1227/3489. 0.2415 s / img. ETA=0:10:37
[32m[03/28 20:53:23 d2.evaluation.evaluator]: [0mInference done 1244/3489. 0.2416 s / img. ETA=0:10:33
[32m[03/28 20:53:28 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2415 s / img. ETA=0:10:26
[32m[03/28 20:53:34 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2412 s / img. ETA=0:10:18
[32m[03/28 20:53:39 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2410 s / img. ETA=0:10:10
[32m[03/28 20:53:44 d2.evaluation.evaluator]: [0mInference done 1329/3489. 0.2408 s / img. ETA=0:10:03
[32m[03/28 20:53:49 d2.evaluation.evaluator]: [0mInference done 1350/3489. 0.2406 s / img. ETA=0:09:56
[32m[03/28 20:53:54 d2.evaluation.evaluator]: [0mInference done 1371/3489. 0.2404 s / img. ETA=0:09:49
[32m[03/28 20:53:59 d2.evaluation.evaluator]: [0mInference done 1393/3489. 0.2402 s / img. ETA=0:09:41
[32m[03/28 20:54:04 d2.evaluation.evaluator]: [0mInference done 1414/3489. 0.2401 s / img. ETA=0:09:35
[32m[03/28 20:54:09 d2.evaluation.evaluator]: [0mInference done 1434/3489. 0.2400 s / img. ETA=0:09:28
[32m[03/28 20:54:15 d2.evaluation.evaluator]: [0mInference done 1455/3489. 0.2399 s / img. ETA=0:09:22
[32m[03/28 20:54:20 d2.evaluation.evaluator]: [0mInference done 1476/3489. 0.2397 s / img. ETA=0:09:15
[32m[03/28 20:54:25 d2.evaluation.evaluator]: [0mInference done 1498/3489. 0.2395 s / img. ETA=0:09:08
[32m[03/28 20:54:30 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2394 s / img. ETA=0:09:01
[32m[03/28 20:54:35 d2.evaluation.evaluator]: [0mInference done 1539/3489. 0.2394 s / img. ETA=0:08:55
[32m[03/28 20:54:40 d2.evaluation.evaluator]: [0mInference done 1560/3489. 0.2392 s / img. ETA=0:08:48
[32m[03/28 20:54:45 d2.evaluation.evaluator]: [0mInference done 1581/3489. 0.2391 s / img. ETA=0:08:42
[32m[03/28 20:54:50 d2.evaluation.evaluator]: [0mInference done 1601/3489. 0.2390 s / img. ETA=0:08:36
[32m[03/28 20:54:55 d2.evaluation.evaluator]: [0mInference done 1619/3489. 0.2391 s / img. ETA=0:08:31
[32m[03/28 20:55:01 d2.evaluation.evaluator]: [0mInference done 1636/3489. 0.2391 s / img. ETA=0:08:27
[32m[03/28 20:55:06 d2.evaluation.evaluator]: [0mInference done 1655/3489. 0.2392 s / img. ETA=0:08:22
[32m[03/28 20:55:11 d2.evaluation.evaluator]: [0mInference done 1673/3489. 0.2392 s / img. ETA=0:08:17
[32m[03/28 20:55:16 d2.evaluation.evaluator]: [0mInference done 1689/3489. 0.2393 s / img. ETA=0:08:14
[32m[03/28 20:55:21 d2.evaluation.evaluator]: [0mInference done 1705/3489. 0.2394 s / img. ETA=0:08:10
[32m[03/28 20:55:26 d2.evaluation.evaluator]: [0mInference done 1721/3489. 0.2396 s / img. ETA=0:08:06
[32m[03/28 20:55:31 d2.evaluation.evaluator]: [0mInference done 1737/3489. 0.2397 s / img. ETA=0:08:03
[32m[03/28 20:55:37 d2.evaluation.evaluator]: [0mInference done 1753/3489. 0.2398 s / img. ETA=0:07:59
[32m[03/28 20:55:42 d2.evaluation.evaluator]: [0mInference done 1769/3489. 0.2399 s / img. ETA=0:07:55
[32m[03/28 20:55:47 d2.evaluation.evaluator]: [0mInference done 1785/3489. 0.2401 s / img. ETA=0:07:52
[32m[03/28 20:55:52 d2.evaluation.evaluator]: [0mInference done 1801/3489. 0.2402 s / img. ETA=0:07:48
[32m[03/28 20:55:57 d2.evaluation.evaluator]: [0mInference done 1817/3489. 0.2404 s / img. ETA=0:07:44
[32m[03/28 20:56:02 d2.evaluation.evaluator]: [0mInference done 1833/3489. 0.2404 s / img. ETA=0:07:40
[32m[03/28 20:56:08 d2.evaluation.evaluator]: [0mInference done 1849/3489. 0.2405 s / img. ETA=0:07:36
[32m[03/28 20:56:13 d2.evaluation.evaluator]: [0mInference done 1865/3489. 0.2406 s / img. ETA=0:07:33
[32m[03/28 20:56:18 d2.evaluation.evaluator]: [0mInference done 1881/3489. 0.2407 s / img. ETA=0:07:29
[32m[03/28 20:56:23 d2.evaluation.evaluator]: [0mInference done 1897/3489. 0.2408 s / img. ETA=0:07:25
[32m[03/28 20:56:28 d2.evaluation.evaluator]: [0mInference done 1913/3489. 0.2410 s / img. ETA=0:07:21
[32m[03/28 20:56:33 d2.evaluation.evaluator]: [0mInference done 1929/3489. 0.2411 s / img. ETA=0:07:17
[32m[03/28 20:56:39 d2.evaluation.evaluator]: [0mInference done 1945/3489. 0.2412 s / img. ETA=0:07:13
[32m[03/28 20:56:44 d2.evaluation.evaluator]: [0mInference done 1960/3489. 0.2413 s / img. ETA=0:07:10
[32m[03/28 20:56:49 d2.evaluation.evaluator]: [0mInference done 1976/3489. 0.2414 s / img. ETA=0:07:06
[32m[03/28 20:56:54 d2.evaluation.evaluator]: [0mInference done 1992/3489. 0.2415 s / img. ETA=0:07:02
[32m[03/28 20:56:59 d2.evaluation.evaluator]: [0mInference done 2009/3489. 0.2415 s / img. ETA=0:06:57
[32m[03/28 20:57:04 d2.evaluation.evaluator]: [0mInference done 2026/3489. 0.2416 s / img. ETA=0:06:53
[32m[03/28 20:57:10 d2.evaluation.evaluator]: [0mInference done 2043/3489. 0.2416 s / img. ETA=0:06:48
[32m[03/28 20:57:15 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2417 s / img. ETA=0:06:44
[32m[03/28 20:57:20 d2.evaluation.evaluator]: [0mInference done 2075/3489. 0.2418 s / img. ETA=0:06:40
[32m[03/28 20:57:25 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2419 s / img. ETA=0:06:36
[32m[03/28 20:57:30 d2.evaluation.evaluator]: [0mInference done 2107/3489. 0.2420 s / img. ETA=0:06:32
[32m[03/28 20:57:36 d2.evaluation.evaluator]: [0mInference done 2123/3489. 0.2421 s / img. ETA=0:06:28
[32m[03/28 20:57:41 d2.evaluation.evaluator]: [0mInference done 2139/3489. 0.2422 s / img. ETA=0:06:24
[32m[03/28 20:57:46 d2.evaluation.evaluator]: [0mInference done 2155/3489. 0.2423 s / img. ETA=0:06:19
[32m[03/28 20:57:51 d2.evaluation.evaluator]: [0mInference done 2171/3489. 0.2424 s / img. ETA=0:06:15
[32m[03/28 20:57:56 d2.evaluation.evaluator]: [0mInference done 2187/3489. 0.2425 s / img. ETA=0:06:11
[32m[03/28 20:58:01 d2.evaluation.evaluator]: [0mInference done 2203/3489. 0.2425 s / img. ETA=0:06:07
[32m[03/28 20:58:07 d2.evaluation.evaluator]: [0mInference done 2219/3489. 0.2426 s / img. ETA=0:06:03
[32m[03/28 20:58:12 d2.evaluation.evaluator]: [0mInference done 2235/3489. 0.2427 s / img. ETA=0:05:58
[32m[03/28 20:58:17 d2.evaluation.evaluator]: [0mInference done 2251/3489. 0.2428 s / img. ETA=0:05:54
[32m[03/28 20:58:22 d2.evaluation.evaluator]: [0mInference done 2268/3489. 0.2428 s / img. ETA=0:05:49
[32m[03/28 20:58:28 d2.evaluation.evaluator]: [0mInference done 2284/3489. 0.2430 s / img. ETA=0:05:45
[32m[03/28 20:58:33 d2.evaluation.evaluator]: [0mInference done 2300/3489. 0.2430 s / img. ETA=0:05:41
[32m[03/28 20:58:38 d2.evaluation.evaluator]: [0mInference done 2316/3489. 0.2432 s / img. ETA=0:05:37
[32m[03/28 20:58:43 d2.evaluation.evaluator]: [0mInference done 2332/3489. 0.2432 s / img. ETA=0:05:32
[32m[03/28 20:58:48 d2.evaluation.evaluator]: [0mInference done 2348/3489. 0.2433 s / img. ETA=0:05:28
[32m[03/28 20:58:53 d2.evaluation.evaluator]: [0mInference done 2365/3489. 0.2433 s / img. ETA=0:05:23
[32m[03/28 20:58:59 d2.evaluation.evaluator]: [0mInference done 2384/3489. 0.2433 s / img. ETA=0:05:18
[32m[03/28 20:59:04 d2.evaluation.evaluator]: [0mInference done 2402/3489. 0.2433 s / img. ETA=0:05:12
[32m[03/28 20:59:09 d2.evaluation.evaluator]: [0mInference done 2419/3489. 0.2433 s / img. ETA=0:05:08
[32m[03/28 20:59:14 d2.evaluation.evaluator]: [0mInference done 2436/3489. 0.2434 s / img. ETA=0:05:03
[32m[03/28 20:59:19 d2.evaluation.evaluator]: [0mInference done 2452/3489. 0.2434 s / img. ETA=0:04:59
[32m[03/28 20:59:25 d2.evaluation.evaluator]: [0mInference done 2469/3489. 0.2435 s / img. ETA=0:04:54
[32m[03/28 20:59:30 d2.evaluation.evaluator]: [0mInference done 2485/3489. 0.2435 s / img. ETA=0:04:49
[32m[03/28 20:59:35 d2.evaluation.evaluator]: [0mInference done 2504/3489. 0.2435 s / img. ETA=0:04:44
[32m[03/28 20:59:40 d2.evaluation.evaluator]: [0mInference done 2523/3489. 0.2435 s / img. ETA=0:04:38
[32m[03/28 20:59:45 d2.evaluation.evaluator]: [0mInference done 2543/3489. 0.2434 s / img. ETA=0:04:32
[32m[03/28 20:59:50 d2.evaluation.evaluator]: [0mInference done 2562/3489. 0.2433 s / img. ETA=0:04:27
[32m[03/28 20:59:56 d2.evaluation.evaluator]: [0mInference done 2582/3489. 0.2433 s / img. ETA=0:04:21
[32m[03/28 21:00:01 d2.evaluation.evaluator]: [0mInference done 2602/3489. 0.2432 s / img. ETA=0:04:15
[32m[03/28 21:00:06 d2.evaluation.evaluator]: [0mInference done 2622/3489. 0.2431 s / img. ETA=0:04:09
[32m[03/28 21:00:11 d2.evaluation.evaluator]: [0mInference done 2643/3489. 0.2430 s / img. ETA=0:04:02
[32m[03/28 21:00:16 d2.evaluation.evaluator]: [0mInference done 2664/3489. 0.2429 s / img. ETA=0:03:56
[32m[03/28 21:00:21 d2.evaluation.evaluator]: [0mInference done 2684/3489. 0.2428 s / img. ETA=0:03:50
[32m[03/28 21:00:26 d2.evaluation.evaluator]: [0mInference done 2704/3489. 0.2427 s / img. ETA=0:03:44
[32m[03/28 21:00:31 d2.evaluation.evaluator]: [0mInference done 2724/3489. 0.2426 s / img. ETA=0:03:38
[32m[03/28 21:00:36 d2.evaluation.evaluator]: [0mInference done 2744/3489. 0.2426 s / img. ETA=0:03:32
[32m[03/28 21:00:42 d2.evaluation.evaluator]: [0mInference done 2764/3489. 0.2425 s / img. ETA=0:03:27
[32m[03/28 21:00:47 d2.evaluation.evaluator]: [0mInference done 2784/3489. 0.2424 s / img. ETA=0:03:21
[32m[03/28 21:00:52 d2.evaluation.evaluator]: [0mInference done 2804/3489. 0.2424 s / img. ETA=0:03:15
[32m[03/28 21:00:57 d2.evaluation.evaluator]: [0mInference done 2824/3489. 0.2423 s / img. ETA=0:03:09
[32m[03/28 21:01:02 d2.evaluation.evaluator]: [0mInference done 2844/3489. 0.2422 s / img. ETA=0:03:03
[32m[03/28 21:01:07 d2.evaluation.evaluator]: [0mInference done 2864/3489. 0.2422 s / img. ETA=0:02:57
[32m[03/28 21:01:12 d2.evaluation.evaluator]: [0mInference done 2884/3489. 0.2421 s / img. ETA=0:02:52
[32m[03/28 21:01:18 d2.evaluation.evaluator]: [0mInference done 2905/3489. 0.2420 s / img. ETA=0:02:45
[32m[03/28 21:01:23 d2.evaluation.evaluator]: [0mInference done 2926/3489. 0.2419 s / img. ETA=0:02:39
[32m[03/28 21:01:28 d2.evaluation.evaluator]: [0mInference done 2947/3489. 0.2418 s / img. ETA=0:02:33
[32m[03/28 21:01:33 d2.evaluation.evaluator]: [0mInference done 2968/3489. 0.2418 s / img. ETA=0:02:27
[32m[03/28 21:01:38 d2.evaluation.evaluator]: [0mInference done 2988/3489. 0.2417 s / img. ETA=0:02:21
[32m[03/28 21:01:43 d2.evaluation.evaluator]: [0mInference done 3007/3489. 0.2417 s / img. ETA=0:02:16
[32m[03/28 21:01:48 d2.evaluation.evaluator]: [0mInference done 3027/3489. 0.2416 s / img. ETA=0:02:10
[32m[03/28 21:01:53 d2.evaluation.evaluator]: [0mInference done 3047/3489. 0.2415 s / img. ETA=0:02:04
[32m[03/28 21:01:58 d2.evaluation.evaluator]: [0mInference done 3067/3489. 0.2415 s / img. ETA=0:01:59
[32m[03/28 21:02:04 d2.evaluation.evaluator]: [0mInference done 3087/3489. 0.2414 s / img. ETA=0:01:53
[32m[03/28 21:02:09 d2.evaluation.evaluator]: [0mInference done 3107/3489. 0.2414 s / img. ETA=0:01:47
[32m[03/28 21:02:14 d2.evaluation.evaluator]: [0mInference done 3127/3489. 0.2413 s / img. ETA=0:01:42
[32m[03/28 21:02:19 d2.evaluation.evaluator]: [0mInference done 3147/3489. 0.2413 s / img. ETA=0:01:36
[32m[03/28 21:02:24 d2.evaluation.evaluator]: [0mInference done 3167/3489. 0.2412 s / img. ETA=0:01:30
[32m[03/28 21:02:29 d2.evaluation.evaluator]: [0mInference done 3187/3489. 0.2412 s / img. ETA=0:01:25
[32m[03/28 21:02:35 d2.evaluation.evaluator]: [0mInference done 3208/3489. 0.2411 s / img. ETA=0:01:19
[32m[03/28 21:02:40 d2.evaluation.evaluator]: [0mInference done 3228/3489. 0.2410 s / img. ETA=0:01:13
[32m[03/28 21:02:45 d2.evaluation.evaluator]: [0mInference done 3248/3489. 0.2410 s / img. ETA=0:01:07
[32m[03/28 21:02:50 d2.evaluation.evaluator]: [0mInference done 3269/3489. 0.2409 s / img. ETA=0:01:01
[32m[03/28 21:02:55 d2.evaluation.evaluator]: [0mInference done 3290/3489. 0.2408 s / img. ETA=0:00:55
[32m[03/28 21:03:00 d2.evaluation.evaluator]: [0mInference done 3312/3489. 0.2407 s / img. ETA=0:00:49
[32m[03/28 21:03:05 d2.evaluation.evaluator]: [0mInference done 3334/3489. 0.2407 s / img. ETA=0:00:43
[32m[03/28 21:03:11 d2.evaluation.evaluator]: [0mInference done 3356/3489. 0.2406 s / img. ETA=0:00:37
[32m[03/28 21:03:16 d2.evaluation.evaluator]: [0mInference done 3377/3489. 0.2405 s / img. ETA=0:00:31
[32m[03/28 21:03:21 d2.evaluation.evaluator]: [0mInference done 3398/3489. 0.2405 s / img. ETA=0:00:25
[32m[03/28 21:03:26 d2.evaluation.evaluator]: [0mInference done 3419/3489. 0.2404 s / img. ETA=0:00:19
[32m[03/28 21:03:31 d2.evaluation.evaluator]: [0mInference done 3440/3489. 0.2403 s / img. ETA=0:00:13
[32m[03/28 21:03:36 d2.evaluation.evaluator]: [0mInference done 3461/3489. 0.2402 s / img. ETA=0:00:07
[32m[03/28 21:03:41 d2.evaluation.evaluator]: [0mInference done 3482/3489. 0.2402 s / img. ETA=0:00:01
[32m[03/28 21:03:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:09.385930 (0.278239 s / img per device, on 1 devices)
[32m[03/28 21:03:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:56 (0.240156 s / img per device, on 1 devices)
[32m[03/28 21:03:45 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:03:45 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.700000/coco_instances_results.json
[32m[03/28 21:03:47 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.57 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[32m[03/28 21:03:49 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.578 | 74.814 | 38.267 | 26.349 | 48.433 | 55.123 |
[32m[03/28 21:03:49 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 59.266 | Pedestrian | 23.891 |
Loading and preparing results...
DONE (t=2.17s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.45 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.64 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720
[32m[03/28 21:04:00 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.286 | 69.308 | 37.742 | 20.198 | 46.624 | 67.782 |
[32m[03/28 21:04:00 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.178 | Pedestrian | 17.393 |
[32m[03/28 21:04:00 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: 41.5782,74.8136,38.2668,26.3492,48.4329,55.1234
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:04:00 d2.evaluation.testing]: [0mcopypaste: 39.2856,69.3078,37.7416,20.1981,46.6240,67.7816
evaluated
Test [0.100000, 0.800000]
[32m[03/28 21:04:01 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:04:01 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:04:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:04:01 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:04:01 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:04:01 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:04:02 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:04:02 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:04:02 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:04:02 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:04:02 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:04:02 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:04:27 d2.utils.events]: [0m eta: 0:02:33  iter: 19  total_loss: 1.988  loss_cls: 0.8767  loss_box_reg: 0.3927  loss_mask: 0.66  loss_rpn_cls: 0.02367  loss_rpn_loc: 0.01001  total_val_loss: 1.88  val_loss_cls: 0.794  val_loss_box_reg: 0.3661  val_loss_mask: 0.6755  val_loss_rpn_cls: 0.03128  val_loss_rpn_loc: 0.01326  time: 0.8526  data_time: 0.0366  lr: 0.00019981  max_mem: 4747M
[32m[03/28 21:04:52 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.926  loss_cls: 0.2156  loss_box_reg: 0.2787  loss_mask: 0.3605  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.006746  total_val_loss: 1.151  val_loss_cls: 0.2747  val_loss_box_reg: 0.4418  val_loss_mask: 0.4558  val_loss_rpn_cls: 0.04114  val_loss_rpn_loc: 0.01243  time: 0.8563  data_time: 0.0085  lr: 0.00039961  max_mem: 4747M
[32m[03/28 21:05:16 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.5502  loss_cls: 0.09014  loss_box_reg: 0.2545  loss_mask: 0.1998  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.01069  total_val_loss: 1.04  val_loss_cls: 0.2155  val_loss_box_reg: 0.3775  val_loss_mask: 0.44  val_loss_rpn_cls: 0.03175  val_loss_rpn_loc: 0.0121  time: 0.8619  data_time: 0.0083  lr: 0.00059941  max_mem: 4747M
[32m[03/28 21:05:41 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.5574  loss_cls: 0.06968  loss_box_reg: 0.2645  loss_mask: 0.142  loss_rpn_cls: 0.007543  loss_rpn_loc: 0.006522  total_val_loss: 1.193  val_loss_cls: 0.2749  val_loss_box_reg: 0.4396  val_loss_mask: 0.3735  val_loss_rpn_cls: 0.01966  val_loss_rpn_loc: 0.01338  time: 0.8635  data_time: 0.0078  lr: 0.00079921  max_mem: 4747M
[32m[03/28 21:06:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:06:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:06:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:06:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:06:06 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4279  loss_cls: 0.04831  loss_box_reg: 0.1732  loss_mask: 0.1678  loss_rpn_cls: 0.009234  loss_rpn_loc: 0.01186  total_val_loss: 0.9805  val_loss_cls: 0.2022  val_loss_box_reg: 0.2376  val_loss_mask: 0.3998  val_loss_rpn_cls: 0.01814  val_loss_rpn_loc: 0.01134  time: 0.8662  data_time: 0.0068  lr: 0.00099901  max_mem: 4747M
[32m[03/28 21:06:30 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3816  loss_cls: 0.05294  loss_box_reg: 0.09383  loss_mask: 0.1855  loss_rpn_cls: 0.006071  loss_rpn_loc: 0.008427  total_val_loss: 0.7517  val_loss_cls: 0.1827  val_loss_box_reg: 0.2229  val_loss_mask: 0.3074  val_loss_rpn_cls: 0.02231  val_loss_rpn_loc: 0.01366  time: 0.8677  data_time: 0.0063  lr: 0.0011988  max_mem: 4747M
[32m[03/28 21:06:55 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.2972  loss_cls: 0.03965  loss_box_reg: 0.07178  loss_mask: 0.1515  loss_rpn_cls: 0.009083  loss_rpn_loc: 0.005767  total_val_loss: 0.9635  val_loss_cls: 0.1734  val_loss_box_reg: 0.2322  val_loss_mask: 0.3693  val_loss_rpn_cls: 0.01662  val_loss_rpn_loc: 0.01287  time: 0.8677  data_time: 0.0073  lr: 0.0013986  max_mem: 4747M
[32m[03/28 21:07:19 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.2943  loss_cls: 0.03653  loss_box_reg: 0.08079  loss_mask: 0.1336  loss_rpn_cls: 0.003755  loss_rpn_loc: 0.007473  total_val_loss: 0.933  val_loss_cls: 0.2139  val_loss_box_reg: 0.2684  val_loss_mask: 0.348  val_loss_rpn_cls: 0.01957  val_loss_rpn_loc: 0.01603  time: 0.8676  data_time: 0.0066  lr: 0.0015984  max_mem: 4747M
[32m[03/28 21:07:44 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.368  loss_cls: 0.06951  loss_box_reg: 0.1344  loss_mask: 0.1368  loss_rpn_cls: 0.007213  loss_rpn_loc: 0.01535  total_val_loss: 0.9861  val_loss_cls: 0.2106  val_loss_box_reg: 0.2598  val_loss_mask: 0.396  val_loss_rpn_cls: 0.01731  val_loss_rpn_loc: 0.01647  time: 0.8687  data_time: 0.0086  lr: 0.0017982  max_mem: 4747M
[32m[03/28 21:08:09 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:08:09 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:08:10 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:08:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:08:10 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3768  loss_cls: 0.0522  loss_box_reg: 0.1217  loss_mask: 0.1701  loss_rpn_cls: 0.006184  loss_rpn_loc: 0.01182  total_val_loss: 0.7556  val_loss_cls: 0.1363  val_loss_box_reg: 0.2721  val_loss_mask: 0.2653  val_loss_rpn_cls: 0.02104  val_loss_rpn_loc: 0.01921  time: 0.8683  data_time: 0.0074  lr: 0.001998  max_mem: 4747M
[32m[03/28 21:08:10 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8683 s / it)
[32m[03/28 21:08:10 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/28 21:08:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:08:10 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:08:10 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:08:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:08:10 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:08:11 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:08:11 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:08:11 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:08:11 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:08:14 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2285 s / img. ETA=0:14:30
[32m[03/28 21:08:19 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2283 s / img. ETA=0:14:11
[32m[03/28 21:08:25 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2306 s / img. ETA=0:14:06
[32m[03/28 21:08:30 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2311 s / img. ETA=0:13:59
[32m[03/28 21:08:35 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2311 s / img. ETA=0:14:02
[32m[03/28 21:08:40 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2334 s / img. ETA=0:14:18
[32m[03/28 21:08:45 d2.evaluation.evaluator]: [0mInference done 129/3489. 0.2352 s / img. ETA=0:14:38
[32m[03/28 21:08:50 d2.evaluation.evaluator]: [0mInference done 145/3489. 0.2377 s / img. ETA=0:15:00
[32m[03/28 21:08:56 d2.evaluation.evaluator]: [0mInference done 161/3489. 0.2392 s / img. ETA=0:15:16
[32m[03/28 21:09:01 d2.evaluation.evaluator]: [0mInference done 177/3489. 0.2403 s / img. ETA=0:15:25
[32m[03/28 21:09:06 d2.evaluation.evaluator]: [0mInference done 194/3489. 0.2412 s / img. ETA=0:15:28
[32m[03/28 21:09:11 d2.evaluation.evaluator]: [0mInference done 214/3489. 0.2403 s / img. ETA=0:15:15
[32m[03/28 21:09:16 d2.evaluation.evaluator]: [0mInference done 233/3489. 0.2400 s / img. ETA=0:15:06
[32m[03/28 21:09:21 d2.evaluation.evaluator]: [0mInference done 250/3489. 0.2409 s / img. ETA=0:15:05
[32m[03/28 21:09:26 d2.evaluation.evaluator]: [0mInference done 268/3489. 0.2409 s / img. ETA=0:15:01
[32m[03/28 21:09:32 d2.evaluation.evaluator]: [0mInference done 286/3489. 0.2411 s / img. ETA=0:14:57
[32m[03/28 21:09:37 d2.evaluation.evaluator]: [0mInference done 304/3489. 0.2412 s / img. ETA=0:14:53
[32m[03/28 21:09:42 d2.evaluation.evaluator]: [0mInference done 322/3489. 0.2413 s / img. ETA=0:14:50
[32m[03/28 21:09:47 d2.evaluation.evaluator]: [0mInference done 340/3489. 0.2415 s / img. ETA=0:14:46
[32m[03/28 21:09:52 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2418 s / img. ETA=0:14:44
[32m[03/28 21:09:57 d2.evaluation.evaluator]: [0mInference done 375/3489. 0.2418 s / img. ETA=0:14:40
[32m[03/28 21:10:02 d2.evaluation.evaluator]: [0mInference done 393/3489. 0.2418 s / img. ETA=0:14:35
[32m[03/28 21:10:08 d2.evaluation.evaluator]: [0mInference done 411/3489. 0.2417 s / img. ETA=0:14:30
[32m[03/28 21:10:13 d2.evaluation.evaluator]: [0mInference done 430/3489. 0.2415 s / img. ETA=0:14:22
[32m[03/28 21:10:18 d2.evaluation.evaluator]: [0mInference done 451/3489. 0.2410 s / img. ETA=0:14:11
[32m[03/28 21:10:23 d2.evaluation.evaluator]: [0mInference done 472/3489. 0.2406 s / img. ETA=0:14:00
[32m[03/28 21:10:28 d2.evaluation.evaluator]: [0mInference done 493/3489. 0.2400 s / img. ETA=0:13:50
[32m[03/28 21:10:33 d2.evaluation.evaluator]: [0mInference done 515/3489. 0.2394 s / img. ETA=0:13:38
[32m[03/28 21:10:38 d2.evaluation.evaluator]: [0mInference done 537/3489. 0.2390 s / img. ETA=0:13:28
[32m[03/28 21:10:44 d2.evaluation.evaluator]: [0mInference done 558/3489. 0.2387 s / img. ETA=0:13:19
[32m[03/28 21:10:49 d2.evaluation.evaluator]: [0mInference done 577/3489. 0.2386 s / img. ETA=0:13:13
[32m[03/28 21:10:54 d2.evaluation.evaluator]: [0mInference done 595/3489. 0.2388 s / img. ETA=0:13:10
[32m[03/28 21:10:59 d2.evaluation.evaluator]: [0mInference done 614/3489. 0.2388 s / img. ETA=0:13:04
[32m[03/28 21:11:04 d2.evaluation.evaluator]: [0mInference done 633/3489. 0.2388 s / img. ETA=0:12:59
[32m[03/28 21:11:09 d2.evaluation.evaluator]: [0mInference done 652/3489. 0.2387 s / img. ETA=0:12:54
[32m[03/28 21:11:14 d2.evaluation.evaluator]: [0mInference done 672/3489. 0.2386 s / img. ETA=0:12:47
[32m[03/28 21:11:20 d2.evaluation.evaluator]: [0mInference done 693/3489. 0.2383 s / img. ETA=0:12:39
[32m[03/28 21:11:25 d2.evaluation.evaluator]: [0mInference done 714/3489. 0.2381 s / img. ETA=0:12:31
[32m[03/28 21:11:30 d2.evaluation.evaluator]: [0mInference done 734/3489. 0.2379 s / img. ETA=0:12:24
[32m[03/28 21:11:35 d2.evaluation.evaluator]: [0mInference done 755/3489. 0.2376 s / img. ETA=0:12:17
[32m[03/28 21:11:40 d2.evaluation.evaluator]: [0mInference done 776/3489. 0.2375 s / img. ETA=0:12:09
[32m[03/28 21:11:45 d2.evaluation.evaluator]: [0mInference done 797/3489. 0.2373 s / img. ETA=0:12:02
[32m[03/28 21:11:50 d2.evaluation.evaluator]: [0mInference done 818/3489. 0.2371 s / img. ETA=0:11:54
[32m[03/28 21:11:55 d2.evaluation.evaluator]: [0mInference done 839/3489. 0.2369 s / img. ETA=0:11:47
[32m[03/28 21:12:00 d2.evaluation.evaluator]: [0mInference done 860/3489. 0.2367 s / img. ETA=0:11:39
[32m[03/28 21:12:05 d2.evaluation.evaluator]: [0mInference done 881/3489. 0.2365 s / img. ETA=0:11:32
[32m[03/28 21:12:10 d2.evaluation.evaluator]: [0mInference done 902/3489. 0.2363 s / img. ETA=0:11:25
[32m[03/28 21:12:15 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2365 s / img. ETA=0:11:23
[32m[03/28 21:12:21 d2.evaluation.evaluator]: [0mInference done 935/3489. 0.2367 s / img. ETA=0:11:20
[32m[03/28 21:12:26 d2.evaluation.evaluator]: [0mInference done 952/3489. 0.2369 s / img. ETA=0:11:17
[32m[03/28 21:12:31 d2.evaluation.evaluator]: [0mInference done 969/3489. 0.2371 s / img. ETA=0:11:14
[32m[03/28 21:12:36 d2.evaluation.evaluator]: [0mInference done 985/3489. 0.2374 s / img. ETA=0:11:12
[32m[03/28 21:12:41 d2.evaluation.evaluator]: [0mInference done 1001/3489. 0.2377 s / img. ETA=0:11:10
[32m[03/28 21:12:46 d2.evaluation.evaluator]: [0mInference done 1017/3489. 0.2379 s / img. ETA=0:11:08
[32m[03/28 21:12:51 d2.evaluation.evaluator]: [0mInference done 1033/3489. 0.2382 s / img. ETA=0:11:05
[32m[03/28 21:12:57 d2.evaluation.evaluator]: [0mInference done 1049/3489. 0.2384 s / img. ETA=0:11:03
[32m[03/28 21:13:02 d2.evaluation.evaluator]: [0mInference done 1066/3489. 0.2386 s / img. ETA=0:11:00
[32m[03/28 21:13:07 d2.evaluation.evaluator]: [0mInference done 1083/3489. 0.2387 s / img. ETA=0:10:56
[32m[03/28 21:13:12 d2.evaluation.evaluator]: [0mInference done 1102/3489. 0.2386 s / img. ETA=0:10:50
[32m[03/28 21:13:17 d2.evaluation.evaluator]: [0mInference done 1120/3489. 0.2387 s / img. ETA=0:10:46
[32m[03/28 21:13:22 d2.evaluation.evaluator]: [0mInference done 1137/3489. 0.2389 s / img. ETA=0:10:43
[32m[03/28 21:13:27 d2.evaluation.evaluator]: [0mInference done 1153/3489. 0.2391 s / img. ETA=0:10:39
[32m[03/28 21:13:33 d2.evaluation.evaluator]: [0mInference done 1170/3489. 0.2392 s / img. ETA=0:10:36
[32m[03/28 21:13:38 d2.evaluation.evaluator]: [0mInference done 1187/3489. 0.2394 s / img. ETA=0:10:33
[32m[03/28 21:13:43 d2.evaluation.evaluator]: [0mInference done 1204/3489. 0.2395 s / img. ETA=0:10:29
[32m[03/28 21:13:48 d2.evaluation.evaluator]: [0mInference done 1221/3489. 0.2396 s / img. ETA=0:10:25
[32m[03/28 21:13:53 d2.evaluation.evaluator]: [0mInference done 1239/3489. 0.2396 s / img. ETA=0:10:20
[32m[03/28 21:13:58 d2.evaluation.evaluator]: [0mInference done 1258/3489. 0.2396 s / img. ETA=0:10:15
[32m[03/28 21:14:04 d2.evaluation.evaluator]: [0mInference done 1280/3489. 0.2394 s / img. ETA=0:10:07
[32m[03/28 21:14:09 d2.evaluation.evaluator]: [0mInference done 1302/3489. 0.2392 s / img. ETA=0:10:00
[32m[03/28 21:14:14 d2.evaluation.evaluator]: [0mInference done 1324/3489. 0.2391 s / img. ETA=0:09:52
[32m[03/28 21:14:19 d2.evaluation.evaluator]: [0mInference done 1345/3489. 0.2389 s / img. ETA=0:09:46
[32m[03/28 21:14:24 d2.evaluation.evaluator]: [0mInference done 1366/3489. 0.2388 s / img. ETA=0:09:39
[32m[03/28 21:14:29 d2.evaluation.evaluator]: [0mInference done 1387/3489. 0.2386 s / img. ETA=0:09:32
[32m[03/28 21:14:34 d2.evaluation.evaluator]: [0mInference done 1408/3489. 0.2384 s / img. ETA=0:09:25
[32m[03/28 21:14:39 d2.evaluation.evaluator]: [0mInference done 1429/3489. 0.2383 s / img. ETA=0:09:19
[32m[03/28 21:14:44 d2.evaluation.evaluator]: [0mInference done 1450/3489. 0.2382 s / img. ETA=0:09:12
[32m[03/28 21:14:50 d2.evaluation.evaluator]: [0mInference done 1471/3489. 0.2381 s / img. ETA=0:09:06
[32m[03/28 21:14:55 d2.evaluation.evaluator]: [0mInference done 1492/3489. 0.2380 s / img. ETA=0:08:59
[32m[03/28 21:15:00 d2.evaluation.evaluator]: [0mInference done 1514/3489. 0.2378 s / img. ETA=0:08:52
[32m[03/28 21:15:05 d2.evaluation.evaluator]: [0mInference done 1535/3489. 0.2376 s / img. ETA=0:08:46
[32m[03/28 21:15:10 d2.evaluation.evaluator]: [0mInference done 1556/3489. 0.2375 s / img. ETA=0:08:39
[32m[03/28 21:15:15 d2.evaluation.evaluator]: [0mInference done 1577/3489. 0.2374 s / img. ETA=0:08:33
[32m[03/28 21:15:20 d2.evaluation.evaluator]: [0mInference done 1597/3489. 0.2374 s / img. ETA=0:08:27
[32m[03/28 21:15:25 d2.evaluation.evaluator]: [0mInference done 1616/3489. 0.2374 s / img. ETA=0:08:22
[32m[03/28 21:15:30 d2.evaluation.evaluator]: [0mInference done 1634/3489. 0.2374 s / img. ETA=0:08:18
[32m[03/28 21:15:36 d2.evaluation.evaluator]: [0mInference done 1653/3489. 0.2374 s / img. ETA=0:08:13
[32m[03/28 21:15:41 d2.evaluation.evaluator]: [0mInference done 1671/3489. 0.2375 s / img. ETA=0:08:09
[32m[03/28 21:15:46 d2.evaluation.evaluator]: [0mInference done 1687/3489. 0.2376 s / img. ETA=0:08:05
[32m[03/28 21:15:51 d2.evaluation.evaluator]: [0mInference done 1703/3489. 0.2378 s / img. ETA=0:08:02
[32m[03/28 21:15:56 d2.evaluation.evaluator]: [0mInference done 1720/3489. 0.2379 s / img. ETA=0:07:58
[32m[03/28 21:16:01 d2.evaluation.evaluator]: [0mInference done 1736/3489. 0.2380 s / img. ETA=0:07:54
[32m[03/28 21:16:07 d2.evaluation.evaluator]: [0mInference done 1753/3489. 0.2381 s / img. ETA=0:07:50
[32m[03/28 21:16:12 d2.evaluation.evaluator]: [0mInference done 1769/3489. 0.2383 s / img. ETA=0:07:47
[32m[03/28 21:16:17 d2.evaluation.evaluator]: [0mInference done 1785/3489. 0.2385 s / img. ETA=0:07:43
[32m[03/28 21:16:22 d2.evaluation.evaluator]: [0mInference done 1800/3489. 0.2386 s / img. ETA=0:07:40
[32m[03/28 21:16:27 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2387 s / img. ETA=0:07:36
[32m[03/28 21:16:32 d2.evaluation.evaluator]: [0mInference done 1832/3489. 0.2388 s / img. ETA=0:07:33
[32m[03/28 21:16:38 d2.evaluation.evaluator]: [0mInference done 1848/3489. 0.2390 s / img. ETA=0:07:29
[32m[03/28 21:16:43 d2.evaluation.evaluator]: [0mInference done 1863/3489. 0.2391 s / img. ETA=0:07:26
[32m[03/28 21:16:48 d2.evaluation.evaluator]: [0mInference done 1879/3489. 0.2392 s / img. ETA=0:07:22
[32m[03/28 21:16:53 d2.evaluation.evaluator]: [0mInference done 1895/3489. 0.2393 s / img. ETA=0:07:18
[32m[03/28 21:16:58 d2.evaluation.evaluator]: [0mInference done 1911/3489. 0.2394 s / img. ETA=0:07:15
[32m[03/28 21:17:04 d2.evaluation.evaluator]: [0mInference done 1927/3489. 0.2395 s / img. ETA=0:07:11
[32m[03/28 21:17:09 d2.evaluation.evaluator]: [0mInference done 1943/3489. 0.2396 s / img. ETA=0:07:07
[32m[03/28 21:17:14 d2.evaluation.evaluator]: [0mInference done 1959/3489. 0.2397 s / img. ETA=0:07:03
[32m[03/28 21:17:19 d2.evaluation.evaluator]: [0mInference done 1975/3489. 0.2399 s / img. ETA=0:07:00
[32m[03/28 21:17:24 d2.evaluation.evaluator]: [0mInference done 1991/3489. 0.2400 s / img. ETA=0:06:56
[32m[03/28 21:17:30 d2.evaluation.evaluator]: [0mInference done 2008/3489. 0.2401 s / img. ETA=0:06:51
[32m[03/28 21:17:35 d2.evaluation.evaluator]: [0mInference done 2026/3489. 0.2401 s / img. ETA=0:06:46
[32m[03/28 21:17:40 d2.evaluation.evaluator]: [0mInference done 2042/3489. 0.2402 s / img. ETA=0:06:42
[32m[03/28 21:17:45 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2403 s / img. ETA=0:06:38
[32m[03/28 21:17:50 d2.evaluation.evaluator]: [0mInference done 2076/3489. 0.2404 s / img. ETA=0:06:34
[32m[03/28 21:17:55 d2.evaluation.evaluator]: [0mInference done 2092/3489. 0.2404 s / img. ETA=0:06:30
[32m[03/28 21:18:01 d2.evaluation.evaluator]: [0mInference done 2108/3489. 0.2405 s / img. ETA=0:06:26
[32m[03/28 21:18:06 d2.evaluation.evaluator]: [0mInference done 2124/3489. 0.2406 s / img. ETA=0:06:21
[32m[03/28 21:18:11 d2.evaluation.evaluator]: [0mInference done 2140/3489. 0.2407 s / img. ETA=0:06:17
[32m[03/28 21:18:16 d2.evaluation.evaluator]: [0mInference done 2156/3489. 0.2408 s / img. ETA=0:06:13
[32m[03/28 21:18:21 d2.evaluation.evaluator]: [0mInference done 2172/3489. 0.2409 s / img. ETA=0:06:09
[32m[03/28 21:18:26 d2.evaluation.evaluator]: [0mInference done 2188/3489. 0.2410 s / img. ETA=0:06:05
[32m[03/28 21:18:32 d2.evaluation.evaluator]: [0mInference done 2204/3489. 0.2411 s / img. ETA=0:06:01
[32m[03/28 21:18:37 d2.evaluation.evaluator]: [0mInference done 2221/3489. 0.2412 s / img. ETA=0:05:57
[32m[03/28 21:18:42 d2.evaluation.evaluator]: [0mInference done 2237/3489. 0.2412 s / img. ETA=0:05:52
[32m[03/28 21:18:47 d2.evaluation.evaluator]: [0mInference done 2254/3489. 0.2413 s / img. ETA=0:05:48
[32m[03/28 21:18:52 d2.evaluation.evaluator]: [0mInference done 2270/3489. 0.2414 s / img. ETA=0:05:44
[32m[03/28 21:18:57 d2.evaluation.evaluator]: [0mInference done 2287/3489. 0.2415 s / img. ETA=0:05:39
[32m[03/28 21:19:02 d2.evaluation.evaluator]: [0mInference done 2303/3489. 0.2416 s / img. ETA=0:05:35
[32m[03/28 21:19:08 d2.evaluation.evaluator]: [0mInference done 2319/3489. 0.2417 s / img. ETA=0:05:31
[32m[03/28 21:19:13 d2.evaluation.evaluator]: [0mInference done 2335/3489. 0.2417 s / img. ETA=0:05:26
[32m[03/28 21:19:18 d2.evaluation.evaluator]: [0mInference done 2352/3489. 0.2418 s / img. ETA=0:05:22
[32m[03/28 21:19:23 d2.evaluation.evaluator]: [0mInference done 2369/3489. 0.2418 s / img. ETA=0:05:17
[32m[03/28 21:19:28 d2.evaluation.evaluator]: [0mInference done 2388/3489. 0.2418 s / img. ETA=0:05:12
[32m[03/28 21:19:33 d2.evaluation.evaluator]: [0mInference done 2406/3489. 0.2418 s / img. ETA=0:05:06
[32m[03/28 21:19:38 d2.evaluation.evaluator]: [0mInference done 2424/3489. 0.2418 s / img. ETA=0:05:01
[32m[03/28 21:19:43 d2.evaluation.evaluator]: [0mInference done 2441/3489. 0.2418 s / img. ETA=0:04:57
[32m[03/28 21:19:49 d2.evaluation.evaluator]: [0mInference done 2457/3489. 0.2419 s / img. ETA=0:04:52
[32m[03/28 21:19:54 d2.evaluation.evaluator]: [0mInference done 2473/3489. 0.2420 s / img. ETA=0:04:48
[32m[03/28 21:19:59 d2.evaluation.evaluator]: [0mInference done 2490/3489. 0.2420 s / img. ETA=0:04:43
[32m[03/28 21:20:04 d2.evaluation.evaluator]: [0mInference done 2511/3489. 0.2419 s / img. ETA=0:04:37
[32m[03/28 21:20:09 d2.evaluation.evaluator]: [0mInference done 2531/3489. 0.2418 s / img. ETA=0:04:31
[32m[03/28 21:20:14 d2.evaluation.evaluator]: [0mInference done 2551/3489. 0.2418 s / img. ETA=0:04:25
[32m[03/28 21:20:19 d2.evaluation.evaluator]: [0mInference done 2571/3489. 0.2417 s / img. ETA=0:04:19
[32m[03/28 21:20:24 d2.evaluation.evaluator]: [0mInference done 2592/3489. 0.2416 s / img. ETA=0:04:13
[32m[03/28 21:20:29 d2.evaluation.evaluator]: [0mInference done 2612/3489. 0.2415 s / img. ETA=0:04:07
[32m[03/28 21:20:34 d2.evaluation.evaluator]: [0mInference done 2633/3489. 0.2414 s / img. ETA=0:04:01
[32m[03/28 21:20:39 d2.evaluation.evaluator]: [0mInference done 2654/3489. 0.2413 s / img. ETA=0:03:55
[32m[03/28 21:20:45 d2.evaluation.evaluator]: [0mInference done 2674/3489. 0.2412 s / img. ETA=0:03:49
[32m[03/28 21:20:50 d2.evaluation.evaluator]: [0mInference done 2694/3489. 0.2412 s / img. ETA=0:03:43
[32m[03/28 21:20:55 d2.evaluation.evaluator]: [0mInference done 2714/3489. 0.2411 s / img. ETA=0:03:37
[32m[03/28 21:21:00 d2.evaluation.evaluator]: [0mInference done 2734/3489. 0.2410 s / img. ETA=0:03:32
[32m[03/28 21:21:05 d2.evaluation.evaluator]: [0mInference done 2754/3489. 0.2410 s / img. ETA=0:03:26
[32m[03/28 21:21:10 d2.evaluation.evaluator]: [0mInference done 2774/3489. 0.2409 s / img. ETA=0:03:20
[32m[03/28 21:21:15 d2.evaluation.evaluator]: [0mInference done 2794/3489. 0.2409 s / img. ETA=0:03:14
[32m[03/28 21:21:20 d2.evaluation.evaluator]: [0mInference done 2814/3489. 0.2408 s / img. ETA=0:03:09
[32m[03/28 21:21:25 d2.evaluation.evaluator]: [0mInference done 2834/3489. 0.2407 s / img. ETA=0:03:03
[32m[03/28 21:21:30 d2.evaluation.evaluator]: [0mInference done 2854/3489. 0.2407 s / img. ETA=0:02:57
[32m[03/28 21:21:36 d2.evaluation.evaluator]: [0mInference done 2875/3489. 0.2406 s / img. ETA=0:02:51
[32m[03/28 21:21:41 d2.evaluation.evaluator]: [0mInference done 2896/3489. 0.2405 s / img. ETA=0:02:45
[32m[03/28 21:21:46 d2.evaluation.evaluator]: [0mInference done 2917/3489. 0.2404 s / img. ETA=0:02:39
[32m[03/28 21:21:51 d2.evaluation.evaluator]: [0mInference done 2938/3489. 0.2404 s / img. ETA=0:02:33
[32m[03/28 21:21:56 d2.evaluation.evaluator]: [0mInference done 2959/3489. 0.2403 s / img. ETA=0:02:27
[32m[03/28 21:22:01 d2.evaluation.evaluator]: [0mInference done 2980/3489. 0.2402 s / img. ETA=0:02:21
[32m[03/28 21:22:06 d2.evaluation.evaluator]: [0mInference done 3000/3489. 0.2402 s / img. ETA=0:02:16
[32m[03/28 21:22:12 d2.evaluation.evaluator]: [0mInference done 3020/3489. 0.2402 s / img. ETA=0:02:10
[32m[03/28 21:22:17 d2.evaluation.evaluator]: [0mInference done 3040/3489. 0.2401 s / img. ETA=0:02:04
[32m[03/28 21:22:22 d2.evaluation.evaluator]: [0mInference done 3060/3489. 0.2400 s / img. ETA=0:01:59
[32m[03/28 21:22:27 d2.evaluation.evaluator]: [0mInference done 3080/3489. 0.2400 s / img. ETA=0:01:53
[32m[03/28 21:22:32 d2.evaluation.evaluator]: [0mInference done 3100/3489. 0.2400 s / img. ETA=0:01:47
[32m[03/28 21:22:37 d2.evaluation.evaluator]: [0mInference done 3120/3489. 0.2399 s / img. ETA=0:01:42
[32m[03/28 21:22:42 d2.evaluation.evaluator]: [0mInference done 3140/3489. 0.2399 s / img. ETA=0:01:36
[32m[03/28 21:22:47 d2.evaluation.evaluator]: [0mInference done 3160/3489. 0.2398 s / img. ETA=0:01:31
[32m[03/28 21:22:52 d2.evaluation.evaluator]: [0mInference done 3180/3489. 0.2398 s / img. ETA=0:01:25
[32m[03/28 21:22:57 d2.evaluation.evaluator]: [0mInference done 3200/3489. 0.2397 s / img. ETA=0:01:20
[32m[03/28 21:23:02 d2.evaluation.evaluator]: [0mInference done 3220/3489. 0.2397 s / img. ETA=0:01:14
[32m[03/28 21:23:08 d2.evaluation.evaluator]: [0mInference done 3240/3489. 0.2396 s / img. ETA=0:01:08
[32m[03/28 21:23:13 d2.evaluation.evaluator]: [0mInference done 3261/3489. 0.2396 s / img. ETA=0:01:03
[32m[03/28 21:23:18 d2.evaluation.evaluator]: [0mInference done 3282/3489. 0.2395 s / img. ETA=0:00:57
[32m[03/28 21:23:23 d2.evaluation.evaluator]: [0mInference done 3304/3489. 0.2394 s / img. ETA=0:00:51
[32m[03/28 21:23:28 d2.evaluation.evaluator]: [0mInference done 3326/3489. 0.2393 s / img. ETA=0:00:44
[32m[03/28 21:23:33 d2.evaluation.evaluator]: [0mInference done 3348/3489. 0.2392 s / img. ETA=0:00:38
[32m[03/28 21:23:38 d2.evaluation.evaluator]: [0mInference done 3369/3489. 0.2392 s / img. ETA=0:00:33
[32m[03/28 21:23:43 d2.evaluation.evaluator]: [0mInference done 3390/3489. 0.2391 s / img. ETA=0:00:27
[32m[03/28 21:23:48 d2.evaluation.evaluator]: [0mInference done 3411/3489. 0.2391 s / img. ETA=0:00:21
[32m[03/28 21:23:53 d2.evaluation.evaluator]: [0mInference done 3432/3489. 0.2390 s / img. ETA=0:00:15
[32m[03/28 21:23:58 d2.evaluation.evaluator]: [0mInference done 3453/3489. 0.2389 s / img. ETA=0:00:09
[32m[03/28 21:24:04 d2.evaluation.evaluator]: [0mInference done 3474/3489. 0.2389 s / img. ETA=0:00:04
[32m[03/28 21:24:07 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:54.635843 (0.274006 s / img per device, on 1 devices)
[32m[03/28 21:24:07 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:52 (0.238825 s / img per device, on 1 devices)
[32m[03/28 21:24:09 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:24:09 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.800000/coco_instances_results.json
[32m[03/28 21:24:11 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.74 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.53 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[32m[03/28 21:24:13 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.528 | 79.018 | 49.230 | 29.806 | 55.992 | 60.813 |
[32m[03/28 21:24:13 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 58.210 | Pedestrian | 36.847 |
Loading and preparing results...
DONE (t=1.92s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.30 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.62 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754
[32m[03/28 21:24:23 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.956 | 75.162 | 43.787 | 24.863 | 54.310 | 70.072 |
[32m[03/28 21:24:23 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.698 | Pedestrian | 26.214 |
[32m[03/28 21:24:23 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: 47.5282,79.0184,49.2296,29.8056,55.9918,60.8127
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:24:23 d2.evaluation.testing]: [0mcopypaste: 44.9563,75.1617,43.7870,24.8629,54.3096,70.0721
evaluated
Test [0.100000, 0.900000]
[32m[03/28 21:24:24 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:24:24 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:24:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:24:24 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:24:24 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:24:24 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:24:25 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:24:25 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:24:25 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:24:25 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:24:25 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:24:25 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:24:50 d2.utils.events]: [0m eta: 0:02:30  iter: 19  total_loss: 1.811  loss_cls: 0.7161  loss_box_reg: 0.2933  loss_mask: 0.6489  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.007183  total_val_loss: 1.985  val_loss_cls: 0.6915  val_loss_box_reg: 0.4564  val_loss_mask: 0.6858  val_loss_rpn_cls: 0.03991  val_loss_rpn_loc: 0.0158  time: 0.8421  data_time: 0.0303  lr: 0.00019981  max_mem: 4747M
[32m[03/28 21:25:14 d2.utils.events]: [0m eta: 0:02:14  iter: 39  total_loss: 0.7955  loss_cls: 0.1548  loss_box_reg: 0.2843  loss_mask: 0.3749  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.006189  total_val_loss: 1.243  val_loss_cls: 0.256  val_loss_box_reg: 0.4818  val_loss_mask: 0.5604  val_loss_rpn_cls: 0.04364  val_loss_rpn_loc: 0.01467  time: 0.8475  data_time: 0.0068  lr: 0.00039961  max_mem: 4747M
[32m[03/28 21:25:38 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.5964  loss_cls: 0.08047  loss_box_reg: 0.2439  loss_mask: 0.2152  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.00667  total_val_loss: 0.9822  val_loss_cls: 0.1526  val_loss_box_reg: 0.3788  val_loss_mask: 0.4451  val_loss_rpn_cls: 0.03682  val_loss_rpn_loc: 0.01323  time: 0.8507  data_time: 0.0071  lr: 0.00059941  max_mem: 4747M
[32m[03/28 21:26:03 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.5666  loss_cls: 0.05756  loss_box_reg: 0.3299  loss_mask: 0.1481  loss_rpn_cls: 0.007152  loss_rpn_loc: 0.009218  total_val_loss: 1.182  val_loss_cls: 0.239  val_loss_box_reg: 0.3491  val_loss_mask: 0.3799  val_loss_rpn_cls: 0.02806  val_loss_rpn_loc: 0.01313  time: 0.8539  data_time: 0.0069  lr: 0.00079921  max_mem: 4747M
[32m[03/28 21:26:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:26:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:26:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:26:28 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:26:28 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.4506  loss_cls: 0.06195  loss_box_reg: 0.1991  loss_mask: 0.1501  loss_rpn_cls: 0.007573  loss_rpn_loc: 0.01204  total_val_loss: 1.089  val_loss_cls: 0.2949  val_loss_box_reg: 0.3602  val_loss_mask: 0.4421  val_loss_rpn_cls: 0.02872  val_loss_rpn_loc: 0.01226  time: 0.8577  data_time: 0.0070  lr: 0.00099901  max_mem: 4747M
[32m[03/28 21:26:52 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3497  loss_cls: 0.05324  loss_box_reg: 0.09664  loss_mask: 0.185  loss_rpn_cls: 0.006313  loss_rpn_loc: 0.008384  total_val_loss: 0.7764  val_loss_cls: 0.1626  val_loss_box_reg: 0.2169  val_loss_mask: 0.3392  val_loss_rpn_cls: 0.02876  val_loss_rpn_loc: 0.01125  time: 0.8566  data_time: 0.0061  lr: 0.0011988  max_mem: 4747M
[32m[03/28 21:27:16 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.4138  loss_cls: 0.06651  loss_box_reg: 0.1518  loss_mask: 0.1734  loss_rpn_cls: 0.009345  loss_rpn_loc: 0.01315  total_val_loss: 0.8865  val_loss_cls: 0.1949  val_loss_box_reg: 0.2426  val_loss_mask: 0.3544  val_loss_rpn_cls: 0.02014  val_loss_rpn_loc: 0.01541  time: 0.8567  data_time: 0.0080  lr: 0.0013986  max_mem: 4747M
[32m[03/28 21:27:40 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3108  loss_cls: 0.0411  loss_box_reg: 0.09605  loss_mask: 0.149  loss_rpn_cls: 0.006163  loss_rpn_loc: 0.006794  total_val_loss: 0.9939  val_loss_cls: 0.2586  val_loss_box_reg: 0.3222  val_loss_mask: 0.3647  val_loss_rpn_cls: 0.02327  val_loss_rpn_loc: 0.01457  time: 0.8576  data_time: 0.0062  lr: 0.0015984  max_mem: 4747M
[32m[03/28 21:28:05 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.2703  loss_cls: 0.0407  loss_box_reg: 0.07309  loss_mask: 0.1373  loss_rpn_cls: 0.006242  loss_rpn_loc: 0.008114  total_val_loss: 0.7494  val_loss_cls: 0.1308  val_loss_box_reg: 0.2044  val_loss_mask: 0.3443  val_loss_rpn_cls: 0.01374  val_loss_rpn_loc: 0.01295  time: 0.8582  data_time: 0.0061  lr: 0.0017982  max_mem: 4747M
[32m[03/28 21:28:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:28:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:28:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:28:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:28:30 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.337  loss_cls: 0.04195  loss_box_reg: 0.0856  loss_mask: 0.1349  loss_rpn_cls: 0.004043  loss_rpn_loc: 0.009665  total_val_loss: 0.7996  val_loss_cls: 0.1584  val_loss_box_reg: 0.283  val_loss_mask: 0.3185  val_loss_rpn_cls: 0.01568  val_loss_rpn_loc: 0.01397  time: 0.8594  data_time: 0.0069  lr: 0.001998  max_mem: 4747M
[32m[03/28 21:28:30 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8594 s / it)
[32m[03/28 21:28:30 d2.engine.hooks]: [0mTotal training time: 0:04:02 (0:01:12 on hooks)
[32m[03/28 21:28:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:28:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:28:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:28:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:28:31 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:28:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:28:32 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:28:32 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:28:32 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:28:35 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2265 s / img. ETA=0:13:58
[32m[03/28 21:28:40 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2289 s / img. ETA=0:14:02
[32m[03/28 21:28:45 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2278 s / img. ETA=0:13:51
[32m[03/28 21:28:50 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2278 s / img. ETA=0:13:45
[32m[03/28 21:28:55 d2.evaluation.evaluator]: [0mInference done 95/3489. 0.2283 s / img. ETA=0:13:47
[32m[03/28 21:29:01 d2.evaluation.evaluator]: [0mInference done 114/3489. 0.2299 s / img. ETA=0:13:58
[32m[03/28 21:29:06 d2.evaluation.evaluator]: [0mInference done 131/3489. 0.2320 s / img. ETA=0:14:15
[32m[03/28 21:29:11 d2.evaluation.evaluator]: [0mInference done 147/3489. 0.2342 s / img. ETA=0:14:33
[32m[03/28 21:29:16 d2.evaluation.evaluator]: [0mInference done 163/3489. 0.2361 s / img. ETA=0:14:49
[32m[03/28 21:29:21 d2.evaluation.evaluator]: [0mInference done 180/3489. 0.2372 s / img. ETA=0:14:56
[32m[03/28 21:29:26 d2.evaluation.evaluator]: [0mInference done 199/3489. 0.2373 s / img. ETA=0:14:52
[32m[03/28 21:29:31 d2.evaluation.evaluator]: [0mInference done 220/3489. 0.2368 s / img. ETA=0:14:40
[32m[03/28 21:29:36 d2.evaluation.evaluator]: [0mInference done 240/3489. 0.2364 s / img. ETA=0:14:30
[32m[03/28 21:29:42 d2.evaluation.evaluator]: [0mInference done 260/3489. 0.2363 s / img. ETA=0:14:22
[32m[03/28 21:29:47 d2.evaluation.evaluator]: [0mInference done 280/3489. 0.2361 s / img. ETA=0:14:15
[32m[03/28 21:29:52 d2.evaluation.evaluator]: [0mInference done 300/3489. 0.2360 s / img. ETA=0:14:08
[32m[03/28 21:29:57 d2.evaluation.evaluator]: [0mInference done 319/3489. 0.2361 s / img. ETA=0:14:03
[32m[03/28 21:30:02 d2.evaluation.evaluator]: [0mInference done 338/3489. 0.2361 s / img. ETA=0:13:59
[32m[03/28 21:30:07 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2363 s / img. ETA=0:13:55
[32m[03/28 21:30:12 d2.evaluation.evaluator]: [0mInference done 375/3489. 0.2364 s / img. ETA=0:13:53
[32m[03/28 21:30:18 d2.evaluation.evaluator]: [0mInference done 394/3489. 0.2363 s / img. ETA=0:13:48
[32m[03/28 21:30:23 d2.evaluation.evaluator]: [0mInference done 413/3489. 0.2363 s / img. ETA=0:13:42
[32m[03/28 21:30:28 d2.evaluation.evaluator]: [0mInference done 433/3489. 0.2362 s / img. ETA=0:13:35
[32m[03/28 21:30:33 d2.evaluation.evaluator]: [0mInference done 454/3489. 0.2360 s / img. ETA=0:13:26
[32m[03/28 21:30:38 d2.evaluation.evaluator]: [0mInference done 475/3489. 0.2359 s / img. ETA=0:13:18
[32m[03/28 21:30:43 d2.evaluation.evaluator]: [0mInference done 496/3489. 0.2357 s / img. ETA=0:13:10
[32m[03/28 21:30:48 d2.evaluation.evaluator]: [0mInference done 517/3489. 0.2353 s / img. ETA=0:13:01
[32m[03/28 21:30:53 d2.evaluation.evaluator]: [0mInference done 539/3489. 0.2350 s / img. ETA=0:12:52
[32m[03/28 21:30:58 d2.evaluation.evaluator]: [0mInference done 559/3489. 0.2349 s / img. ETA=0:12:46
[32m[03/28 21:31:04 d2.evaluation.evaluator]: [0mInference done 579/3489. 0.2349 s / img. ETA=0:12:40
[32m[03/28 21:31:09 d2.evaluation.evaluator]: [0mInference done 598/3489. 0.2350 s / img. ETA=0:12:37
[32m[03/28 21:31:14 d2.evaluation.evaluator]: [0mInference done 618/3489. 0.2350 s / img. ETA=0:12:31
[32m[03/28 21:31:19 d2.evaluation.evaluator]: [0mInference done 637/3489. 0.2350 s / img. ETA=0:12:27
[32m[03/28 21:31:24 d2.evaluation.evaluator]: [0mInference done 657/3489. 0.2350 s / img. ETA=0:12:21
[32m[03/28 21:31:29 d2.evaluation.evaluator]: [0mInference done 677/3489. 0.2349 s / img. ETA=0:12:15
[32m[03/28 21:31:34 d2.evaluation.evaluator]: [0mInference done 698/3489. 0.2347 s / img. ETA=0:12:08
[32m[03/28 21:31:40 d2.evaluation.evaluator]: [0mInference done 719/3489. 0.2346 s / img. ETA=0:12:02
[32m[03/28 21:31:45 d2.evaluation.evaluator]: [0mInference done 740/3489. 0.2346 s / img. ETA=0:11:55
[32m[03/28 21:31:50 d2.evaluation.evaluator]: [0mInference done 761/3489. 0.2344 s / img. ETA=0:11:48
[32m[03/28 21:31:55 d2.evaluation.evaluator]: [0mInference done 783/3489. 0.2342 s / img. ETA=0:11:40
[32m[03/28 21:32:00 d2.evaluation.evaluator]: [0mInference done 805/3489. 0.2340 s / img. ETA=0:11:33
[32m[03/28 21:32:05 d2.evaluation.evaluator]: [0mInference done 827/3489. 0.2338 s / img. ETA=0:11:26
[32m[03/28 21:32:10 d2.evaluation.evaluator]: [0mInference done 848/3489. 0.2337 s / img. ETA=0:11:19
[32m[03/28 21:32:15 d2.evaluation.evaluator]: [0mInference done 869/3489. 0.2336 s / img. ETA=0:11:12
[32m[03/28 21:32:21 d2.evaluation.evaluator]: [0mInference done 891/3489. 0.2335 s / img. ETA=0:11:06
[32m[03/28 21:32:26 d2.evaluation.evaluator]: [0mInference done 910/3489. 0.2335 s / img. ETA=0:11:01
[32m[03/28 21:32:31 d2.evaluation.evaluator]: [0mInference done 928/3489. 0.2338 s / img. ETA=0:10:58
[32m[03/28 21:32:36 d2.evaluation.evaluator]: [0mInference done 945/3489. 0.2340 s / img. ETA=0:10:56
[32m[03/28 21:32:41 d2.evaluation.evaluator]: [0mInference done 963/3489. 0.2342 s / img. ETA=0:10:53
[32m[03/28 21:32:46 d2.evaluation.evaluator]: [0mInference done 980/3489. 0.2346 s / img. ETA=0:10:50
[32m[03/28 21:32:52 d2.evaluation.evaluator]: [0mInference done 997/3489. 0.2348 s / img. ETA=0:10:48
[32m[03/28 21:32:57 d2.evaluation.evaluator]: [0mInference done 1014/3489. 0.2351 s / img. ETA=0:10:45
[32m[03/28 21:33:02 d2.evaluation.evaluator]: [0mInference done 1031/3489. 0.2353 s / img. ETA=0:10:43
[32m[03/28 21:33:07 d2.evaluation.evaluator]: [0mInference done 1048/3489. 0.2355 s / img. ETA=0:10:40
[32m[03/28 21:33:13 d2.evaluation.evaluator]: [0mInference done 1066/3489. 0.2357 s / img. ETA=0:10:37
[32m[03/28 21:33:18 d2.evaluation.evaluator]: [0mInference done 1084/3489. 0.2358 s / img. ETA=0:10:33
[32m[03/28 21:33:23 d2.evaluation.evaluator]: [0mInference done 1103/3489. 0.2359 s / img. ETA=0:10:29
[32m[03/28 21:33:28 d2.evaluation.evaluator]: [0mInference done 1122/3489. 0.2360 s / img. ETA=0:10:24
[32m[03/28 21:33:33 d2.evaluation.evaluator]: [0mInference done 1140/3489. 0.2360 s / img. ETA=0:10:19
[32m[03/28 21:33:38 d2.evaluation.evaluator]: [0mInference done 1158/3489. 0.2361 s / img. ETA=0:10:15
[32m[03/28 21:33:43 d2.evaluation.evaluator]: [0mInference done 1176/3489. 0.2362 s / img. ETA=0:10:11
[32m[03/28 21:33:48 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2362 s / img. ETA=0:10:06
[32m[03/28 21:33:53 d2.evaluation.evaluator]: [0mInference done 1214/3489. 0.2363 s / img. ETA=0:10:02
[32m[03/28 21:33:58 d2.evaluation.evaluator]: [0mInference done 1233/3489. 0.2363 s / img. ETA=0:09:57
[32m[03/28 21:34:04 d2.evaluation.evaluator]: [0mInference done 1253/3489. 0.2362 s / img. ETA=0:09:51
[32m[03/28 21:34:09 d2.evaluation.evaluator]: [0mInference done 1275/3489. 0.2361 s / img. ETA=0:09:44
[32m[03/28 21:34:14 d2.evaluation.evaluator]: [0mInference done 1297/3489. 0.2360 s / img. ETA=0:09:37
[32m[03/28 21:34:19 d2.evaluation.evaluator]: [0mInference done 1319/3489. 0.2358 s / img. ETA=0:09:30
[32m[03/28 21:34:24 d2.evaluation.evaluator]: [0mInference done 1341/3489. 0.2357 s / img. ETA=0:09:24
[32m[03/28 21:34:29 d2.evaluation.evaluator]: [0mInference done 1362/3489. 0.2356 s / img. ETA=0:09:18
[32m[03/28 21:34:35 d2.evaluation.evaluator]: [0mInference done 1383/3489. 0.2355 s / img. ETA=0:09:11
[32m[03/28 21:34:40 d2.evaluation.evaluator]: [0mInference done 1404/3489. 0.2355 s / img. ETA=0:09:05
[32m[03/28 21:34:45 d2.evaluation.evaluator]: [0mInference done 1425/3489. 0.2354 s / img. ETA=0:08:59
[32m[03/28 21:34:50 d2.evaluation.evaluator]: [0mInference done 1446/3489. 0.2353 s / img. ETA=0:08:53
[32m[03/28 21:34:55 d2.evaluation.evaluator]: [0mInference done 1467/3489. 0.2352 s / img. ETA=0:08:47
[32m[03/28 21:35:00 d2.evaluation.evaluator]: [0mInference done 1488/3489. 0.2352 s / img. ETA=0:08:41
[32m[03/28 21:35:05 d2.evaluation.evaluator]: [0mInference done 1509/3489. 0.2351 s / img. ETA=0:08:35
[32m[03/28 21:35:10 d2.evaluation.evaluator]: [0mInference done 1530/3489. 0.2350 s / img. ETA=0:08:29
[32m[03/28 21:35:15 d2.evaluation.evaluator]: [0mInference done 1551/3489. 0.2350 s / img. ETA=0:08:23
[32m[03/28 21:35:20 d2.evaluation.evaluator]: [0mInference done 1572/3489. 0.2349 s / img. ETA=0:08:17
[32m[03/28 21:35:26 d2.evaluation.evaluator]: [0mInference done 1593/3489. 0.2349 s / img. ETA=0:08:12
[32m[03/28 21:35:31 d2.evaluation.evaluator]: [0mInference done 1612/3489. 0.2349 s / img. ETA=0:08:07
[32m[03/28 21:35:36 d2.evaluation.evaluator]: [0mInference done 1632/3489. 0.2349 s / img. ETA=0:08:02
[32m[03/28 21:35:41 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2348 s / img. ETA=0:07:56
[32m[03/28 21:35:46 d2.evaluation.evaluator]: [0mInference done 1672/3489. 0.2348 s / img. ETA=0:07:51
[32m[03/28 21:35:51 d2.evaluation.evaluator]: [0mInference done 1690/3489. 0.2349 s / img. ETA=0:07:47
[32m[03/28 21:35:56 d2.evaluation.evaluator]: [0mInference done 1708/3489. 0.2350 s / img. ETA=0:07:43
[32m[03/28 21:36:01 d2.evaluation.evaluator]: [0mInference done 1726/3489. 0.2350 s / img. ETA=0:07:38
[32m[03/28 21:36:06 d2.evaluation.evaluator]: [0mInference done 1744/3489. 0.2351 s / img. ETA=0:07:34
[32m[03/28 21:36:12 d2.evaluation.evaluator]: [0mInference done 1761/3489. 0.2352 s / img. ETA=0:07:30
[32m[03/28 21:36:17 d2.evaluation.evaluator]: [0mInference done 1777/3489. 0.2354 s / img. ETA=0:07:27
[32m[03/28 21:36:22 d2.evaluation.evaluator]: [0mInference done 1793/3489. 0.2355 s / img. ETA=0:07:24
[32m[03/28 21:36:27 d2.evaluation.evaluator]: [0mInference done 1809/3489. 0.2357 s / img. ETA=0:07:21
[32m[03/28 21:36:32 d2.evaluation.evaluator]: [0mInference done 1825/3489. 0.2359 s / img. ETA=0:07:17
[32m[03/28 21:36:38 d2.evaluation.evaluator]: [0mInference done 1841/3489. 0.2360 s / img. ETA=0:07:14
[32m[03/28 21:36:43 d2.evaluation.evaluator]: [0mInference done 1857/3489. 0.2361 s / img. ETA=0:07:11
[32m[03/28 21:36:48 d2.evaluation.evaluator]: [0mInference done 1874/3489. 0.2362 s / img. ETA=0:07:07
[32m[03/28 21:36:53 d2.evaluation.evaluator]: [0mInference done 1891/3489. 0.2363 s / img. ETA=0:07:03
[32m[03/28 21:36:58 d2.evaluation.evaluator]: [0mInference done 1908/3489. 0.2364 s / img. ETA=0:06:59
[32m[03/28 21:37:03 d2.evaluation.evaluator]: [0mInference done 1925/3489. 0.2365 s / img. ETA=0:06:55
[32m[03/28 21:37:08 d2.evaluation.evaluator]: [0mInference done 1942/3489. 0.2366 s / img. ETA=0:06:50
[32m[03/28 21:37:13 d2.evaluation.evaluator]: [0mInference done 1959/3489. 0.2367 s / img. ETA=0:06:46
[32m[03/28 21:37:18 d2.evaluation.evaluator]: [0mInference done 1976/3489. 0.2368 s / img. ETA=0:06:42
[32m[03/28 21:37:23 d2.evaluation.evaluator]: [0mInference done 1993/3489. 0.2369 s / img. ETA=0:06:38
[32m[03/28 21:37:29 d2.evaluation.evaluator]: [0mInference done 2012/3489. 0.2369 s / img. ETA=0:06:33
[32m[03/28 21:37:34 d2.evaluation.evaluator]: [0mInference done 2031/3489. 0.2369 s / img. ETA=0:06:28
[32m[03/28 21:37:39 d2.evaluation.evaluator]: [0mInference done 2049/3489. 0.2370 s / img. ETA=0:06:24
[32m[03/28 21:37:44 d2.evaluation.evaluator]: [0mInference done 2067/3489. 0.2370 s / img. ETA=0:06:19
[32m[03/28 21:37:49 d2.evaluation.evaluator]: [0mInference done 2084/3489. 0.2371 s / img. ETA=0:06:15
[32m[03/28 21:37:54 d2.evaluation.evaluator]: [0mInference done 2102/3489. 0.2372 s / img. ETA=0:06:11
[32m[03/28 21:38:00 d2.evaluation.evaluator]: [0mInference done 2119/3489. 0.2373 s / img. ETA=0:06:06
[32m[03/28 21:38:05 d2.evaluation.evaluator]: [0mInference done 2136/3489. 0.2374 s / img. ETA=0:06:02
[32m[03/28 21:38:10 d2.evaluation.evaluator]: [0mInference done 2152/3489. 0.2375 s / img. ETA=0:05:58
[32m[03/28 21:38:15 d2.evaluation.evaluator]: [0mInference done 2168/3489. 0.2376 s / img. ETA=0:05:55
[32m[03/28 21:38:20 d2.evaluation.evaluator]: [0mInference done 2184/3489. 0.2377 s / img. ETA=0:05:51
[32m[03/28 21:38:26 d2.evaluation.evaluator]: [0mInference done 2201/3489. 0.2378 s / img. ETA=0:05:47
[32m[03/28 21:38:31 d2.evaluation.evaluator]: [0mInference done 2218/3489. 0.2379 s / img. ETA=0:05:42
[32m[03/28 21:38:36 d2.evaluation.evaluator]: [0mInference done 2235/3489. 0.2379 s / img. ETA=0:05:38
[32m[03/28 21:38:41 d2.evaluation.evaluator]: [0mInference done 2253/3489. 0.2379 s / img. ETA=0:05:33
[32m[03/28 21:38:46 d2.evaluation.evaluator]: [0mInference done 2271/3489. 0.2380 s / img. ETA=0:05:29
[32m[03/28 21:38:51 d2.evaluation.evaluator]: [0mInference done 2289/3489. 0.2380 s / img. ETA=0:05:24
[32m[03/28 21:38:56 d2.evaluation.evaluator]: [0mInference done 2307/3489. 0.2381 s / img. ETA=0:05:19
[32m[03/28 21:39:01 d2.evaluation.evaluator]: [0mInference done 2325/3489. 0.2381 s / img. ETA=0:05:14
[32m[03/28 21:39:06 d2.evaluation.evaluator]: [0mInference done 2343/3489. 0.2381 s / img. ETA=0:05:10
[32m[03/28 21:39:11 d2.evaluation.evaluator]: [0mInference done 2361/3489. 0.2381 s / img. ETA=0:05:05
[32m[03/28 21:39:17 d2.evaluation.evaluator]: [0mInference done 2381/3489. 0.2381 s / img. ETA=0:04:59
[32m[03/28 21:39:22 d2.evaluation.evaluator]: [0mInference done 2401/3489. 0.2381 s / img. ETA=0:04:54
[32m[03/28 21:39:27 d2.evaluation.evaluator]: [0mInference done 2420/3489. 0.2381 s / img. ETA=0:04:49
[32m[03/28 21:39:32 d2.evaluation.evaluator]: [0mInference done 2439/3489. 0.2381 s / img. ETA=0:04:44
[32m[03/28 21:39:37 d2.evaluation.evaluator]: [0mInference done 2458/3489. 0.2381 s / img. ETA=0:04:39
[32m[03/28 21:39:42 d2.evaluation.evaluator]: [0mInference done 2476/3489. 0.2381 s / img. ETA=0:04:34
[32m[03/28 21:39:47 d2.evaluation.evaluator]: [0mInference done 2495/3489. 0.2381 s / img. ETA=0:04:29
[32m[03/28 21:39:53 d2.evaluation.evaluator]: [0mInference done 2516/3489. 0.2380 s / img. ETA=0:04:23
[32m[03/28 21:39:58 d2.evaluation.evaluator]: [0mInference done 2536/3489. 0.2380 s / img. ETA=0:04:17
[32m[03/28 21:40:03 d2.evaluation.evaluator]: [0mInference done 2557/3489. 0.2379 s / img. ETA=0:04:11
[32m[03/28 21:40:08 d2.evaluation.evaluator]: [0mInference done 2578/3489. 0.2379 s / img. ETA=0:04:05
[32m[03/28 21:40:13 d2.evaluation.evaluator]: [0mInference done 2599/3489. 0.2378 s / img. ETA=0:04:00
[32m[03/28 21:40:18 d2.evaluation.evaluator]: [0mInference done 2620/3489. 0.2378 s / img. ETA=0:03:54
[32m[03/28 21:40:23 d2.evaluation.evaluator]: [0mInference done 2641/3489. 0.2377 s / img. ETA=0:03:48
[32m[03/28 21:40:28 d2.evaluation.evaluator]: [0mInference done 2662/3489. 0.2376 s / img. ETA=0:03:42
[32m[03/28 21:40:34 d2.evaluation.evaluator]: [0mInference done 2682/3489. 0.2376 s / img. ETA=0:03:37
[32m[03/28 21:40:39 d2.evaluation.evaluator]: [0mInference done 2702/3489. 0.2375 s / img. ETA=0:03:31
[32m[03/28 21:40:44 d2.evaluation.evaluator]: [0mInference done 2722/3489. 0.2375 s / img. ETA=0:03:26
[32m[03/28 21:40:49 d2.evaluation.evaluator]: [0mInference done 2742/3489. 0.2375 s / img. ETA=0:03:20
[32m[03/28 21:40:54 d2.evaluation.evaluator]: [0mInference done 2762/3489. 0.2374 s / img. ETA=0:03:15
[32m[03/28 21:40:59 d2.evaluation.evaluator]: [0mInference done 2782/3489. 0.2374 s / img. ETA=0:03:09
[32m[03/28 21:41:04 d2.evaluation.evaluator]: [0mInference done 2802/3489. 0.2373 s / img. ETA=0:03:04
[32m[03/28 21:41:09 d2.evaluation.evaluator]: [0mInference done 2822/3489. 0.2373 s / img. ETA=0:02:58
[32m[03/28 21:41:14 d2.evaluation.evaluator]: [0mInference done 2842/3489. 0.2373 s / img. ETA=0:02:53
[32m[03/28 21:41:19 d2.evaluation.evaluator]: [0mInference done 2863/3489. 0.2372 s / img. ETA=0:02:47
[32m[03/28 21:41:24 d2.evaluation.evaluator]: [0mInference done 2884/3489. 0.2372 s / img. ETA=0:02:42
[32m[03/28 21:41:30 d2.evaluation.evaluator]: [0mInference done 2905/3489. 0.2371 s / img. ETA=0:02:36
[32m[03/28 21:41:35 d2.evaluation.evaluator]: [0mInference done 2927/3489. 0.2370 s / img. ETA=0:02:30
[32m[03/28 21:41:40 d2.evaluation.evaluator]: [0mInference done 2948/3489. 0.2370 s / img. ETA=0:02:24
[32m[03/28 21:41:45 d2.evaluation.evaluator]: [0mInference done 2970/3489. 0.2369 s / img. ETA=0:02:18
[32m[03/28 21:41:50 d2.evaluation.evaluator]: [0mInference done 2991/3489. 0.2368 s / img. ETA=0:02:12
[32m[03/28 21:41:55 d2.evaluation.evaluator]: [0mInference done 3011/3489. 0.2368 s / img. ETA=0:02:07
[32m[03/28 21:42:00 d2.evaluation.evaluator]: [0mInference done 3031/3489. 0.2368 s / img. ETA=0:02:02
[32m[03/28 21:42:06 d2.evaluation.evaluator]: [0mInference done 3052/3489. 0.2368 s / img. ETA=0:01:56
[32m[03/28 21:42:11 d2.evaluation.evaluator]: [0mInference done 3072/3489. 0.2367 s / img. ETA=0:01:51
[32m[03/28 21:42:16 d2.evaluation.evaluator]: [0mInference done 3092/3489. 0.2367 s / img. ETA=0:01:45
[32m[03/28 21:42:21 d2.evaluation.evaluator]: [0mInference done 3113/3489. 0.2367 s / img. ETA=0:01:40
[32m[03/28 21:42:26 d2.evaluation.evaluator]: [0mInference done 3133/3489. 0.2366 s / img. ETA=0:01:34
[32m[03/28 21:42:31 d2.evaluation.evaluator]: [0mInference done 3153/3489. 0.2366 s / img. ETA=0:01:29
[32m[03/28 21:42:36 d2.evaluation.evaluator]: [0mInference done 3173/3489. 0.2366 s / img. ETA=0:01:24
[32m[03/28 21:42:41 d2.evaluation.evaluator]: [0mInference done 3194/3489. 0.2365 s / img. ETA=0:01:18
[32m[03/28 21:42:47 d2.evaluation.evaluator]: [0mInference done 3214/3489. 0.2365 s / img. ETA=0:01:13
[32m[03/28 21:42:52 d2.evaluation.evaluator]: [0mInference done 3234/3489. 0.2365 s / img. ETA=0:01:07
[32m[03/28 21:42:57 d2.evaluation.evaluator]: [0mInference done 3255/3489. 0.2365 s / img. ETA=0:01:02
[32m[03/28 21:43:02 d2.evaluation.evaluator]: [0mInference done 3276/3489. 0.2364 s / img. ETA=0:00:56
[32m[03/28 21:43:07 d2.evaluation.evaluator]: [0mInference done 3297/3489. 0.2364 s / img. ETA=0:00:50
[32m[03/28 21:43:12 d2.evaluation.evaluator]: [0mInference done 3319/3489. 0.2363 s / img. ETA=0:00:45
[32m[03/28 21:43:17 d2.evaluation.evaluator]: [0mInference done 3341/3489. 0.2362 s / img. ETA=0:00:39
[32m[03/28 21:43:22 d2.evaluation.evaluator]: [0mInference done 3363/3489. 0.2362 s / img. ETA=0:00:33
[32m[03/28 21:43:28 d2.evaluation.evaluator]: [0mInference done 3385/3489. 0.2362 s / img. ETA=0:00:27
[32m[03/28 21:43:33 d2.evaluation.evaluator]: [0mInference done 3406/3489. 0.2361 s / img. ETA=0:00:21
[32m[03/28 21:43:38 d2.evaluation.evaluator]: [0mInference done 3427/3489. 0.2360 s / img. ETA=0:00:16
[32m[03/28 21:43:43 d2.evaluation.evaluator]: [0mInference done 3448/3489. 0.2360 s / img. ETA=0:00:10
[32m[03/28 21:43:48 d2.evaluation.evaluator]: [0mInference done 3469/3489. 0.2360 s / img. ETA=0:00:05
[32m[03/28 21:43:53 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:19.619908 (0.263955 s / img per device, on 1 devices)
[32m[03/28 21:43:53 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:41 (0.235934 s / img per device, on 1 devices)
[32m[03/28 21:43:55 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:43:55 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.100000_0.900000/coco_instances_results.json
[32m[03/28 21:43:56 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.58 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.48 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.415
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[32m[03/28 21:43:58 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.900 | 80.429 | 53.097 | 31.441 | 61.034 | 65.672 |
[32m[03/28 21:43:58 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.235 | Pedestrian | 38.566 |
Loading and preparing results...
DONE (t=1.62s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.00 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.48 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.776
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
[32m[03/28 21:44:06 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.838 | 77.605 | 45.018 | 24.372 | 54.333 | 71.083 |
[32m[03/28 21:44:06 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.763 | Pedestrian | 28.912 |
[32m[03/28 21:44:06 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: 50.9002,80.4295,53.0972,31.4408,61.0338,65.6718
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:44:06 d2.evaluation.testing]: [0mcopypaste: 45.8376,77.6050,45.0176,24.3722,54.3330,71.0830
evaluated
Test [0.200000, 0.100000]
[32m[03/28 21:44:07 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:44:07 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:44:07 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:44:07 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:44:07 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:44:07 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:44:08 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:44:08 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:44:08 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:44:08 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:44:08 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:44:08 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:44:33 d2.utils.events]: [0m eta: 0:02:33  iter: 19  total_loss: 1.938  loss_cls: 0.7637  loss_box_reg: 0.3501  loss_mask: 0.6697  loss_rpn_cls: 0.01891  loss_rpn_loc: 0.008166  total_val_loss: 1.854  val_loss_cls: 0.7146  val_loss_box_reg: 0.4119  val_loss_mask: 0.6813  val_loss_rpn_cls: 0.04085  val_loss_rpn_loc: 0.01083  time: 0.8490  data_time: 0.0362  lr: 0.00019981  max_mem: 4747M
[32m[03/28 21:44:58 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.8793  loss_cls: 0.1641  loss_box_reg: 0.2383  loss_mask: 0.3706  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.007851  total_val_loss: 1.189  val_loss_cls: 0.2341  val_loss_box_reg: 0.338  val_loss_mask: 0.5342  val_loss_rpn_cls: 0.03042  val_loss_rpn_loc: 0.008621  time: 0.8567  data_time: 0.0080  lr: 0.00039961  max_mem: 4747M
[32m[03/28 21:45:22 d2.utils.events]: [0m eta: 0:02:00  iter: 59  total_loss: 0.7056  loss_cls: 0.1001  loss_box_reg: 0.3417  loss_mask: 0.2323  loss_rpn_cls: 0.007709  loss_rpn_loc: 0.009375  total_val_loss: 0.8753  val_loss_cls: 0.1388  val_loss_box_reg: 0.4799  val_loss_mask: 0.2059  val_loss_rpn_cls: 0.01921  val_loss_rpn_loc: 0.01319  time: 0.8606  data_time: 0.0075  lr: 0.00059941  max_mem: 4747M
[32m[03/28 21:45:47 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.5378  loss_cls: 0.06338  loss_box_reg: 0.2616  loss_mask: 0.1285  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.009253  total_val_loss: 0.868  val_loss_cls: 0.1859  val_loss_box_reg: 0.3659  val_loss_mask: 0.3746  val_loss_rpn_cls: 0.02161  val_loss_rpn_loc: 0.0133  time: 0.8635  data_time: 0.0072  lr: 0.00079921  max_mem: 4747M
[32m[03/28 21:46:11 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:46:11 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:46:11 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:46:11 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:46:12 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4237  loss_cls: 0.05355  loss_box_reg: 0.1476  loss_mask: 0.1542  loss_rpn_cls: 0.005082  loss_rpn_loc: 0.008794  total_val_loss: 0.896  val_loss_cls: 0.2183  val_loss_box_reg: 0.2829  val_loss_mask: 0.4352  val_loss_rpn_cls: 0.02302  val_loss_rpn_loc: 0.01298  time: 0.8650  data_time: 0.0073  lr: 0.00099901  max_mem: 4747M
[32m[03/28 21:46:37 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.3167  loss_cls: 0.05515  loss_box_reg: 0.1039  loss_mask: 0.1395  loss_rpn_cls: 0.006755  loss_rpn_loc: 0.008935  total_val_loss: 1.017  val_loss_cls: 0.2215  val_loss_box_reg: 0.2976  val_loss_mask: 0.415  val_loss_rpn_cls: 0.01656  val_loss_rpn_loc: 0.01005  time: 0.8693  data_time: 0.0089  lr: 0.0011988  max_mem: 4747M
[32m[03/28 21:47:01 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.3928  loss_cls: 0.05011  loss_box_reg: 0.1016  loss_mask: 0.1742  loss_rpn_cls: 0.009188  loss_rpn_loc: 0.004555  total_val_loss: 0.7114  val_loss_cls: 0.1261  val_loss_box_reg: 0.1895  val_loss_mask: 0.2934  val_loss_rpn_cls: 0.02037  val_loss_rpn_loc: 0.01085  time: 0.8695  data_time: 0.0069  lr: 0.0013986  max_mem: 4747M
[32m[03/28 21:47:26 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3196  loss_cls: 0.04858  loss_box_reg: 0.09115  loss_mask: 0.1641  loss_rpn_cls: 0.006187  loss_rpn_loc: 0.006631  total_val_loss: 0.6122  val_loss_cls: 0.1028  val_loss_box_reg: 0.2142  val_loss_mask: 0.2945  val_loss_rpn_cls: 0.0161  val_loss_rpn_loc: 0.01376  time: 0.8700  data_time: 0.0068  lr: 0.0015984  max_mem: 4747M
[32m[03/28 21:47:50 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.326  loss_cls: 0.0515  loss_box_reg: 0.1065  loss_mask: 0.1337  loss_rpn_cls: 0.006095  loss_rpn_loc: 0.01172  total_val_loss: 0.6774  val_loss_cls: 0.1064  val_loss_box_reg: 0.2129  val_loss_mask: 0.3031  val_loss_rpn_cls: 0.01265  val_loss_rpn_loc: 0.01218  time: 0.8704  data_time: 0.0086  lr: 0.0017982  max_mem: 4747M
[32m[03/28 21:48:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:48:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:48:16 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:48:16 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:48:16 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.2982  loss_cls: 0.04288  loss_box_reg: 0.09157  loss_mask: 0.1589  loss_rpn_cls: 0.004426  loss_rpn_loc: 0.005861  total_val_loss: 0.7715  val_loss_cls: 0.1477  val_loss_box_reg: 0.2497  val_loss_mask: 0.3308  val_loss_rpn_cls: 0.01523  val_loss_rpn_loc: 0.01018  time: 0.8696  data_time: 0.0067  lr: 0.001998  max_mem: 4747M
[32m[03/28 21:48:16 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:52 (0.8696 s / it)
[32m[03/28 21:48:16 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/28 21:48:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:48:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:48:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:48:17 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:48:17 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:48:17 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:48:17 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:48:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:48:17 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:48:20 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2267 s / img. ETA=0:14:26
[32m[03/28 21:48:26 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2281 s / img. ETA=0:14:12
[32m[03/28 21:48:31 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2289 s / img. ETA=0:14:05
[32m[03/28 21:48:36 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2285 s / img. ETA=0:13:56
[32m[03/28 21:48:41 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2293 s / img. ETA=0:14:02
[32m[03/28 21:48:46 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2314 s / img. ETA=0:14:22
[32m[03/28 21:48:51 d2.evaluation.evaluator]: [0mInference done 128/3489. 0.2336 s / img. ETA=0:14:43
[32m[03/28 21:48:56 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2360 s / img. ETA=0:15:04
[32m[03/28 21:49:02 d2.evaluation.evaluator]: [0mInference done 160/3489. 0.2381 s / img. ETA=0:15:20
[32m[03/28 21:49:07 d2.evaluation.evaluator]: [0mInference done 176/3489. 0.2397 s / img. ETA=0:15:31
[32m[03/28 21:49:12 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2406 s / img. ETA=0:15:34
[32m[03/28 21:49:17 d2.evaluation.evaluator]: [0mInference done 212/3489. 0.2400 s / img. ETA=0:15:26
[32m[03/28 21:49:22 d2.evaluation.evaluator]: [0mInference done 231/3489. 0.2398 s / img. ETA=0:15:16
[32m[03/28 21:49:28 d2.evaluation.evaluator]: [0mInference done 249/3489. 0.2400 s / img. ETA=0:15:12
[32m[03/28 21:49:33 d2.evaluation.evaluator]: [0mInference done 268/3489. 0.2398 s / img. ETA=0:15:05
[32m[03/28 21:49:38 d2.evaluation.evaluator]: [0mInference done 286/3489. 0.2400 s / img. ETA=0:15:02
[32m[03/28 21:49:43 d2.evaluation.evaluator]: [0mInference done 304/3489. 0.2400 s / img. ETA=0:14:57
[32m[03/28 21:49:48 d2.evaluation.evaluator]: [0mInference done 321/3489. 0.2404 s / img. ETA=0:14:55
[32m[03/28 21:49:53 d2.evaluation.evaluator]: [0mInference done 339/3489. 0.2405 s / img. ETA=0:14:51
[32m[03/28 21:49:59 d2.evaluation.evaluator]: [0mInference done 356/3489. 0.2410 s / img. ETA=0:14:50
[32m[03/28 21:50:04 d2.evaluation.evaluator]: [0mInference done 373/3489. 0.2413 s / img. ETA=0:14:47
[32m[03/28 21:50:09 d2.evaluation.evaluator]: [0mInference done 391/3489. 0.2414 s / img. ETA=0:14:43
[32m[03/28 21:50:14 d2.evaluation.evaluator]: [0mInference done 409/3489. 0.2414 s / img. ETA=0:14:38
[32m[03/28 21:50:19 d2.evaluation.evaluator]: [0mInference done 427/3489. 0.2414 s / img. ETA=0:14:32
[32m[03/28 21:50:24 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2408 s / img. ETA=0:14:20
[32m[03/28 21:50:29 d2.evaluation.evaluator]: [0mInference done 469/3489. 0.2404 s / img. ETA=0:14:09
[32m[03/28 21:50:35 d2.evaluation.evaluator]: [0mInference done 490/3489. 0.2400 s / img. ETA=0:13:59
[32m[03/28 21:50:40 d2.evaluation.evaluator]: [0mInference done 511/3489. 0.2396 s / img. ETA=0:13:48
[32m[03/28 21:50:45 d2.evaluation.evaluator]: [0mInference done 533/3489. 0.2391 s / img. ETA=0:13:37
[32m[03/28 21:50:50 d2.evaluation.evaluator]: [0mInference done 554/3489. 0.2387 s / img. ETA=0:13:28
[32m[03/28 21:50:55 d2.evaluation.evaluator]: [0mInference done 573/3489. 0.2386 s / img. ETA=0:13:22
[32m[03/28 21:51:00 d2.evaluation.evaluator]: [0mInference done 590/3489. 0.2389 s / img. ETA=0:13:19
[32m[03/28 21:51:05 d2.evaluation.evaluator]: [0mInference done 608/3489. 0.2389 s / img. ETA=0:13:14
[32m[03/28 21:51:10 d2.evaluation.evaluator]: [0mInference done 626/3489. 0.2390 s / img. ETA=0:13:10
[32m[03/28 21:51:15 d2.evaluation.evaluator]: [0mInference done 644/3489. 0.2390 s / img. ETA=0:13:05
[32m[03/28 21:51:21 d2.evaluation.evaluator]: [0mInference done 663/3489. 0.2390 s / img. ETA=0:12:59
[32m[03/28 21:51:26 d2.evaluation.evaluator]: [0mInference done 683/3489. 0.2390 s / img. ETA=0:12:53
[32m[03/28 21:51:31 d2.evaluation.evaluator]: [0mInference done 704/3489. 0.2387 s / img. ETA=0:12:45
[32m[03/28 21:51:36 d2.evaluation.evaluator]: [0mInference done 724/3489. 0.2386 s / img. ETA=0:12:38
[32m[03/28 21:51:41 d2.evaluation.evaluator]: [0mInference done 744/3489. 0.2385 s / img. ETA=0:12:31
[32m[03/28 21:51:46 d2.evaluation.evaluator]: [0mInference done 765/3489. 0.2383 s / img. ETA=0:12:23
[32m[03/28 21:51:51 d2.evaluation.evaluator]: [0mInference done 786/3489. 0.2380 s / img. ETA=0:12:15
[32m[03/28 21:51:56 d2.evaluation.evaluator]: [0mInference done 807/3489. 0.2378 s / img. ETA=0:12:07
[32m[03/28 21:52:01 d2.evaluation.evaluator]: [0mInference done 828/3489. 0.2376 s / img. ETA=0:11:59
[32m[03/28 21:52:06 d2.evaluation.evaluator]: [0mInference done 849/3489. 0.2373 s / img. ETA=0:11:51
[32m[03/28 21:52:12 d2.evaluation.evaluator]: [0mInference done 870/3489. 0.2372 s / img. ETA=0:11:44
[32m[03/28 21:52:17 d2.evaluation.evaluator]: [0mInference done 892/3489. 0.2370 s / img. ETA=0:11:36
[32m[03/28 21:52:22 d2.evaluation.evaluator]: [0mInference done 910/3489. 0.2370 s / img. ETA=0:11:32
[32m[03/28 21:52:27 d2.evaluation.evaluator]: [0mInference done 927/3489. 0.2372 s / img. ETA=0:11:29
[32m[03/28 21:52:32 d2.evaluation.evaluator]: [0mInference done 943/3489. 0.2375 s / img. ETA=0:11:27
[32m[03/28 21:52:37 d2.evaluation.evaluator]: [0mInference done 959/3489. 0.2378 s / img. ETA=0:11:25
[32m[03/28 21:52:42 d2.evaluation.evaluator]: [0mInference done 975/3489. 0.2381 s / img. ETA=0:11:22
[32m[03/28 21:52:48 d2.evaluation.evaluator]: [0mInference done 991/3489. 0.2383 s / img. ETA=0:11:20
[32m[03/28 21:52:53 d2.evaluation.evaluator]: [0mInference done 1007/3489. 0.2386 s / img. ETA=0:11:18
[32m[03/28 21:52:58 d2.evaluation.evaluator]: [0mInference done 1023/3489. 0.2390 s / img. ETA=0:11:15
[32m[03/28 21:53:03 d2.evaluation.evaluator]: [0mInference done 1039/3489. 0.2392 s / img. ETA=0:11:13
[32m[03/28 21:53:08 d2.evaluation.evaluator]: [0mInference done 1055/3489. 0.2394 s / img. ETA=0:11:10
[32m[03/28 21:53:13 d2.evaluation.evaluator]: [0mInference done 1071/3489. 0.2395 s / img. ETA=0:11:07
[32m[03/28 21:53:18 d2.evaluation.evaluator]: [0mInference done 1089/3489. 0.2396 s / img. ETA=0:11:03
[32m[03/28 21:53:24 d2.evaluation.evaluator]: [0mInference done 1108/3489. 0.2396 s / img. ETA=0:10:57
[32m[03/28 21:53:29 d2.evaluation.evaluator]: [0mInference done 1125/3489. 0.2398 s / img. ETA=0:10:54
[32m[03/28 21:53:34 d2.evaluation.evaluator]: [0mInference done 1141/3489. 0.2400 s / img. ETA=0:10:52
[32m[03/28 21:53:40 d2.evaluation.evaluator]: [0mInference done 1157/3489. 0.2402 s / img. ETA=0:10:49
[32m[03/28 21:53:45 d2.evaluation.evaluator]: [0mInference done 1173/3489. 0.2404 s / img. ETA=0:10:46
[32m[03/28 21:53:50 d2.evaluation.evaluator]: [0mInference done 1189/3489. 0.2406 s / img. ETA=0:10:42
[32m[03/28 21:53:55 d2.evaluation.evaluator]: [0mInference done 1206/3489. 0.2407 s / img. ETA=0:10:38
[32m[03/28 21:54:00 d2.evaluation.evaluator]: [0mInference done 1223/3489. 0.2408 s / img. ETA=0:10:35
[32m[03/28 21:54:05 d2.evaluation.evaluator]: [0mInference done 1240/3489. 0.2409 s / img. ETA=0:10:30
[32m[03/28 21:54:10 d2.evaluation.evaluator]: [0mInference done 1258/3489. 0.2409 s / img. ETA=0:10:25
[32m[03/28 21:54:16 d2.evaluation.evaluator]: [0mInference done 1280/3489. 0.2407 s / img. ETA=0:10:17
[32m[03/28 21:54:21 d2.evaluation.evaluator]: [0mInference done 1302/3489. 0.2404 s / img. ETA=0:10:10
[32m[03/28 21:54:26 d2.evaluation.evaluator]: [0mInference done 1324/3489. 0.2402 s / img. ETA=0:10:02
[32m[03/28 21:54:31 d2.evaluation.evaluator]: [0mInference done 1345/3489. 0.2400 s / img. ETA=0:09:55
[32m[03/28 21:54:36 d2.evaluation.evaluator]: [0mInference done 1367/3489. 0.2398 s / img. ETA=0:09:47
[32m[03/28 21:54:41 d2.evaluation.evaluator]: [0mInference done 1389/3489. 0.2396 s / img. ETA=0:09:40
[32m[03/28 21:54:46 d2.evaluation.evaluator]: [0mInference done 1410/3489. 0.2395 s / img. ETA=0:09:33
[32m[03/28 21:54:51 d2.evaluation.evaluator]: [0mInference done 1430/3489. 0.2393 s / img. ETA=0:09:27
[32m[03/28 21:54:57 d2.evaluation.evaluator]: [0mInference done 1451/3489. 0.2392 s / img. ETA=0:09:20
[32m[03/28 21:55:02 d2.evaluation.evaluator]: [0mInference done 1472/3489. 0.2391 s / img. ETA=0:09:13
[32m[03/28 21:55:07 d2.evaluation.evaluator]: [0mInference done 1493/3489. 0.2389 s / img. ETA=0:09:07
[32m[03/28 21:55:12 d2.evaluation.evaluator]: [0mInference done 1515/3489. 0.2387 s / img. ETA=0:08:59
[32m[03/28 21:55:17 d2.evaluation.evaluator]: [0mInference done 1536/3489. 0.2386 s / img. ETA=0:08:53
[32m[03/28 21:55:22 d2.evaluation.evaluator]: [0mInference done 1557/3489. 0.2385 s / img. ETA=0:08:46
[32m[03/28 21:55:27 d2.evaluation.evaluator]: [0mInference done 1578/3489. 0.2383 s / img. ETA=0:08:40
[32m[03/28 21:55:32 d2.evaluation.evaluator]: [0mInference done 1598/3489. 0.2383 s / img. ETA=0:08:34
[32m[03/28 21:55:37 d2.evaluation.evaluator]: [0mInference done 1616/3489. 0.2383 s / img. ETA=0:08:29
[32m[03/28 21:55:43 d2.evaluation.evaluator]: [0mInference done 1634/3489. 0.2384 s / img. ETA=0:08:25
[32m[03/28 21:55:48 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2384 s / img. ETA=0:08:20
[32m[03/28 21:55:53 d2.evaluation.evaluator]: [0mInference done 1670/3489. 0.2385 s / img. ETA=0:08:15
[32m[03/28 21:55:58 d2.evaluation.evaluator]: [0mInference done 1686/3489. 0.2386 s / img. ETA=0:08:12
[32m[03/28 21:56:03 d2.evaluation.evaluator]: [0mInference done 1702/3489. 0.2388 s / img. ETA=0:08:08
[32m[03/28 21:56:08 d2.evaluation.evaluator]: [0mInference done 1719/3489. 0.2389 s / img. ETA=0:08:04
[32m[03/28 21:56:13 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2390 s / img. ETA=0:08:01
[32m[03/28 21:56:19 d2.evaluation.evaluator]: [0mInference done 1751/3489. 0.2391 s / img. ETA=0:07:57
[32m[03/28 21:56:24 d2.evaluation.evaluator]: [0mInference done 1766/3489. 0.2392 s / img. ETA=0:07:54
[32m[03/28 21:56:29 d2.evaluation.evaluator]: [0mInference done 1782/3489. 0.2394 s / img. ETA=0:07:50
[32m[03/28 21:56:34 d2.evaluation.evaluator]: [0mInference done 1798/3489. 0.2395 s / img. ETA=0:07:47
[32m[03/28 21:56:39 d2.evaluation.evaluator]: [0mInference done 1814/3489. 0.2396 s / img. ETA=0:07:43
[32m[03/28 21:56:45 d2.evaluation.evaluator]: [0mInference done 1830/3489. 0.2397 s / img. ETA=0:07:39
[32m[03/28 21:56:50 d2.evaluation.evaluator]: [0mInference done 1846/3489. 0.2398 s / img. ETA=0:07:35
[32m[03/28 21:56:55 d2.evaluation.evaluator]: [0mInference done 1862/3489. 0.2400 s / img. ETA=0:07:32
[32m[03/28 21:57:00 d2.evaluation.evaluator]: [0mInference done 1878/3489. 0.2401 s / img. ETA=0:07:28
[32m[03/28 21:57:05 d2.evaluation.evaluator]: [0mInference done 1894/3489. 0.2402 s / img. ETA=0:07:24
[32m[03/28 21:57:11 d2.evaluation.evaluator]: [0mInference done 1910/3489. 0.2403 s / img. ETA=0:07:20
[32m[03/28 21:57:16 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2404 s / img. ETA=0:07:16
[32m[03/28 21:57:21 d2.evaluation.evaluator]: [0mInference done 1942/3489. 0.2406 s / img. ETA=0:07:12
[32m[03/28 21:57:26 d2.evaluation.evaluator]: [0mInference done 1958/3489. 0.2406 s / img. ETA=0:07:09
[32m[03/28 21:57:31 d2.evaluation.evaluator]: [0mInference done 1974/3489. 0.2407 s / img. ETA=0:07:05
[32m[03/28 21:57:37 d2.evaluation.evaluator]: [0mInference done 1990/3489. 0.2408 s / img. ETA=0:07:01
[32m[03/28 21:57:42 d2.evaluation.evaluator]: [0mInference done 2007/3489. 0.2409 s / img. ETA=0:06:56
[32m[03/28 21:57:47 d2.evaluation.evaluator]: [0mInference done 2024/3489. 0.2409 s / img. ETA=0:06:52
[32m[03/28 21:57:52 d2.evaluation.evaluator]: [0mInference done 2041/3489. 0.2410 s / img. ETA=0:06:47
[32m[03/28 21:57:57 d2.evaluation.evaluator]: [0mInference done 2057/3489. 0.2411 s / img. ETA=0:06:43
[32m[03/28 21:58:02 d2.evaluation.evaluator]: [0mInference done 2073/3489. 0.2412 s / img. ETA=0:06:39
[32m[03/28 21:58:08 d2.evaluation.evaluator]: [0mInference done 2089/3489. 0.2413 s / img. ETA=0:06:35
[32m[03/28 21:58:13 d2.evaluation.evaluator]: [0mInference done 2105/3489. 0.2414 s / img. ETA=0:06:31
[32m[03/28 21:58:18 d2.evaluation.evaluator]: [0mInference done 2121/3489. 0.2415 s / img. ETA=0:06:27
[32m[03/28 21:58:23 d2.evaluation.evaluator]: [0mInference done 2136/3489. 0.2416 s / img. ETA=0:06:23
[32m[03/28 21:58:28 d2.evaluation.evaluator]: [0mInference done 2152/3489. 0.2416 s / img. ETA=0:06:19
[32m[03/28 21:58:33 d2.evaluation.evaluator]: [0mInference done 2168/3489. 0.2417 s / img. ETA=0:06:15
[32m[03/28 21:58:39 d2.evaluation.evaluator]: [0mInference done 2184/3489. 0.2419 s / img. ETA=0:06:11
[32m[03/28 21:58:44 d2.evaluation.evaluator]: [0mInference done 2200/3489. 0.2420 s / img. ETA=0:06:07
[32m[03/28 21:58:49 d2.evaluation.evaluator]: [0mInference done 2216/3489. 0.2421 s / img. ETA=0:06:02
[32m[03/28 21:58:54 d2.evaluation.evaluator]: [0mInference done 2232/3489. 0.2421 s / img. ETA=0:05:58
[32m[03/28 21:59:00 d2.evaluation.evaluator]: [0mInference done 2248/3489. 0.2422 s / img. ETA=0:05:54
[32m[03/28 21:59:05 d2.evaluation.evaluator]: [0mInference done 2265/3489. 0.2422 s / img. ETA=0:05:49
[32m[03/28 21:59:10 d2.evaluation.evaluator]: [0mInference done 2282/3489. 0.2423 s / img. ETA=0:05:45
[32m[03/28 21:59:15 d2.evaluation.evaluator]: [0mInference done 2298/3489. 0.2424 s / img. ETA=0:05:40
[32m[03/28 21:59:20 d2.evaluation.evaluator]: [0mInference done 2314/3489. 0.2425 s / img. ETA=0:05:36
[32m[03/28 21:59:25 d2.evaluation.evaluator]: [0mInference done 2330/3489. 0.2426 s / img. ETA=0:05:32
[32m[03/28 21:59:30 d2.evaluation.evaluator]: [0mInference done 2346/3489. 0.2426 s / img. ETA=0:05:27
[32m[03/28 21:59:36 d2.evaluation.evaluator]: [0mInference done 2362/3489. 0.2427 s / img. ETA=0:05:23
[32m[03/28 21:59:41 d2.evaluation.evaluator]: [0mInference done 2381/3489. 0.2427 s / img. ETA=0:05:17
[32m[03/28 21:59:46 d2.evaluation.evaluator]: [0mInference done 2399/3489. 0.2427 s / img. ETA=0:05:12
[32m[03/28 21:59:51 d2.evaluation.evaluator]: [0mInference done 2416/3489. 0.2427 s / img. ETA=0:05:07
[32m[03/28 21:59:56 d2.evaluation.evaluator]: [0mInference done 2434/3489. 0.2427 s / img. ETA=0:05:02
[32m[03/28 22:00:01 d2.evaluation.evaluator]: [0mInference done 2450/3489. 0.2427 s / img. ETA=0:04:58
[32m[03/28 22:00:06 d2.evaluation.evaluator]: [0mInference done 2466/3489. 0.2428 s / img. ETA=0:04:53
[32m[03/28 22:00:11 d2.evaluation.evaluator]: [0mInference done 2482/3489. 0.2429 s / img. ETA=0:04:49
[32m[03/28 22:00:16 d2.evaluation.evaluator]: [0mInference done 2501/3489. 0.2428 s / img. ETA=0:04:43
[32m[03/28 22:00:21 d2.evaluation.evaluator]: [0mInference done 2521/3489. 0.2427 s / img. ETA=0:04:37
[32m[03/28 22:00:27 d2.evaluation.evaluator]: [0mInference done 2541/3489. 0.2427 s / img. ETA=0:04:32
[32m[03/28 22:00:32 d2.evaluation.evaluator]: [0mInference done 2561/3489. 0.2426 s / img. ETA=0:04:26
[32m[03/28 22:00:37 d2.evaluation.evaluator]: [0mInference done 2581/3489. 0.2425 s / img. ETA=0:04:20
[32m[03/28 22:00:42 d2.evaluation.evaluator]: [0mInference done 2602/3489. 0.2424 s / img. ETA=0:04:13
[32m[03/28 22:00:47 d2.evaluation.evaluator]: [0mInference done 2623/3489. 0.2423 s / img. ETA=0:04:07
[32m[03/28 22:00:52 d2.evaluation.evaluator]: [0mInference done 2644/3489. 0.2422 s / img. ETA=0:04:01
[32m[03/28 22:00:57 d2.evaluation.evaluator]: [0mInference done 2665/3489. 0.2421 s / img. ETA=0:03:54
[32m[03/28 22:01:03 d2.evaluation.evaluator]: [0mInference done 2685/3489. 0.2420 s / img. ETA=0:03:49
[32m[03/28 22:01:08 d2.evaluation.evaluator]: [0mInference done 2705/3489. 0.2419 s / img. ETA=0:03:43
[32m[03/28 22:01:13 d2.evaluation.evaluator]: [0mInference done 2725/3489. 0.2419 s / img. ETA=0:03:37
[32m[03/28 22:01:18 d2.evaluation.evaluator]: [0mInference done 2745/3489. 0.2418 s / img. ETA=0:03:31
[32m[03/28 22:01:23 d2.evaluation.evaluator]: [0mInference done 2765/3489. 0.2417 s / img. ETA=0:03:25
[32m[03/28 22:01:28 d2.evaluation.evaluator]: [0mInference done 2785/3489. 0.2417 s / img. ETA=0:03:19
[32m[03/28 22:01:33 d2.evaluation.evaluator]: [0mInference done 2805/3489. 0.2416 s / img. ETA=0:03:14
[32m[03/28 22:01:38 d2.evaluation.evaluator]: [0mInference done 2825/3489. 0.2416 s / img. ETA=0:03:08
[32m[03/28 22:01:44 d2.evaluation.evaluator]: [0mInference done 2845/3489. 0.2415 s / img. ETA=0:03:02
[32m[03/28 22:01:49 d2.evaluation.evaluator]: [0mInference done 2866/3489. 0.2414 s / img. ETA=0:02:56
[32m[03/28 22:01:54 d2.evaluation.evaluator]: [0mInference done 2886/3489. 0.2414 s / img. ETA=0:02:50
[32m[03/28 22:01:59 d2.evaluation.evaluator]: [0mInference done 2907/3489. 0.2413 s / img. ETA=0:02:44
[32m[03/28 22:02:04 d2.evaluation.evaluator]: [0mInference done 2928/3489. 0.2412 s / img. ETA=0:02:38
[32m[03/28 22:02:09 d2.evaluation.evaluator]: [0mInference done 2949/3489. 0.2411 s / img. ETA=0:02:32
[32m[03/28 22:02:14 d2.evaluation.evaluator]: [0mInference done 2970/3489. 0.2410 s / img. ETA=0:02:26
[32m[03/28 22:02:19 d2.evaluation.evaluator]: [0mInference done 2990/3489. 0.2410 s / img. ETA=0:02:20
[32m[03/28 22:02:25 d2.evaluation.evaluator]: [0mInference done 3010/3489. 0.2409 s / img. ETA=0:02:14
[32m[03/28 22:02:30 d2.evaluation.evaluator]: [0mInference done 3030/3489. 0.2409 s / img. ETA=0:02:09
[32m[03/28 22:02:35 d2.evaluation.evaluator]: [0mInference done 3051/3489. 0.2408 s / img. ETA=0:02:03
[32m[03/28 22:02:40 d2.evaluation.evaluator]: [0mInference done 3070/3489. 0.2409 s / img. ETA=0:01:57
[32m[03/28 22:02:45 d2.evaluation.evaluator]: [0mInference done 3090/3489. 0.2408 s / img. ETA=0:01:52
[32m[03/28 22:02:50 d2.evaluation.evaluator]: [0mInference done 3110/3489. 0.2408 s / img. ETA=0:01:46
[32m[03/28 22:02:56 d2.evaluation.evaluator]: [0mInference done 3130/3489. 0.2407 s / img. ETA=0:01:40
[32m[03/28 22:03:01 d2.evaluation.evaluator]: [0mInference done 3150/3489. 0.2407 s / img. ETA=0:01:35
[32m[03/28 22:03:06 d2.evaluation.evaluator]: [0mInference done 3170/3489. 0.2406 s / img. ETA=0:01:29
[32m[03/28 22:03:11 d2.evaluation.evaluator]: [0mInference done 3191/3489. 0.2405 s / img. ETA=0:01:23
[32m[03/28 22:03:16 d2.evaluation.evaluator]: [0mInference done 3212/3489. 0.2405 s / img. ETA=0:01:17
[32m[03/28 22:03:21 d2.evaluation.evaluator]: [0mInference done 3232/3489. 0.2404 s / img. ETA=0:01:11
[32m[03/28 22:03:26 d2.evaluation.evaluator]: [0mInference done 3252/3489. 0.2403 s / img. ETA=0:01:06
[32m[03/28 22:03:31 d2.evaluation.evaluator]: [0mInference done 3273/3489. 0.2403 s / img. ETA=0:01:00
[32m[03/28 22:03:37 d2.evaluation.evaluator]: [0mInference done 3295/3489. 0.2402 s / img. ETA=0:00:54
[32m[03/28 22:03:42 d2.evaluation.evaluator]: [0mInference done 3317/3489. 0.2401 s / img. ETA=0:00:47
[32m[03/28 22:03:47 d2.evaluation.evaluator]: [0mInference done 3339/3489. 0.2400 s / img. ETA=0:00:41
[32m[03/28 22:03:52 d2.evaluation.evaluator]: [0mInference done 3361/3489. 0.2399 s / img. ETA=0:00:35
[32m[03/28 22:03:57 d2.evaluation.evaluator]: [0mInference done 3382/3489. 0.2399 s / img. ETA=0:00:29
[32m[03/28 22:04:02 d2.evaluation.evaluator]: [0mInference done 3403/3489. 0.2398 s / img. ETA=0:00:23
[32m[03/28 22:04:07 d2.evaluation.evaluator]: [0mInference done 3424/3489. 0.2397 s / img. ETA=0:00:18
[32m[03/28 22:04:13 d2.evaluation.evaluator]: [0mInference done 3445/3489. 0.2397 s / img. ETA=0:00:12
[32m[03/28 22:04:18 d2.evaluation.evaluator]: [0mInference done 3465/3489. 0.2397 s / img. ETA=0:00:06
[32m[03/28 22:04:23 d2.evaluation.evaluator]: [0mInference done 3485/3489. 0.2396 s / img. ETA=0:00:01
[32m[03/28 22:04:24 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:04.904258 (0.276953 s / img per device, on 1 devices)
[32m[03/28 22:04:24 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:54 (0.239595 s / img per device, on 1 devices)
[32m[03/28 22:04:26 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 22:04:26 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.100000/coco_instances_results.json
[32m[03/28 22:04:27 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.48 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.53 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.795
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[32m[03/28 22:04:30 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.184 | 79.455 | 49.877 | 31.708 | 58.403 | 60.931 |
[32m[03/28 22:04:30 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.931 | Pedestrian | 36.438 |
Loading and preparing results...
DONE (t=1.97s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.31 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[32m[03/28 22:04:39 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.924 | 75.481 | 42.159 | 23.388 | 53.682 | 70.600 |
[32m[03/28 22:04:39 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.436 | Pedestrian | 25.412 |
[32m[03/28 22:04:39 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: 49.1844,79.4548,49.8766,31.7084,58.4030,60.9306
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:04:39 d2.evaluation.testing]: [0mcopypaste: 43.9240,75.4813,42.1594,23.3879,53.6815,70.6001
evaluated
Test [0.200000, 0.200000]
[32m[03/28 22:04:40 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 22:04:40 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 22:04:41 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:04:41 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:04:41 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 22:04:41 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 22:04:41 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 22:04:41 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:04:41 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:04:41 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 22:04:41 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 22:04:41 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 22:05:06 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.769  loss_cls: 0.6329  loss_box_reg: 0.4244  loss_mask: 0.6635  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.01311  total_val_loss: 1.842  val_loss_cls: 0.6875  val_loss_box_reg: 0.3989  val_loss_mask: 0.6847  val_loss_rpn_cls: 0.04676  val_loss_rpn_loc: 0.01205  time: 0.8447  data_time: 0.0309  lr: 0.00019981  max_mem: 4747M
[32m[03/28 22:05:30 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.8615  loss_cls: 0.1702  loss_box_reg: 0.3465  loss_mask: 0.3219  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.007229  total_val_loss: 1.283  val_loss_cls: 0.2813  val_loss_box_reg: 0.4771  val_loss_mask: 0.472  val_loss_rpn_cls: 0.02775  val_loss_rpn_loc: 0.01357  time: 0.8483  data_time: 0.0063  lr: 0.00039961  max_mem: 4747M
[32m[03/28 22:05:54 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.5958  loss_cls: 0.08194  loss_box_reg: 0.2945  loss_mask: 0.1768  loss_rpn_cls: 0.011  loss_rpn_loc: 0.008824  total_val_loss: 1.218  val_loss_cls: 0.2547  val_loss_box_reg: 0.4964  val_loss_mask: 0.4286  val_loss_rpn_cls: 0.03608  val_loss_rpn_loc: 0.01685  time: 0.8545  data_time: 0.0072  lr: 0.00059941  max_mem: 4747M
[32m[03/28 22:06:19 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.4771  loss_cls: 0.05091  loss_box_reg: 0.2547  loss_mask: 0.1635  loss_rpn_cls: 0.007922  loss_rpn_loc: 0.007093  total_val_loss: 0.9669  val_loss_cls: 0.193  val_loss_box_reg: 0.4575  val_loss_mask: 0.3706  val_loss_rpn_cls: 0.02241  val_loss_rpn_loc: 0.0179  time: 0.8564  data_time: 0.0067  lr: 0.00079921  max_mem: 4747M
[32m[03/28 22:06:43 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:06:43 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:06:44 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:06:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:06:44 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.4802  loss_cls: 0.06576  loss_box_reg: 0.1759  loss_mask: 0.1718  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.01044  total_val_loss: 0.9916  val_loss_cls: 0.2433  val_loss_box_reg: 0.3303  val_loss_mask: 0.3923  val_loss_rpn_cls: 0.02518  val_loss_rpn_loc: 0.01365  time: 0.8596  data_time: 0.0064  lr: 0.00099901  max_mem: 4747M
[32m[03/28 22:07:08 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.2994  loss_cls: 0.04875  loss_box_reg: 0.08082  loss_mask: 0.1475  loss_rpn_cls: 0.006171  loss_rpn_loc: 0.008286  total_val_loss: 0.9822  val_loss_cls: 0.1996  val_loss_box_reg: 0.2504  val_loss_mask: 0.4075  val_loss_rpn_cls: 0.02236  val_loss_rpn_loc: 0.01273  time: 0.8604  data_time: 0.0070  lr: 0.0011988  max_mem: 4747M
[32m[03/28 22:07:33 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3355  loss_cls: 0.0614  loss_box_reg: 0.1079  loss_mask: 0.1626  loss_rpn_cls: 0.005721  loss_rpn_loc: 0.009666  total_val_loss: 0.8221  val_loss_cls: 0.1631  val_loss_box_reg: 0.2362  val_loss_mask: 0.4414  val_loss_rpn_cls: 0.01127  val_loss_rpn_loc: 0.01475  time: 0.8620  data_time: 0.0081  lr: 0.0013986  max_mem: 4747M
[32m[03/28 22:07:57 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3082  loss_cls: 0.04716  loss_box_reg: 0.105  loss_mask: 0.1453  loss_rpn_cls: 0.004781  loss_rpn_loc: 0.008867  total_val_loss: 0.8027  val_loss_cls: 0.1744  val_loss_box_reg: 0.2729  val_loss_mask: 0.3188  val_loss_rpn_cls: 0.01275  val_loss_rpn_loc: 0.01356  time: 0.8623  data_time: 0.0067  lr: 0.0015984  max_mem: 4747M
[32m[03/28 22:08:22 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3153  loss_cls: 0.03769  loss_box_reg: 0.08993  loss_mask: 0.1548  loss_rpn_cls: 0.006429  loss_rpn_loc: 0.007481  total_val_loss: 0.7848  val_loss_cls: 0.1833  val_loss_box_reg: 0.2751  val_loss_mask: 0.2782  val_loss_rpn_cls: 0.01498  val_loss_rpn_loc: 0.01671  time: 0.8617  data_time: 0.0075  lr: 0.0017982  max_mem: 4747M
[32m[03/28 22:08:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:08:47 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:08:48 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:08:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:08:48 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3359  loss_cls: 0.05454  loss_box_reg: 0.1054  loss_mask: 0.1491  loss_rpn_cls: 0.00865  loss_rpn_loc: 0.009725  total_val_loss: 0.4594  val_loss_cls: 0.07899  val_loss_box_reg: 0.1437  val_loss_mask: 0.2124  val_loss_rpn_cls: 0.01921  val_loss_rpn_loc: 0.01381  time: 0.8623  data_time: 0.0070  lr: 0.001998  max_mem: 4747M
[32m[03/28 22:08:48 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8623 s / it)
[32m[03/28 22:08:48 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/28 22:08:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:08:48 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:08:48 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:08:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 22:08:48 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 22:08:49 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:08:49 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:08:49 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 22:08:49 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 22:08:52 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2253 s / img. ETA=0:14:04
[32m[03/28 22:08:58 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2281 s / img. ETA=0:14:05
[32m[03/28 22:09:03 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2280 s / img. ETA=0:13:52
[32m[03/28 22:09:08 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2279 s / img. ETA=0:13:45
[32m[03/28 22:09:13 d2.evaluation.evaluator]: [0mInference done 95/3489. 0.2285 s / img. ETA=0:13:43
[32m[03/28 22:09:18 d2.evaluation.evaluator]: [0mInference done 115/3489. 0.2290 s / img. ETA=0:13:47
[32m[03/28 22:09:23 d2.evaluation.evaluator]: [0mInference done 133/3489. 0.2307 s / img. ETA=0:14:03
[32m[03/28 22:09:28 d2.evaluation.evaluator]: [0mInference done 150/3489. 0.2328 s / img. ETA=0:14:21
[32m[03/28 22:09:33 d2.evaluation.evaluator]: [0mInference done 166/3489. 0.2350 s / img. ETA=0:14:38
[32m[03/28 22:09:39 d2.evaluation.evaluator]: [0mInference done 184/3489. 0.2357 s / img. ETA=0:14:42
[32m[03/28 22:09:44 d2.evaluation.evaluator]: [0mInference done 203/3489. 0.2359 s / img. ETA=0:14:38
[32m[03/28 22:09:49 d2.evaluation.evaluator]: [0mInference done 224/3489. 0.2353 s / img. ETA=0:14:26
[32m[03/28 22:09:54 d2.evaluation.evaluator]: [0mInference done 244/3489. 0.2351 s / img. ETA=0:14:18
[32m[03/28 22:09:59 d2.evaluation.evaluator]: [0mInference done 264/3489. 0.2351 s / img. ETA=0:14:11
[32m[03/28 22:10:04 d2.evaluation.evaluator]: [0mInference done 283/3489. 0.2353 s / img. ETA=0:14:08
[32m[03/28 22:10:10 d2.evaluation.evaluator]: [0mInference done 303/3489. 0.2352 s / img. ETA=0:14:02
[32m[03/28 22:10:15 d2.evaluation.evaluator]: [0mInference done 322/3489. 0.2354 s / img. ETA=0:13:58
[32m[03/28 22:10:20 d2.evaluation.evaluator]: [0mInference done 341/3489. 0.2355 s / img. ETA=0:13:54
[32m[03/28 22:10:25 d2.evaluation.evaluator]: [0mInference done 359/3489. 0.2358 s / img. ETA=0:13:52
[32m[03/28 22:10:30 d2.evaluation.evaluator]: [0mInference done 378/3489. 0.2359 s / img. ETA=0:13:49
[32m[03/28 22:10:35 d2.evaluation.evaluator]: [0mInference done 397/3489. 0.2359 s / img. ETA=0:13:44
[32m[03/28 22:10:41 d2.evaluation.evaluator]: [0mInference done 416/3489. 0.2359 s / img. ETA=0:13:39
[32m[03/28 22:10:46 d2.evaluation.evaluator]: [0mInference done 437/3489. 0.2356 s / img. ETA=0:13:30
[32m[03/28 22:10:51 d2.evaluation.evaluator]: [0mInference done 458/3489. 0.2352 s / img. ETA=0:13:21
[32m[03/28 22:10:56 d2.evaluation.evaluator]: [0mInference done 479/3489. 0.2350 s / img. ETA=0:13:13
[32m[03/28 22:11:01 d2.evaluation.evaluator]: [0mInference done 500/3489. 0.2347 s / img. ETA=0:13:04
[32m[03/28 22:11:06 d2.evaluation.evaluator]: [0mInference done 522/3489. 0.2344 s / img. ETA=0:12:55
[32m[03/28 22:11:11 d2.evaluation.evaluator]: [0mInference done 544/3489. 0.2342 s / img. ETA=0:12:46
[32m[03/28 22:11:16 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2341 s / img. ETA=0:12:39
[32m[03/28 22:11:22 d2.evaluation.evaluator]: [0mInference done 585/3489. 0.2341 s / img. ETA=0:12:34
[32m[03/28 22:11:27 d2.evaluation.evaluator]: [0mInference done 605/3489. 0.2341 s / img. ETA=0:12:29
[32m[03/28 22:11:32 d2.evaluation.evaluator]: [0mInference done 624/3489. 0.2342 s / img. ETA=0:12:24
[32m[03/28 22:11:37 d2.evaluation.evaluator]: [0mInference done 643/3489. 0.2343 s / img. ETA=0:12:20
[32m[03/28 22:11:42 d2.evaluation.evaluator]: [0mInference done 663/3489. 0.2343 s / img. ETA=0:12:14
[32m[03/28 22:11:47 d2.evaluation.evaluator]: [0mInference done 684/3489. 0.2341 s / img. ETA=0:12:07
[32m[03/28 22:11:52 d2.evaluation.evaluator]: [0mInference done 705/3489. 0.2340 s / img. ETA=0:12:00
[32m[03/28 22:11:57 d2.evaluation.evaluator]: [0mInference done 726/3489. 0.2338 s / img. ETA=0:11:53
[32m[03/28 22:12:02 d2.evaluation.evaluator]: [0mInference done 747/3489. 0.2337 s / img. ETA=0:11:47
[32m[03/28 22:12:08 d2.evaluation.evaluator]: [0mInference done 769/3489. 0.2336 s / img. ETA=0:11:39
[32m[03/28 22:12:13 d2.evaluation.evaluator]: [0mInference done 791/3489. 0.2334 s / img. ETA=0:11:32
[32m[03/28 22:12:18 d2.evaluation.evaluator]: [0mInference done 813/3489. 0.2332 s / img. ETA=0:11:25
[32m[03/28 22:12:23 d2.evaluation.evaluator]: [0mInference done 835/3489. 0.2330 s / img. ETA=0:11:17
[32m[03/28 22:12:28 d2.evaluation.evaluator]: [0mInference done 857/3489. 0.2328 s / img. ETA=0:11:10
[32m[03/28 22:12:33 d2.evaluation.evaluator]: [0mInference done 879/3489. 0.2325 s / img. ETA=0:11:03
[32m[03/28 22:12:38 d2.evaluation.evaluator]: [0mInference done 901/3489. 0.2324 s / img. ETA=0:10:56
[32m[03/28 22:12:43 d2.evaluation.evaluator]: [0mInference done 919/3489. 0.2325 s / img. ETA=0:10:53
[32m[03/28 22:12:48 d2.evaluation.evaluator]: [0mInference done 937/3489. 0.2327 s / img. ETA=0:10:50
[32m[03/28 22:12:53 d2.evaluation.evaluator]: [0mInference done 955/3489. 0.2329 s / img. ETA=0:10:47
[32m[03/28 22:12:59 d2.evaluation.evaluator]: [0mInference done 973/3489. 0.2331 s / img. ETA=0:10:44
[32m[03/28 22:13:04 d2.evaluation.evaluator]: [0mInference done 990/3489. 0.2334 s / img. ETA=0:10:41
[32m[03/28 22:13:09 d2.evaluation.evaluator]: [0mInference done 1007/3489. 0.2336 s / img. ETA=0:10:38
[32m[03/28 22:13:14 d2.evaluation.evaluator]: [0mInference done 1024/3489. 0.2339 s / img. ETA=0:10:36
[32m[03/28 22:13:19 d2.evaluation.evaluator]: [0mInference done 1041/3489. 0.2342 s / img. ETA=0:10:34
[32m[03/28 22:13:24 d2.evaluation.evaluator]: [0mInference done 1058/3489. 0.2344 s / img. ETA=0:10:31
[32m[03/28 22:13:29 d2.evaluation.evaluator]: [0mInference done 1075/3489. 0.2346 s / img. ETA=0:10:28
[32m[03/28 22:13:34 d2.evaluation.evaluator]: [0mInference done 1094/3489. 0.2346 s / img. ETA=0:10:23
[32m[03/28 22:13:40 d2.evaluation.evaluator]: [0mInference done 1114/3489. 0.2346 s / img. ETA=0:10:18
[32m[03/28 22:13:45 d2.evaluation.evaluator]: [0mInference done 1132/3489. 0.2347 s / img. ETA=0:10:14
[32m[03/28 22:13:50 d2.evaluation.evaluator]: [0mInference done 1149/3489. 0.2349 s / img. ETA=0:10:11
[32m[03/28 22:13:55 d2.evaluation.evaluator]: [0mInference done 1167/3489. 0.2351 s / img. ETA=0:10:07
[32m[03/28 22:14:00 d2.evaluation.evaluator]: [0mInference done 1185/3489. 0.2353 s / img. ETA=0:10:04
[32m[03/28 22:14:05 d2.evaluation.evaluator]: [0mInference done 1203/3489. 0.2354 s / img. ETA=0:10:00
[32m[03/28 22:14:10 d2.evaluation.evaluator]: [0mInference done 1221/3489. 0.2355 s / img. ETA=0:09:56
[32m[03/28 22:14:16 d2.evaluation.evaluator]: [0mInference done 1240/3489. 0.2355 s / img. ETA=0:09:51
[32m[03/28 22:14:21 d2.evaluation.evaluator]: [0mInference done 1260/3489. 0.2355 s / img. ETA=0:09:45
[32m[03/28 22:14:26 d2.evaluation.evaluator]: [0mInference done 1282/3489. 0.2353 s / img. ETA=0:09:38
[32m[03/28 22:14:31 d2.evaluation.evaluator]: [0mInference done 1304/3489. 0.2351 s / img. ETA=0:09:31
[32m[03/28 22:14:36 d2.evaluation.evaluator]: [0mInference done 1326/3489. 0.2350 s / img. ETA=0:09:25
[32m[03/28 22:14:41 d2.evaluation.evaluator]: [0mInference done 1347/3489. 0.2349 s / img. ETA=0:09:18
[32m[03/28 22:14:46 d2.evaluation.evaluator]: [0mInference done 1369/3489. 0.2348 s / img. ETA=0:09:12
[32m[03/28 22:14:51 d2.evaluation.evaluator]: [0mInference done 1391/3489. 0.2347 s / img. ETA=0:09:05
[32m[03/28 22:14:57 d2.evaluation.evaluator]: [0mInference done 1412/3489. 0.2346 s / img. ETA=0:08:59
[32m[03/28 22:15:02 d2.evaluation.evaluator]: [0mInference done 1433/3489. 0.2345 s / img. ETA=0:08:53
[32m[03/28 22:15:07 d2.evaluation.evaluator]: [0mInference done 1454/3489. 0.2344 s / img. ETA=0:08:47
[32m[03/28 22:15:12 d2.evaluation.evaluator]: [0mInference done 1475/3489. 0.2343 s / img. ETA=0:08:41
[32m[03/28 22:15:17 d2.evaluation.evaluator]: [0mInference done 1497/3489. 0.2342 s / img. ETA=0:08:35
[32m[03/28 22:15:22 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2341 s / img. ETA=0:08:29
[32m[03/28 22:15:27 d2.evaluation.evaluator]: [0mInference done 1541/3489. 0.2340 s / img. ETA=0:08:22
[32m[03/28 22:15:32 d2.evaluation.evaluator]: [0mInference done 1562/3489. 0.2339 s / img. ETA=0:08:16
[32m[03/28 22:15:37 d2.evaluation.evaluator]: [0mInference done 1583/3489. 0.2338 s / img. ETA=0:08:11
[32m[03/28 22:15:42 d2.evaluation.evaluator]: [0mInference done 1603/3489. 0.2338 s / img. ETA=0:08:05
[32m[03/28 22:15:48 d2.evaluation.evaluator]: [0mInference done 1623/3489. 0.2338 s / img. ETA=0:08:00
[32m[03/28 22:15:53 d2.evaluation.evaluator]: [0mInference done 1642/3489. 0.2338 s / img. ETA=0:07:55
[32m[03/28 22:15:58 d2.evaluation.evaluator]: [0mInference done 1662/3489. 0.2338 s / img. ETA=0:07:50
[32m[03/28 22:16:03 d2.evaluation.evaluator]: [0mInference done 1681/3489. 0.2338 s / img. ETA=0:07:46
[32m[03/28 22:16:08 d2.evaluation.evaluator]: [0mInference done 1699/3489. 0.2339 s / img. ETA=0:07:42
[32m[03/28 22:16:13 d2.evaluation.evaluator]: [0mInference done 1717/3489. 0.2340 s / img. ETA=0:07:37
[32m[03/28 22:16:18 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2341 s / img. ETA=0:07:33
[32m[03/28 22:16:24 d2.evaluation.evaluator]: [0mInference done 1752/3489. 0.2342 s / img. ETA=0:07:30
[32m[03/28 22:16:29 d2.evaluation.evaluator]: [0mInference done 1768/3489. 0.2344 s / img. ETA=0:07:26
[32m[03/28 22:16:34 d2.evaluation.evaluator]: [0mInference done 1784/3489. 0.2346 s / img. ETA=0:07:23
[32m[03/28 22:16:39 d2.evaluation.evaluator]: [0mInference done 1800/3489. 0.2348 s / img. ETA=0:07:20
[32m[03/28 22:16:44 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2349 s / img. ETA=0:07:17
[32m[03/28 22:16:49 d2.evaluation.evaluator]: [0mInference done 1832/3489. 0.2351 s / img. ETA=0:07:13
[32m[03/28 22:16:54 d2.evaluation.evaluator]: [0mInference done 1848/3489. 0.2352 s / img. ETA=0:07:10
[32m[03/28 22:17:00 d2.evaluation.evaluator]: [0mInference done 1865/3489. 0.2354 s / img. ETA=0:07:06
[32m[03/28 22:17:05 d2.evaluation.evaluator]: [0mInference done 1882/3489. 0.2355 s / img. ETA=0:07:02
[32m[03/28 22:17:10 d2.evaluation.evaluator]: [0mInference done 1899/3489. 0.2356 s / img. ETA=0:06:59
[32m[03/28 22:17:15 d2.evaluation.evaluator]: [0mInference done 1916/3489. 0.2357 s / img. ETA=0:06:55
[32m[03/28 22:17:20 d2.evaluation.evaluator]: [0mInference done 1932/3489. 0.2359 s / img. ETA=0:06:51
[32m[03/28 22:17:26 d2.evaluation.evaluator]: [0mInference done 1949/3489. 0.2360 s / img. ETA=0:06:47
[32m[03/28 22:17:31 d2.evaluation.evaluator]: [0mInference done 1966/3489. 0.2361 s / img. ETA=0:06:43
[32m[03/28 22:17:36 d2.evaluation.evaluator]: [0mInference done 1982/3489. 0.2362 s / img. ETA=0:06:40
[32m[03/28 22:17:41 d2.evaluation.evaluator]: [0mInference done 2000/3489. 0.2363 s / img. ETA=0:06:35
[32m[03/28 22:17:46 d2.evaluation.evaluator]: [0mInference done 2019/3489. 0.2363 s / img. ETA=0:06:30
[32m[03/28 22:17:51 d2.evaluation.evaluator]: [0mInference done 2038/3489. 0.2363 s / img. ETA=0:06:25
[32m[03/28 22:17:57 d2.evaluation.evaluator]: [0mInference done 2056/3489. 0.2364 s / img. ETA=0:06:21
[32m[03/28 22:18:02 d2.evaluation.evaluator]: [0mInference done 2073/3489. 0.2365 s / img. ETA=0:06:17
[32m[03/28 22:18:07 d2.evaluation.evaluator]: [0mInference done 2090/3489. 0.2366 s / img. ETA=0:06:13
[32m[03/28 22:18:12 d2.evaluation.evaluator]: [0mInference done 2107/3489. 0.2367 s / img. ETA=0:06:09
[32m[03/28 22:18:17 d2.evaluation.evaluator]: [0mInference done 2123/3489. 0.2368 s / img. ETA=0:06:05
[32m[03/28 22:18:22 d2.evaluation.evaluator]: [0mInference done 2139/3489. 0.2369 s / img. ETA=0:06:01
[32m[03/28 22:18:27 d2.evaluation.evaluator]: [0mInference done 2155/3489. 0.2370 s / img. ETA=0:05:57
[32m[03/28 22:18:33 d2.evaluation.evaluator]: [0mInference done 2172/3489. 0.2371 s / img. ETA=0:05:53
[32m[03/28 22:18:38 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2372 s / img. ETA=0:05:49
[32m[03/28 22:18:43 d2.evaluation.evaluator]: [0mInference done 2206/3489. 0.2373 s / img. ETA=0:05:45
[32m[03/28 22:18:48 d2.evaluation.evaluator]: [0mInference done 2223/3489. 0.2374 s / img. ETA=0:05:40
[32m[03/28 22:18:53 d2.evaluation.evaluator]: [0mInference done 2240/3489. 0.2375 s / img. ETA=0:05:36
[32m[03/28 22:18:58 d2.evaluation.evaluator]: [0mInference done 2258/3489. 0.2375 s / img. ETA=0:05:31
[32m[03/28 22:19:04 d2.evaluation.evaluator]: [0mInference done 2276/3489. 0.2375 s / img. ETA=0:05:27
[32m[03/28 22:19:09 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2376 s / img. ETA=0:05:22
[32m[03/28 22:19:14 d2.evaluation.evaluator]: [0mInference done 2311/3489. 0.2376 s / img. ETA=0:05:18
[32m[03/28 22:19:19 d2.evaluation.evaluator]: [0mInference done 2328/3489. 0.2377 s / img. ETA=0:05:13
[32m[03/28 22:19:24 d2.evaluation.evaluator]: [0mInference done 2346/3489. 0.2377 s / img. ETA=0:05:09
[32m[03/28 22:19:29 d2.evaluation.evaluator]: [0mInference done 2364/3489. 0.2378 s / img. ETA=0:05:04
[32m[03/28 22:19:34 d2.evaluation.evaluator]: [0mInference done 2384/3489. 0.2377 s / img. ETA=0:04:58
[32m[03/28 22:19:39 d2.evaluation.evaluator]: [0mInference done 2404/3489. 0.2377 s / img. ETA=0:04:53
[32m[03/28 22:19:44 d2.evaluation.evaluator]: [0mInference done 2423/3489. 0.2377 s / img. ETA=0:04:48
[32m[03/28 22:19:50 d2.evaluation.evaluator]: [0mInference done 2442/3489. 0.2377 s / img. ETA=0:04:43
[32m[03/28 22:19:55 d2.evaluation.evaluator]: [0mInference done 2460/3489. 0.2378 s / img. ETA=0:04:38
[32m[03/28 22:20:00 d2.evaluation.evaluator]: [0mInference done 2477/3489. 0.2378 s / img. ETA=0:04:33
[32m[03/28 22:20:05 d2.evaluation.evaluator]: [0mInference done 2496/3489. 0.2378 s / img. ETA=0:04:28
[32m[03/28 22:20:10 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2378 s / img. ETA=0:04:22
[32m[03/28 22:20:15 d2.evaluation.evaluator]: [0mInference done 2537/3489. 0.2378 s / img. ETA=0:04:17
[32m[03/28 22:20:21 d2.evaluation.evaluator]: [0mInference done 2558/3489. 0.2377 s / img. ETA=0:04:11
[32m[03/28 22:20:26 d2.evaluation.evaluator]: [0mInference done 2578/3489. 0.2377 s / img. ETA=0:04:06
[32m[03/28 22:20:31 d2.evaluation.evaluator]: [0mInference done 2600/3489. 0.2376 s / img. ETA=0:03:59
[32m[03/28 22:20:36 d2.evaluation.evaluator]: [0mInference done 2621/3489. 0.2375 s / img. ETA=0:03:53
[32m[03/28 22:20:41 d2.evaluation.evaluator]: [0mInference done 2643/3489. 0.2374 s / img. ETA=0:03:47
[32m[03/28 22:20:46 d2.evaluation.evaluator]: [0mInference done 2664/3489. 0.2373 s / img. ETA=0:03:41
[32m[03/28 22:20:52 d2.evaluation.evaluator]: [0mInference done 2685/3489. 0.2373 s / img. ETA=0:03:36
[32m[03/28 22:20:57 d2.evaluation.evaluator]: [0mInference done 2706/3489. 0.2372 s / img. ETA=0:03:30
[32m[03/28 22:21:02 d2.evaluation.evaluator]: [0mInference done 2727/3489. 0.2372 s / img. ETA=0:03:24
[32m[03/28 22:21:07 d2.evaluation.evaluator]: [0mInference done 2747/3489. 0.2371 s / img. ETA=0:03:19
[32m[03/28 22:21:12 d2.evaluation.evaluator]: [0mInference done 2767/3489. 0.2371 s / img. ETA=0:03:13
[32m[03/28 22:21:17 d2.evaluation.evaluator]: [0mInference done 2788/3489. 0.2371 s / img. ETA=0:03:07
[32m[03/28 22:21:22 d2.evaluation.evaluator]: [0mInference done 2809/3489. 0.2370 s / img. ETA=0:03:02
[32m[03/28 22:21:27 d2.evaluation.evaluator]: [0mInference done 2830/3489. 0.2370 s / img. ETA=0:02:56
[32m[03/28 22:21:33 d2.evaluation.evaluator]: [0mInference done 2851/3489. 0.2369 s / img. ETA=0:02:50
[32m[03/28 22:21:38 d2.evaluation.evaluator]: [0mInference done 2872/3489. 0.2369 s / img. ETA=0:02:45
[32m[03/28 22:21:43 d2.evaluation.evaluator]: [0mInference done 2893/3489. 0.2368 s / img. ETA=0:02:39
[32m[03/28 22:21:48 d2.evaluation.evaluator]: [0mInference done 2914/3489. 0.2367 s / img. ETA=0:02:33
[32m[03/28 22:21:53 d2.evaluation.evaluator]: [0mInference done 2935/3489. 0.2367 s / img. ETA=0:02:27
[32m[03/28 22:21:58 d2.evaluation.evaluator]: [0mInference done 2956/3489. 0.2366 s / img. ETA=0:02:22
[32m[03/28 22:22:03 d2.evaluation.evaluator]: [0mInference done 2978/3489. 0.2366 s / img. ETA=0:02:16
[32m[03/28 22:22:09 d2.evaluation.evaluator]: [0mInference done 2999/3489. 0.2365 s / img. ETA=0:02:10
[32m[03/28 22:22:14 d2.evaluation.evaluator]: [0mInference done 3019/3489. 0.2365 s / img. ETA=0:02:05
[32m[03/28 22:22:19 d2.evaluation.evaluator]: [0mInference done 3040/3489. 0.2364 s / img. ETA=0:01:59
[32m[03/28 22:22:24 d2.evaluation.evaluator]: [0mInference done 3061/3489. 0.2364 s / img. ETA=0:01:53
[32m[03/28 22:22:29 d2.evaluation.evaluator]: [0mInference done 3081/3489. 0.2364 s / img. ETA=0:01:48
[32m[03/28 22:22:34 d2.evaluation.evaluator]: [0mInference done 3101/3489. 0.2363 s / img. ETA=0:01:43
[32m[03/28 22:22:39 d2.evaluation.evaluator]: [0mInference done 3122/3489. 0.2363 s / img. ETA=0:01:37
[32m[03/28 22:22:44 d2.evaluation.evaluator]: [0mInference done 3141/3489. 0.2363 s / img. ETA=0:01:32
[32m[03/28 22:22:49 d2.evaluation.evaluator]: [0mInference done 3162/3489. 0.2363 s / img. ETA=0:01:26
[32m[03/28 22:22:55 d2.evaluation.evaluator]: [0mInference done 3183/3489. 0.2363 s / img. ETA=0:01:21
[32m[03/28 22:23:00 d2.evaluation.evaluator]: [0mInference done 3204/3489. 0.2362 s / img. ETA=0:01:15
[32m[03/28 22:23:05 d2.evaluation.evaluator]: [0mInference done 3224/3489. 0.2362 s / img. ETA=0:01:10
[32m[03/28 22:23:10 d2.evaluation.evaluator]: [0mInference done 3244/3489. 0.2361 s / img. ETA=0:01:04
[32m[03/28 22:23:15 d2.evaluation.evaluator]: [0mInference done 3265/3489. 0.2361 s / img. ETA=0:00:59
[32m[03/28 22:23:20 d2.evaluation.evaluator]: [0mInference done 3286/3489. 0.2360 s / img. ETA=0:00:53
[32m[03/28 22:23:25 d2.evaluation.evaluator]: [0mInference done 3308/3489. 0.2360 s / img. ETA=0:00:47
[32m[03/28 22:23:30 d2.evaluation.evaluator]: [0mInference done 3330/3489. 0.2359 s / img. ETA=0:00:42
[32m[03/28 22:23:35 d2.evaluation.evaluator]: [0mInference done 3352/3489. 0.2359 s / img. ETA=0:00:36
[32m[03/28 22:23:40 d2.evaluation.evaluator]: [0mInference done 3374/3489. 0.2358 s / img. ETA=0:00:30
[32m[03/28 22:23:45 d2.evaluation.evaluator]: [0mInference done 3396/3489. 0.2358 s / img. ETA=0:00:24
[32m[03/28 22:23:51 d2.evaluation.evaluator]: [0mInference done 3418/3489. 0.2357 s / img. ETA=0:00:18
[32m[03/28 22:23:56 d2.evaluation.evaluator]: [0mInference done 3439/3489. 0.2357 s / img. ETA=0:00:13
[32m[03/28 22:24:01 d2.evaluation.evaluator]: [0mInference done 3460/3489. 0.2356 s / img. ETA=0:00:07
[32m[03/28 22:24:06 d2.evaluation.evaluator]: [0mInference done 3482/3489. 0.2355 s / img. ETA=0:00:01
[32m[03/28 22:24:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:16.740928 (0.263129 s / img per device, on 1 devices)
[32m[03/28 22:24:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:40 (0.235532 s / img per device, on 1 devices)
[32m[03/28 22:24:09 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 22:24:09 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.200000/coco_instances_results.json
[32m[03/28 22:24:10 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.23 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.42 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.806
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[32m[03/28 22:24:12 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.114 | 80.560 | 54.748 | 32.019 | 61.115 | 64.133 |
[32m[03/28 22:24:12 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.983 | Pedestrian | 40.245 |
Loading and preparing results...
DONE (t=1.60s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 1.90 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.44 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754
[32m[03/28 22:24:19 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.493 | 77.159 | 46.038 | 24.810 | 55.825 | 70.201 |
[32m[03/28 22:24:19 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.470 | Pedestrian | 28.515 |
[32m[03/28 22:24:20 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: 51.1140,80.5598,54.7481,32.0194,61.1154,64.1327
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:24:20 d2.evaluation.testing]: [0mcopypaste: 46.4928,77.1589,46.0377,24.8100,55.8246,70.2012
evaluated
Test [0.200000, 0.500000]
[32m[03/28 22:24:20 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 22:24:21 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 22:24:21 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:24:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:24:21 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 22:24:21 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 22:24:21 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 22:24:21 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:24:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:24:21 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 22:24:21 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 22:24:21 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 22:24:46 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.722  loss_cls: 0.7954  loss_box_reg: 0.2503  loss_mask: 0.6536  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.004821  total_val_loss: 1.884  val_loss_cls: 0.7149  val_loss_box_reg: 0.4439  val_loss_mask: 0.6773  val_loss_rpn_cls: 0.03477  val_loss_rpn_loc: 0.01354  time: 0.8396  data_time: 0.0284  lr: 0.00019981  max_mem: 4747M
[32m[03/28 22:25:11 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.8936  loss_cls: 0.1834  loss_box_reg: 0.3692  loss_mask: 0.3306  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.009386  total_val_loss: 1.175  val_loss_cls: 0.2487  val_loss_box_reg: 0.4134  val_loss_mask: 0.4505  val_loss_rpn_cls: 0.03892  val_loss_rpn_loc: 0.01026  time: 0.8554  data_time: 0.0071  lr: 0.00039961  max_mem: 4747M
[32m[03/28 22:25:35 d2.utils.events]: [0m eta: 0:02:00  iter: 59  total_loss: 0.5093  loss_cls: 0.06113  loss_box_reg: 0.2002  loss_mask: 0.2159  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.004061  total_val_loss: 1.182  val_loss_cls: 0.2275  val_loss_box_reg: 0.4308  val_loss_mask: 0.4932  val_loss_rpn_cls: 0.04106  val_loss_rpn_loc: 0.01394  time: 0.8594  data_time: 0.0069  lr: 0.00059941  max_mem: 4747M
[32m[03/28 22:26:00 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.6594  loss_cls: 0.08885  loss_box_reg: 0.2885  loss_mask: 0.1845  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.007518  total_val_loss: 1.238  val_loss_cls: 0.2945  val_loss_box_reg: 0.4531  val_loss_mask: 0.4915  val_loss_rpn_cls: 0.02698  val_loss_rpn_loc: 0.01671  time: 0.8633  data_time: 0.0069  lr: 0.00079921  max_mem: 4747M
[32m[03/28 22:26:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:26:24 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:26:24 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:26:24 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:26:25 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4538  loss_cls: 0.05337  loss_box_reg: 0.2014  loss_mask: 0.1439  loss_rpn_cls: 0.008644  loss_rpn_loc: 0.00982  total_val_loss: 1.012  val_loss_cls: 0.2199  val_loss_box_reg: 0.2969  val_loss_mask: 0.3658  val_loss_rpn_cls: 0.02344  val_loss_rpn_loc: 0.0146  time: 0.8640  data_time: 0.0061  lr: 0.00099901  max_mem: 4747M
[32m[03/28 22:26:49 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3558  loss_cls: 0.05075  loss_box_reg: 0.1241  loss_mask: 0.1382  loss_rpn_cls: 0.007996  loss_rpn_loc: 0.01283  total_val_loss: 0.7204  val_loss_cls: 0.1591  val_loss_box_reg: 0.2049  val_loss_mask: 0.3834  val_loss_rpn_cls: 0.01727  val_loss_rpn_loc: 0.01039  time: 0.8637  data_time: 0.0065  lr: 0.0011988  max_mem: 4747M
[32m[03/28 22:27:14 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3677  loss_cls: 0.0476  loss_box_reg: 0.09971  loss_mask: 0.1494  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.01002  total_val_loss: 0.6901  val_loss_cls: 0.1387  val_loss_box_reg: 0.2126  val_loss_mask: 0.3052  val_loss_rpn_cls: 0.02342  val_loss_rpn_loc: 0.01286  time: 0.8641  data_time: 0.0072  lr: 0.0013986  max_mem: 4747M
[32m[03/28 22:27:38 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.4025  loss_cls: 0.0586  loss_box_reg: 0.1371  loss_mask: 0.1586  loss_rpn_cls: 0.005294  loss_rpn_loc: 0.01019  total_val_loss: 0.6204  val_loss_cls: 0.1246  val_loss_box_reg: 0.1993  val_loss_mask: 0.279  val_loss_rpn_cls: 0.02509  val_loss_rpn_loc: 0.01726  time: 0.8654  data_time: 0.0070  lr: 0.0015984  max_mem: 4747M
[32m[03/28 22:28:03 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3723  loss_cls: 0.0508  loss_box_reg: 0.119  loss_mask: 0.1691  loss_rpn_cls: 0.004085  loss_rpn_loc: 0.006593  total_val_loss: 0.8605  val_loss_cls: 0.1829  val_loss_box_reg: 0.3112  val_loss_mask: 0.3052  val_loss_rpn_cls: 0.01654  val_loss_rpn_loc: 0.01367  time: 0.8654  data_time: 0.0070  lr: 0.0017982  max_mem: 4747M
[32m[03/28 22:28:28 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:28:28 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:28:29 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:28:29 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:28:29 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3089  loss_cls: 0.0505  loss_box_reg: 0.09104  loss_mask: 0.1367  loss_rpn_cls: 0.007368  loss_rpn_loc: 0.0103  total_val_loss: 0.9402  val_loss_cls: 0.2117  val_loss_box_reg: 0.3305  val_loss_mask: 0.3296  val_loss_rpn_cls: 0.02086  val_loss_rpn_loc: 0.0127  time: 0.8660  data_time: 0.0066  lr: 0.001998  max_mem: 4747M
[32m[03/28 22:28:29 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8660 s / it)
[32m[03/28 22:28:29 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/28 22:28:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:28:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:28:29 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:28:29 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 22:28:29 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 22:28:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:28:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:28:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 22:28:30 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 22:28:33 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2247 s / img. ETA=0:13:57
[32m[03/28 22:28:38 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2279 s / img. ETA=0:13:56
[32m[03/28 22:28:43 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2282 s / img. ETA=0:13:51
[32m[03/28 22:28:49 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2305 s / img. ETA=0:13:51
[32m[03/28 22:28:54 d2.evaluation.evaluator]: [0mInference done 95/3489. 0.2303 s / img. ETA=0:13:51
[32m[03/28 22:28:59 d2.evaluation.evaluator]: [0mInference done 114/3489. 0.2314 s / img. ETA=0:14:00
[32m[03/28 22:29:04 d2.evaluation.evaluator]: [0mInference done 131/3489. 0.2332 s / img. ETA=0:14:17
[32m[03/28 22:29:09 d2.evaluation.evaluator]: [0mInference done 147/3489. 0.2352 s / img. ETA=0:14:36
[32m[03/28 22:29:14 d2.evaluation.evaluator]: [0mInference done 163/3489. 0.2374 s / img. ETA=0:14:53
[32m[03/28 22:29:19 d2.evaluation.evaluator]: [0mInference done 179/3489. 0.2387 s / img. ETA=0:15:02
[32m[03/28 22:29:24 d2.evaluation.evaluator]: [0mInference done 196/3489. 0.2393 s / img. ETA=0:15:04
[32m[03/28 22:29:29 d2.evaluation.evaluator]: [0mInference done 216/3489. 0.2386 s / img. ETA=0:14:51
[32m[03/28 22:29:34 d2.evaluation.evaluator]: [0mInference done 236/3489. 0.2379 s / img. ETA=0:14:40
[32m[03/28 22:29:39 d2.evaluation.evaluator]: [0mInference done 255/3489. 0.2377 s / img. ETA=0:14:35
[32m[03/28 22:29:44 d2.evaluation.evaluator]: [0mInference done 274/3489. 0.2376 s / img. ETA=0:14:29
[32m[03/28 22:29:50 d2.evaluation.evaluator]: [0mInference done 293/3489. 0.2374 s / img. ETA=0:14:23
[32m[03/28 22:29:55 d2.evaluation.evaluator]: [0mInference done 311/3489. 0.2377 s / img. ETA=0:14:20
[32m[03/28 22:30:00 d2.evaluation.evaluator]: [0mInference done 329/3489. 0.2380 s / img. ETA=0:14:18
[32m[03/28 22:30:05 d2.evaluation.evaluator]: [0mInference done 346/3489. 0.2384 s / img. ETA=0:14:17
[32m[03/28 22:30:10 d2.evaluation.evaluator]: [0mInference done 364/3489. 0.2385 s / img. ETA=0:14:13
[32m[03/28 22:30:15 d2.evaluation.evaluator]: [0mInference done 383/3489. 0.2385 s / img. ETA=0:14:09
[32m[03/28 22:30:20 d2.evaluation.evaluator]: [0mInference done 402/3489. 0.2386 s / img. ETA=0:14:03
[32m[03/28 22:30:25 d2.evaluation.evaluator]: [0mInference done 420/3489. 0.2387 s / img. ETA=0:14:00
[32m[03/28 22:30:31 d2.evaluation.evaluator]: [0mInference done 441/3489. 0.2384 s / img. ETA=0:13:50
[32m[03/28 22:30:36 d2.evaluation.evaluator]: [0mInference done 462/3489. 0.2380 s / img. ETA=0:13:40
[32m[03/28 22:30:41 d2.evaluation.evaluator]: [0mInference done 483/3489. 0.2377 s / img. ETA=0:13:31
[32m[03/28 22:30:46 d2.evaluation.evaluator]: [0mInference done 504/3489. 0.2373 s / img. ETA=0:13:21
[32m[03/28 22:30:51 d2.evaluation.evaluator]: [0mInference done 525/3489. 0.2369 s / img. ETA=0:13:12
[32m[03/28 22:30:56 d2.evaluation.evaluator]: [0mInference done 547/3489. 0.2364 s / img. ETA=0:13:02
[32m[03/28 22:31:01 d2.evaluation.evaluator]: [0mInference done 567/3489. 0.2362 s / img. ETA=0:12:56
[32m[03/28 22:31:06 d2.evaluation.evaluator]: [0mInference done 585/3489. 0.2366 s / img. ETA=0:12:52
[32m[03/28 22:31:11 d2.evaluation.evaluator]: [0mInference done 604/3489. 0.2366 s / img. ETA=0:12:48
[32m[03/28 22:31:16 d2.evaluation.evaluator]: [0mInference done 623/3489. 0.2367 s / img. ETA=0:12:43
[32m[03/28 22:31:21 d2.evaluation.evaluator]: [0mInference done 641/3489. 0.2368 s / img. ETA=0:12:39
[32m[03/28 22:31:26 d2.evaluation.evaluator]: [0mInference done 660/3489. 0.2368 s / img. ETA=0:12:34
[32m[03/28 22:31:32 d2.evaluation.evaluator]: [0mInference done 680/3489. 0.2367 s / img. ETA=0:12:28
[32m[03/28 22:31:37 d2.evaluation.evaluator]: [0mInference done 701/3489. 0.2365 s / img. ETA=0:12:20
[32m[03/28 22:31:42 d2.evaluation.evaluator]: [0mInference done 722/3489. 0.2364 s / img. ETA=0:12:13
[32m[03/28 22:31:47 d2.evaluation.evaluator]: [0mInference done 743/3489. 0.2362 s / img. ETA=0:12:06
[32m[03/28 22:31:52 d2.evaluation.evaluator]: [0mInference done 764/3489. 0.2360 s / img. ETA=0:11:59
[32m[03/28 22:31:57 d2.evaluation.evaluator]: [0mInference done 786/3489. 0.2357 s / img. ETA=0:11:50
[32m[03/28 22:32:02 d2.evaluation.evaluator]: [0mInference done 808/3489. 0.2354 s / img. ETA=0:11:42
[32m[03/28 22:32:07 d2.evaluation.evaluator]: [0mInference done 830/3489. 0.2352 s / img. ETA=0:11:35
[32m[03/28 22:32:13 d2.evaluation.evaluator]: [0mInference done 852/3489. 0.2350 s / img. ETA=0:11:27
[32m[03/28 22:32:18 d2.evaluation.evaluator]: [0mInference done 874/3489. 0.2348 s / img. ETA=0:11:20
[32m[03/28 22:32:23 d2.evaluation.evaluator]: [0mInference done 896/3489. 0.2346 s / img. ETA=0:11:12
[32m[03/28 22:32:28 d2.evaluation.evaluator]: [0mInference done 914/3489. 0.2348 s / img. ETA=0:11:09
[32m[03/28 22:32:33 d2.evaluation.evaluator]: [0mInference done 931/3489. 0.2350 s / img. ETA=0:11:06
[32m[03/28 22:32:38 d2.evaluation.evaluator]: [0mInference done 948/3489. 0.2353 s / img. ETA=0:11:04
[32m[03/28 22:32:43 d2.evaluation.evaluator]: [0mInference done 965/3489. 0.2356 s / img. ETA=0:11:01
[32m[03/28 22:32:49 d2.evaluation.evaluator]: [0mInference done 981/3489. 0.2359 s / img. ETA=0:10:59
[32m[03/28 22:32:54 d2.evaluation.evaluator]: [0mInference done 997/3489. 0.2361 s / img. ETA=0:10:57
[32m[03/28 22:32:59 d2.evaluation.evaluator]: [0mInference done 1013/3489. 0.2364 s / img. ETA=0:10:55
[32m[03/28 22:33:04 d2.evaluation.evaluator]: [0mInference done 1029/3489. 0.2367 s / img. ETA=0:10:53
[32m[03/28 22:33:09 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2370 s / img. ETA=0:10:50
[32m[03/28 22:33:14 d2.evaluation.evaluator]: [0mInference done 1061/3489. 0.2372 s / img. ETA=0:10:48
[32m[03/28 22:33:19 d2.evaluation.evaluator]: [0mInference done 1078/3489. 0.2373 s / img. ETA=0:10:45
[32m[03/28 22:33:24 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2374 s / img. ETA=0:10:40
[32m[03/28 22:33:29 d2.evaluation.evaluator]: [0mInference done 1116/3489. 0.2375 s / img. ETA=0:10:35
[32m[03/28 22:33:34 d2.evaluation.evaluator]: [0mInference done 1133/3489. 0.2377 s / img. ETA=0:10:32
[32m[03/28 22:33:40 d2.evaluation.evaluator]: [0mInference done 1151/3489. 0.2378 s / img. ETA=0:10:28
[32m[03/28 22:33:45 d2.evaluation.evaluator]: [0mInference done 1168/3489. 0.2379 s / img. ETA=0:10:24
[32m[03/28 22:33:50 d2.evaluation.evaluator]: [0mInference done 1186/3489. 0.2380 s / img. ETA=0:10:20
[32m[03/28 22:33:55 d2.evaluation.evaluator]: [0mInference done 1204/3489. 0.2381 s / img. ETA=0:10:16
[32m[03/28 22:34:00 d2.evaluation.evaluator]: [0mInference done 1223/3489. 0.2381 s / img. ETA=0:10:11
[32m[03/28 22:34:05 d2.evaluation.evaluator]: [0mInference done 1242/3489. 0.2381 s / img. ETA=0:10:06
[32m[03/28 22:34:10 d2.evaluation.evaluator]: [0mInference done 1262/3489. 0.2380 s / img. ETA=0:10:00
[32m[03/28 22:34:16 d2.evaluation.evaluator]: [0mInference done 1284/3489. 0.2378 s / img. ETA=0:09:52
[32m[03/28 22:34:21 d2.evaluation.evaluator]: [0mInference done 1306/3489. 0.2376 s / img. ETA=0:09:45
[32m[03/28 22:34:26 d2.evaluation.evaluator]: [0mInference done 1328/3489. 0.2374 s / img. ETA=0:09:38
[32m[03/28 22:34:31 d2.evaluation.evaluator]: [0mInference done 1349/3489. 0.2373 s / img. ETA=0:09:31
[32m[03/28 22:34:36 d2.evaluation.evaluator]: [0mInference done 1370/3489. 0.2372 s / img. ETA=0:09:25
[32m[03/28 22:34:41 d2.evaluation.evaluator]: [0mInference done 1391/3489. 0.2371 s / img. ETA=0:09:18
[32m[03/28 22:34:46 d2.evaluation.evaluator]: [0mInference done 1412/3489. 0.2370 s / img. ETA=0:09:12
[32m[03/28 22:34:51 d2.evaluation.evaluator]: [0mInference done 1433/3489. 0.2368 s / img. ETA=0:09:06
[32m[03/28 22:34:56 d2.evaluation.evaluator]: [0mInference done 1454/3489. 0.2368 s / img. ETA=0:09:00
[32m[03/28 22:35:01 d2.evaluation.evaluator]: [0mInference done 1475/3489. 0.2367 s / img. ETA=0:08:53
[32m[03/28 22:35:07 d2.evaluation.evaluator]: [0mInference done 1497/3489. 0.2365 s / img. ETA=0:08:47
[32m[03/28 22:35:12 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2364 s / img. ETA=0:08:40
[32m[03/28 22:35:17 d2.evaluation.evaluator]: [0mInference done 1540/3489. 0.2363 s / img. ETA=0:08:34
[32m[03/28 22:35:22 d2.evaluation.evaluator]: [0mInference done 1561/3489. 0.2362 s / img. ETA=0:08:28
[32m[03/28 22:35:27 d2.evaluation.evaluator]: [0mInference done 1582/3489. 0.2361 s / img. ETA=0:08:22
[32m[03/28 22:35:32 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2361 s / img. ETA=0:08:16
[32m[03/28 22:35:37 d2.evaluation.evaluator]: [0mInference done 1621/3489. 0.2361 s / img. ETA=0:08:11
[32m[03/28 22:35:42 d2.evaluation.evaluator]: [0mInference done 1640/3489. 0.2361 s / img. ETA=0:08:07
[32m[03/28 22:35:47 d2.evaluation.evaluator]: [0mInference done 1659/3489. 0.2361 s / img. ETA=0:08:02
[32m[03/28 22:35:53 d2.evaluation.evaluator]: [0mInference done 1677/3489. 0.2362 s / img. ETA=0:07:57
[32m[03/28 22:35:58 d2.evaluation.evaluator]: [0mInference done 1694/3489. 0.2363 s / img. ETA=0:07:53
[32m[03/28 22:36:03 d2.evaluation.evaluator]: [0mInference done 1711/3489. 0.2364 s / img. ETA=0:07:50
[32m[03/28 22:36:08 d2.evaluation.evaluator]: [0mInference done 1728/3489. 0.2365 s / img. ETA=0:07:46
[32m[03/28 22:36:13 d2.evaluation.evaluator]: [0mInference done 1744/3489. 0.2366 s / img. ETA=0:07:42
[32m[03/28 22:36:18 d2.evaluation.evaluator]: [0mInference done 1760/3489. 0.2368 s / img. ETA=0:07:39
[32m[03/28 22:36:23 d2.evaluation.evaluator]: [0mInference done 1776/3489. 0.2370 s / img. ETA=0:07:35
[32m[03/28 22:36:28 d2.evaluation.evaluator]: [0mInference done 1792/3489. 0.2371 s / img. ETA=0:07:32
[32m[03/28 22:36:33 d2.evaluation.evaluator]: [0mInference done 1808/3489. 0.2373 s / img. ETA=0:07:28
[32m[03/28 22:36:38 d2.evaluation.evaluator]: [0mInference done 1824/3489. 0.2374 s / img. ETA=0:07:25
[32m[03/28 22:36:44 d2.evaluation.evaluator]: [0mInference done 1840/3489. 0.2376 s / img. ETA=0:07:22
[32m[03/28 22:36:49 d2.evaluation.evaluator]: [0mInference done 1856/3489. 0.2377 s / img. ETA=0:07:18
[32m[03/28 22:36:54 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2378 s / img. ETA=0:07:14
[32m[03/28 22:36:59 d2.evaluation.evaluator]: [0mInference done 1888/3489. 0.2380 s / img. ETA=0:07:11
[32m[03/28 22:37:04 d2.evaluation.evaluator]: [0mInference done 1904/3489. 0.2381 s / img. ETA=0:07:07
[32m[03/28 22:37:09 d2.evaluation.evaluator]: [0mInference done 1920/3489. 0.2383 s / img. ETA=0:07:04
[32m[03/28 22:37:15 d2.evaluation.evaluator]: [0mInference done 1936/3489. 0.2384 s / img. ETA=0:07:00
[32m[03/28 22:37:20 d2.evaluation.evaluator]: [0mInference done 1952/3489. 0.2385 s / img. ETA=0:06:56
[32m[03/28 22:37:25 d2.evaluation.evaluator]: [0mInference done 1968/3489. 0.2386 s / img. ETA=0:06:53
[32m[03/28 22:37:30 d2.evaluation.evaluator]: [0mInference done 1984/3489. 0.2388 s / img. ETA=0:06:49
[32m[03/28 22:37:35 d2.evaluation.evaluator]: [0mInference done 2002/3489. 0.2388 s / img. ETA=0:06:44
[32m[03/28 22:37:40 d2.evaluation.evaluator]: [0mInference done 2020/3489. 0.2389 s / img. ETA=0:06:39
[32m[03/28 22:37:45 d2.evaluation.evaluator]: [0mInference done 2038/3489. 0.2389 s / img. ETA=0:06:35
[32m[03/28 22:37:50 d2.evaluation.evaluator]: [0mInference done 2055/3489. 0.2389 s / img. ETA=0:06:30
[32m[03/28 22:37:56 d2.evaluation.evaluator]: [0mInference done 2072/3489. 0.2390 s / img. ETA=0:06:26
[32m[03/28 22:38:01 d2.evaluation.evaluator]: [0mInference done 2089/3489. 0.2391 s / img. ETA=0:06:22
[32m[03/28 22:38:06 d2.evaluation.evaluator]: [0mInference done 2105/3489. 0.2392 s / img. ETA=0:06:18
[32m[03/28 22:38:11 d2.evaluation.evaluator]: [0mInference done 2122/3489. 0.2393 s / img. ETA=0:06:14
[32m[03/28 22:38:17 d2.evaluation.evaluator]: [0mInference done 2138/3489. 0.2394 s / img. ETA=0:06:10
[32m[03/28 22:38:22 d2.evaluation.evaluator]: [0mInference done 2154/3489. 0.2396 s / img. ETA=0:06:06
[32m[03/28 22:38:27 d2.evaluation.evaluator]: [0mInference done 2170/3489. 0.2397 s / img. ETA=0:06:02
[32m[03/28 22:38:32 d2.evaluation.evaluator]: [0mInference done 2186/3489. 0.2398 s / img. ETA=0:05:58
[32m[03/28 22:38:37 d2.evaluation.evaluator]: [0mInference done 2202/3489. 0.2399 s / img. ETA=0:05:54
[32m[03/28 22:38:42 d2.evaluation.evaluator]: [0mInference done 2218/3489. 0.2400 s / img. ETA=0:05:50
[32m[03/28 22:38:47 d2.evaluation.evaluator]: [0mInference done 2234/3489. 0.2401 s / img. ETA=0:05:46
[32m[03/28 22:38:52 d2.evaluation.evaluator]: [0mInference done 2251/3489. 0.2402 s / img. ETA=0:05:42
[32m[03/28 22:38:57 d2.evaluation.evaluator]: [0mInference done 2268/3489. 0.2402 s / img. ETA=0:05:37
[32m[03/28 22:39:03 d2.evaluation.evaluator]: [0mInference done 2285/3489. 0.2403 s / img. ETA=0:05:33
[32m[03/28 22:39:08 d2.evaluation.evaluator]: [0mInference done 2302/3489. 0.2404 s / img. ETA=0:05:28
[32m[03/28 22:39:13 d2.evaluation.evaluator]: [0mInference done 2318/3489. 0.2405 s / img. ETA=0:05:24
[32m[03/28 22:39:18 d2.evaluation.evaluator]: [0mInference done 2334/3489. 0.2405 s / img. ETA=0:05:20
[32m[03/28 22:39:23 d2.evaluation.evaluator]: [0mInference done 2351/3489. 0.2406 s / img. ETA=0:05:16
[32m[03/28 22:39:28 d2.evaluation.evaluator]: [0mInference done 2369/3489. 0.2406 s / img. ETA=0:05:11
[32m[03/28 22:39:33 d2.evaluation.evaluator]: [0mInference done 2388/3489. 0.2406 s / img. ETA=0:05:05
[32m[03/28 22:39:39 d2.evaluation.evaluator]: [0mInference done 2407/3489. 0.2406 s / img. ETA=0:05:00
[32m[03/28 22:39:44 d2.evaluation.evaluator]: [0mInference done 2426/3489. 0.2405 s / img. ETA=0:04:55
[32m[03/28 22:39:49 d2.evaluation.evaluator]: [0mInference done 2444/3489. 0.2406 s / img. ETA=0:04:50
[32m[03/28 22:39:54 d2.evaluation.evaluator]: [0mInference done 2461/3489. 0.2406 s / img. ETA=0:04:45
[32m[03/28 22:39:59 d2.evaluation.evaluator]: [0mInference done 2477/3489. 0.2407 s / img. ETA=0:04:41
[32m[03/28 22:40:04 d2.evaluation.evaluator]: [0mInference done 2495/3489. 0.2407 s / img. ETA=0:04:36
[32m[03/28 22:40:09 d2.evaluation.evaluator]: [0mInference done 2516/3489. 0.2406 s / img. ETA=0:04:30
[32m[03/28 22:40:14 d2.evaluation.evaluator]: [0mInference done 2536/3489. 0.2405 s / img. ETA=0:04:24
[32m[03/28 22:40:19 d2.evaluation.evaluator]: [0mInference done 2556/3489. 0.2405 s / img. ETA=0:04:18
[32m[03/28 22:40:25 d2.evaluation.evaluator]: [0mInference done 2576/3489. 0.2404 s / img. ETA=0:04:13
[32m[03/28 22:40:30 d2.evaluation.evaluator]: [0mInference done 2597/3489. 0.2403 s / img. ETA=0:04:07
[32m[03/28 22:40:35 d2.evaluation.evaluator]: [0mInference done 2618/3489. 0.2402 s / img. ETA=0:04:01
[32m[03/28 22:40:40 d2.evaluation.evaluator]: [0mInference done 2640/3489. 0.2401 s / img. ETA=0:03:54
[32m[03/28 22:40:45 d2.evaluation.evaluator]: [0mInference done 2661/3489. 0.2400 s / img. ETA=0:03:48
[32m[03/28 22:40:50 d2.evaluation.evaluator]: [0mInference done 2681/3489. 0.2400 s / img. ETA=0:03:42
[32m[03/28 22:40:55 d2.evaluation.evaluator]: [0mInference done 2701/3489. 0.2399 s / img. ETA=0:03:37
[32m[03/28 22:41:00 d2.evaluation.evaluator]: [0mInference done 2721/3489. 0.2398 s / img. ETA=0:03:31
[32m[03/28 22:41:05 d2.evaluation.evaluator]: [0mInference done 2741/3489. 0.2398 s / img. ETA=0:03:26
[32m[03/28 22:41:11 d2.evaluation.evaluator]: [0mInference done 2761/3489. 0.2397 s / img. ETA=0:03:20
[32m[03/28 22:41:16 d2.evaluation.evaluator]: [0mInference done 2781/3489. 0.2397 s / img. ETA=0:03:14
[32m[03/28 22:41:21 d2.evaluation.evaluator]: [0mInference done 2801/3489. 0.2396 s / img. ETA=0:03:09
[32m[03/28 22:41:26 d2.evaluation.evaluator]: [0mInference done 2821/3489. 0.2396 s / img. ETA=0:03:03
[32m[03/28 22:41:31 d2.evaluation.evaluator]: [0mInference done 2841/3489. 0.2395 s / img. ETA=0:02:58
[32m[03/28 22:41:36 d2.evaluation.evaluator]: [0mInference done 2861/3489. 0.2395 s / img. ETA=0:02:52
[32m[03/28 22:41:41 d2.evaluation.evaluator]: [0mInference done 2880/3489. 0.2395 s / img. ETA=0:02:47
[32m[03/28 22:41:46 d2.evaluation.evaluator]: [0mInference done 2901/3489. 0.2394 s / img. ETA=0:02:41
[32m[03/28 22:41:51 d2.evaluation.evaluator]: [0mInference done 2922/3489. 0.2394 s / img. ETA=0:02:35
[32m[03/28 22:41:56 d2.evaluation.evaluator]: [0mInference done 2943/3489. 0.2393 s / img. ETA=0:02:29
[32m[03/28 22:42:01 d2.evaluation.evaluator]: [0mInference done 2964/3489. 0.2392 s / img. ETA=0:02:23
[32m[03/28 22:42:07 d2.evaluation.evaluator]: [0mInference done 2985/3489. 0.2392 s / img. ETA=0:02:17
[32m[03/28 22:42:12 d2.evaluation.evaluator]: [0mInference done 3005/3489. 0.2391 s / img. ETA=0:02:12
[32m[03/28 22:42:17 d2.evaluation.evaluator]: [0mInference done 3025/3489. 0.2391 s / img. ETA=0:02:06
[32m[03/28 22:42:22 d2.evaluation.evaluator]: [0mInference done 3046/3489. 0.2390 s / img. ETA=0:02:00
[32m[03/28 22:42:27 d2.evaluation.evaluator]: [0mInference done 3066/3489. 0.2389 s / img. ETA=0:01:55
[32m[03/28 22:42:32 d2.evaluation.evaluator]: [0mInference done 3086/3489. 0.2389 s / img. ETA=0:01:49
[32m[03/28 22:42:37 d2.evaluation.evaluator]: [0mInference done 3106/3489. 0.2389 s / img. ETA=0:01:44
[32m[03/28 22:42:42 d2.evaluation.evaluator]: [0mInference done 3126/3489. 0.2388 s / img. ETA=0:01:38
[32m[03/28 22:42:47 d2.evaluation.evaluator]: [0mInference done 3146/3489. 0.2388 s / img. ETA=0:01:33
[32m[03/28 22:42:52 d2.evaluation.evaluator]: [0mInference done 3166/3489. 0.2387 s / img. ETA=0:01:27
[32m[03/28 22:42:58 d2.evaluation.evaluator]: [0mInference done 3187/3489. 0.2387 s / img. ETA=0:01:22
[32m[03/28 22:43:03 d2.evaluation.evaluator]: [0mInference done 3208/3489. 0.2386 s / img. ETA=0:01:16
[32m[03/28 22:43:08 d2.evaluation.evaluator]: [0mInference done 3228/3489. 0.2386 s / img. ETA=0:01:10
[32m[03/28 22:43:13 d2.evaluation.evaluator]: [0mInference done 3248/3489. 0.2385 s / img. ETA=0:01:05
[32m[03/28 22:43:18 d2.evaluation.evaluator]: [0mInference done 3269/3489. 0.2384 s / img. ETA=0:00:59
[32m[03/28 22:43:23 d2.evaluation.evaluator]: [0mInference done 3291/3489. 0.2383 s / img. ETA=0:00:53
[32m[03/28 22:43:28 d2.evaluation.evaluator]: [0mInference done 3313/3489. 0.2383 s / img. ETA=0:00:47
[32m[03/28 22:43:33 d2.evaluation.evaluator]: [0mInference done 3335/3489. 0.2382 s / img. ETA=0:00:41
[32m[03/28 22:43:38 d2.evaluation.evaluator]: [0mInference done 3357/3489. 0.2381 s / img. ETA=0:00:35
[32m[03/28 22:43:44 d2.evaluation.evaluator]: [0mInference done 3379/3489. 0.2381 s / img. ETA=0:00:29
[32m[03/28 22:43:49 d2.evaluation.evaluator]: [0mInference done 3401/3489. 0.2380 s / img. ETA=0:00:23
[32m[03/28 22:43:54 d2.evaluation.evaluator]: [0mInference done 3422/3489. 0.2379 s / img. ETA=0:00:18
[32m[03/28 22:43:59 d2.evaluation.evaluator]: [0mInference done 3443/3489. 0.2379 s / img. ETA=0:00:12
[32m[03/28 22:44:04 d2.evaluation.evaluator]: [0mInference done 3464/3489. 0.2378 s / img. ETA=0:00:06
[32m[03/28 22:44:09 d2.evaluation.evaluator]: [0mInference done 3485/3489. 0.2378 s / img. ETA=0:00:01
[32m[03/28 22:44:10 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:38.703164 (0.269433 s / img per device, on 1 devices)
[32m[03/28 22:44:10 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:48 (0.237772 s / img per device, on 1 devices)
[32m[03/28 22:44:12 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 22:44:12 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.500000/coco_instances_results.json
[32m[03/28 22:44:13 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.38 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.48 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[32m[03/28 22:44:15 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.023 | 76.609 | 41.797 | 29.840 | 53.061 | 60.951 |
[32m[03/28 22:44:15 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.673 | Pedestrian | 28.374 |
Loading and preparing results...
DONE (t=1.73s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.24 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734
[32m[03/28 22:44:24 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.827 | 72.044 | 38.517 | 21.539 | 47.940 | 67.108 |
[32m[03/28 22:44:24 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.340 | Pedestrian | 20.314 |
[32m[03/28 22:44:24 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: 45.0235,76.6088,41.7965,29.8400,53.0612,60.9508
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:44:24 d2.evaluation.testing]: [0mcopypaste: 40.8265,72.0442,38.5168,21.5388,47.9400,67.1078
evaluated
Test [0.200000, 0.700000]
[32m[03/28 22:44:25 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 22:44:25 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 22:44:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:44:26 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:44:26 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 22:44:26 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 22:44:26 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 22:44:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 22:44:26 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 22:44:26 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 22:44:26 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 22:44:26 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 22:44:51 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.749  loss_cls: 0.6764  loss_box_reg: 0.2794  loss_mask: 0.663  loss_rpn_cls: 0.01891  loss_rpn_loc: 0.009128  total_val_loss: 1.928  val_loss_cls: 0.6856  val_loss_box_reg: 0.4842  val_loss_mask: 0.6709  val_loss_rpn_cls: 0.03163  val_loss_rpn_loc: 0.01138  time: 0.8434  data_time: 0.0269  lr: 0.00019981  max_mem: 4747M
[32m[03/28 22:45:16 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.9326  loss_cls: 0.199  loss_box_reg: 0.2984  loss_mask: 0.3608  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.005793  total_val_loss: 1.335  val_loss_cls: 0.3339  val_loss_box_reg: 0.5748  val_loss_mask: 0.4111  val_loss_rpn_cls: 0.02432  val_loss_rpn_loc: 0.01185  time: 0.8511  data_time: 0.0071  lr: 0.00039961  max_mem: 4747M
[32m[03/28 22:45:40 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.6057  loss_cls: 0.09036  loss_box_reg: 0.2706  loss_mask: 0.1975  loss_rpn_cls: 0.009281  loss_rpn_loc: 0.006091  total_val_loss: 1.298  val_loss_cls: 0.2887  val_loss_box_reg: 0.4316  val_loss_mask: 0.5159  val_loss_rpn_cls: 0.02942  val_loss_rpn_loc: 0.01486  time: 0.8523  data_time: 0.0058  lr: 0.00059941  max_mem: 4747M
[32m[03/28 22:46:04 d2.utils.events]: [0m eta: 0:01:41  iter: 79  total_loss: 0.5647  loss_cls: 0.0654  loss_box_reg: 0.2543  loss_mask: 0.1811  loss_rpn_cls: 0.006708  loss_rpn_loc: 0.007753  total_val_loss: 0.92  val_loss_cls: 0.1821  val_loss_box_reg: 0.4052  val_loss_mask: 0.3491  val_loss_rpn_cls: 0.0141  val_loss_rpn_loc: 0.01337  time: 0.8538  data_time: 0.0072  lr: 0.00079921  max_mem: 4747M
[32m[03/28 22:46:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:46:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:46:29 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:46:29 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:46:29 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.4685  loss_cls: 0.06603  loss_box_reg: 0.1929  loss_mask: 0.1712  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.008817  total_val_loss: 0.8423  val_loss_cls: 0.1689  val_loss_box_reg: 0.2612  val_loss_mask: 0.3917  val_loss_rpn_cls: 0.02208  val_loss_rpn_loc: 0.01146  time: 0.8545  data_time: 0.0064  lr: 0.00099901  max_mem: 4747M
[32m[03/28 22:46:53 d2.utils.events]: [0m eta: 0:01:07  iter: 119  total_loss: 0.3478  loss_cls: 0.04678  loss_box_reg: 0.1081  loss_mask: 0.1445  loss_rpn_cls: 0.005302  loss_rpn_loc: 0.007993  total_val_loss: 1.051  val_loss_cls: 0.2328  val_loss_box_reg: 0.2554  val_loss_mask: 0.4474  val_loss_rpn_cls: 0.02032  val_loss_rpn_loc: 0.01264  time: 0.8559  data_time: 0.0062  lr: 0.0011988  max_mem: 4747M
[32m[03/28 22:47:18 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3056  loss_cls: 0.04267  loss_box_reg: 0.09749  loss_mask: 0.1252  loss_rpn_cls: 0.004821  loss_rpn_loc: 0.008574  total_val_loss: 0.6913  val_loss_cls: 0.1358  val_loss_box_reg: 0.1885  val_loss_mask: 0.3496  val_loss_rpn_cls: 0.01828  val_loss_rpn_loc: 0.01186  time: 0.8572  data_time: 0.0072  lr: 0.0013986  max_mem: 4747M
[32m[03/28 22:47:42 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3076  loss_cls: 0.05108  loss_box_reg: 0.1063  loss_mask: 0.14  loss_rpn_cls: 0.005768  loss_rpn_loc: 0.008693  total_val_loss: 0.9034  val_loss_cls: 0.1949  val_loss_box_reg: 0.2814  val_loss_mask: 0.3999  val_loss_rpn_cls: 0.02537  val_loss_rpn_loc: 0.01292  time: 0.8576  data_time: 0.0063  lr: 0.0015984  max_mem: 4747M
[32m[03/28 22:48:07 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3417  loss_cls: 0.0601  loss_box_reg: 0.1122  loss_mask: 0.156  loss_rpn_cls: 0.006496  loss_rpn_loc: 0.01176  total_val_loss: 0.957  val_loss_cls: 0.2118  val_loss_box_reg: 0.2865  val_loss_mask: 0.3228  val_loss_rpn_cls: 0.02131  val_loss_rpn_loc: 0.01814  time: 0.8589  data_time: 0.0067  lr: 0.0017982  max_mem: 4747M
[32m[03/28 22:48:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:48:32 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:48:33 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:48:33 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 22:48:33 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3661  loss_cls: 0.05622  loss_box_reg: 0.1066  loss_mask: 0.1649  loss_rpn_cls: 0.005528  loss_rpn_loc: 0.00716  total_val_loss: 0.7742  val_loss_cls: 0.1395  val_loss_box_reg: 0.2055  val_loss_mask: 0.3448  val_loss_rpn_cls: 0.01515  val_loss_rpn_loc: 0.01191  time: 0.8602  data_time: 0.0077  lr: 0.001998  max_mem: 4747M
[32m[03/28 22:48:33 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8602 s / it)
[32m[03/28 22:48:33 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/28 22:48:33 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:48:33 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:48:33 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 22:48:33 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 22:48:33 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 22:48:34 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 22:48:34 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 22:48:34 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 22:48:34 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 22:48:37 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2270 s / img. ETA=0:14:31
[32m[03/28 22:48:43 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2265 s / img. ETA=0:14:11
[32m[03/28 22:48:48 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2267 s / img. ETA=0:13:59
[32m[03/28 22:48:53 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2275 s / img. ETA=0:13:51
[32m[03/28 22:48:58 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2282 s / img. ETA=0:13:53
[32m[03/28 22:49:03 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2301 s / img. ETA=0:14:05
[32m[03/28 22:49:08 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2322 s / img. ETA=0:14:22
[32m[03/28 22:49:13 d2.evaluation.evaluator]: [0mInference done 146/3489. 0.2349 s / img. ETA=0:14:43
[32m[03/28 22:49:18 d2.evaluation.evaluator]: [0mInference done 162/3489. 0.2369 s / img. ETA=0:14:58
[32m[03/28 22:49:23 d2.evaluation.evaluator]: [0mInference done 178/3489. 0.2384 s / img. ETA=0:15:08
[32m[03/28 22:49:29 d2.evaluation.evaluator]: [0mInference done 196/3489. 0.2391 s / img. ETA=0:15:09
[32m[03/28 22:49:34 d2.evaluation.evaluator]: [0mInference done 217/3489. 0.2381 s / img. ETA=0:14:54
[32m[03/28 22:49:39 d2.evaluation.evaluator]: [0mInference done 237/3489. 0.2377 s / img. ETA=0:14:44
[32m[03/28 22:49:44 d2.evaluation.evaluator]: [0mInference done 256/3489. 0.2378 s / img. ETA=0:14:40
[32m[03/28 22:49:49 d2.evaluation.evaluator]: [0mInference done 275/3489. 0.2378 s / img. ETA=0:14:35
[32m[03/28 22:49:55 d2.evaluation.evaluator]: [0mInference done 294/3489. 0.2377 s / img. ETA=0:14:30
[32m[03/28 22:50:00 d2.evaluation.evaluator]: [0mInference done 312/3489. 0.2380 s / img. ETA=0:14:27
[32m[03/28 22:50:05 d2.evaluation.evaluator]: [0mInference done 330/3489. 0.2382 s / img. ETA=0:14:24
[32m[03/28 22:50:10 d2.evaluation.evaluator]: [0mInference done 348/3489. 0.2384 s / img. ETA=0:14:21
[32m[03/28 22:50:15 d2.evaluation.evaluator]: [0mInference done 366/3489. 0.2385 s / img. ETA=0:14:17
[32m[03/28 22:50:20 d2.evaluation.evaluator]: [0mInference done 384/3489. 0.2386 s / img. ETA=0:14:14
[32m[03/28 22:50:25 d2.evaluation.evaluator]: [0mInference done 403/3489. 0.2387 s / img. ETA=0:14:08
[32m[03/28 22:50:31 d2.evaluation.evaluator]: [0mInference done 422/3489. 0.2387 s / img. ETA=0:14:03
[32m[03/28 22:50:36 d2.evaluation.evaluator]: [0mInference done 443/3489. 0.2383 s / img. ETA=0:13:52
[32m[03/28 22:50:41 d2.evaluation.evaluator]: [0mInference done 464/3489. 0.2379 s / img. ETA=0:13:43
[32m[03/28 22:50:46 d2.evaluation.evaluator]: [0mInference done 485/3489. 0.2376 s / img. ETA=0:13:33
[32m[03/28 22:50:51 d2.evaluation.evaluator]: [0mInference done 506/3489. 0.2372 s / img. ETA=0:13:24
[32m[03/28 22:50:56 d2.evaluation.evaluator]: [0mInference done 527/3489. 0.2368 s / img. ETA=0:13:15
[32m[03/28 22:51:01 d2.evaluation.evaluator]: [0mInference done 549/3489. 0.2365 s / img. ETA=0:13:05
[32m[03/28 22:51:06 d2.evaluation.evaluator]: [0mInference done 568/3489. 0.2365 s / img. ETA=0:13:00
[32m[03/28 22:51:11 d2.evaluation.evaluator]: [0mInference done 586/3489. 0.2367 s / img. ETA=0:12:56
[32m[03/28 22:51:16 d2.evaluation.evaluator]: [0mInference done 605/3489. 0.2368 s / img. ETA=0:12:52
[32m[03/28 22:51:22 d2.evaluation.evaluator]: [0mInference done 624/3489. 0.2368 s / img. ETA=0:12:47
[32m[03/28 22:51:27 d2.evaluation.evaluator]: [0mInference done 643/3489. 0.2369 s / img. ETA=0:12:42
[32m[03/28 22:51:32 d2.evaluation.evaluator]: [0mInference done 662/3489. 0.2368 s / img. ETA=0:12:36
[32m[03/28 22:51:37 d2.evaluation.evaluator]: [0mInference done 683/3489. 0.2366 s / img. ETA=0:12:29
[32m[03/28 22:51:42 d2.evaluation.evaluator]: [0mInference done 704/3489. 0.2364 s / img. ETA=0:12:21
[32m[03/28 22:51:47 d2.evaluation.evaluator]: [0mInference done 724/3489. 0.2364 s / img. ETA=0:12:15
[32m[03/28 22:51:52 d2.evaluation.evaluator]: [0mInference done 745/3489. 0.2362 s / img. ETA=0:12:08
[32m[03/28 22:51:57 d2.evaluation.evaluator]: [0mInference done 766/3489. 0.2359 s / img. ETA=0:12:01
[32m[03/28 22:52:03 d2.evaluation.evaluator]: [0mInference done 788/3489. 0.2357 s / img. ETA=0:11:53
[32m[03/28 22:52:08 d2.evaluation.evaluator]: [0mInference done 810/3489. 0.2355 s / img. ETA=0:11:45
[32m[03/28 22:52:13 d2.evaluation.evaluator]: [0mInference done 832/3489. 0.2352 s / img. ETA=0:11:37
[32m[03/28 22:52:18 d2.evaluation.evaluator]: [0mInference done 853/3489. 0.2352 s / img. ETA=0:11:31
[32m[03/28 22:52:23 d2.evaluation.evaluator]: [0mInference done 874/3489. 0.2350 s / img. ETA=0:11:24
[32m[03/28 22:52:28 d2.evaluation.evaluator]: [0mInference done 896/3489. 0.2348 s / img. ETA=0:11:16
[32m[03/28 22:52:34 d2.evaluation.evaluator]: [0mInference done 914/3489. 0.2350 s / img. ETA=0:11:13
[32m[03/28 22:52:39 d2.evaluation.evaluator]: [0mInference done 931/3489. 0.2352 s / img. ETA=0:11:10
[32m[03/28 22:52:44 d2.evaluation.evaluator]: [0mInference done 948/3489. 0.2355 s / img. ETA=0:11:07
[32m[03/28 22:52:49 d2.evaluation.evaluator]: [0mInference done 965/3489. 0.2357 s / img. ETA=0:11:05
[32m[03/28 22:52:54 d2.evaluation.evaluator]: [0mInference done 981/3489. 0.2360 s / img. ETA=0:11:02
[32m[03/28 22:52:59 d2.evaluation.evaluator]: [0mInference done 997/3489. 0.2362 s / img. ETA=0:11:00
[32m[03/28 22:53:04 d2.evaluation.evaluator]: [0mInference done 1014/3489. 0.2365 s / img. ETA=0:10:58
[32m[03/28 22:53:10 d2.evaluation.evaluator]: [0mInference done 1031/3489. 0.2367 s / img. ETA=0:10:55
[32m[03/28 22:53:15 d2.evaluation.evaluator]: [0mInference done 1048/3489. 0.2369 s / img. ETA=0:10:52
[32m[03/28 22:53:20 d2.evaluation.evaluator]: [0mInference done 1065/3489. 0.2371 s / img. ETA=0:10:49
[32m[03/28 22:53:25 d2.evaluation.evaluator]: [0mInference done 1083/3489. 0.2373 s / img. ETA=0:10:45
[32m[03/28 22:53:30 d2.evaluation.evaluator]: [0mInference done 1102/3489. 0.2373 s / img. ETA=0:10:40
[32m[03/28 22:53:36 d2.evaluation.evaluator]: [0mInference done 1121/3489. 0.2375 s / img. ETA=0:10:36
[32m[03/28 22:53:41 d2.evaluation.evaluator]: [0mInference done 1138/3489. 0.2376 s / img. ETA=0:10:32
[32m[03/28 22:53:46 d2.evaluation.evaluator]: [0mInference done 1155/3489. 0.2377 s / img. ETA=0:10:28
[32m[03/28 22:53:51 d2.evaluation.evaluator]: [0mInference done 1172/3489. 0.2378 s / img. ETA=0:10:25
[32m[03/28 22:53:56 d2.evaluation.evaluator]: [0mInference done 1190/3489. 0.2380 s / img. ETA=0:10:21
[32m[03/28 22:54:02 d2.evaluation.evaluator]: [0mInference done 1208/3489. 0.2381 s / img. ETA=0:10:17
[32m[03/28 22:54:07 d2.evaluation.evaluator]: [0mInference done 1226/3489. 0.2382 s / img. ETA=0:10:13
[32m[03/28 22:54:12 d2.evaluation.evaluator]: [0mInference done 1245/3489. 0.2382 s / img. ETA=0:10:08
[32m[03/28 22:54:17 d2.evaluation.evaluator]: [0mInference done 1265/3489. 0.2382 s / img. ETA=0:10:01
[32m[03/28 22:54:22 d2.evaluation.evaluator]: [0mInference done 1287/3489. 0.2380 s / img. ETA=0:09:54
[32m[03/28 22:54:27 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2379 s / img. ETA=0:09:47
[32m[03/28 22:54:32 d2.evaluation.evaluator]: [0mInference done 1329/3489. 0.2379 s / img. ETA=0:09:41
[32m[03/28 22:54:37 d2.evaluation.evaluator]: [0mInference done 1350/3489. 0.2378 s / img. ETA=0:09:34
[32m[03/28 22:54:42 d2.evaluation.evaluator]: [0mInference done 1371/3489. 0.2377 s / img. ETA=0:09:28
[32m[03/28 22:54:48 d2.evaluation.evaluator]: [0mInference done 1392/3489. 0.2376 s / img. ETA=0:09:21
[32m[03/28 22:54:53 d2.evaluation.evaluator]: [0mInference done 1413/3489. 0.2376 s / img. ETA=0:09:15
[32m[03/28 22:54:58 d2.evaluation.evaluator]: [0mInference done 1434/3489. 0.2374 s / img. ETA=0:09:09
[32m[03/28 22:55:03 d2.evaluation.evaluator]: [0mInference done 1455/3489. 0.2373 s / img. ETA=0:09:03
[32m[03/28 22:55:08 d2.evaluation.evaluator]: [0mInference done 1476/3489. 0.2372 s / img. ETA=0:08:56
[32m[03/28 22:55:13 d2.evaluation.evaluator]: [0mInference done 1498/3489. 0.2370 s / img. ETA=0:08:49
[32m[03/28 22:55:18 d2.evaluation.evaluator]: [0mInference done 1520/3489. 0.2369 s / img. ETA=0:08:43
[32m[03/28 22:55:24 d2.evaluation.evaluator]: [0mInference done 1541/3489. 0.2368 s / img. ETA=0:08:36
[32m[03/28 22:55:29 d2.evaluation.evaluator]: [0mInference done 1562/3489. 0.2367 s / img. ETA=0:08:30
[32m[03/28 22:55:34 d2.evaluation.evaluator]: [0mInference done 1583/3489. 0.2366 s / img. ETA=0:08:24
[32m[03/28 22:55:39 d2.evaluation.evaluator]: [0mInference done 1603/3489. 0.2366 s / img. ETA=0:08:19
[32m[03/28 22:55:44 d2.evaluation.evaluator]: [0mInference done 1622/3489. 0.2366 s / img. ETA=0:08:14
[32m[03/28 22:55:49 d2.evaluation.evaluator]: [0mInference done 1641/3489. 0.2366 s / img. ETA=0:08:09
[32m[03/28 22:55:55 d2.evaluation.evaluator]: [0mInference done 1660/3489. 0.2367 s / img. ETA=0:08:04
[32m[03/28 22:56:00 d2.evaluation.evaluator]: [0mInference done 1678/3489. 0.2367 s / img. ETA=0:08:00
[32m[03/28 22:56:05 d2.evaluation.evaluator]: [0mInference done 1695/3489. 0.2369 s / img. ETA=0:07:56
[32m[03/28 22:56:10 d2.evaluation.evaluator]: [0mInference done 1712/3489. 0.2370 s / img. ETA=0:07:52
[32m[03/28 22:56:15 d2.evaluation.evaluator]: [0mInference done 1729/3489. 0.2371 s / img. ETA=0:07:48
[32m[03/28 22:56:20 d2.evaluation.evaluator]: [0mInference done 1746/3489. 0.2372 s / img. ETA=0:07:44
[32m[03/28 22:56:25 d2.evaluation.evaluator]: [0mInference done 1762/3489. 0.2374 s / img. ETA=0:07:41
[32m[03/28 22:56:30 d2.evaluation.evaluator]: [0mInference done 1778/3489. 0.2375 s / img. ETA=0:07:38
[32m[03/28 22:56:36 d2.evaluation.evaluator]: [0mInference done 1794/3489. 0.2376 s / img. ETA=0:07:34
[32m[03/28 22:56:41 d2.evaluation.evaluator]: [0mInference done 1810/3489. 0.2378 s / img. ETA=0:07:30
[32m[03/28 22:56:46 d2.evaluation.evaluator]: [0mInference done 1826/3489. 0.2379 s / img. ETA=0:07:27
[32m[03/28 22:56:51 d2.evaluation.evaluator]: [0mInference done 1842/3489. 0.2380 s / img. ETA=0:07:24
[32m[03/28 22:56:56 d2.evaluation.evaluator]: [0mInference done 1858/3489. 0.2382 s / img. ETA=0:07:20
[32m[03/28 22:57:01 d2.evaluation.evaluator]: [0mInference done 1874/3489. 0.2383 s / img. ETA=0:07:16
[32m[03/28 22:57:06 d2.evaluation.evaluator]: [0mInference done 1890/3489. 0.2384 s / img. ETA=0:07:13
[32m[03/28 22:57:11 d2.evaluation.evaluator]: [0mInference done 1906/3489. 0.2385 s / img. ETA=0:07:09
[32m[03/28 22:57:17 d2.evaluation.evaluator]: [0mInference done 1922/3489. 0.2387 s / img. ETA=0:07:05
[32m[03/28 22:57:22 d2.evaluation.evaluator]: [0mInference done 1938/3489. 0.2388 s / img. ETA=0:07:01
[32m[03/28 22:57:27 d2.evaluation.evaluator]: [0mInference done 1954/3489. 0.2390 s / img. ETA=0:06:58
[32m[03/28 22:57:32 d2.evaluation.evaluator]: [0mInference done 1970/3489. 0.2391 s / img. ETA=0:06:54
[32m[03/28 22:57:37 d2.evaluation.evaluator]: [0mInference done 1986/3489. 0.2392 s / img. ETA=0:06:50
[32m[03/28 22:57:42 d2.evaluation.evaluator]: [0mInference done 2004/3489. 0.2393 s / img. ETA=0:06:46
[32m[03/28 22:57:48 d2.evaluation.evaluator]: [0mInference done 2022/3489. 0.2393 s / img. ETA=0:06:41
[32m[03/28 22:57:53 d2.evaluation.evaluator]: [0mInference done 2040/3489. 0.2393 s / img. ETA=0:06:36
[32m[03/28 22:57:58 d2.evaluation.evaluator]: [0mInference done 2057/3489. 0.2394 s / img. ETA=0:06:32
[32m[03/28 22:58:03 d2.evaluation.evaluator]: [0mInference done 2074/3489. 0.2395 s / img. ETA=0:06:27
[32m[03/28 22:58:08 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2395 s / img. ETA=0:06:23
[32m[03/28 22:58:14 d2.evaluation.evaluator]: [0mInference done 2108/3489. 0.2396 s / img. ETA=0:06:19
[32m[03/28 22:58:19 d2.evaluation.evaluator]: [0mInference done 2124/3489. 0.2398 s / img. ETA=0:06:15
[32m[03/28 22:58:24 d2.evaluation.evaluator]: [0mInference done 2140/3489. 0.2398 s / img. ETA=0:06:11
[32m[03/28 22:58:29 d2.evaluation.evaluator]: [0mInference done 2156/3489. 0.2399 s / img. ETA=0:06:07
[32m[03/28 22:58:34 d2.evaluation.evaluator]: [0mInference done 2172/3489. 0.2400 s / img. ETA=0:06:03
[32m[03/28 22:58:39 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2401 s / img. ETA=0:05:59
[32m[03/28 22:58:45 d2.evaluation.evaluator]: [0mInference done 2206/3489. 0.2402 s / img. ETA=0:05:54
[32m[03/28 22:58:50 d2.evaluation.evaluator]: [0mInference done 2223/3489. 0.2403 s / img. ETA=0:05:50
[32m[03/28 22:58:55 d2.evaluation.evaluator]: [0mInference done 2239/3489. 0.2404 s / img. ETA=0:05:46
[32m[03/28 22:59:00 d2.evaluation.evaluator]: [0mInference done 2257/3489. 0.2405 s / img. ETA=0:05:41
[32m[03/28 22:59:05 d2.evaluation.evaluator]: [0mInference done 2274/3489. 0.2405 s / img. ETA=0:05:36
[32m[03/28 22:59:10 d2.evaluation.evaluator]: [0mInference done 2292/3489. 0.2405 s / img. ETA=0:05:32
[32m[03/28 22:59:16 d2.evaluation.evaluator]: [0mInference done 2309/3489. 0.2406 s / img. ETA=0:05:27
[32m[03/28 22:59:21 d2.evaluation.evaluator]: [0mInference done 2326/3489. 0.2407 s / img. ETA=0:05:23
[32m[03/28 22:59:26 d2.evaluation.evaluator]: [0mInference done 2343/3489. 0.2407 s / img. ETA=0:05:18
[32m[03/28 22:59:31 d2.evaluation.evaluator]: [0mInference done 2360/3489. 0.2408 s / img. ETA=0:05:14
[32m[03/28 22:59:36 d2.evaluation.evaluator]: [0mInference done 2378/3489. 0.2408 s / img. ETA=0:05:09
[32m[03/28 22:59:41 d2.evaluation.evaluator]: [0mInference done 2396/3489. 0.2408 s / img. ETA=0:05:04
[32m[03/28 22:59:46 d2.evaluation.evaluator]: [0mInference done 2414/3489. 0.2408 s / img. ETA=0:04:59
[32m[03/28 22:59:52 d2.evaluation.evaluator]: [0mInference done 2433/3489. 0.2408 s / img. ETA=0:04:53
[32m[03/28 22:59:57 d2.evaluation.evaluator]: [0mInference done 2450/3489. 0.2409 s / img. ETA=0:04:49
[32m[03/28 23:00:02 d2.evaluation.evaluator]: [0mInference done 2467/3489. 0.2409 s / img. ETA=0:04:44
[32m[03/28 23:00:07 d2.evaluation.evaluator]: [0mInference done 2484/3489. 0.2410 s / img. ETA=0:04:40
[32m[03/28 23:00:12 d2.evaluation.evaluator]: [0mInference done 2505/3489. 0.2409 s / img. ETA=0:04:34
[32m[03/28 23:00:17 d2.evaluation.evaluator]: [0mInference done 2526/3489. 0.2408 s / img. ETA=0:04:27
[32m[03/28 23:00:23 d2.evaluation.evaluator]: [0mInference done 2547/3489. 0.2407 s / img. ETA=0:04:21
[32m[03/28 23:00:28 d2.evaluation.evaluator]: [0mInference done 2567/3489. 0.2407 s / img. ETA=0:04:16
[32m[03/28 23:00:33 d2.evaluation.evaluator]: [0mInference done 2588/3489. 0.2406 s / img. ETA=0:04:10
[32m[03/28 23:00:38 d2.evaluation.evaluator]: [0mInference done 2609/3489. 0.2405 s / img. ETA=0:04:03
[32m[03/28 23:00:43 d2.evaluation.evaluator]: [0mInference done 2631/3489. 0.2404 s / img. ETA=0:03:57
[32m[03/28 23:00:48 d2.evaluation.evaluator]: [0mInference done 2653/3489. 0.2402 s / img. ETA=0:03:51
[32m[03/28 23:00:53 d2.evaluation.evaluator]: [0mInference done 2673/3489. 0.2402 s / img. ETA=0:03:45
[32m[03/28 23:00:59 d2.evaluation.evaluator]: [0mInference done 2693/3489. 0.2402 s / img. ETA=0:03:39
[32m[03/28 23:01:04 d2.evaluation.evaluator]: [0mInference done 2713/3489. 0.2401 s / img. ETA=0:03:34
[32m[03/28 23:01:09 d2.evaluation.evaluator]: [0mInference done 2733/3489. 0.2400 s / img. ETA=0:03:28
[32m[03/28 23:01:14 d2.evaluation.evaluator]: [0mInference done 2753/3489. 0.2400 s / img. ETA=0:03:23
[32m[03/28 23:01:19 d2.evaluation.evaluator]: [0mInference done 2773/3489. 0.2399 s / img. ETA=0:03:17
[32m[03/28 23:01:24 d2.evaluation.evaluator]: [0mInference done 2793/3489. 0.2399 s / img. ETA=0:03:11
[32m[03/28 23:01:29 d2.evaluation.evaluator]: [0mInference done 2813/3489. 0.2398 s / img. ETA=0:03:06
[32m[03/28 23:01:34 d2.evaluation.evaluator]: [0mInference done 2833/3489. 0.2397 s / img. ETA=0:03:00
[32m[03/28 23:01:39 d2.evaluation.evaluator]: [0mInference done 2853/3489. 0.2397 s / img. ETA=0:02:54
[32m[03/28 23:01:44 d2.evaluation.evaluator]: [0mInference done 2873/3489. 0.2396 s / img. ETA=0:02:49
[32m[03/28 23:01:49 d2.evaluation.evaluator]: [0mInference done 2893/3489. 0.2396 s / img. ETA=0:02:43
[32m[03/28 23:01:54 d2.evaluation.evaluator]: [0mInference done 2914/3489. 0.2395 s / img. ETA=0:02:37
[32m[03/28 23:02:00 d2.evaluation.evaluator]: [0mInference done 2936/3489. 0.2394 s / img. ETA=0:02:31
[32m[03/28 23:02:05 d2.evaluation.evaluator]: [0mInference done 2957/3489. 0.2394 s / img. ETA=0:02:25
[32m[03/28 23:02:10 d2.evaluation.evaluator]: [0mInference done 2978/3489. 0.2393 s / img. ETA=0:02:19
[32m[03/28 23:02:15 d2.evaluation.evaluator]: [0mInference done 2998/3489. 0.2392 s / img. ETA=0:02:14
[32m[03/28 23:02:20 d2.evaluation.evaluator]: [0mInference done 3018/3489. 0.2392 s / img. ETA=0:02:08
[32m[03/28 23:02:25 d2.evaluation.evaluator]: [0mInference done 3038/3489. 0.2392 s / img. ETA=0:02:03
[32m[03/28 23:02:30 d2.evaluation.evaluator]: [0mInference done 3059/3489. 0.2391 s / img. ETA=0:01:57
[32m[03/28 23:02:36 d2.evaluation.evaluator]: [0mInference done 3079/3489. 0.2390 s / img. ETA=0:01:51
[32m[03/28 23:02:41 d2.evaluation.evaluator]: [0mInference done 3099/3489. 0.2390 s / img. ETA=0:01:46
[32m[03/28 23:02:46 d2.evaluation.evaluator]: [0mInference done 3119/3489. 0.2389 s / img. ETA=0:01:40
[32m[03/28 23:02:51 d2.evaluation.evaluator]: [0mInference done 3139/3489. 0.2389 s / img. ETA=0:01:35
[32m[03/28 23:02:56 d2.evaluation.evaluator]: [0mInference done 3159/3489. 0.2388 s / img. ETA=0:01:29
[32m[03/28 23:03:01 d2.evaluation.evaluator]: [0mInference done 3180/3489. 0.2388 s / img. ETA=0:01:24
[32m[03/28 23:03:06 d2.evaluation.evaluator]: [0mInference done 3201/3489. 0.2387 s / img. ETA=0:01:18
[32m[03/28 23:03:12 d2.evaluation.evaluator]: [0mInference done 3222/3489. 0.2387 s / img. ETA=0:01:12
[32m[03/28 23:03:17 d2.evaluation.evaluator]: [0mInference done 3242/3489. 0.2386 s / img. ETA=0:01:07
[32m[03/28 23:03:22 d2.evaluation.evaluator]: [0mInference done 3263/3489. 0.2386 s / img. ETA=0:01:01
[32m[03/28 23:03:27 d2.evaluation.evaluator]: [0mInference done 3284/3489. 0.2385 s / img. ETA=0:00:55
[32m[03/28 23:03:32 d2.evaluation.evaluator]: [0mInference done 3306/3489. 0.2384 s / img. ETA=0:00:49
[32m[03/28 23:03:37 d2.evaluation.evaluator]: [0mInference done 3328/3489. 0.2383 s / img. ETA=0:00:43
[32m[03/28 23:03:42 d2.evaluation.evaluator]: [0mInference done 3350/3489. 0.2383 s / img. ETA=0:00:37
[32m[03/28 23:03:47 d2.evaluation.evaluator]: [0mInference done 3372/3489. 0.2382 s / img. ETA=0:00:31
[32m[03/28 23:03:52 d2.evaluation.evaluator]: [0mInference done 3393/3489. 0.2381 s / img. ETA=0:00:25
[32m[03/28 23:03:57 d2.evaluation.evaluator]: [0mInference done 3414/3489. 0.2380 s / img. ETA=0:00:20
[32m[03/28 23:04:03 d2.evaluation.evaluator]: [0mInference done 3435/3489. 0.2380 s / img. ETA=0:00:14
[32m[03/28 23:04:08 d2.evaluation.evaluator]: [0mInference done 3456/3489. 0.2379 s / img. ETA=0:00:08
[32m[03/28 23:04:13 d2.evaluation.evaluator]: [0mInference done 3477/3489. 0.2379 s / img. ETA=0:00:03
[32m[03/28 23:04:16 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:40.171223 (0.269854 s / img per device, on 1 devices)
[32m[03/28 23:04:16 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:48 (0.237868 s / img per device, on 1 devices)
[32m[03/28 23:04:18 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 23:04:18 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.700000/coco_instances_results.json
[32m[03/28 23:04:19 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.63 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.49 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722
[32m[03/28 23:04:21 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.080 | 78.305 | 38.496 | 29.018 | 50.768 | 54.992 |
[32m[03/28 23:04:21 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 58.946 | Pedestrian | 27.215 |
Loading and preparing results...
DONE (t=1.80s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.19 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.52 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[32m[03/28 23:04:30 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.220 | 74.323 | 38.760 | 22.388 | 50.575 | 66.956 |
[32m[03/28 23:04:30 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.312 | Pedestrian | 23.128 |
[32m[03/28 23:04:30 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: 43.0804,78.3054,38.4958,29.0177,50.7683,54.9922
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:04:30 d2.evaluation.testing]: [0mcopypaste: 42.2196,74.3226,38.7604,22.3883,50.5750,66.9556
evaluated
Test [0.200000, 0.800000]
[32m[03/28 23:04:31 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 23:04:31 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 23:04:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:04:31 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:04:31 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 23:04:31 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 23:04:32 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 23:04:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:04:32 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:04:32 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 23:04:32 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 23:04:32 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 23:04:57 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.648  loss_cls: 0.657  loss_box_reg: 0.3401  loss_mask: 0.6542  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.007467  total_val_loss: 1.802  val_loss_cls: 0.5932  val_loss_box_reg: 0.4503  val_loss_mask: 0.6785  val_loss_rpn_cls: 0.03471  val_loss_rpn_loc: 0.01234  time: 0.8445  data_time: 0.0295  lr: 0.00019981  max_mem: 4747M
[32m[03/28 23:05:21 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.9322  loss_cls: 0.1985  loss_box_reg: 0.3062  loss_mask: 0.3494  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.008606  total_val_loss: 1.444  val_loss_cls: 0.3335  val_loss_box_reg: 0.4952  val_loss_mask: 0.5377  val_loss_rpn_cls: 0.038  val_loss_rpn_loc: 0.01494  time: 0.8480  data_time: 0.0063  lr: 0.00039961  max_mem: 4747M
[32m[03/28 23:05:45 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.6663  loss_cls: 0.1034  loss_box_reg: 0.2836  loss_mask: 0.2038  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.008986  total_val_loss: 1.308  val_loss_cls: 0.2733  val_loss_box_reg: 0.5103  val_loss_mask: 0.426  val_loss_rpn_cls: 0.03245  val_loss_rpn_loc: 0.01449  time: 0.8530  data_time: 0.0058  lr: 0.00059941  max_mem: 4747M
[32m[03/28 23:06:09 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.4887  loss_cls: 0.05704  loss_box_reg: 0.2019  loss_mask: 0.1709  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.005806  total_val_loss: 0.8663  val_loss_cls: 0.1428  val_loss_box_reg: 0.3547  val_loss_mask: 0.36  val_loss_rpn_cls: 0.02567  val_loss_rpn_loc: 0.01328  time: 0.8542  data_time: 0.0067  lr: 0.00079921  max_mem: 4747M
[32m[03/28 23:06:34 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:06:34 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:06:34 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:06:34 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:06:34 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.4226  loss_cls: 0.06649  loss_box_reg: 0.2274  loss_mask: 0.1408  loss_rpn_cls: 0.007995  loss_rpn_loc: 0.0153  total_val_loss: 0.8898  val_loss_cls: 0.1943  val_loss_box_reg: 0.3618  val_loss_mask: 0.3143  val_loss_rpn_cls: 0.01927  val_loss_rpn_loc: 0.01545  time: 0.8567  data_time: 0.0059  lr: 0.00099901  max_mem: 4747M
[32m[03/28 23:06:59 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3245  loss_cls: 0.05032  loss_box_reg: 0.1163  loss_mask: 0.1625  loss_rpn_cls: 0.005841  loss_rpn_loc: 0.008529  total_val_loss: 1.045  val_loss_cls: 0.233  val_loss_box_reg: 0.232  val_loss_mask: 0.407  val_loss_rpn_cls: 0.02481  val_loss_rpn_loc: 0.01274  time: 0.8578  data_time: 0.0060  lr: 0.0011988  max_mem: 4747M
[32m[03/28 23:07:23 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3877  loss_cls: 0.05694  loss_box_reg: 0.09124  loss_mask: 0.1722  loss_rpn_cls: 0.009726  loss_rpn_loc: 0.00747  total_val_loss: 0.6727  val_loss_cls: 0.1282  val_loss_box_reg: 0.2008  val_loss_mask: 0.27  val_loss_rpn_cls: 0.01327  val_loss_rpn_loc: 0.01561  time: 0.8568  data_time: 0.0058  lr: 0.0013986  max_mem: 4747M
[32m[03/28 23:07:48 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3807  loss_cls: 0.07792  loss_box_reg: 0.109  loss_mask: 0.1798  loss_rpn_cls: 0.007502  loss_rpn_loc: 0.0131  total_val_loss: 0.7295  val_loss_cls: 0.147  val_loss_box_reg: 0.2179  val_loss_mask: 0.2662  val_loss_rpn_cls: 0.02151  val_loss_rpn_loc: 0.01542  time: 0.8583  data_time: 0.0064  lr: 0.0015984  max_mem: 4747M
[32m[03/28 23:08:12 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3334  loss_cls: 0.04909  loss_box_reg: 0.08244  loss_mask: 0.1547  loss_rpn_cls: 0.008079  loss_rpn_loc: 0.01263  total_val_loss: 0.7178  val_loss_cls: 0.1432  val_loss_box_reg: 0.2049  val_loss_mask: 0.2893  val_loss_rpn_cls: 0.01964  val_loss_rpn_loc: 0.01332  time: 0.8586  data_time: 0.0065  lr: 0.0017982  max_mem: 4747M
[32m[03/28 23:08:37 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:08:37 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:08:37 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:08:37 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:08:37 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4051  loss_cls: 0.06057  loss_box_reg: 0.1366  loss_mask: 0.1804  loss_rpn_cls: 0.007265  loss_rpn_loc: 0.01212  total_val_loss: 0.5725  val_loss_cls: 0.1241  val_loss_box_reg: 0.19  val_loss_mask: 0.2692  val_loss_rpn_cls: 0.01849  val_loss_rpn_loc: 0.01106  time: 0.8586  data_time: 0.0059  lr: 0.001998  max_mem: 4747M
[32m[03/28 23:08:37 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:49 (0.8586 s / it)
[32m[03/28 23:08:37 d2.engine.hooks]: [0mTotal training time: 0:04:02 (0:01:12 on hooks)
[32m[03/28 23:08:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:08:38 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:08:38 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:08:38 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 23:08:38 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 23:08:39 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:08:39 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:08:39 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 23:08:39 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 23:08:42 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2263 s / img. ETA=0:14:17
[32m[03/28 23:08:47 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2312 s / img. ETA=0:14:25
[32m[03/28 23:08:52 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2309 s / img. ETA=0:14:12
[32m[03/28 23:08:57 d2.evaluation.evaluator]: [0mInference done 73/3489. 0.2310 s / img. ETA=0:14:04
[32m[03/28 23:09:02 d2.evaluation.evaluator]: [0mInference done 93/3489. 0.2314 s / img. ETA=0:14:07
[32m[03/28 23:09:07 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2328 s / img. ETA=0:14:19
[32m[03/28 23:09:13 d2.evaluation.evaluator]: [0mInference done 128/3489. 0.2352 s / img. ETA=0:14:39
[32m[03/28 23:09:18 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2373 s / img. ETA=0:14:58
[32m[03/28 23:09:23 d2.evaluation.evaluator]: [0mInference done 160/3489. 0.2390 s / img. ETA=0:15:12
[32m[03/28 23:09:28 d2.evaluation.evaluator]: [0mInference done 176/3489. 0.2403 s / img. ETA=0:15:22
[32m[03/28 23:09:33 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2409 s / img. ETA=0:15:24
[32m[03/28 23:09:38 d2.evaluation.evaluator]: [0mInference done 212/3489. 0.2403 s / img. ETA=0:15:14
[32m[03/28 23:09:43 d2.evaluation.evaluator]: [0mInference done 231/3489. 0.2398 s / img. ETA=0:15:04
[32m[03/28 23:09:48 d2.evaluation.evaluator]: [0mInference done 250/3489. 0.2398 s / img. ETA=0:14:58
[32m[03/28 23:09:53 d2.evaluation.evaluator]: [0mInference done 268/3489. 0.2399 s / img. ETA=0:14:54
[32m[03/28 23:09:59 d2.evaluation.evaluator]: [0mInference done 286/3489. 0.2400 s / img. ETA=0:14:50
[32m[03/28 23:10:04 d2.evaluation.evaluator]: [0mInference done 304/3489. 0.2401 s / img. ETA=0:14:46
[32m[03/28 23:10:09 d2.evaluation.evaluator]: [0mInference done 322/3489. 0.2404 s / img. ETA=0:14:43
[32m[03/28 23:10:14 d2.evaluation.evaluator]: [0mInference done 340/3489. 0.2406 s / img. ETA=0:14:40
[32m[03/28 23:10:19 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2409 s / img. ETA=0:14:38
[32m[03/28 23:10:24 d2.evaluation.evaluator]: [0mInference done 375/3489. 0.2410 s / img. ETA=0:14:34
[32m[03/28 23:10:29 d2.evaluation.evaluator]: [0mInference done 392/3489. 0.2412 s / img. ETA=0:14:32
[32m[03/28 23:10:35 d2.evaluation.evaluator]: [0mInference done 410/3489. 0.2411 s / img. ETA=0:14:27
[32m[03/28 23:10:40 d2.evaluation.evaluator]: [0mInference done 429/3489. 0.2410 s / img. ETA=0:14:20
[32m[03/28 23:10:45 d2.evaluation.evaluator]: [0mInference done 450/3489. 0.2405 s / img. ETA=0:14:09
[32m[03/28 23:10:50 d2.evaluation.evaluator]: [0mInference done 471/3489. 0.2401 s / img. ETA=0:13:58
[32m[03/28 23:10:55 d2.evaluation.evaluator]: [0mInference done 492/3489. 0.2397 s / img. ETA=0:13:48
[32m[03/28 23:11:00 d2.evaluation.evaluator]: [0mInference done 513/3489. 0.2392 s / img. ETA=0:13:38
[32m[03/28 23:11:05 d2.evaluation.evaluator]: [0mInference done 534/3489. 0.2389 s / img. ETA=0:13:29
[32m[03/28 23:11:10 d2.evaluation.evaluator]: [0mInference done 554/3489. 0.2387 s / img. ETA=0:13:21
[32m[03/28 23:11:15 d2.evaluation.evaluator]: [0mInference done 573/3489. 0.2387 s / img. ETA=0:13:15
[32m[03/28 23:11:20 d2.evaluation.evaluator]: [0mInference done 590/3489. 0.2389 s / img. ETA=0:13:13
[32m[03/28 23:11:25 d2.evaluation.evaluator]: [0mInference done 608/3489. 0.2390 s / img. ETA=0:13:08
[32m[03/28 23:11:31 d2.evaluation.evaluator]: [0mInference done 626/3489. 0.2391 s / img. ETA=0:13:04
[32m[03/28 23:11:36 d2.evaluation.evaluator]: [0mInference done 645/3489. 0.2391 s / img. ETA=0:12:59
[32m[03/28 23:11:41 d2.evaluation.evaluator]: [0mInference done 664/3489. 0.2391 s / img. ETA=0:12:54
[32m[03/28 23:11:46 d2.evaluation.evaluator]: [0mInference done 684/3489. 0.2390 s / img. ETA=0:12:46
[32m[03/28 23:11:51 d2.evaluation.evaluator]: [0mInference done 705/3489. 0.2387 s / img. ETA=0:12:38
[32m[03/28 23:11:56 d2.evaluation.evaluator]: [0mInference done 726/3489. 0.2384 s / img. ETA=0:12:31
[32m[03/28 23:12:02 d2.evaluation.evaluator]: [0mInference done 747/3489. 0.2382 s / img. ETA=0:12:23
[32m[03/28 23:12:07 d2.evaluation.evaluator]: [0mInference done 768/3489. 0.2380 s / img. ETA=0:12:15
[32m[03/28 23:12:12 d2.evaluation.evaluator]: [0mInference done 789/3489. 0.2378 s / img. ETA=0:12:08
[32m[03/28 23:12:17 d2.evaluation.evaluator]: [0mInference done 810/3489. 0.2375 s / img. ETA=0:12:00
[32m[03/28 23:12:22 d2.evaluation.evaluator]: [0mInference done 831/3489. 0.2373 s / img. ETA=0:11:53
[32m[03/28 23:12:27 d2.evaluation.evaluator]: [0mInference done 852/3489. 0.2370 s / img. ETA=0:11:45
[32m[03/28 23:12:32 d2.evaluation.evaluator]: [0mInference done 873/3489. 0.2369 s / img. ETA=0:11:38
[32m[03/28 23:12:37 d2.evaluation.evaluator]: [0mInference done 895/3489. 0.2367 s / img. ETA=0:11:30
[32m[03/28 23:12:43 d2.evaluation.evaluator]: [0mInference done 913/3489. 0.2368 s / img. ETA=0:11:26
[32m[03/28 23:12:48 d2.evaluation.evaluator]: [0mInference done 930/3489. 0.2371 s / img. ETA=0:11:23
[32m[03/28 23:12:53 d2.evaluation.evaluator]: [0mInference done 947/3489. 0.2373 s / img. ETA=0:11:21
[32m[03/28 23:12:58 d2.evaluation.evaluator]: [0mInference done 964/3489. 0.2376 s / img. ETA=0:11:18
[32m[03/28 23:13:03 d2.evaluation.evaluator]: [0mInference done 980/3489. 0.2378 s / img. ETA=0:11:16
[32m[03/28 23:13:08 d2.evaluation.evaluator]: [0mInference done 996/3489. 0.2380 s / img. ETA=0:11:13
[32m[03/28 23:13:13 d2.evaluation.evaluator]: [0mInference done 1012/3489. 0.2383 s / img. ETA=0:11:11
[32m[03/28 23:13:18 d2.evaluation.evaluator]: [0mInference done 1028/3489. 0.2386 s / img. ETA=0:11:08
[32m[03/28 23:13:24 d2.evaluation.evaluator]: [0mInference done 1044/3489. 0.2389 s / img. ETA=0:11:06
[32m[03/28 23:13:29 d2.evaluation.evaluator]: [0mInference done 1061/3489. 0.2390 s / img. ETA=0:11:03
[32m[03/28 23:13:34 d2.evaluation.evaluator]: [0mInference done 1078/3489. 0.2392 s / img. ETA=0:10:59
[32m[03/28 23:13:39 d2.evaluation.evaluator]: [0mInference done 1096/3489. 0.2393 s / img. ETA=0:10:55
[32m[03/28 23:13:44 d2.evaluation.evaluator]: [0mInference done 1115/3489. 0.2393 s / img. ETA=0:10:50
[32m[03/28 23:13:49 d2.evaluation.evaluator]: [0mInference done 1132/3489. 0.2394 s / img. ETA=0:10:46
[32m[03/28 23:13:55 d2.evaluation.evaluator]: [0mInference done 1149/3489. 0.2396 s / img. ETA=0:10:42
[32m[03/28 23:14:00 d2.evaluation.evaluator]: [0mInference done 1166/3489. 0.2397 s / img. ETA=0:10:39
[32m[03/28 23:14:05 d2.evaluation.evaluator]: [0mInference done 1183/3489. 0.2398 s / img. ETA=0:10:35
[32m[03/28 23:14:10 d2.evaluation.evaluator]: [0mInference done 1200/3489. 0.2399 s / img. ETA=0:10:31
[32m[03/28 23:14:15 d2.evaluation.evaluator]: [0mInference done 1217/3489. 0.2400 s / img. ETA=0:10:27
[32m[03/28 23:14:20 d2.evaluation.evaluator]: [0mInference done 1235/3489. 0.2401 s / img. ETA=0:10:22
[32m[03/28 23:14:25 d2.evaluation.evaluator]: [0mInference done 1253/3489. 0.2401 s / img. ETA=0:10:17
[32m[03/28 23:14:30 d2.evaluation.evaluator]: [0mInference done 1275/3489. 0.2399 s / img. ETA=0:10:10
[32m[03/28 23:14:36 d2.evaluation.evaluator]: [0mInference done 1297/3489. 0.2397 s / img. ETA=0:10:02
[32m[03/28 23:14:41 d2.evaluation.evaluator]: [0mInference done 1319/3489. 0.2395 s / img. ETA=0:09:55
[32m[03/28 23:14:46 d2.evaluation.evaluator]: [0mInference done 1340/3489. 0.2393 s / img. ETA=0:09:48
[32m[03/28 23:14:51 d2.evaluation.evaluator]: [0mInference done 1361/3489. 0.2392 s / img. ETA=0:09:41
[32m[03/28 23:14:56 d2.evaluation.evaluator]: [0mInference done 1382/3489. 0.2390 s / img. ETA=0:09:34
[32m[03/28 23:15:01 d2.evaluation.evaluator]: [0mInference done 1403/3489. 0.2389 s / img. ETA=0:09:28
[32m[03/28 23:15:06 d2.evaluation.evaluator]: [0mInference done 1422/3489. 0.2390 s / img. ETA=0:09:22
[32m[03/28 23:15:11 d2.evaluation.evaluator]: [0mInference done 1442/3489. 0.2389 s / img. ETA=0:09:16
[32m[03/28 23:15:16 d2.evaluation.evaluator]: [0mInference done 1463/3489. 0.2388 s / img. ETA=0:09:10
[32m[03/28 23:15:21 d2.evaluation.evaluator]: [0mInference done 1484/3489. 0.2386 s / img. ETA=0:09:03
[32m[03/28 23:15:27 d2.evaluation.evaluator]: [0mInference done 1505/3489. 0.2385 s / img. ETA=0:08:57
[32m[03/28 23:15:32 d2.evaluation.evaluator]: [0mInference done 1526/3489. 0.2383 s / img. ETA=0:08:50
[32m[03/28 23:15:37 d2.evaluation.evaluator]: [0mInference done 1547/3489. 0.2382 s / img. ETA=0:08:44
[32m[03/28 23:15:42 d2.evaluation.evaluator]: [0mInference done 1568/3489. 0.2381 s / img. ETA=0:08:38
[32m[03/28 23:15:47 d2.evaluation.evaluator]: [0mInference done 1589/3489. 0.2380 s / img. ETA=0:08:31
[32m[03/28 23:15:52 d2.evaluation.evaluator]: [0mInference done 1608/3489. 0.2380 s / img. ETA=0:08:26
[32m[03/28 23:15:57 d2.evaluation.evaluator]: [0mInference done 1626/3489. 0.2380 s / img. ETA=0:08:22
[32m[03/28 23:16:02 d2.evaluation.evaluator]: [0mInference done 1644/3489. 0.2381 s / img. ETA=0:08:17
[32m[03/28 23:16:07 d2.evaluation.evaluator]: [0mInference done 1662/3489. 0.2381 s / img. ETA=0:08:12
[32m[03/28 23:16:12 d2.evaluation.evaluator]: [0mInference done 1679/3489. 0.2382 s / img. ETA=0:08:08
[32m[03/28 23:16:18 d2.evaluation.evaluator]: [0mInference done 1695/3489. 0.2383 s / img. ETA=0:08:05
[32m[03/28 23:16:23 d2.evaluation.evaluator]: [0mInference done 1711/3489. 0.2385 s / img. ETA=0:08:01
[32m[03/28 23:16:28 d2.evaluation.evaluator]: [0mInference done 1728/3489. 0.2387 s / img. ETA=0:07:57
[32m[03/28 23:16:33 d2.evaluation.evaluator]: [0mInference done 1745/3489. 0.2387 s / img. ETA=0:07:53
[32m[03/28 23:16:38 d2.evaluation.evaluator]: [0mInference done 1761/3489. 0.2389 s / img. ETA=0:07:50
[32m[03/28 23:16:43 d2.evaluation.evaluator]: [0mInference done 1777/3489. 0.2390 s / img. ETA=0:07:46
[32m[03/28 23:16:48 d2.evaluation.evaluator]: [0mInference done 1793/3489. 0.2391 s / img. ETA=0:07:42
[32m[03/28 23:16:53 d2.evaluation.evaluator]: [0mInference done 1809/3489. 0.2392 s / img. ETA=0:07:39
[32m[03/28 23:16:59 d2.evaluation.evaluator]: [0mInference done 1825/3489. 0.2393 s / img. ETA=0:07:35
[32m[03/28 23:17:04 d2.evaluation.evaluator]: [0mInference done 1841/3489. 0.2395 s / img. ETA=0:07:31
[32m[03/28 23:17:09 d2.evaluation.evaluator]: [0mInference done 1857/3489. 0.2396 s / img. ETA=0:07:28
[32m[03/28 23:17:14 d2.evaluation.evaluator]: [0mInference done 1873/3489. 0.2398 s / img. ETA=0:07:24
[32m[03/28 23:17:19 d2.evaluation.evaluator]: [0mInference done 1889/3489. 0.2399 s / img. ETA=0:07:20
[32m[03/28 23:17:24 d2.evaluation.evaluator]: [0mInference done 1905/3489. 0.2400 s / img. ETA=0:07:16
[32m[03/28 23:17:30 d2.evaluation.evaluator]: [0mInference done 1921/3489. 0.2401 s / img. ETA=0:07:13
[32m[03/28 23:17:35 d2.evaluation.evaluator]: [0mInference done 1936/3489. 0.2402 s / img. ETA=0:07:09
[32m[03/28 23:17:40 d2.evaluation.evaluator]: [0mInference done 1952/3489. 0.2404 s / img. ETA=0:07:05
[32m[03/28 23:17:45 d2.evaluation.evaluator]: [0mInference done 1968/3489. 0.2404 s / img. ETA=0:07:01
[32m[03/28 23:17:50 d2.evaluation.evaluator]: [0mInference done 1984/3489. 0.2405 s / img. ETA=0:06:57
[32m[03/28 23:17:55 d2.evaluation.evaluator]: [0mInference done 2001/3489. 0.2406 s / img. ETA=0:06:53
[32m[03/28 23:18:00 d2.evaluation.evaluator]: [0mInference done 2019/3489. 0.2406 s / img. ETA=0:06:48
[32m[03/28 23:18:06 d2.evaluation.evaluator]: [0mInference done 2036/3489. 0.2407 s / img. ETA=0:06:44
[32m[03/28 23:18:11 d2.evaluation.evaluator]: [0mInference done 2053/3489. 0.2408 s / img. ETA=0:06:40
[32m[03/28 23:18:16 d2.evaluation.evaluator]: [0mInference done 2069/3489. 0.2409 s / img. ETA=0:06:36
[32m[03/28 23:18:21 d2.evaluation.evaluator]: [0mInference done 2085/3489. 0.2410 s / img. ETA=0:06:31
[32m[03/28 23:18:26 d2.evaluation.evaluator]: [0mInference done 2101/3489. 0.2411 s / img. ETA=0:06:27
[32m[03/28 23:18:31 d2.evaluation.evaluator]: [0mInference done 2117/3489. 0.2412 s / img. ETA=0:06:23
[32m[03/28 23:18:36 d2.evaluation.evaluator]: [0mInference done 2133/3489. 0.2413 s / img. ETA=0:06:19
[32m[03/28 23:18:42 d2.evaluation.evaluator]: [0mInference done 2149/3489. 0.2414 s / img. ETA=0:06:15
[32m[03/28 23:18:47 d2.evaluation.evaluator]: [0mInference done 2165/3489. 0.2415 s / img. ETA=0:06:11
[32m[03/28 23:18:52 d2.evaluation.evaluator]: [0mInference done 2181/3489. 0.2416 s / img. ETA=0:06:07
[32m[03/28 23:18:57 d2.evaluation.evaluator]: [0mInference done 2197/3489. 0.2417 s / img. ETA=0:06:03
[32m[03/28 23:19:02 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2418 s / img. ETA=0:05:59
[32m[03/28 23:19:07 d2.evaluation.evaluator]: [0mInference done 2229/3489. 0.2419 s / img. ETA=0:05:55
[32m[03/28 23:19:12 d2.evaluation.evaluator]: [0mInference done 2245/3489. 0.2419 s / img. ETA=0:05:50
[32m[03/28 23:19:17 d2.evaluation.evaluator]: [0mInference done 2262/3489. 0.2420 s / img. ETA=0:05:46
[32m[03/28 23:19:22 d2.evaluation.evaluator]: [0mInference done 2278/3489. 0.2420 s / img. ETA=0:05:42
[32m[03/28 23:19:28 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2421 s / img. ETA=0:05:37
[32m[03/28 23:19:33 d2.evaluation.evaluator]: [0mInference done 2310/3489. 0.2422 s / img. ETA=0:05:33
[32m[03/28 23:19:38 d2.evaluation.evaluator]: [0mInference done 2326/3489. 0.2423 s / img. ETA=0:05:29
[32m[03/28 23:19:43 d2.evaluation.evaluator]: [0mInference done 2342/3489. 0.2424 s / img. ETA=0:05:25
[32m[03/28 23:19:48 d2.evaluation.evaluator]: [0mInference done 2357/3489. 0.2424 s / img. ETA=0:05:21
[32m[03/28 23:19:53 d2.evaluation.evaluator]: [0mInference done 2375/3489. 0.2424 s / img. ETA=0:05:16
[32m[03/28 23:19:58 d2.evaluation.evaluator]: [0mInference done 2394/3489. 0.2424 s / img. ETA=0:05:10
[32m[03/28 23:20:04 d2.evaluation.evaluator]: [0mInference done 2412/3489. 0.2424 s / img. ETA=0:05:05
[32m[03/28 23:20:09 d2.evaluation.evaluator]: [0mInference done 2430/3489. 0.2424 s / img. ETA=0:05:00
[32m[03/28 23:20:14 d2.evaluation.evaluator]: [0mInference done 2447/3489. 0.2424 s / img. ETA=0:04:55
[32m[03/28 23:20:19 d2.evaluation.evaluator]: [0mInference done 2463/3489. 0.2425 s / img. ETA=0:04:51
[32m[03/28 23:20:24 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2426 s / img. ETA=0:04:47
[32m[03/28 23:20:29 d2.evaluation.evaluator]: [0mInference done 2497/3489. 0.2425 s / img. ETA=0:04:42
[32m[03/28 23:20:34 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2425 s / img. ETA=0:04:36
[32m[03/28 23:20:39 d2.evaluation.evaluator]: [0mInference done 2537/3489. 0.2424 s / img. ETA=0:04:30
[32m[03/28 23:20:45 d2.evaluation.evaluator]: [0mInference done 2557/3489. 0.2423 s / img. ETA=0:04:24
[32m[03/28 23:20:50 d2.evaluation.evaluator]: [0mInference done 2577/3489. 0.2423 s / img. ETA=0:04:18
[32m[03/28 23:20:55 d2.evaluation.evaluator]: [0mInference done 2598/3489. 0.2422 s / img. ETA=0:04:12
[32m[03/28 23:21:00 d2.evaluation.evaluator]: [0mInference done 2618/3489. 0.2421 s / img. ETA=0:04:06
[32m[03/28 23:21:05 d2.evaluation.evaluator]: [0mInference done 2639/3489. 0.2420 s / img. ETA=0:04:00
[32m[03/28 23:21:10 d2.evaluation.evaluator]: [0mInference done 2660/3489. 0.2419 s / img. ETA=0:03:54
[32m[03/28 23:21:15 d2.evaluation.evaluator]: [0mInference done 2679/3489. 0.2419 s / img. ETA=0:03:48
[32m[03/28 23:21:20 d2.evaluation.evaluator]: [0mInference done 2699/3489. 0.2418 s / img. ETA=0:03:42
[32m[03/28 23:21:26 d2.evaluation.evaluator]: [0mInference done 2719/3489. 0.2417 s / img. ETA=0:03:37
[32m[03/28 23:21:31 d2.evaluation.evaluator]: [0mInference done 2739/3489. 0.2417 s / img. ETA=0:03:31
[32m[03/28 23:21:36 d2.evaluation.evaluator]: [0mInference done 2758/3489. 0.2416 s / img. ETA=0:03:25
[32m[03/28 23:21:41 d2.evaluation.evaluator]: [0mInference done 2778/3489. 0.2415 s / img. ETA=0:03:20
[32m[03/28 23:21:46 d2.evaluation.evaluator]: [0mInference done 2798/3489. 0.2415 s / img. ETA=0:03:14
[32m[03/28 23:21:51 d2.evaluation.evaluator]: [0mInference done 2818/3489. 0.2414 s / img. ETA=0:03:08
[32m[03/28 23:21:56 d2.evaluation.evaluator]: [0mInference done 2838/3489. 0.2414 s / img. ETA=0:03:02
[32m[03/28 23:22:02 d2.evaluation.evaluator]: [0mInference done 2858/3489. 0.2413 s / img. ETA=0:02:57
[32m[03/28 23:22:07 d2.evaluation.evaluator]: [0mInference done 2878/3489. 0.2412 s / img. ETA=0:02:51
[32m[03/28 23:22:12 d2.evaluation.evaluator]: [0mInference done 2898/3489. 0.2412 s / img. ETA=0:02:45
[32m[03/28 23:22:17 d2.evaluation.evaluator]: [0mInference done 2919/3489. 0.2411 s / img. ETA=0:02:39
[32m[03/28 23:22:22 d2.evaluation.evaluator]: [0mInference done 2940/3489. 0.2410 s / img. ETA=0:02:33
[32m[03/28 23:22:27 d2.evaluation.evaluator]: [0mInference done 2961/3489. 0.2409 s / img. ETA=0:02:27
[32m[03/28 23:22:32 d2.evaluation.evaluator]: [0mInference done 2982/3489. 0.2408 s / img. ETA=0:02:21
[32m[03/28 23:22:37 d2.evaluation.evaluator]: [0mInference done 3001/3489. 0.2408 s / img. ETA=0:02:16
[32m[03/28 23:22:42 d2.evaluation.evaluator]: [0mInference done 3021/3489. 0.2407 s / img. ETA=0:02:10
[32m[03/28 23:22:47 d2.evaluation.evaluator]: [0mInference done 3041/3489. 0.2407 s / img. ETA=0:02:04
[32m[03/28 23:22:53 d2.evaluation.evaluator]: [0mInference done 3061/3489. 0.2406 s / img. ETA=0:01:59
[32m[03/28 23:22:58 d2.evaluation.evaluator]: [0mInference done 3080/3489. 0.2406 s / img. ETA=0:01:54
[32m[03/28 23:23:03 d2.evaluation.evaluator]: [0mInference done 3099/3489. 0.2406 s / img. ETA=0:01:48
[32m[03/28 23:23:08 d2.evaluation.evaluator]: [0mInference done 3119/3489. 0.2405 s / img. ETA=0:01:43
[32m[03/28 23:23:13 d2.evaluation.evaluator]: [0mInference done 3138/3489. 0.2405 s / img. ETA=0:01:37
[32m[03/28 23:23:18 d2.evaluation.evaluator]: [0mInference done 3158/3489. 0.2405 s / img. ETA=0:01:32
[32m[03/28 23:23:23 d2.evaluation.evaluator]: [0mInference done 3178/3489. 0.2404 s / img. ETA=0:01:26
[32m[03/28 23:23:28 d2.evaluation.evaluator]: [0mInference done 3198/3489. 0.2403 s / img. ETA=0:01:20
[32m[03/28 23:23:34 d2.evaluation.evaluator]: [0mInference done 3218/3489. 0.2403 s / img. ETA=0:01:15
[32m[03/28 23:23:39 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2403 s / img. ETA=0:01:10
[32m[03/28 23:23:44 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2402 s / img. ETA=0:01:04
[32m[03/28 23:23:49 d2.evaluation.evaluator]: [0mInference done 3278/3489. 0.2402 s / img. ETA=0:00:58
[32m[03/28 23:23:54 d2.evaluation.evaluator]: [0mInference done 3300/3489. 0.2401 s / img. ETA=0:00:52
[32m[03/28 23:23:59 d2.evaluation.evaluator]: [0mInference done 3322/3489. 0.2400 s / img. ETA=0:00:46
[32m[03/28 23:24:04 d2.evaluation.evaluator]: [0mInference done 3344/3489. 0.2399 s / img. ETA=0:00:40
[32m[03/28 23:24:09 d2.evaluation.evaluator]: [0mInference done 3366/3489. 0.2398 s / img. ETA=0:00:33
[32m[03/28 23:24:14 d2.evaluation.evaluator]: [0mInference done 3387/3489. 0.2397 s / img. ETA=0:00:28
[32m[03/28 23:24:19 d2.evaluation.evaluator]: [0mInference done 3408/3489. 0.2397 s / img. ETA=0:00:22
[32m[03/28 23:24:25 d2.evaluation.evaluator]: [0mInference done 3428/3489. 0.2396 s / img. ETA=0:00:16
[32m[03/28 23:24:30 d2.evaluation.evaluator]: [0mInference done 3448/3489. 0.2396 s / img. ETA=0:00:11
[32m[03/28 23:24:35 d2.evaluation.evaluator]: [0mInference done 3468/3489. 0.2396 s / img. ETA=0:00:05
[32m[03/28 23:24:40 d2.evaluation.evaluator]: [0mInference done 3488/3489. 0.2396 s / img. ETA=0:00:00
[32m[03/28 23:24:40 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:59.759348 (0.275476 s / img per device, on 1 devices)
[32m[03/28 23:24:40 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:54 (0.239554 s / img per device, on 1 devices)
[32m[03/28 23:24:42 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 23:24:42 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.800000/coco_instances_results.json
[32m[03/28 23:24:44 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.49 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.53 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.808
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
[32m[03/28 23:24:46 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.410 | 80.809 | 53.593 | 32.190 | 60.324 | 66.645 |
[32m[03/28 23:24:46 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.072 | Pedestrian | 39.748 |
Loading and preparing results...
DONE (t=1.97s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.27 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.776
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[32m[03/28 23:24:56 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.484 | 77.630 | 45.509 | 24.124 | 55.137 | 73.242 |
[32m[03/28 23:24:56 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.298 | Pedestrian | 29.671 |
[32m[03/28 23:24:56 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: 51.4102,80.8089,53.5933,32.1900,60.3235,66.6454
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:24:56 d2.evaluation.testing]: [0mcopypaste: 46.4843,77.6299,45.5094,24.1237,55.1372,73.2422
evaluated
Test [0.200000, 0.900000]
[32m[03/28 23:24:57 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 23:24:57 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 23:24:57 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:24:57 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:24:57 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 23:24:57 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 23:24:57 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 23:24:57 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:24:57 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:24:57 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 23:24:57 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 23:24:58 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 23:25:22 d2.utils.events]: [0m eta: 0:02:30  iter: 19  total_loss: 1.931  loss_cls: 0.8133  loss_box_reg: 0.4389  loss_mask: 0.6575  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.01174  total_val_loss: 1.93  val_loss_cls: 0.7482  val_loss_box_reg: 0.4177  val_loss_mask: 0.6697  val_loss_rpn_cls: 0.03959  val_loss_rpn_loc: 0.01575  time: 0.8470  data_time: 0.0255  lr: 0.00019981  max_mem: 4747M
[32m[03/28 23:25:46 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.9863  loss_cls: 0.203  loss_box_reg: 0.3627  loss_mask: 0.3484  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.008324  total_val_loss: 1.269  val_loss_cls: 0.2687  val_loss_box_reg: 0.4449  val_loss_mask: 0.5573  val_loss_rpn_cls: 0.04001  val_loss_rpn_loc: 0.01057  time: 0.8539  data_time: 0.0064  lr: 0.00039961  max_mem: 4747M
[32m[03/28 23:26:11 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.7557  loss_cls: 0.108  loss_box_reg: 0.4058  loss_mask: 0.2018  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01126  total_val_loss: 1.04  val_loss_cls: 0.1782  val_loss_box_reg: 0.4213  val_loss_mask: 0.4272  val_loss_rpn_cls: 0.02419  val_loss_rpn_loc: 0.01139  time: 0.8612  data_time: 0.0067  lr: 0.00059941  max_mem: 4747M
[32m[03/28 23:26:35 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.5992  loss_cls: 0.07556  loss_box_reg: 0.2693  loss_mask: 0.193  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.01278  total_val_loss: 0.7557  val_loss_cls: 0.1389  val_loss_box_reg: 0.2915  val_loss_mask: 0.3195  val_loss_rpn_cls: 0.01636  val_loss_rpn_loc: 0.008475  time: 0.8620  data_time: 0.0070  lr: 0.00079921  max_mem: 4747M
[32m[03/28 23:27:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:27:00 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:27:00 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:27:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:27:01 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4495  loss_cls: 0.06527  loss_box_reg: 0.1639  loss_mask: 0.1703  loss_rpn_cls: 0.007291  loss_rpn_loc: 0.01019  total_val_loss: 1.033  val_loss_cls: 0.2318  val_loss_box_reg: 0.2891  val_loss_mask: 0.4155  val_loss_rpn_cls: 0.0279  val_loss_rpn_loc: 0.01299  time: 0.8639  data_time: 0.0065  lr: 0.00099901  max_mem: 4747M
[32m[03/28 23:27:25 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3641  loss_cls: 0.05878  loss_box_reg: 0.1306  loss_mask: 0.1705  loss_rpn_cls: 0.008436  loss_rpn_loc: 0.01094  total_val_loss: 0.62  val_loss_cls: 0.1111  val_loss_box_reg: 0.1856  val_loss_mask: 0.3127  val_loss_rpn_cls: 0.01782  val_loss_rpn_loc: 0.008246  time: 0.8637  data_time: 0.0062  lr: 0.0011988  max_mem: 4747M
[32m[03/28 23:27:50 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3954  loss_cls: 0.05792  loss_box_reg: 0.1023  loss_mask: 0.1751  loss_rpn_cls: 0.005091  loss_rpn_loc: 0.00732  total_val_loss: 0.9686  val_loss_cls: 0.2182  val_loss_box_reg: 0.3524  val_loss_mask: 0.3576  val_loss_rpn_cls: 0.02645  val_loss_rpn_loc: 0.01574  time: 0.8633  data_time: 0.0059  lr: 0.0013986  max_mem: 4747M
[32m[03/28 23:28:14 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.2715  loss_cls: 0.04045  loss_box_reg: 0.07802  loss_mask: 0.1392  loss_rpn_cls: 0.004315  loss_rpn_loc: 0.007359  total_val_loss: 0.7168  val_loss_cls: 0.1619  val_loss_box_reg: 0.2892  val_loss_mask: 0.2945  val_loss_rpn_cls: 0.01201  val_loss_rpn_loc: 0.01388  time: 0.8642  data_time: 0.0062  lr: 0.0015984  max_mem: 4747M
[32m[03/28 23:28:38 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3539  loss_cls: 0.05146  loss_box_reg: 0.09208  loss_mask: 0.1723  loss_rpn_cls: 0.005804  loss_rpn_loc: 0.009088  total_val_loss: 0.8026  val_loss_cls: 0.1529  val_loss_box_reg: 0.224  val_loss_mask: 0.2983  val_loss_rpn_cls: 0.01915  val_loss_rpn_loc: 0.01703  time: 0.8646  data_time: 0.0067  lr: 0.0017982  max_mem: 4747M
[32m[03/28 23:29:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:29:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:29:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:29:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:29:04 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.2307  loss_cls: 0.0307  loss_box_reg: 0.04966  loss_mask: 0.1303  loss_rpn_cls: 0.002964  loss_rpn_loc: 0.007046  total_val_loss: 0.9274  val_loss_cls: 0.1639  val_loss_box_reg: 0.3217  val_loss_mask: 0.3318  val_loss_rpn_cls: 0.01714  val_loss_rpn_loc: 0.01316  time: 0.8647  data_time: 0.0064  lr: 0.001998  max_mem: 4747M
[32m[03/28 23:29:04 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8648 s / it)
[32m[03/28 23:29:04 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/28 23:29:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:29:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:29:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:29:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 23:29:04 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 23:29:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:29:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:29:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 23:29:05 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 23:29:08 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2263 s / img. ETA=0:14:14
[32m[03/28 23:29:14 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2319 s / img. ETA=0:14:22
[32m[03/28 23:29:19 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2302 s / img. ETA=0:14:01
[32m[03/28 23:29:24 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2295 s / img. ETA=0:13:47
[32m[03/28 23:29:29 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2301 s / img. ETA=0:13:55
[32m[03/28 23:29:34 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2321 s / img. ETA=0:14:11
[32m[03/28 23:29:39 d2.evaluation.evaluator]: [0mInference done 129/3489. 0.2348 s / img. ETA=0:14:34
[32m[03/28 23:29:44 d2.evaluation.evaluator]: [0mInference done 145/3489. 0.2372 s / img. ETA=0:14:54
[32m[03/28 23:29:50 d2.evaluation.evaluator]: [0mInference done 161/3489. 0.2389 s / img. ETA=0:15:08
[32m[03/28 23:29:55 d2.evaluation.evaluator]: [0mInference done 177/3489. 0.2401 s / img. ETA=0:15:17
[32m[03/28 23:30:00 d2.evaluation.evaluator]: [0mInference done 194/3489. 0.2410 s / img. ETA=0:15:19
[32m[03/28 23:30:05 d2.evaluation.evaluator]: [0mInference done 214/3489. 0.2404 s / img. ETA=0:15:08
[32m[03/28 23:30:10 d2.evaluation.evaluator]: [0mInference done 234/3489. 0.2399 s / img. ETA=0:14:58
[32m[03/28 23:30:15 d2.evaluation.evaluator]: [0mInference done 252/3489. 0.2400 s / img. ETA=0:14:55
[32m[03/28 23:30:21 d2.evaluation.evaluator]: [0mInference done 271/3489. 0.2399 s / img. ETA=0:14:50
[32m[03/28 23:30:26 d2.evaluation.evaluator]: [0mInference done 289/3489. 0.2400 s / img. ETA=0:14:45
[32m[03/28 23:30:31 d2.evaluation.evaluator]: [0mInference done 307/3489. 0.2401 s / img. ETA=0:14:41
[32m[03/28 23:30:36 d2.evaluation.evaluator]: [0mInference done 325/3489. 0.2402 s / img. ETA=0:14:37
[32m[03/28 23:30:41 d2.evaluation.evaluator]: [0mInference done 343/3489. 0.2403 s / img. ETA=0:14:34
[32m[03/28 23:30:46 d2.evaluation.evaluator]: [0mInference done 360/3489. 0.2406 s / img. ETA=0:14:32
[32m[03/28 23:30:51 d2.evaluation.evaluator]: [0mInference done 377/3489. 0.2408 s / img. ETA=0:14:30
[32m[03/28 23:30:56 d2.evaluation.evaluator]: [0mInference done 395/3489. 0.2409 s / img. ETA=0:14:25
[32m[03/28 23:31:01 d2.evaluation.evaluator]: [0mInference done 413/3489. 0.2409 s / img. ETA=0:14:20
[32m[03/28 23:31:06 d2.evaluation.evaluator]: [0mInference done 433/3489. 0.2406 s / img. ETA=0:14:11
[32m[03/28 23:31:11 d2.evaluation.evaluator]: [0mInference done 454/3489. 0.2401 s / img. ETA=0:14:00
[32m[03/28 23:31:17 d2.evaluation.evaluator]: [0mInference done 475/3489. 0.2396 s / img. ETA=0:13:50
[32m[03/28 23:31:22 d2.evaluation.evaluator]: [0mInference done 496/3489. 0.2392 s / img. ETA=0:13:40
[32m[03/28 23:31:27 d2.evaluation.evaluator]: [0mInference done 518/3489. 0.2387 s / img. ETA=0:13:29
[32m[03/28 23:31:32 d2.evaluation.evaluator]: [0mInference done 540/3489. 0.2381 s / img. ETA=0:13:18
[32m[03/28 23:31:37 d2.evaluation.evaluator]: [0mInference done 561/3489. 0.2379 s / img. ETA=0:13:10
[32m[03/28 23:31:42 d2.evaluation.evaluator]: [0mInference done 580/3489. 0.2378 s / img. ETA=0:13:05
[32m[03/28 23:31:47 d2.evaluation.evaluator]: [0mInference done 598/3489. 0.2380 s / img. ETA=0:13:02
[32m[03/28 23:31:53 d2.evaluation.evaluator]: [0mInference done 617/3489. 0.2380 s / img. ETA=0:12:56
[32m[03/28 23:31:58 d2.evaluation.evaluator]: [0mInference done 635/3489. 0.2381 s / img. ETA=0:12:52
[32m[03/28 23:32:03 d2.evaluation.evaluator]: [0mInference done 654/3489. 0.2380 s / img. ETA=0:12:47
[32m[03/28 23:32:08 d2.evaluation.evaluator]: [0mInference done 674/3489. 0.2378 s / img. ETA=0:12:40
[32m[03/28 23:32:13 d2.evaluation.evaluator]: [0mInference done 695/3489. 0.2375 s / img. ETA=0:12:32
[32m[03/28 23:32:18 d2.evaluation.evaluator]: [0mInference done 716/3489. 0.2373 s / img. ETA=0:12:24
[32m[03/28 23:32:23 d2.evaluation.evaluator]: [0mInference done 736/3489. 0.2373 s / img. ETA=0:12:18
[32m[03/28 23:32:28 d2.evaluation.evaluator]: [0mInference done 757/3489. 0.2371 s / img. ETA=0:12:11
[32m[03/28 23:32:33 d2.evaluation.evaluator]: [0mInference done 778/3489. 0.2369 s / img. ETA=0:12:03
[32m[03/28 23:32:38 d2.evaluation.evaluator]: [0mInference done 799/3489. 0.2367 s / img. ETA=0:11:55
[32m[03/28 23:32:43 d2.evaluation.evaluator]: [0mInference done 820/3489. 0.2365 s / img. ETA=0:11:48
[32m[03/28 23:32:48 d2.evaluation.evaluator]: [0mInference done 841/3489. 0.2363 s / img. ETA=0:11:41
[32m[03/28 23:32:53 d2.evaluation.evaluator]: [0mInference done 862/3489. 0.2361 s / img. ETA=0:11:33
[32m[03/28 23:32:59 d2.evaluation.evaluator]: [0mInference done 884/3489. 0.2359 s / img. ETA=0:11:26
[32m[03/28 23:33:04 d2.evaluation.evaluator]: [0mInference done 905/3489. 0.2358 s / img. ETA=0:11:20
[32m[03/28 23:33:09 d2.evaluation.evaluator]: [0mInference done 922/3489. 0.2360 s / img. ETA=0:11:17
[32m[03/28 23:33:14 d2.evaluation.evaluator]: [0mInference done 939/3489. 0.2363 s / img. ETA=0:11:14
[32m[03/28 23:33:19 d2.evaluation.evaluator]: [0mInference done 956/3489. 0.2365 s / img. ETA=0:11:11
[32m[03/28 23:33:25 d2.evaluation.evaluator]: [0mInference done 973/3489. 0.2367 s / img. ETA=0:11:09
[32m[03/28 23:33:30 d2.evaluation.evaluator]: [0mInference done 989/3489. 0.2371 s / img. ETA=0:11:07
[32m[03/28 23:33:35 d2.evaluation.evaluator]: [0mInference done 1005/3489. 0.2374 s / img. ETA=0:11:05
[32m[03/28 23:33:40 d2.evaluation.evaluator]: [0mInference done 1021/3489. 0.2376 s / img. ETA=0:11:02
[32m[03/28 23:33:45 d2.evaluation.evaluator]: [0mInference done 1037/3489. 0.2379 s / img. ETA=0:11:00
[32m[03/28 23:33:50 d2.evaluation.evaluator]: [0mInference done 1054/3489. 0.2381 s / img. ETA=0:10:57
[32m[03/28 23:33:55 d2.evaluation.evaluator]: [0mInference done 1071/3489. 0.2382 s / img. ETA=0:10:53
[32m[03/28 23:34:00 d2.evaluation.evaluator]: [0mInference done 1089/3489. 0.2384 s / img. ETA=0:10:49
[32m[03/28 23:34:06 d2.evaluation.evaluator]: [0mInference done 1109/3489. 0.2383 s / img. ETA=0:10:44
[32m[03/28 23:34:11 d2.evaluation.evaluator]: [0mInference done 1127/3489. 0.2384 s / img. ETA=0:10:39
[32m[03/28 23:34:16 d2.evaluation.evaluator]: [0mInference done 1144/3489. 0.2385 s / img. ETA=0:10:36
[32m[03/28 23:34:21 d2.evaluation.evaluator]: [0mInference done 1162/3489. 0.2386 s / img. ETA=0:10:32
[32m[03/28 23:34:26 d2.evaluation.evaluator]: [0mInference done 1179/3489. 0.2387 s / img. ETA=0:10:28
[32m[03/28 23:34:31 d2.evaluation.evaluator]: [0mInference done 1197/3489. 0.2388 s / img. ETA=0:10:23
[32m[03/28 23:34:36 d2.evaluation.evaluator]: [0mInference done 1215/3489. 0.2388 s / img. ETA=0:10:19
[32m[03/28 23:34:42 d2.evaluation.evaluator]: [0mInference done 1234/3489. 0.2388 s / img. ETA=0:10:14
[32m[03/28 23:34:47 d2.evaluation.evaluator]: [0mInference done 1253/3489. 0.2388 s / img. ETA=0:10:08
[32m[03/28 23:34:52 d2.evaluation.evaluator]: [0mInference done 1275/3489. 0.2385 s / img. ETA=0:10:01
[32m[03/28 23:34:57 d2.evaluation.evaluator]: [0mInference done 1297/3489. 0.2383 s / img. ETA=0:09:53
[32m[03/28 23:35:02 d2.evaluation.evaluator]: [0mInference done 1319/3489. 0.2381 s / img. ETA=0:09:46
[32m[03/28 23:35:07 d2.evaluation.evaluator]: [0mInference done 1341/3489. 0.2379 s / img. ETA=0:09:38
[32m[03/28 23:35:12 d2.evaluation.evaluator]: [0mInference done 1363/3489. 0.2377 s / img. ETA=0:09:31
[32m[03/28 23:35:17 d2.evaluation.evaluator]: [0mInference done 1385/3489. 0.2375 s / img. ETA=0:09:24
[32m[03/28 23:35:23 d2.evaluation.evaluator]: [0mInference done 1407/3489. 0.2374 s / img. ETA=0:09:17
[32m[03/28 23:35:28 d2.evaluation.evaluator]: [0mInference done 1429/3489. 0.2372 s / img. ETA=0:09:10
[32m[03/28 23:35:33 d2.evaluation.evaluator]: [0mInference done 1450/3489. 0.2371 s / img. ETA=0:09:04
[32m[03/28 23:35:38 d2.evaluation.evaluator]: [0mInference done 1472/3489. 0.2369 s / img. ETA=0:08:57
[32m[03/28 23:35:43 d2.evaluation.evaluator]: [0mInference done 1494/3489. 0.2368 s / img. ETA=0:08:50
[32m[03/28 23:35:48 d2.evaluation.evaluator]: [0mInference done 1516/3489. 0.2366 s / img. ETA=0:08:43
[32m[03/28 23:35:53 d2.evaluation.evaluator]: [0mInference done 1538/3489. 0.2365 s / img. ETA=0:08:37
[32m[03/28 23:35:59 d2.evaluation.evaluator]: [0mInference done 1560/3489. 0.2363 s / img. ETA=0:08:30
[32m[03/28 23:36:04 d2.evaluation.evaluator]: [0mInference done 1582/3489. 0.2362 s / img. ETA=0:08:23
[32m[03/28 23:36:09 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2361 s / img. ETA=0:08:18
[32m[03/28 23:36:14 d2.evaluation.evaluator]: [0mInference done 1621/3489. 0.2361 s / img. ETA=0:08:13
[32m[03/28 23:36:19 d2.evaluation.evaluator]: [0mInference done 1640/3489. 0.2362 s / img. ETA=0:08:08
[32m[03/28 23:36:24 d2.evaluation.evaluator]: [0mInference done 1659/3489. 0.2362 s / img. ETA=0:08:03
[32m[03/28 23:36:29 d2.evaluation.evaluator]: [0mInference done 1677/3489. 0.2362 s / img. ETA=0:07:59
[32m[03/28 23:36:34 d2.evaluation.evaluator]: [0mInference done 1693/3489. 0.2364 s / img. ETA=0:07:55
[32m[03/28 23:36:40 d2.evaluation.evaluator]: [0mInference done 1710/3489. 0.2365 s / img. ETA=0:07:52
[32m[03/28 23:36:45 d2.evaluation.evaluator]: [0mInference done 1727/3489. 0.2366 s / img. ETA=0:07:48
[32m[03/28 23:36:50 d2.evaluation.evaluator]: [0mInference done 1744/3489. 0.2367 s / img. ETA=0:07:44
[32m[03/28 23:36:55 d2.evaluation.evaluator]: [0mInference done 1760/3489. 0.2369 s / img. ETA=0:07:41
[32m[03/28 23:37:00 d2.evaluation.evaluator]: [0mInference done 1776/3489. 0.2371 s / img. ETA=0:07:37
[32m[03/28 23:37:05 d2.evaluation.evaluator]: [0mInference done 1792/3489. 0.2372 s / img. ETA=0:07:34
[32m[03/28 23:37:11 d2.evaluation.evaluator]: [0mInference done 1808/3489. 0.2374 s / img. ETA=0:07:30
[32m[03/28 23:37:16 d2.evaluation.evaluator]: [0mInference done 1824/3489. 0.2375 s / img. ETA=0:07:27
[32m[03/28 23:37:21 d2.evaluation.evaluator]: [0mInference done 1840/3489. 0.2376 s / img. ETA=0:07:23
[32m[03/28 23:37:26 d2.evaluation.evaluator]: [0mInference done 1856/3489. 0.2378 s / img. ETA=0:07:20
[32m[03/28 23:37:31 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2379 s / img. ETA=0:07:16
[32m[03/28 23:37:36 d2.evaluation.evaluator]: [0mInference done 1889/3489. 0.2380 s / img. ETA=0:07:12
[32m[03/28 23:37:42 d2.evaluation.evaluator]: [0mInference done 1905/3489. 0.2381 s / img. ETA=0:07:08
[32m[03/28 23:37:47 d2.evaluation.evaluator]: [0mInference done 1921/3489. 0.2382 s / img. ETA=0:07:05
[32m[03/28 23:37:52 d2.evaluation.evaluator]: [0mInference done 1938/3489. 0.2383 s / img. ETA=0:07:01
[32m[03/28 23:37:57 d2.evaluation.evaluator]: [0mInference done 1954/3489. 0.2384 s / img. ETA=0:06:57
[32m[03/28 23:38:02 d2.evaluation.evaluator]: [0mInference done 1970/3489. 0.2385 s / img. ETA=0:06:53
[32m[03/28 23:38:07 d2.evaluation.evaluator]: [0mInference done 1986/3489. 0.2387 s / img. ETA=0:06:49
[32m[03/28 23:38:12 d2.evaluation.evaluator]: [0mInference done 2004/3489. 0.2387 s / img. ETA=0:06:45
[32m[03/28 23:38:17 d2.evaluation.evaluator]: [0mInference done 2022/3489. 0.2387 s / img. ETA=0:06:40
[32m[03/28 23:38:23 d2.evaluation.evaluator]: [0mInference done 2040/3489. 0.2388 s / img. ETA=0:06:35
[32m[03/28 23:38:28 d2.evaluation.evaluator]: [0mInference done 2057/3489. 0.2389 s / img. ETA=0:06:31
[32m[03/28 23:38:33 d2.evaluation.evaluator]: [0mInference done 2074/3489. 0.2390 s / img. ETA=0:06:27
[32m[03/28 23:38:38 d2.evaluation.evaluator]: [0mInference done 2090/3489. 0.2391 s / img. ETA=0:06:23
[32m[03/28 23:38:43 d2.evaluation.evaluator]: [0mInference done 2107/3489. 0.2392 s / img. ETA=0:06:18
[32m[03/28 23:38:49 d2.evaluation.evaluator]: [0mInference done 2124/3489. 0.2393 s / img. ETA=0:06:14
[32m[03/28 23:38:54 d2.evaluation.evaluator]: [0mInference done 2140/3489. 0.2394 s / img. ETA=0:06:10
[32m[03/28 23:38:59 d2.evaluation.evaluator]: [0mInference done 2156/3489. 0.2395 s / img. ETA=0:06:06
[32m[03/28 23:39:04 d2.evaluation.evaluator]: [0mInference done 2172/3489. 0.2396 s / img. ETA=0:06:02
[32m[03/28 23:39:09 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2397 s / img. ETA=0:05:58
[32m[03/28 23:39:14 d2.evaluation.evaluator]: [0mInference done 2205/3489. 0.2398 s / img. ETA=0:05:54
[32m[03/28 23:39:20 d2.evaluation.evaluator]: [0mInference done 2222/3489. 0.2398 s / img. ETA=0:05:50
[32m[03/28 23:39:25 d2.evaluation.evaluator]: [0mInference done 2238/3489. 0.2399 s / img. ETA=0:05:46
[32m[03/28 23:39:30 d2.evaluation.evaluator]: [0mInference done 2255/3489. 0.2400 s / img. ETA=0:05:41
[32m[03/28 23:39:35 d2.evaluation.evaluator]: [0mInference done 2272/3489. 0.2400 s / img. ETA=0:05:37
[32m[03/28 23:39:40 d2.evaluation.evaluator]: [0mInference done 2290/3489. 0.2401 s / img. ETA=0:05:32
[32m[03/28 23:39:45 d2.evaluation.evaluator]: [0mInference done 2307/3489. 0.2401 s / img. ETA=0:05:27
[32m[03/28 23:39:50 d2.evaluation.evaluator]: [0mInference done 2323/3489. 0.2402 s / img. ETA=0:05:23
[32m[03/28 23:39:56 d2.evaluation.evaluator]: [0mInference done 2340/3489. 0.2403 s / img. ETA=0:05:19
[32m[03/28 23:40:01 d2.evaluation.evaluator]: [0mInference done 2357/3489. 0.2403 s / img. ETA=0:05:14
[32m[03/28 23:40:06 d2.evaluation.evaluator]: [0mInference done 2376/3489. 0.2403 s / img. ETA=0:05:09
[32m[03/28 23:40:11 d2.evaluation.evaluator]: [0mInference done 2395/3489. 0.2403 s / img. ETA=0:05:03
[32m[03/28 23:40:16 d2.evaluation.evaluator]: [0mInference done 2413/3489. 0.2403 s / img. ETA=0:04:59
[32m[03/28 23:40:22 d2.evaluation.evaluator]: [0mInference done 2432/3489. 0.2403 s / img. ETA=0:04:53
[32m[03/28 23:40:27 d2.evaluation.evaluator]: [0mInference done 2449/3489. 0.2404 s / img. ETA=0:04:49
[32m[03/28 23:40:32 d2.evaluation.evaluator]: [0mInference done 2466/3489. 0.2404 s / img. ETA=0:04:44
[32m[03/28 23:40:37 d2.evaluation.evaluator]: [0mInference done 2483/3489. 0.2405 s / img. ETA=0:04:40
[32m[03/28 23:40:42 d2.evaluation.evaluator]: [0mInference done 2503/3489. 0.2405 s / img. ETA=0:04:34
[32m[03/28 23:40:47 d2.evaluation.evaluator]: [0mInference done 2524/3489. 0.2404 s / img. ETA=0:04:28
[32m[03/28 23:40:52 d2.evaluation.evaluator]: [0mInference done 2544/3489. 0.2403 s / img. ETA=0:04:22
[32m[03/28 23:40:58 d2.evaluation.evaluator]: [0mInference done 2564/3489. 0.2403 s / img. ETA=0:04:16
[32m[03/28 23:41:03 d2.evaluation.evaluator]: [0mInference done 2585/3489. 0.2402 s / img. ETA=0:04:10
[32m[03/28 23:41:08 d2.evaluation.evaluator]: [0mInference done 2606/3489. 0.2401 s / img. ETA=0:04:04
[32m[03/28 23:41:13 d2.evaluation.evaluator]: [0mInference done 2627/3489. 0.2401 s / img. ETA=0:03:58
[32m[03/28 23:41:18 d2.evaluation.evaluator]: [0mInference done 2649/3489. 0.2400 s / img. ETA=0:03:52
[32m[03/28 23:41:23 d2.evaluation.evaluator]: [0mInference done 2669/3489. 0.2399 s / img. ETA=0:03:46
[32m[03/28 23:41:29 d2.evaluation.evaluator]: [0mInference done 2690/3489. 0.2398 s / img. ETA=0:03:40
[32m[03/28 23:41:34 d2.evaluation.evaluator]: [0mInference done 2710/3489. 0.2398 s / img. ETA=0:03:35
[32m[03/28 23:41:39 d2.evaluation.evaluator]: [0mInference done 2731/3489. 0.2397 s / img. ETA=0:03:29
[32m[03/28 23:41:44 d2.evaluation.evaluator]: [0mInference done 2752/3489. 0.2397 s / img. ETA=0:03:23
[32m[03/28 23:41:49 d2.evaluation.evaluator]: [0mInference done 2773/3489. 0.2396 s / img. ETA=0:03:17
[32m[03/28 23:41:54 d2.evaluation.evaluator]: [0mInference done 2794/3489. 0.2395 s / img. ETA=0:03:11
[32m[03/28 23:42:00 d2.evaluation.evaluator]: [0mInference done 2815/3489. 0.2394 s / img. ETA=0:03:05
[32m[03/28 23:42:05 d2.evaluation.evaluator]: [0mInference done 2836/3489. 0.2394 s / img. ETA=0:02:59
[32m[03/28 23:42:10 d2.evaluation.evaluator]: [0mInference done 2857/3489. 0.2393 s / img. ETA=0:02:53
[32m[03/28 23:42:15 d2.evaluation.evaluator]: [0mInference done 2878/3489. 0.2392 s / img. ETA=0:02:47
[32m[03/28 23:42:20 d2.evaluation.evaluator]: [0mInference done 2899/3489. 0.2391 s / img. ETA=0:02:41
[32m[03/28 23:42:25 d2.evaluation.evaluator]: [0mInference done 2920/3489. 0.2391 s / img. ETA=0:02:35
[32m[03/28 23:42:30 d2.evaluation.evaluator]: [0mInference done 2942/3489. 0.2390 s / img. ETA=0:02:29
[32m[03/28 23:42:35 d2.evaluation.evaluator]: [0mInference done 2964/3489. 0.2389 s / img. ETA=0:02:23
[32m[03/28 23:42:40 d2.evaluation.evaluator]: [0mInference done 2985/3489. 0.2388 s / img. ETA=0:02:17
[32m[03/28 23:42:46 d2.evaluation.evaluator]: [0mInference done 3006/3489. 0.2388 s / img. ETA=0:02:11
[32m[03/28 23:42:51 d2.evaluation.evaluator]: [0mInference done 3027/3489. 0.2387 s / img. ETA=0:02:05
[32m[03/28 23:42:56 d2.evaluation.evaluator]: [0mInference done 3048/3489. 0.2386 s / img. ETA=0:02:00
[32m[03/28 23:43:01 d2.evaluation.evaluator]: [0mInference done 3069/3489. 0.2386 s / img. ETA=0:01:54
[32m[03/28 23:43:06 d2.evaluation.evaluator]: [0mInference done 3090/3489. 0.2385 s / img. ETA=0:01:48
[32m[03/28 23:43:11 d2.evaluation.evaluator]: [0mInference done 3111/3489. 0.2385 s / img. ETA=0:01:42
[32m[03/28 23:43:17 d2.evaluation.evaluator]: [0mInference done 3132/3489. 0.2384 s / img. ETA=0:01:36
[32m[03/28 23:43:22 d2.evaluation.evaluator]: [0mInference done 3153/3489. 0.2384 s / img. ETA=0:01:31
[32m[03/28 23:43:27 d2.evaluation.evaluator]: [0mInference done 3174/3489. 0.2383 s / img. ETA=0:01:25
[32m[03/28 23:43:32 d2.evaluation.evaluator]: [0mInference done 3195/3489. 0.2382 s / img. ETA=0:01:19
[32m[03/28 23:43:37 d2.evaluation.evaluator]: [0mInference done 3216/3489. 0.2381 s / img. ETA=0:01:13
[32m[03/28 23:43:42 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2381 s / img. ETA=0:01:08
[32m[03/28 23:43:47 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2380 s / img. ETA=0:01:02
[32m[03/28 23:43:52 d2.evaluation.evaluator]: [0mInference done 3279/3489. 0.2379 s / img. ETA=0:00:56
[32m[03/28 23:43:57 d2.evaluation.evaluator]: [0mInference done 3301/3489. 0.2379 s / img. ETA=0:00:50
[32m[03/28 23:44:02 d2.evaluation.evaluator]: [0mInference done 3323/3489. 0.2378 s / img. ETA=0:00:44
[32m[03/28 23:44:07 d2.evaluation.evaluator]: [0mInference done 3345/3489. 0.2377 s / img. ETA=0:00:38
[32m[03/28 23:44:12 d2.evaluation.evaluator]: [0mInference done 3367/3489. 0.2376 s / img. ETA=0:00:32
[32m[03/28 23:44:17 d2.evaluation.evaluator]: [0mInference done 3389/3489. 0.2375 s / img. ETA=0:00:26
[32m[03/28 23:44:22 d2.evaluation.evaluator]: [0mInference done 3411/3489. 0.2375 s / img. ETA=0:00:20
[32m[03/28 23:44:28 d2.evaluation.evaluator]: [0mInference done 3433/3489. 0.2374 s / img. ETA=0:00:15
[32m[03/28 23:44:33 d2.evaluation.evaluator]: [0mInference done 3455/3489. 0.2373 s / img. ETA=0:00:09
[32m[03/28 23:44:38 d2.evaluation.evaluator]: [0mInference done 3477/3489. 0.2372 s / img. ETA=0:00:03
[32m[03/28 23:44:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:33.913434 (0.268058 s / img per device, on 1 devices)
[32m[03/28 23:44:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:46 (0.237207 s / img per device, on 1 devices)
[32m[03/28 23:44:43 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 23:44:43 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.200000_0.900000/coco_instances_results.json
[32m[03/28 23:44:44 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.67 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.48 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[32m[03/28 23:44:46 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.512 | 76.666 | 46.543 | 30.283 | 56.823 | 61.712 |
[32m[03/28 23:44:46 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.501 | Pedestrian | 32.522 |
Loading and preparing results...
DONE (t=1.66s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.09 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.51 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[32m[03/28 23:44:55 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.661 | 73.585 | 41.913 | 22.074 | 52.270 | 70.610 |
[32m[03/28 23:44:55 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.497 | Pedestrian | 25.824 |
[32m[03/28 23:44:55 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: 47.5116,76.6656,46.5435,30.2834,56.8230,61.7121
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 23:44:55 d2.evaluation.testing]: [0mcopypaste: 43.6607,73.5852,41.9133,22.0740,52.2704,70.6100
evaluated
Test [0.500000, 0.100000]
[32m[03/28 23:44:56 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 23:44:56 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 23:44:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:44:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:44:56 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 23:44:56 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 23:44:56 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 23:44:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 23:44:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 23:44:56 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 23:44:56 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 23:44:57 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 23:45:21 d2.utils.events]: [0m eta: 0:02:32  iter: 19  total_loss: 1.769  loss_cls: 0.7482  loss_box_reg: 0.2983  loss_mask: 0.6396  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.007685  total_val_loss: 1.855  val_loss_cls: 0.7608  val_loss_box_reg: 0.4742  val_loss_mask: 0.6541  val_loss_rpn_cls: 0.03548  val_loss_rpn_loc: 0.01093  time: 0.8443  data_time: 0.0336  lr: 0.00019981  max_mem: 4747M
[32m[03/28 23:45:46 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.9652  loss_cls: 0.2173  loss_box_reg: 0.4098  loss_mask: 0.3256  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.01065  total_val_loss: 1.133  val_loss_cls: 0.2439  val_loss_box_reg: 0.3913  val_loss_mask: 0.4389  val_loss_rpn_cls: 0.0327  val_loss_rpn_loc: 0.011  time: 0.8571  data_time: 0.0067  lr: 0.00039961  max_mem: 4747M
[32m[03/28 23:46:10 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.7081  loss_cls: 0.1112  loss_box_reg: 0.3912  loss_mask: 0.2057  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01187  total_val_loss: 1.162  val_loss_cls: 0.2322  val_loss_box_reg: 0.5046  val_loss_mask: 0.3985  val_loss_rpn_cls: 0.03067  val_loss_rpn_loc: 0.01417  time: 0.8624  data_time: 0.0064  lr: 0.00059941  max_mem: 4747M
[32m[03/28 23:46:35 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.438  loss_cls: 0.05345  loss_box_reg: 0.1594  loss_mask: 0.1741  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.005457  total_val_loss: 1.172  val_loss_cls: 0.2655  val_loss_box_reg: 0.375  val_loss_mask: 0.3159  val_loss_rpn_cls: 0.02335  val_loss_rpn_loc: 0.01238  time: 0.8633  data_time: 0.0062  lr: 0.00079921  max_mem: 4747M
[32m[03/28 23:47:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:47:00 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:47:00 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:47:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:47:00 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.5027  loss_cls: 0.07103  loss_box_reg: 0.2084  loss_mask: 0.1787  loss_rpn_cls: 0.009701  loss_rpn_loc: 0.008765  total_val_loss: 1.119  val_loss_cls: 0.2418  val_loss_box_reg: 0.3352  val_loss_mask: 0.4003  val_loss_rpn_cls: 0.02027  val_loss_rpn_loc: 0.01428  time: 0.8643  data_time: 0.0065  lr: 0.00099901  max_mem: 4747M
[32m[03/28 23:47:25 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.4041  loss_cls: 0.06395  loss_box_reg: 0.1335  loss_mask: 0.1576  loss_rpn_cls: 0.009353  loss_rpn_loc: 0.01291  total_val_loss: 0.7945  val_loss_cls: 0.1787  val_loss_box_reg: 0.2226  val_loss_mask: 0.3887  val_loss_rpn_cls: 0.02034  val_loss_rpn_loc: 0.01036  time: 0.8660  data_time: 0.0070  lr: 0.0011988  max_mem: 4747M
[32m[03/28 23:47:49 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3913  loss_cls: 0.06581  loss_box_reg: 0.1386  loss_mask: 0.1782  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.01215  total_val_loss: 1.026  val_loss_cls: 0.2247  val_loss_box_reg: 0.3071  val_loss_mask: 0.398  val_loss_rpn_cls: 0.02167  val_loss_rpn_loc: 0.01666  time: 0.8666  data_time: 0.0066  lr: 0.0013986  max_mem: 4747M
[32m[03/28 23:48:14 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3087  loss_cls: 0.04156  loss_box_reg: 0.1017  loss_mask: 0.16  loss_rpn_cls: 0.005962  loss_rpn_loc: 0.01015  total_val_loss: 1.084  val_loss_cls: 0.2536  val_loss_box_reg: 0.4244  val_loss_mask: 0.3628  val_loss_rpn_cls: 0.02244  val_loss_rpn_loc: 0.02324  time: 0.8664  data_time: 0.0063  lr: 0.0015984  max_mem: 4747M
[32m[03/28 23:48:38 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3272  loss_cls: 0.04467  loss_box_reg: 0.09909  loss_mask: 0.1688  loss_rpn_cls: 0.005978  loss_rpn_loc: 0.009206  total_val_loss: 0.8681  val_loss_cls: 0.1754  val_loss_box_reg: 0.2789  val_loss_mask: 0.3513  val_loss_rpn_cls: 0.02095  val_loss_rpn_loc: 0.01393  time: 0.8662  data_time: 0.0058  lr: 0.0017982  max_mem: 4747M
[32m[03/28 23:49:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:49:03 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:49:03 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:49:03 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 23:49:04 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.2992  loss_cls: 0.03522  loss_box_reg: 0.1023  loss_mask: 0.1368  loss_rpn_cls: 0.002646  loss_rpn_loc: 0.006427  total_val_loss: 1.043  val_loss_cls: 0.2008  val_loss_box_reg: 0.419  val_loss_mask: 0.3651  val_loss_rpn_cls: 0.01814  val_loss_rpn_loc: 0.01412  time: 0.8665  data_time: 0.0057  lr: 0.001998  max_mem: 4748M
[32m[03/28 23:49:04 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8665 s / it)
[32m[03/28 23:49:04 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/28 23:49:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:49:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:49:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 23:49:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 23:49:04 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 23:49:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 23:49:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 23:49:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 23:49:05 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 23:49:08 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2271 s / img. ETA=0:14:25
[32m[03/28 23:49:13 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2307 s / img. ETA=0:14:12
[32m[03/28 23:49:18 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2303 s / img. ETA=0:14:02
[32m[03/28 23:49:23 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2303 s / img. ETA=0:13:52
[32m[03/28 23:49:29 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2306 s / img. ETA=0:13:58
[32m[03/28 23:49:34 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2335 s / img. ETA=0:14:12
[32m[03/28 23:49:39 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2348 s / img. ETA=0:14:25
[32m[03/28 23:49:44 d2.evaluation.evaluator]: [0mInference done 146/3489. 0.2367 s / img. ETA=0:14:43
[32m[03/28 23:49:49 d2.evaluation.evaluator]: [0mInference done 162/3489. 0.2384 s / img. ETA=0:14:59
[32m[03/28 23:49:54 d2.evaluation.evaluator]: [0mInference done 179/3489. 0.2393 s / img. ETA=0:15:05
[32m[03/28 23:49:59 d2.evaluation.evaluator]: [0mInference done 197/3489. 0.2396 s / img. ETA=0:15:03
[32m[03/28 23:50:05 d2.evaluation.evaluator]: [0mInference done 218/3489. 0.2386 s / img. ETA=0:14:49
[32m[03/28 23:50:10 d2.evaluation.evaluator]: [0mInference done 238/3489. 0.2381 s / img. ETA=0:14:39
[32m[03/28 23:50:15 d2.evaluation.evaluator]: [0mInference done 257/3489. 0.2381 s / img. ETA=0:14:34
[32m[03/28 23:50:20 d2.evaluation.evaluator]: [0mInference done 276/3489. 0.2379 s / img. ETA=0:14:28
[32m[03/28 23:50:25 d2.evaluation.evaluator]: [0mInference done 296/3489. 0.2378 s / img. ETA=0:14:20
[32m[03/28 23:50:30 d2.evaluation.evaluator]: [0mInference done 314/3489. 0.2380 s / img. ETA=0:14:19
[32m[03/28 23:50:35 d2.evaluation.evaluator]: [0mInference done 333/3489. 0.2381 s / img. ETA=0:14:14
[32m[03/28 23:50:41 d2.evaluation.evaluator]: [0mInference done 351/3489. 0.2384 s / img. ETA=0:14:13
[32m[03/28 23:50:46 d2.evaluation.evaluator]: [0mInference done 369/3489. 0.2386 s / img. ETA=0:14:10
[32m[03/28 23:50:51 d2.evaluation.evaluator]: [0mInference done 387/3489. 0.2387 s / img. ETA=0:14:06
[32m[03/28 23:50:56 d2.evaluation.evaluator]: [0mInference done 406/3489. 0.2386 s / img. ETA=0:14:01
[32m[03/28 23:51:01 d2.evaluation.evaluator]: [0mInference done 425/3489. 0.2386 s / img. ETA=0:13:56
[32m[03/28 23:51:06 d2.evaluation.evaluator]: [0mInference done 446/3489. 0.2382 s / img. ETA=0:13:45
[32m[03/28 23:51:11 d2.evaluation.evaluator]: [0mInference done 467/3489. 0.2378 s / img. ETA=0:13:36
[32m[03/28 23:51:16 d2.evaluation.evaluator]: [0mInference done 488/3489. 0.2375 s / img. ETA=0:13:26
[32m[03/28 23:51:22 d2.evaluation.evaluator]: [0mInference done 510/3489. 0.2370 s / img. ETA=0:13:17
[32m[03/28 23:51:27 d2.evaluation.evaluator]: [0mInference done 532/3489. 0.2366 s / img. ETA=0:13:07
[32m[03/28 23:51:32 d2.evaluation.evaluator]: [0mInference done 553/3489. 0.2363 s / img. ETA=0:12:58
[32m[03/28 23:51:37 d2.evaluation.evaluator]: [0mInference done 573/3489. 0.2362 s / img. ETA=0:12:51
[32m[03/28 23:51:42 d2.evaluation.evaluator]: [0mInference done 592/3489. 0.2363 s / img. ETA=0:12:47
[32m[03/28 23:51:47 d2.evaluation.evaluator]: [0mInference done 611/3489. 0.2363 s / img. ETA=0:12:42
[32m[03/28 23:51:52 d2.evaluation.evaluator]: [0mInference done 630/3489. 0.2365 s / img. ETA=0:12:38
[32m[03/28 23:51:58 d2.evaluation.evaluator]: [0mInference done 649/3489. 0.2365 s / img. ETA=0:12:33
[32m[03/28 23:52:03 d2.evaluation.evaluator]: [0mInference done 669/3489. 0.2365 s / img. ETA=0:12:28
[32m[03/28 23:52:08 d2.evaluation.evaluator]: [0mInference done 690/3489. 0.2363 s / img. ETA=0:12:20
[32m[03/28 23:52:13 d2.evaluation.evaluator]: [0mInference done 711/3489. 0.2361 s / img. ETA=0:12:13
[32m[03/28 23:52:18 d2.evaluation.evaluator]: [0mInference done 732/3489. 0.2360 s / img. ETA=0:12:06
[32m[03/28 23:52:23 d2.evaluation.evaluator]: [0mInference done 753/3489. 0.2358 s / img. ETA=0:11:59
[32m[03/28 23:52:29 d2.evaluation.evaluator]: [0mInference done 775/3489. 0.2356 s / img. ETA=0:11:51
[32m[03/28 23:52:34 d2.evaluation.evaluator]: [0mInference done 797/3489. 0.2354 s / img. ETA=0:11:43
[32m[03/28 23:52:39 d2.evaluation.evaluator]: [0mInference done 819/3489. 0.2351 s / img. ETA=0:11:36
[32m[03/28 23:52:44 d2.evaluation.evaluator]: [0mInference done 841/3489. 0.2349 s / img. ETA=0:11:28
[32m[03/28 23:52:49 d2.evaluation.evaluator]: [0mInference done 863/3489. 0.2346 s / img. ETA=0:11:21
[32m[03/28 23:52:54 d2.evaluation.evaluator]: [0mInference done 885/3489. 0.2345 s / img. ETA=0:11:13
[32m[03/28 23:53:00 d2.evaluation.evaluator]: [0mInference done 906/3489. 0.2344 s / img. ETA=0:11:07
[32m[03/28 23:53:05 d2.evaluation.evaluator]: [0mInference done 924/3489. 0.2346 s / img. ETA=0:11:04
[32m[03/28 23:53:10 d2.evaluation.evaluator]: [0mInference done 941/3489. 0.2348 s / img. ETA=0:11:02
[32m[03/28 23:53:15 d2.evaluation.evaluator]: [0mInference done 959/3489. 0.2350 s / img. ETA=0:10:58
[32m[03/28 23:53:20 d2.evaluation.evaluator]: [0mInference done 976/3489. 0.2353 s / img. ETA=0:10:56
[32m[03/28 23:53:25 d2.evaluation.evaluator]: [0mInference done 993/3489. 0.2355 s / img. ETA=0:10:53
[32m[03/28 23:53:31 d2.evaluation.evaluator]: [0mInference done 1010/3489. 0.2358 s / img. ETA=0:10:51
[32m[03/28 23:53:36 d2.evaluation.evaluator]: [0mInference done 1026/3489. 0.2361 s / img. ETA=0:10:49
[32m[03/28 23:53:41 d2.evaluation.evaluator]: [0mInference done 1043/3489. 0.2363 s / img. ETA=0:10:46
[32m[03/28 23:53:46 d2.evaluation.evaluator]: [0mInference done 1060/3489. 0.2366 s / img. ETA=0:10:43
[32m[03/28 23:53:51 d2.evaluation.evaluator]: [0mInference done 1077/3489. 0.2367 s / img. ETA=0:10:40
[32m[03/28 23:53:56 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2367 s / img. ETA=0:10:34
[32m[03/28 23:54:02 d2.evaluation.evaluator]: [0mInference done 1117/3489. 0.2366 s / img. ETA=0:10:29
[32m[03/28 23:54:07 d2.evaluation.evaluator]: [0mInference done 1135/3489. 0.2368 s / img. ETA=0:10:25
[32m[03/28 23:54:12 d2.evaluation.evaluator]: [0mInference done 1152/3489. 0.2371 s / img. ETA=0:10:22
[32m[03/28 23:54:17 d2.evaluation.evaluator]: [0mInference done 1169/3489. 0.2372 s / img. ETA=0:10:18
[32m[03/28 23:54:22 d2.evaluation.evaluator]: [0mInference done 1187/3489. 0.2373 s / img. ETA=0:10:14
[32m[03/28 23:54:27 d2.evaluation.evaluator]: [0mInference done 1205/3489. 0.2374 s / img. ETA=0:10:10
[32m[03/28 23:54:33 d2.evaluation.evaluator]: [0mInference done 1224/3489. 0.2374 s / img. ETA=0:10:05
[32m[03/28 23:54:38 d2.evaluation.evaluator]: [0mInference done 1243/3489. 0.2375 s / img. ETA=0:10:00
[32m[03/28 23:54:43 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2374 s / img. ETA=0:09:54
[32m[03/28 23:54:48 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2371 s / img. ETA=0:09:47
[32m[03/28 23:54:53 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2370 s / img. ETA=0:09:40
[32m[03/28 23:54:58 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2367 s / img. ETA=0:09:32
[32m[03/28 23:55:03 d2.evaluation.evaluator]: [0mInference done 1352/3489. 0.2366 s / img. ETA=0:09:25
[32m[03/28 23:55:08 d2.evaluation.evaluator]: [0mInference done 1373/3489. 0.2364 s / img. ETA=0:09:19
[32m[03/28 23:55:13 d2.evaluation.evaluator]: [0mInference done 1394/3489. 0.2363 s / img. ETA=0:09:13
[32m[03/28 23:55:19 d2.evaluation.evaluator]: [0mInference done 1415/3489. 0.2362 s / img. ETA=0:09:07
[32m[03/28 23:55:24 d2.evaluation.evaluator]: [0mInference done 1436/3489. 0.2361 s / img. ETA=0:09:01
[32m[03/28 23:55:29 d2.evaluation.evaluator]: [0mInference done 1457/3489. 0.2361 s / img. ETA=0:08:54
[32m[03/28 23:55:34 d2.evaluation.evaluator]: [0mInference done 1478/3489. 0.2360 s / img. ETA=0:08:48
[32m[03/28 23:55:39 d2.evaluation.evaluator]: [0mInference done 1500/3489. 0.2358 s / img. ETA=0:08:42
[32m[03/28 23:55:44 d2.evaluation.evaluator]: [0mInference done 1522/3489. 0.2357 s / img. ETA=0:08:35
[32m[03/28 23:55:49 d2.evaluation.evaluator]: [0mInference done 1543/3489. 0.2356 s / img. ETA=0:08:29
[32m[03/28 23:55:54 d2.evaluation.evaluator]: [0mInference done 1564/3489. 0.2355 s / img. ETA=0:08:23
[32m[03/28 23:55:59 d2.evaluation.evaluator]: [0mInference done 1585/3489. 0.2354 s / img. ETA=0:08:17
[32m[03/28 23:56:05 d2.evaluation.evaluator]: [0mInference done 1605/3489. 0.2354 s / img. ETA=0:08:12
[32m[03/28 23:56:10 d2.evaluation.evaluator]: [0mInference done 1624/3489. 0.2355 s / img. ETA=0:08:07
[32m[03/28 23:56:15 d2.evaluation.evaluator]: [0mInference done 1643/3489. 0.2355 s / img. ETA=0:08:02
[32m[03/28 23:56:20 d2.evaluation.evaluator]: [0mInference done 1663/3489. 0.2355 s / img. ETA=0:07:57
[32m[03/28 23:56:25 d2.evaluation.evaluator]: [0mInference done 1680/3489. 0.2356 s / img. ETA=0:07:53
[32m[03/28 23:56:30 d2.evaluation.evaluator]: [0mInference done 1697/3489. 0.2357 s / img. ETA=0:07:49
[32m[03/28 23:56:35 d2.evaluation.evaluator]: [0mInference done 1714/3489. 0.2358 s / img. ETA=0:07:46
[32m[03/28 23:56:41 d2.evaluation.evaluator]: [0mInference done 1731/3489. 0.2359 s / img. ETA=0:07:42
[32m[03/28 23:56:46 d2.evaluation.evaluator]: [0mInference done 1748/3489. 0.2360 s / img. ETA=0:07:38
[32m[03/28 23:56:51 d2.evaluation.evaluator]: [0mInference done 1764/3489. 0.2362 s / img. ETA=0:07:35
[32m[03/28 23:56:56 d2.evaluation.evaluator]: [0mInference done 1780/3489. 0.2364 s / img. ETA=0:07:31
[32m[03/28 23:57:01 d2.evaluation.evaluator]: [0mInference done 1796/3489. 0.2365 s / img. ETA=0:07:28
[32m[03/28 23:57:06 d2.evaluation.evaluator]: [0mInference done 1812/3489. 0.2367 s / img. ETA=0:07:25
[32m[03/28 23:57:11 d2.evaluation.evaluator]: [0mInference done 1828/3489. 0.2368 s / img. ETA=0:07:21
[32m[03/28 23:57:16 d2.evaluation.evaluator]: [0mInference done 1844/3489. 0.2369 s / img. ETA=0:07:18
[32m[03/28 23:57:21 d2.evaluation.evaluator]: [0mInference done 1860/3489. 0.2371 s / img. ETA=0:07:14
[32m[03/28 23:57:27 d2.evaluation.evaluator]: [0mInference done 1877/3489. 0.2372 s / img. ETA=0:07:10
[32m[03/28 23:57:32 d2.evaluation.evaluator]: [0mInference done 1893/3489. 0.2373 s / img. ETA=0:07:07
[32m[03/28 23:57:37 d2.evaluation.evaluator]: [0mInference done 1909/3489. 0.2375 s / img. ETA=0:07:03
[32m[03/28 23:57:42 d2.evaluation.evaluator]: [0mInference done 1925/3489. 0.2376 s / img. ETA=0:06:59
[32m[03/28 23:57:47 d2.evaluation.evaluator]: [0mInference done 1941/3489. 0.2377 s / img. ETA=0:06:56
[32m[03/28 23:57:52 d2.evaluation.evaluator]: [0mInference done 1957/3489. 0.2379 s / img. ETA=0:06:52
[32m[03/28 23:57:57 d2.evaluation.evaluator]: [0mInference done 1973/3489. 0.2380 s / img. ETA=0:06:48
[32m[03/28 23:58:03 d2.evaluation.evaluator]: [0mInference done 1990/3489. 0.2381 s / img. ETA=0:06:44
[32m[03/28 23:58:08 d2.evaluation.evaluator]: [0mInference done 2008/3489. 0.2381 s / img. ETA=0:06:39
[32m[03/28 23:58:13 d2.evaluation.evaluator]: [0mInference done 2026/3489. 0.2381 s / img. ETA=0:06:35
[32m[03/28 23:58:18 d2.evaluation.evaluator]: [0mInference done 2044/3489. 0.2382 s / img. ETA=0:06:30
[32m[03/28 23:58:23 d2.evaluation.evaluator]: [0mInference done 2061/3489. 0.2383 s / img. ETA=0:06:26
[32m[03/28 23:58:28 d2.evaluation.evaluator]: [0mInference done 2078/3489. 0.2384 s / img. ETA=0:06:22
[32m[03/28 23:58:33 d2.evaluation.evaluator]: [0mInference done 2095/3489. 0.2384 s / img. ETA=0:06:18
[32m[03/28 23:58:39 d2.evaluation.evaluator]: [0mInference done 2112/3489. 0.2385 s / img. ETA=0:06:13
[32m[03/28 23:58:44 d2.evaluation.evaluator]: [0mInference done 2128/3489. 0.2386 s / img. ETA=0:06:10
[32m[03/28 23:58:49 d2.evaluation.evaluator]: [0mInference done 2144/3489. 0.2388 s / img. ETA=0:06:06
[32m[03/28 23:58:54 d2.evaluation.evaluator]: [0mInference done 2160/3489. 0.2389 s / img. ETA=0:06:02
[32m[03/28 23:58:59 d2.evaluation.evaluator]: [0mInference done 2176/3489. 0.2390 s / img. ETA=0:05:58
[32m[03/28 23:59:04 d2.evaluation.evaluator]: [0mInference done 2192/3489. 0.2391 s / img. ETA=0:05:54
[32m[03/28 23:59:09 d2.evaluation.evaluator]: [0mInference done 2208/3489. 0.2392 s / img. ETA=0:05:50
[32m[03/28 23:59:15 d2.evaluation.evaluator]: [0mInference done 2225/3489. 0.2393 s / img. ETA=0:05:46
[32m[03/28 23:59:20 d2.evaluation.evaluator]: [0mInference done 2242/3489. 0.2394 s / img. ETA=0:05:41
[32m[03/28 23:59:25 d2.evaluation.evaluator]: [0mInference done 2260/3489. 0.2394 s / img. ETA=0:05:37
[32m[03/28 23:59:30 d2.evaluation.evaluator]: [0mInference done 2278/3489. 0.2395 s / img. ETA=0:05:32
[32m[03/28 23:59:35 d2.evaluation.evaluator]: [0mInference done 2295/3489. 0.2395 s / img. ETA=0:05:27
[32m[03/28 23:59:41 d2.evaluation.evaluator]: [0mInference done 2312/3489. 0.2396 s / img. ETA=0:05:23
[32m[03/28 23:59:46 d2.evaluation.evaluator]: [0mInference done 2329/3489. 0.2397 s / img. ETA=0:05:19
[32m[03/28 23:59:51 d2.evaluation.evaluator]: [0mInference done 2346/3489. 0.2397 s / img. ETA=0:05:14
[32m[03/28 23:59:56 d2.evaluation.evaluator]: [0mInference done 2364/3489. 0.2398 s / img. ETA=0:05:09
[32m[03/29 00:00:01 d2.evaluation.evaluator]: [0mInference done 2383/3489. 0.2397 s / img. ETA=0:05:04
[32m[03/29 00:00:06 d2.evaluation.evaluator]: [0mInference done 2402/3489. 0.2397 s / img. ETA=0:04:59
[32m[03/29 00:00:12 d2.evaluation.evaluator]: [0mInference done 2421/3489. 0.2397 s / img. ETA=0:04:53
[32m[03/29 00:00:17 d2.evaluation.evaluator]: [0mInference done 2440/3489. 0.2397 s / img. ETA=0:04:48
[32m[03/29 00:00:22 d2.evaluation.evaluator]: [0mInference done 2457/3489. 0.2397 s / img. ETA=0:04:44
[32m[03/29 00:00:27 d2.evaluation.evaluator]: [0mInference done 2474/3489. 0.2398 s / img. ETA=0:04:39
[32m[03/29 00:00:32 d2.evaluation.evaluator]: [0mInference done 2492/3489. 0.2398 s / img. ETA=0:04:34
[32m[03/29 00:00:37 d2.evaluation.evaluator]: [0mInference done 2514/3489. 0.2397 s / img. ETA=0:04:28
[32m[03/29 00:00:42 d2.evaluation.evaluator]: [0mInference done 2534/3489. 0.2397 s / img. ETA=0:04:22
[32m[03/29 00:00:47 d2.evaluation.evaluator]: [0mInference done 2554/3489. 0.2396 s / img. ETA=0:04:17
[32m[03/29 00:00:52 d2.evaluation.evaluator]: [0mInference done 2574/3489. 0.2396 s / img. ETA=0:04:11
[32m[03/29 00:00:57 d2.evaluation.evaluator]: [0mInference done 2595/3489. 0.2395 s / img. ETA=0:04:05
[32m[03/29 00:01:03 d2.evaluation.evaluator]: [0mInference done 2615/3489. 0.2395 s / img. ETA=0:03:59
[32m[03/29 00:01:08 d2.evaluation.evaluator]: [0mInference done 2636/3489. 0.2394 s / img. ETA=0:03:53
[32m[03/29 00:01:13 d2.evaluation.evaluator]: [0mInference done 2658/3489. 0.2393 s / img. ETA=0:03:47
[32m[03/29 00:01:18 d2.evaluation.evaluator]: [0mInference done 2678/3489. 0.2393 s / img. ETA=0:03:41
[32m[03/29 00:01:23 d2.evaluation.evaluator]: [0mInference done 2698/3489. 0.2392 s / img. ETA=0:03:36
[32m[03/29 00:01:28 d2.evaluation.evaluator]: [0mInference done 2718/3489. 0.2392 s / img. ETA=0:03:30
[32m[03/29 00:01:33 d2.evaluation.evaluator]: [0mInference done 2738/3489. 0.2391 s / img. ETA=0:03:25
[32m[03/29 00:01:38 d2.evaluation.evaluator]: [0mInference done 2758/3489. 0.2391 s / img. ETA=0:03:19
[32m[03/29 00:01:44 d2.evaluation.evaluator]: [0mInference done 2779/3489. 0.2390 s / img. ETA=0:03:13
[32m[03/29 00:01:49 d2.evaluation.evaluator]: [0mInference done 2800/3489. 0.2390 s / img. ETA=0:03:07
[32m[03/29 00:01:54 d2.evaluation.evaluator]: [0mInference done 2820/3489. 0.2389 s / img. ETA=0:03:02
[32m[03/29 00:01:59 d2.evaluation.evaluator]: [0mInference done 2840/3489. 0.2389 s / img. ETA=0:02:56
[32m[03/29 00:02:04 d2.evaluation.evaluator]: [0mInference done 2860/3489. 0.2388 s / img. ETA=0:02:51
[32m[03/29 00:02:09 d2.evaluation.evaluator]: [0mInference done 2881/3489. 0.2388 s / img. ETA=0:02:45
[32m[03/29 00:02:14 d2.evaluation.evaluator]: [0mInference done 2902/3489. 0.2387 s / img. ETA=0:02:39
[32m[03/29 00:02:19 d2.evaluation.evaluator]: [0mInference done 2923/3489. 0.2386 s / img. ETA=0:02:33
[32m[03/29 00:02:24 d2.evaluation.evaluator]: [0mInference done 2944/3489. 0.2385 s / img. ETA=0:02:27
[32m[03/29 00:02:30 d2.evaluation.evaluator]: [0mInference done 2966/3489. 0.2385 s / img. ETA=0:02:21
[32m[03/29 00:02:35 d2.evaluation.evaluator]: [0mInference done 2987/3489. 0.2384 s / img. ETA=0:02:16
[32m[03/29 00:02:40 d2.evaluation.evaluator]: [0mInference done 3007/3489. 0.2384 s / img. ETA=0:02:10
[32m[03/29 00:02:45 d2.evaluation.evaluator]: [0mInference done 3027/3489. 0.2383 s / img. ETA=0:02:05
[32m[03/29 00:02:50 d2.evaluation.evaluator]: [0mInference done 3048/3489. 0.2383 s / img. ETA=0:01:59
[32m[03/29 00:02:55 d2.evaluation.evaluator]: [0mInference done 3068/3489. 0.2382 s / img. ETA=0:01:53
[32m[03/29 00:03:01 d2.evaluation.evaluator]: [0mInference done 3088/3489. 0.2382 s / img. ETA=0:01:48
[32m[03/29 00:03:06 d2.evaluation.evaluator]: [0mInference done 3108/3489. 0.2382 s / img. ETA=0:01:43
[32m[03/29 00:03:11 d2.evaluation.evaluator]: [0mInference done 3128/3489. 0.2381 s / img. ETA=0:01:37
[32m[03/29 00:03:16 d2.evaluation.evaluator]: [0mInference done 3148/3489. 0.2381 s / img. ETA=0:01:32
[32m[03/29 00:03:21 d2.evaluation.evaluator]: [0mInference done 3168/3489. 0.2380 s / img. ETA=0:01:26
[32m[03/29 00:03:26 d2.evaluation.evaluator]: [0mInference done 3189/3489. 0.2380 s / img. ETA=0:01:20
[32m[03/29 00:03:31 d2.evaluation.evaluator]: [0mInference done 3209/3489. 0.2380 s / img. ETA=0:01:15
[32m[03/29 00:03:36 d2.evaluation.evaluator]: [0mInference done 3229/3489. 0.2379 s / img. ETA=0:01:10
[32m[03/29 00:03:41 d2.evaluation.evaluator]: [0mInference done 3249/3489. 0.2379 s / img. ETA=0:01:04
[32m[03/29 00:03:46 d2.evaluation.evaluator]: [0mInference done 3270/3489. 0.2378 s / img. ETA=0:00:59
[32m[03/29 00:03:52 d2.evaluation.evaluator]: [0mInference done 3292/3489. 0.2378 s / img. ETA=0:00:53
[32m[03/29 00:03:57 d2.evaluation.evaluator]: [0mInference done 3314/3489. 0.2377 s / img. ETA=0:00:47
[32m[03/29 00:04:02 d2.evaluation.evaluator]: [0mInference done 3336/3489. 0.2376 s / img. ETA=0:00:41
[32m[03/29 00:04:07 d2.evaluation.evaluator]: [0mInference done 3358/3489. 0.2375 s / img. ETA=0:00:35
[32m[03/29 00:04:12 d2.evaluation.evaluator]: [0mInference done 3380/3489. 0.2374 s / img. ETA=0:00:29
[32m[03/29 00:04:17 d2.evaluation.evaluator]: [0mInference done 3402/3489. 0.2374 s / img. ETA=0:00:23
[32m[03/29 00:04:22 d2.evaluation.evaluator]: [0mInference done 3423/3489. 0.2373 s / img. ETA=0:00:17
[32m[03/29 00:04:27 d2.evaluation.evaluator]: [0mInference done 3444/3489. 0.2373 s / img. ETA=0:00:12
[32m[03/29 00:04:32 d2.evaluation.evaluator]: [0mInference done 3465/3489. 0.2372 s / img. ETA=0:00:06
[32m[03/29 00:04:37 d2.evaluation.evaluator]: [0mInference done 3486/3489. 0.2372 s / img. ETA=0:00:00
[32m[03/29 00:04:38 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:31.608361 (0.267396 s / img per device, on 1 devices)
[32m[03/29 00:04:38 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:46 (0.237144 s / img per device, on 1 devices)
[32m[03/29 00:04:40 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 00:04:40 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.500000_0.100000/coco_instances_results.json
[32m[03/29 00:04:41 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.38 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.46 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.763
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[32m[03/29 00:04:43 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.739 | 76.306 | 39.774 | 30.709 | 51.180 | 57.948 |
[32m[03/29 00:04:43 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 65.198 | Pedestrian | 24.281 |
Loading and preparing results...
DONE (t=1.68s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.51 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.50 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772
[32m[03/29 00:04:52 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.935 | 72.949 | 40.184 | 23.867 | 51.259 | 70.736 |
[32m[03/29 00:04:52 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.677 | Pedestrian | 21.193 |
[32m[03/29 00:04:52 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: 44.7393,76.3060,39.7744,30.7094,51.1801,57.9481
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:04:52 d2.evaluation.testing]: [0mcopypaste: 42.9353,72.9488,40.1835,23.8668,51.2591,70.7357
evaluated
Test [0.500000, 0.200000]
[32m[03/29 00:04:53 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 00:04:53 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/29 00:04:53 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:04:53 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:04:53 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/29 00:04:53 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/29 00:04:53 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 00:04:53 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:04:53 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:04:53 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 00:04:53 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 00:04:54 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 00:05:18 d2.utils.events]: [0m eta: 0:02:29  iter: 19  total_loss: 1.89  loss_cls: 0.8917  loss_box_reg: 0.383  loss_mask: 0.6611  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.008583  total_val_loss: 2.013  val_loss_cls: 0.845  val_loss_box_reg: 0.4724  val_loss_mask: 0.6708  val_loss_rpn_cls: 0.03602  val_loss_rpn_loc: 0.01286  time: 0.8349  data_time: 0.0236  lr: 0.00019981  max_mem: 4748M
[32m[03/29 00:05:42 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 0.8649  loss_cls: 0.1535  loss_box_reg: 0.2441  loss_mask: 0.4139  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.005783  total_val_loss: 1.293  val_loss_cls: 0.2941  val_loss_box_reg: 0.4243  val_loss_mask: 0.5534  val_loss_rpn_cls: 0.04542  val_loss_rpn_loc: 0.0153  time: 0.8517  data_time: 0.0068  lr: 0.00039961  max_mem: 4748M
[32m[03/29 00:06:07 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.6655  loss_cls: 0.0988  loss_box_reg: 0.3472  loss_mask: 0.2136  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.009859  total_val_loss: 1.129  val_loss_cls: 0.2219  val_loss_box_reg: 0.4719  val_loss_mask: 0.4367  val_loss_rpn_cls: 0.02978  val_loss_rpn_loc: 0.01299  time: 0.8584  data_time: 0.0066  lr: 0.00059941  max_mem: 4748M
[32m[03/29 00:06:31 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 0.5685  loss_cls: 0.06694  loss_box_reg: 0.3182  loss_mask: 0.1779  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.009932  total_val_loss: 0.7166  val_loss_cls: 0.1121  val_loss_box_reg: 0.3093  val_loss_mask: 0.2731  val_loss_rpn_cls: 0.02203  val_loss_rpn_loc: 0.0122  time: 0.8627  data_time: 0.0065  lr: 0.00079921  max_mem: 4748M
[32m[03/29 00:06:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:06:56 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:06:56 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:06:56 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:06:56 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.3644  loss_cls: 0.05323  loss_box_reg: 0.1364  loss_mask: 0.1353  loss_rpn_cls: 0.009702  loss_rpn_loc: 0.009396  total_val_loss: 1.069  val_loss_cls: 0.2525  val_loss_box_reg: 0.3075  val_loss_mask: 0.4237  val_loss_rpn_cls: 0.02151  val_loss_rpn_loc: 0.01273  time: 0.8644  data_time: 0.0064  lr: 0.00099901  max_mem: 4748M
[32m[03/29 00:07:21 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.4041  loss_cls: 0.05278  loss_box_reg: 0.1099  loss_mask: 0.1854  loss_rpn_cls: 0.006531  loss_rpn_loc: 0.007777  total_val_loss: 0.6967  val_loss_cls: 0.1466  val_loss_box_reg: 0.2003  val_loss_mask: 0.3005  val_loss_rpn_cls: 0.01613  val_loss_rpn_loc: 0.01287  time: 0.8652  data_time: 0.0064  lr: 0.0011988  max_mem: 4748M
[32m[03/29 00:07:45 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3464  loss_cls: 0.04562  loss_box_reg: 0.06322  loss_mask: 0.1842  loss_rpn_cls: 0.009208  loss_rpn_loc: 0.006828  total_val_loss: 0.7464  val_loss_cls: 0.1355  val_loss_box_reg: 0.1864  val_loss_mask: 0.355  val_loss_rpn_cls: 0.01542  val_loss_rpn_loc: 0.01109  time: 0.8665  data_time: 0.0070  lr: 0.0013986  max_mem: 4748M
[32m[03/29 00:08:10 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.4301  loss_cls: 0.04908  loss_box_reg: 0.16  loss_mask: 0.1844  loss_rpn_cls: 0.006955  loss_rpn_loc: 0.006395  total_val_loss: 0.8791  val_loss_cls: 0.182  val_loss_box_reg: 0.3223  val_loss_mask: 0.3191  val_loss_rpn_cls: 0.01901  val_loss_rpn_loc: 0.01733  time: 0.8673  data_time: 0.0070  lr: 0.0015984  max_mem: 4748M
[32m[03/29 00:08:35 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3787  loss_cls: 0.05297  loss_box_reg: 0.1094  loss_mask: 0.1504  loss_rpn_cls: 0.008289  loss_rpn_loc: 0.01006  total_val_loss: 0.8176  val_loss_cls: 0.1453  val_loss_box_reg: 0.229  val_loss_mask: 0.3005  val_loss_rpn_cls: 0.01955  val_loss_rpn_loc: 0.01248  time: 0.8678  data_time: 0.0062  lr: 0.0017982  max_mem: 4748M
[32m[03/29 00:09:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:09:00 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:09:00 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:09:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:09:01 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.371  loss_cls: 0.06097  loss_box_reg: 0.1152  loss_mask: 0.1507  loss_rpn_cls: 0.003954  loss_rpn_loc: 0.01135  total_val_loss: 0.5445  val_loss_cls: 0.1021  val_loss_box_reg: 0.2041  val_loss_mask: 0.2238  val_loss_rpn_cls: 0.01463  val_loss_rpn_loc: 0.01069  time: 0.8684  data_time: 0.0068  lr: 0.001998  max_mem: 4748M
[32m[03/29 00:09:01 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8684 s / it)
[32m[03/29 00:09:01 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/29 00:09:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:09:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:09:01 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:09:01 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 00:09:01 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 00:09:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:09:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:09:02 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 00:09:02 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 00:09:05 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2249 s / img. ETA=0:13:49
[32m[03/29 00:09:10 d2.evaluation.evaluator]: [0mInference done 33/3489. 0.2256 s / img. ETA=0:13:39
[32m[03/29 00:09:15 d2.evaluation.evaluator]: [0mInference done 55/3489. 0.2263 s / img. ETA=0:13:34
[32m[03/29 00:09:20 d2.evaluation.evaluator]: [0mInference done 77/3489. 0.2268 s / img. ETA=0:13:27
[32m[03/29 00:09:25 d2.evaluation.evaluator]: [0mInference done 97/3489. 0.2274 s / img. ETA=0:13:36
[32m[03/29 00:09:31 d2.evaluation.evaluator]: [0mInference done 117/3489. 0.2285 s / img. ETA=0:13:45
[32m[03/29 00:09:36 d2.evaluation.evaluator]: [0mInference done 134/3489. 0.2309 s / img. ETA=0:14:03
[32m[03/29 00:09:41 d2.evaluation.evaluator]: [0mInference done 150/3489. 0.2331 s / img. ETA=0:14:21
[32m[03/29 00:09:46 d2.evaluation.evaluator]: [0mInference done 166/3489. 0.2358 s / img. ETA=0:14:40
[32m[03/29 00:09:51 d2.evaluation.evaluator]: [0mInference done 183/3489. 0.2366 s / img. ETA=0:14:45
[32m[03/29 00:09:56 d2.evaluation.evaluator]: [0mInference done 202/3489. 0.2368 s / img. ETA=0:14:42
[32m[03/29 00:10:01 d2.evaluation.evaluator]: [0mInference done 222/3489. 0.2370 s / img. ETA=0:14:33
[32m[03/29 00:10:06 d2.evaluation.evaluator]: [0mInference done 242/3489. 0.2366 s / img. ETA=0:14:24
[32m[03/29 00:10:11 d2.evaluation.evaluator]: [0mInference done 262/3489. 0.2364 s / img. ETA=0:14:17
[32m[03/29 00:10:17 d2.evaluation.evaluator]: [0mInference done 282/3489. 0.2362 s / img. ETA=0:14:10
[32m[03/29 00:10:22 d2.evaluation.evaluator]: [0mInference done 302/3489. 0.2361 s / img. ETA=0:14:04
[32m[03/29 00:10:27 d2.evaluation.evaluator]: [0mInference done 321/3489. 0.2361 s / img. ETA=0:14:00
[32m[03/29 00:10:32 d2.evaluation.evaluator]: [0mInference done 340/3489. 0.2363 s / img. ETA=0:13:57
[32m[03/29 00:10:37 d2.evaluation.evaluator]: [0mInference done 358/3489. 0.2365 s / img. ETA=0:13:55
[32m[03/29 00:10:42 d2.evaluation.evaluator]: [0mInference done 377/3489. 0.2366 s / img. ETA=0:13:51
[32m[03/29 00:10:48 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2367 s / img. ETA=0:13:46
[32m[03/29 00:10:53 d2.evaluation.evaluator]: [0mInference done 415/3489. 0.2367 s / img. ETA=0:13:42
[32m[03/29 00:10:58 d2.evaluation.evaluator]: [0mInference done 436/3489. 0.2363 s / img. ETA=0:13:33
[32m[03/29 00:11:03 d2.evaluation.evaluator]: [0mInference done 457/3489. 0.2361 s / img. ETA=0:13:24
[32m[03/29 00:11:08 d2.evaluation.evaluator]: [0mInference done 478/3489. 0.2358 s / img. ETA=0:13:15
[32m[03/29 00:11:13 d2.evaluation.evaluator]: [0mInference done 500/3489. 0.2353 s / img. ETA=0:13:06
[32m[03/29 00:11:18 d2.evaluation.evaluator]: [0mInference done 522/3489. 0.2349 s / img. ETA=0:12:56
[32m[03/29 00:11:24 d2.evaluation.evaluator]: [0mInference done 544/3489. 0.2344 s / img. ETA=0:12:47
[32m[03/29 00:11:29 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2343 s / img. ETA=0:12:40
[32m[03/29 00:11:34 d2.evaluation.evaluator]: [0mInference done 585/3489. 0.2343 s / img. ETA=0:12:35
[32m[03/29 00:11:39 d2.evaluation.evaluator]: [0mInference done 604/3489. 0.2343 s / img. ETA=0:12:30
[32m[03/29 00:11:44 d2.evaluation.evaluator]: [0mInference done 623/3489. 0.2344 s / img. ETA=0:12:26
[32m[03/29 00:11:49 d2.evaluation.evaluator]: [0mInference done 642/3489. 0.2344 s / img. ETA=0:12:21
[32m[03/29 00:11:54 d2.evaluation.evaluator]: [0mInference done 662/3489. 0.2344 s / img. ETA=0:12:16
[32m[03/29 00:12:00 d2.evaluation.evaluator]: [0mInference done 683/3489. 0.2344 s / img. ETA=0:12:10
[32m[03/29 00:12:05 d2.evaluation.evaluator]: [0mInference done 704/3489. 0.2342 s / img. ETA=0:12:03
[32m[03/29 00:12:10 d2.evaluation.evaluator]: [0mInference done 725/3489. 0.2340 s / img. ETA=0:11:56
[32m[03/29 00:12:15 d2.evaluation.evaluator]: [0mInference done 746/3489. 0.2339 s / img. ETA=0:11:50
[32m[03/29 00:12:20 d2.evaluation.evaluator]: [0mInference done 767/3489. 0.2338 s / img. ETA=0:11:43
[32m[03/29 00:12:25 d2.evaluation.evaluator]: [0mInference done 789/3489. 0.2336 s / img. ETA=0:11:35
[32m[03/29 00:12:30 d2.evaluation.evaluator]: [0mInference done 811/3489. 0.2333 s / img. ETA=0:11:28
[32m[03/29 00:12:35 d2.evaluation.evaluator]: [0mInference done 833/3489. 0.2331 s / img. ETA=0:11:20
[32m[03/29 00:12:41 d2.evaluation.evaluator]: [0mInference done 855/3489. 0.2329 s / img. ETA=0:11:13
[32m[03/29 00:12:46 d2.evaluation.evaluator]: [0mInference done 876/3489. 0.2328 s / img. ETA=0:11:07
[32m[03/29 00:12:51 d2.evaluation.evaluator]: [0mInference done 898/3489. 0.2326 s / img. ETA=0:11:00
[32m[03/29 00:12:56 d2.evaluation.evaluator]: [0mInference done 916/3489. 0.2328 s / img. ETA=0:10:57
[32m[03/29 00:13:01 d2.evaluation.evaluator]: [0mInference done 934/3489. 0.2330 s / img. ETA=0:10:54
[32m[03/29 00:13:06 d2.evaluation.evaluator]: [0mInference done 951/3489. 0.2332 s / img. ETA=0:10:51
[32m[03/29 00:13:11 d2.evaluation.evaluator]: [0mInference done 969/3489. 0.2334 s / img. ETA=0:10:48
[32m[03/29 00:13:16 d2.evaluation.evaluator]: [0mInference done 986/3489. 0.2337 s / img. ETA=0:10:46
[32m[03/29 00:13:22 d2.evaluation.evaluator]: [0mInference done 1003/3489. 0.2340 s / img. ETA=0:10:44
[32m[03/29 00:13:27 d2.evaluation.evaluator]: [0mInference done 1020/3489. 0.2344 s / img. ETA=0:10:41
[32m[03/29 00:13:32 d2.evaluation.evaluator]: [0mInference done 1037/3489. 0.2346 s / img. ETA=0:10:39
[32m[03/29 00:13:37 d2.evaluation.evaluator]: [0mInference done 1054/3489. 0.2347 s / img. ETA=0:10:36
[32m[03/29 00:13:42 d2.evaluation.evaluator]: [0mInference done 1071/3489. 0.2350 s / img. ETA=0:10:33
[32m[03/29 00:13:47 d2.evaluation.evaluator]: [0mInference done 1090/3489. 0.2350 s / img. ETA=0:10:28
[32m[03/29 00:13:52 d2.evaluation.evaluator]: [0mInference done 1110/3489. 0.2349 s / img. ETA=0:10:22
[32m[03/29 00:13:58 d2.evaluation.evaluator]: [0mInference done 1129/3489. 0.2350 s / img. ETA=0:10:18
[32m[03/29 00:14:03 d2.evaluation.evaluator]: [0mInference done 1147/3489. 0.2350 s / img. ETA=0:10:14
[32m[03/29 00:14:08 d2.evaluation.evaluator]: [0mInference done 1165/3489. 0.2352 s / img. ETA=0:10:10
[32m[03/29 00:14:13 d2.evaluation.evaluator]: [0mInference done 1184/3489. 0.2353 s / img. ETA=0:10:06
[32m[03/29 00:14:18 d2.evaluation.evaluator]: [0mInference done 1203/3489. 0.2353 s / img. ETA=0:10:01
[32m[03/29 00:14:23 d2.evaluation.evaluator]: [0mInference done 1222/3489. 0.2353 s / img. ETA=0:09:56
[32m[03/29 00:14:28 d2.evaluation.evaluator]: [0mInference done 1241/3489. 0.2353 s / img. ETA=0:09:51
[32m[03/29 00:14:33 d2.evaluation.evaluator]: [0mInference done 1262/3489. 0.2352 s / img. ETA=0:09:45
[32m[03/29 00:14:38 d2.evaluation.evaluator]: [0mInference done 1284/3489. 0.2350 s / img. ETA=0:09:38
[32m[03/29 00:14:44 d2.evaluation.evaluator]: [0mInference done 1306/3489. 0.2349 s / img. ETA=0:09:31
[32m[03/29 00:14:49 d2.evaluation.evaluator]: [0mInference done 1328/3489. 0.2348 s / img. ETA=0:09:24
[32m[03/29 00:14:54 d2.evaluation.evaluator]: [0mInference done 1350/3489. 0.2346 s / img. ETA=0:09:17
[32m[03/29 00:14:59 d2.evaluation.evaluator]: [0mInference done 1371/3489. 0.2345 s / img. ETA=0:09:11
[32m[03/29 00:15:04 d2.evaluation.evaluator]: [0mInference done 1393/3489. 0.2344 s / img. ETA=0:09:05
[32m[03/29 00:15:09 d2.evaluation.evaluator]: [0mInference done 1414/3489. 0.2343 s / img. ETA=0:08:59
[32m[03/29 00:15:14 d2.evaluation.evaluator]: [0mInference done 1435/3489. 0.2342 s / img. ETA=0:08:53
[32m[03/29 00:15:19 d2.evaluation.evaluator]: [0mInference done 1456/3489. 0.2341 s / img. ETA=0:08:47
[32m[03/29 00:15:25 d2.evaluation.evaluator]: [0mInference done 1478/3489. 0.2340 s / img. ETA=0:08:40
[32m[03/29 00:15:30 d2.evaluation.evaluator]: [0mInference done 1500/3489. 0.2339 s / img. ETA=0:08:34
[32m[03/29 00:15:35 d2.evaluation.evaluator]: [0mInference done 1522/3489. 0.2338 s / img. ETA=0:08:28
[32m[03/29 00:15:40 d2.evaluation.evaluator]: [0mInference done 1543/3489. 0.2337 s / img. ETA=0:08:22
[32m[03/29 00:15:45 d2.evaluation.evaluator]: [0mInference done 1564/3489. 0.2336 s / img. ETA=0:08:16
[32m[03/29 00:15:50 d2.evaluation.evaluator]: [0mInference done 1585/3489. 0.2335 s / img. ETA=0:08:10
[32m[03/29 00:15:55 d2.evaluation.evaluator]: [0mInference done 1605/3489. 0.2335 s / img. ETA=0:08:05
[32m[03/29 00:16:00 d2.evaluation.evaluator]: [0mInference done 1625/3489. 0.2335 s / img. ETA=0:07:59
[32m[03/29 00:16:05 d2.evaluation.evaluator]: [0mInference done 1644/3489. 0.2335 s / img. ETA=0:07:55
[32m[03/29 00:16:11 d2.evaluation.evaluator]: [0mInference done 1664/3489. 0.2335 s / img. ETA=0:07:50
[32m[03/29 00:16:16 d2.evaluation.evaluator]: [0mInference done 1683/3489. 0.2336 s / img. ETA=0:07:45
[32m[03/29 00:16:21 d2.evaluation.evaluator]: [0mInference done 1701/3489. 0.2336 s / img. ETA=0:07:41
[32m[03/29 00:16:26 d2.evaluation.evaluator]: [0mInference done 1719/3489. 0.2337 s / img. ETA=0:07:37
[32m[03/29 00:16:31 d2.evaluation.evaluator]: [0mInference done 1737/3489. 0.2338 s / img. ETA=0:07:33
[32m[03/29 00:16:36 d2.evaluation.evaluator]: [0mInference done 1755/3489. 0.2339 s / img. ETA=0:07:28
[32m[03/29 00:16:41 d2.evaluation.evaluator]: [0mInference done 1772/3489. 0.2340 s / img. ETA=0:07:25
[32m[03/29 00:16:47 d2.evaluation.evaluator]: [0mInference done 1788/3489. 0.2342 s / img. ETA=0:07:22
[32m[03/29 00:16:52 d2.evaluation.evaluator]: [0mInference done 1804/3489. 0.2344 s / img. ETA=0:07:18
[32m[03/29 00:16:57 d2.evaluation.evaluator]: [0mInference done 1820/3489. 0.2345 s / img. ETA=0:07:15
[32m[03/29 00:17:02 d2.evaluation.evaluator]: [0mInference done 1836/3489. 0.2347 s / img. ETA=0:07:12
[32m[03/29 00:17:07 d2.evaluation.evaluator]: [0mInference done 1852/3489. 0.2348 s / img. ETA=0:07:08
[32m[03/29 00:17:12 d2.evaluation.evaluator]: [0mInference done 1869/3489. 0.2350 s / img. ETA=0:07:04
[32m[03/29 00:17:17 d2.evaluation.evaluator]: [0mInference done 1886/3489. 0.2351 s / img. ETA=0:07:01
[32m[03/29 00:17:22 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2352 s / img. ETA=0:06:57
[32m[03/29 00:17:28 d2.evaluation.evaluator]: [0mInference done 1920/3489. 0.2353 s / img. ETA=0:06:53
[32m[03/29 00:17:33 d2.evaluation.evaluator]: [0mInference done 1937/3489. 0.2354 s / img. ETA=0:06:49
[32m[03/29 00:17:38 d2.evaluation.evaluator]: [0mInference done 1953/3489. 0.2355 s / img. ETA=0:06:46
[32m[03/29 00:17:43 d2.evaluation.evaluator]: [0mInference done 1970/3489. 0.2356 s / img. ETA=0:06:42
[32m[03/29 00:17:48 d2.evaluation.evaluator]: [0mInference done 1986/3489. 0.2357 s / img. ETA=0:06:38
[32m[03/29 00:17:54 d2.evaluation.evaluator]: [0mInference done 2005/3489. 0.2357 s / img. ETA=0:06:33
[32m[03/29 00:17:59 d2.evaluation.evaluator]: [0mInference done 2024/3489. 0.2358 s / img. ETA=0:06:28
[32m[03/29 00:18:04 d2.evaluation.evaluator]: [0mInference done 2043/3489. 0.2358 s / img. ETA=0:06:23
[32m[03/29 00:18:09 d2.evaluation.evaluator]: [0mInference done 2061/3489. 0.2358 s / img. ETA=0:06:19
[32m[03/29 00:18:14 d2.evaluation.evaluator]: [0mInference done 2079/3489. 0.2359 s / img. ETA=0:06:14
[32m[03/29 00:18:19 d2.evaluation.evaluator]: [0mInference done 2096/3489. 0.2360 s / img. ETA=0:06:10
[32m[03/29 00:18:24 d2.evaluation.evaluator]: [0mInference done 2113/3489. 0.2361 s / img. ETA=0:06:06
[32m[03/29 00:18:30 d2.evaluation.evaluator]: [0mInference done 2130/3489. 0.2361 s / img. ETA=0:06:02
[32m[03/29 00:18:35 d2.evaluation.evaluator]: [0mInference done 2147/3489. 0.2363 s / img. ETA=0:05:58
[32m[03/29 00:18:40 d2.evaluation.evaluator]: [0mInference done 2163/3489. 0.2364 s / img. ETA=0:05:54
[32m[03/29 00:18:45 d2.evaluation.evaluator]: [0mInference done 2179/3489. 0.2366 s / img. ETA=0:05:50
[32m[03/29 00:18:50 d2.evaluation.evaluator]: [0mInference done 2195/3489. 0.2367 s / img. ETA=0:05:46
[32m[03/29 00:18:55 d2.evaluation.evaluator]: [0mInference done 2212/3489. 0.2367 s / img. ETA=0:05:42
[32m[03/29 00:19:01 d2.evaluation.evaluator]: [0mInference done 2229/3489. 0.2368 s / img. ETA=0:05:38
[32m[03/29 00:19:06 d2.evaluation.evaluator]: [0mInference done 2246/3489. 0.2369 s / img. ETA=0:05:34
[32m[03/29 00:19:11 d2.evaluation.evaluator]: [0mInference done 2264/3489. 0.2370 s / img. ETA=0:05:29
[32m[03/29 00:19:16 d2.evaluation.evaluator]: [0mInference done 2282/3489. 0.2370 s / img. ETA=0:05:24
[32m[03/29 00:19:21 d2.evaluation.evaluator]: [0mInference done 2300/3489. 0.2371 s / img. ETA=0:05:20
[32m[03/29 00:19:26 d2.evaluation.evaluator]: [0mInference done 2317/3489. 0.2371 s / img. ETA=0:05:15
[32m[03/29 00:19:32 d2.evaluation.evaluator]: [0mInference done 2334/3489. 0.2372 s / img. ETA=0:05:11
[32m[03/29 00:19:37 d2.evaluation.evaluator]: [0mInference done 2351/3489. 0.2373 s / img. ETA=0:05:07
[32m[03/29 00:19:42 d2.evaluation.evaluator]: [0mInference done 2369/3489. 0.2373 s / img. ETA=0:05:02
[32m[03/29 00:19:47 d2.evaluation.evaluator]: [0mInference done 2389/3489. 0.2373 s / img. ETA=0:04:56
[32m[03/29 00:19:52 d2.evaluation.evaluator]: [0mInference done 2408/3489. 0.2373 s / img. ETA=0:04:51
[32m[03/29 00:19:57 d2.evaluation.evaluator]: [0mInference done 2427/3489. 0.2373 s / img. ETA=0:04:46
[32m[03/29 00:20:02 d2.evaluation.evaluator]: [0mInference done 2444/3489. 0.2373 s / img. ETA=0:04:42
[32m[03/29 00:20:07 d2.evaluation.evaluator]: [0mInference done 2462/3489. 0.2373 s / img. ETA=0:04:37
[32m[03/29 00:20:12 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2374 s / img. ETA=0:04:33
[32m[03/29 00:20:17 d2.evaluation.evaluator]: [0mInference done 2498/3489. 0.2374 s / img. ETA=0:04:27
[32m[03/29 00:20:22 d2.evaluation.evaluator]: [0mInference done 2519/3489. 0.2373 s / img. ETA=0:04:22
[32m[03/29 00:20:27 d2.evaluation.evaluator]: [0mInference done 2539/3489. 0.2373 s / img. ETA=0:04:16
[32m[03/29 00:20:32 d2.evaluation.evaluator]: [0mInference done 2559/3489. 0.2372 s / img. ETA=0:04:10
[32m[03/29 00:20:37 d2.evaluation.evaluator]: [0mInference done 2579/3489. 0.2372 s / img. ETA=0:04:05
[32m[03/29 00:20:42 d2.evaluation.evaluator]: [0mInference done 2600/3489. 0.2371 s / img. ETA=0:03:59
[32m[03/29 00:20:47 d2.evaluation.evaluator]: [0mInference done 2621/3489. 0.2370 s / img. ETA=0:03:53
[32m[03/29 00:20:53 d2.evaluation.evaluator]: [0mInference done 2643/3489. 0.2369 s / img. ETA=0:03:47
[32m[03/29 00:20:58 d2.evaluation.evaluator]: [0mInference done 2664/3489. 0.2369 s / img. ETA=0:03:41
[32m[03/29 00:21:03 d2.evaluation.evaluator]: [0mInference done 2684/3489. 0.2368 s / img. ETA=0:03:36
[32m[03/29 00:21:08 d2.evaluation.evaluator]: [0mInference done 2704/3489. 0.2368 s / img. ETA=0:03:30
[32m[03/29 00:21:13 d2.evaluation.evaluator]: [0mInference done 2724/3489. 0.2367 s / img. ETA=0:03:25
[32m[03/29 00:21:18 d2.evaluation.evaluator]: [0mInference done 2744/3489. 0.2367 s / img. ETA=0:03:19
[32m[03/29 00:21:23 d2.evaluation.evaluator]: [0mInference done 2764/3489. 0.2366 s / img. ETA=0:03:14
[32m[03/29 00:21:28 d2.evaluation.evaluator]: [0mInference done 2784/3489. 0.2366 s / img. ETA=0:03:08
[32m[03/29 00:21:33 d2.evaluation.evaluator]: [0mInference done 2805/3489. 0.2365 s / img. ETA=0:03:03
[32m[03/29 00:21:38 d2.evaluation.evaluator]: [0mInference done 2825/3489. 0.2365 s / img. ETA=0:02:57
[32m[03/29 00:21:43 d2.evaluation.evaluator]: [0mInference done 2845/3489. 0.2365 s / img. ETA=0:02:52
[32m[03/29 00:21:48 d2.evaluation.evaluator]: [0mInference done 2866/3489. 0.2364 s / img. ETA=0:02:46
[32m[03/29 00:21:54 d2.evaluation.evaluator]: [0mInference done 2887/3489. 0.2364 s / img. ETA=0:02:40
[32m[03/29 00:21:59 d2.evaluation.evaluator]: [0mInference done 2908/3489. 0.2363 s / img. ETA=0:02:35
[32m[03/29 00:22:04 d2.evaluation.evaluator]: [0mInference done 2929/3489. 0.2362 s / img. ETA=0:02:29
[32m[03/29 00:22:09 d2.evaluation.evaluator]: [0mInference done 2950/3489. 0.2362 s / img. ETA=0:02:23
[32m[03/29 00:22:14 d2.evaluation.evaluator]: [0mInference done 2971/3489. 0.2361 s / img. ETA=0:02:18
[32m[03/29 00:22:19 d2.evaluation.evaluator]: [0mInference done 2992/3489. 0.2361 s / img. ETA=0:02:12
[32m[03/29 00:22:24 d2.evaluation.evaluator]: [0mInference done 3012/3489. 0.2361 s / img. ETA=0:02:07
[32m[03/29 00:22:29 d2.evaluation.evaluator]: [0mInference done 3032/3489. 0.2360 s / img. ETA=0:02:01
[32m[03/29 00:22:34 d2.evaluation.evaluator]: [0mInference done 3053/3489. 0.2360 s / img. ETA=0:01:56
[32m[03/29 00:22:39 d2.evaluation.evaluator]: [0mInference done 3073/3489. 0.2360 s / img. ETA=0:01:50
[32m[03/29 00:22:45 d2.evaluation.evaluator]: [0mInference done 3093/3489. 0.2359 s / img. ETA=0:01:45
[32m[03/29 00:22:50 d2.evaluation.evaluator]: [0mInference done 3114/3489. 0.2359 s / img. ETA=0:01:39
[32m[03/29 00:22:55 d2.evaluation.evaluator]: [0mInference done 3134/3489. 0.2359 s / img. ETA=0:01:34
[32m[03/29 00:23:00 d2.evaluation.evaluator]: [0mInference done 3154/3489. 0.2358 s / img. ETA=0:01:29
[32m[03/29 00:23:05 d2.evaluation.evaluator]: [0mInference done 3175/3489. 0.2358 s / img. ETA=0:01:23
[32m[03/29 00:23:10 d2.evaluation.evaluator]: [0mInference done 3196/3489. 0.2358 s / img. ETA=0:01:17
[32m[03/29 00:23:16 d2.evaluation.evaluator]: [0mInference done 3217/3489. 0.2357 s / img. ETA=0:01:12
[32m[03/29 00:23:21 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2357 s / img. ETA=0:01:06
[32m[03/29 00:23:26 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2356 s / img. ETA=0:01:01
[32m[03/29 00:23:31 d2.evaluation.evaluator]: [0mInference done 3279/3489. 0.2356 s / img. ETA=0:00:55
[32m[03/29 00:23:36 d2.evaluation.evaluator]: [0mInference done 3301/3489. 0.2355 s / img. ETA=0:00:49
[32m[03/29 00:23:41 d2.evaluation.evaluator]: [0mInference done 3323/3489. 0.2354 s / img. ETA=0:00:43
[32m[03/29 00:23:46 d2.evaluation.evaluator]: [0mInference done 3345/3489. 0.2354 s / img. ETA=0:00:38
[32m[03/29 00:23:51 d2.evaluation.evaluator]: [0mInference done 3367/3489. 0.2353 s / img. ETA=0:00:32
[32m[03/29 00:23:56 d2.evaluation.evaluator]: [0mInference done 3389/3489. 0.2352 s / img. ETA=0:00:26
[32m[03/29 00:24:01 d2.evaluation.evaluator]: [0mInference done 3410/3489. 0.2352 s / img. ETA=0:00:20
[32m[03/29 00:24:06 d2.evaluation.evaluator]: [0mInference done 3431/3489. 0.2351 s / img. ETA=0:00:15
[32m[03/29 00:24:11 d2.evaluation.evaluator]: [0mInference done 3452/3489. 0.2351 s / img. ETA=0:00:09
[32m[03/29 00:24:16 d2.evaluation.evaluator]: [0mInference done 3473/3489. 0.2350 s / img. ETA=0:00:04
[32m[03/29 00:24:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:16.968059 (0.263194 s / img per device, on 1 devices)
[32m[03/29 00:24:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:38 (0.234975 s / img per device, on 1 devices)
[32m[03/29 00:24:22 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 00:24:22 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.500000_0.200000/coco_instances_results.json
[32m[03/29 00:24:23 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.27 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.43 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[32m[03/29 00:24:25 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.043 | 76.821 | 39.681 | 30.718 | 50.814 | 56.773 |
[32m[03/29 00:24:25 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.218 | Pedestrian | 23.868 |
Loading and preparing results...
DONE (t=1.57s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 1.96 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.49 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.728
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769
[32m[03/29 00:24:33 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.009 | 72.815 | 39.061 | 23.018 | 49.629 | 69.483 |
[32m[03/29 00:24:33 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.673 | Pedestrian | 20.345 |
[32m[03/29 00:24:33 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: 44.0432,76.8207,39.6812,30.7185,50.8136,56.7734
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:24:33 d2.evaluation.testing]: [0mcopypaste: 42.0089,72.8151,39.0615,23.0183,49.6287,69.4832
evaluated
Test [0.500000, 0.500000]
[32m[03/29 00:24:33 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 00:24:34 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/29 00:24:34 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:24:34 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:24:34 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/29 00:24:34 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/29 00:24:34 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 00:24:34 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:24:34 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:24:34 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 00:24:34 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 00:24:34 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 00:24:59 d2.utils.events]: [0m eta: 0:02:30  iter: 19  total_loss: 1.633  loss_cls: 0.7256  loss_box_reg: 0.2407  loss_mask: 0.6558  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.005572  total_val_loss: 1.963  val_loss_cls: 0.7802  val_loss_box_reg: 0.4612  val_loss_mask: 0.6767  val_loss_rpn_cls: 0.03858  val_loss_rpn_loc: 0.014  time: 0.8395  data_time: 0.0268  lr: 0.00019981  max_mem: 4748M
[32m[03/29 00:25:23 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.9051  loss_cls: 0.2042  loss_box_reg: 0.3148  loss_mask: 0.3588  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.009547  total_val_loss: 1.355  val_loss_cls: 0.3129  val_loss_box_reg: 0.4998  val_loss_mask: 0.4589  val_loss_rpn_cls: 0.03086  val_loss_rpn_loc: 0.01319  time: 0.8524  data_time: 0.0057  lr: 0.00039961  max_mem: 4748M
[32m[03/29 00:25:48 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.7508  loss_cls: 0.1275  loss_box_reg: 0.4188  loss_mask: 0.1952  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01189  total_val_loss: 1.084  val_loss_cls: 0.2373  val_loss_box_reg: 0.4373  val_loss_mask: 0.3598  val_loss_rpn_cls: 0.03474  val_loss_rpn_loc: 0.01441  time: 0.8578  data_time: 0.0065  lr: 0.00059941  max_mem: 4748M
[32m[03/29 00:26:13 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.6067  loss_cls: 0.06911  loss_box_reg: 0.3402  loss_mask: 0.1735  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.01104  total_val_loss: 0.9589  val_loss_cls: 0.1718  val_loss_box_reg: 0.3545  val_loss_mask: 0.3941  val_loss_rpn_cls: 0.01922  val_loss_rpn_loc: 0.01217  time: 0.8605  data_time: 0.0062  lr: 0.00079921  max_mem: 4748M
[32m[03/29 00:26:37 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:26:37 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:26:37 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:26:37 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:26:37 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.431  loss_cls: 0.06215  loss_box_reg: 0.1668  loss_mask: 0.1785  loss_rpn_cls: 0.008577  loss_rpn_loc: 0.007901  total_val_loss: 0.877  val_loss_cls: 0.1521  val_loss_box_reg: 0.2424  val_loss_mask: 0.3773  val_loss_rpn_cls: 0.01815  val_loss_rpn_loc: 0.01312  time: 0.8616  data_time: 0.0062  lr: 0.00099901  max_mem: 4748M
[32m[03/29 00:27:02 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3511  loss_cls: 0.04981  loss_box_reg: 0.08902  loss_mask: 0.1888  loss_rpn_cls: 0.008689  loss_rpn_loc: 0.005647  total_val_loss: 0.6407  val_loss_cls: 0.1248  val_loss_box_reg: 0.1871  val_loss_mask: 0.2785  val_loss_rpn_cls: 0.01516  val_loss_rpn_loc: 0.01174  time: 0.8619  data_time: 0.0062  lr: 0.0011988  max_mem: 4748M
[32m[03/29 00:27:26 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.4401  loss_cls: 0.05379  loss_box_reg: 0.08993  loss_mask: 0.2027  loss_rpn_cls: 0.007718  loss_rpn_loc: 0.00829  total_val_loss: 0.6345  val_loss_cls: 0.1384  val_loss_box_reg: 0.1836  val_loss_mask: 0.3075  val_loss_rpn_cls: 0.01913  val_loss_rpn_loc: 0.009665  time: 0.8629  data_time: 0.0058  lr: 0.0013986  max_mem: 4748M
[32m[03/29 00:27:51 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3479  loss_cls: 0.04091  loss_box_reg: 0.08266  loss_mask: 0.1628  loss_rpn_cls: 0.008288  loss_rpn_loc: 0.005613  total_val_loss: 0.6771  val_loss_cls: 0.1022  val_loss_box_reg: 0.1926  val_loss_mask: 0.3411  val_loss_rpn_cls: 0.01536  val_loss_rpn_loc: 0.0108  time: 0.8642  data_time: 0.0063  lr: 0.0015984  max_mem: 4748M
[32m[03/29 00:28:15 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.347  loss_cls: 0.04073  loss_box_reg: 0.1246  loss_mask: 0.1464  loss_rpn_cls: 0.006628  loss_rpn_loc: 0.006708  total_val_loss: 0.7324  val_loss_cls: 0.1413  val_loss_box_reg: 0.2255  val_loss_mask: 0.3304  val_loss_rpn_cls: 0.01683  val_loss_rpn_loc: 0.01173  time: 0.8640  data_time: 0.0065  lr: 0.0017982  max_mem: 4748M
[32m[03/29 00:28:41 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:28:41 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:28:41 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:28:41 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:28:41 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3995  loss_cls: 0.05986  loss_box_reg: 0.1365  loss_mask: 0.1681  loss_rpn_cls: 0.007931  loss_rpn_loc: 0.01057  total_val_loss: 0.7619  val_loss_cls: 0.1514  val_loss_box_reg: 0.19  val_loss_mask: 0.3119  val_loss_rpn_cls: 0.01539  val_loss_rpn_loc: 0.01488  time: 0.8649  data_time: 0.0059  lr: 0.001998  max_mem: 4748M
[32m[03/29 00:28:41 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8649 s / it)
[32m[03/29 00:28:41 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/29 00:28:42 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:28:42 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:28:42 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:28:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 00:28:42 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 00:28:43 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:28:43 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:28:43 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 00:28:43 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 00:28:46 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2306 s / img. ETA=0:14:35
[32m[03/29 00:28:51 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2302 s / img. ETA=0:14:27
[32m[03/29 00:28:56 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2296 s / img. ETA=0:14:11
[32m[03/29 00:29:01 d2.evaluation.evaluator]: [0mInference done 73/3489. 0.2290 s / img. ETA=0:13:57
[32m[03/29 00:29:06 d2.evaluation.evaluator]: [0mInference done 93/3489. 0.2297 s / img. ETA=0:14:04
[32m[03/29 00:29:11 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2318 s / img. ETA=0:14:20
[32m[03/29 00:29:16 d2.evaluation.evaluator]: [0mInference done 127/3489. 0.2344 s / img. ETA=0:14:42
[32m[03/29 00:29:21 d2.evaluation.evaluator]: [0mInference done 143/3489. 0.2369 s / img. ETA=0:15:01
[32m[03/29 00:29:27 d2.evaluation.evaluator]: [0mInference done 159/3489. 0.2389 s / img. ETA=0:15:16
[32m[03/29 00:29:32 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2404 s / img. ETA=0:15:26
[32m[03/29 00:29:37 d2.evaluation.evaluator]: [0mInference done 192/3489. 0.2414 s / img. ETA=0:15:31
[32m[03/29 00:29:42 d2.evaluation.evaluator]: [0mInference done 211/3489. 0.2410 s / img. ETA=0:15:22
[32m[03/29 00:29:47 d2.evaluation.evaluator]: [0mInference done 230/3489. 0.2406 s / img. ETA=0:15:12
[32m[03/29 00:29:52 d2.evaluation.evaluator]: [0mInference done 248/3489. 0.2406 s / img. ETA=0:15:07
[32m[03/29 00:29:57 d2.evaluation.evaluator]: [0mInference done 266/3489. 0.2408 s / img. ETA=0:15:04
[32m[03/29 00:30:03 d2.evaluation.evaluator]: [0mInference done 283/3489. 0.2412 s / img. ETA=0:15:02
[32m[03/29 00:30:08 d2.evaluation.evaluator]: [0mInference done 301/3489. 0.2410 s / img. ETA=0:14:57
[32m[03/29 00:30:13 d2.evaluation.evaluator]: [0mInference done 317/3489. 0.2414 s / img. ETA=0:14:58
[32m[03/29 00:30:18 d2.evaluation.evaluator]: [0mInference done 335/3489. 0.2416 s / img. ETA=0:14:54
[32m[03/29 00:30:23 d2.evaluation.evaluator]: [0mInference done 351/3489. 0.2421 s / img. ETA=0:14:54
[32m[03/29 00:30:28 d2.evaluation.evaluator]: [0mInference done 368/3489. 0.2425 s / img. ETA=0:14:52
[32m[03/29 00:30:33 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2429 s / img. ETA=0:14:50
[32m[03/29 00:30:38 d2.evaluation.evaluator]: [0mInference done 403/3489. 0.2431 s / img. ETA=0:14:45
[32m[03/29 00:30:44 d2.evaluation.evaluator]: [0mInference done 420/3489. 0.2433 s / img. ETA=0:14:42
[32m[03/29 00:30:49 d2.evaluation.evaluator]: [0mInference done 441/3489. 0.2428 s / img. ETA=0:14:30
[32m[03/29 00:30:54 d2.evaluation.evaluator]: [0mInference done 461/3489. 0.2422 s / img. ETA=0:14:20
[32m[03/29 00:30:59 d2.evaluation.evaluator]: [0mInference done 482/3489. 0.2417 s / img. ETA=0:14:09
[32m[03/29 00:31:04 d2.evaluation.evaluator]: [0mInference done 503/3489. 0.2411 s / img. ETA=0:13:57
[32m[03/29 00:31:09 d2.evaluation.evaluator]: [0mInference done 525/3489. 0.2404 s / img. ETA=0:13:45
[32m[03/29 00:31:14 d2.evaluation.evaluator]: [0mInference done 547/3489. 0.2399 s / img. ETA=0:13:34
[32m[03/29 00:31:19 d2.evaluation.evaluator]: [0mInference done 566/3489. 0.2398 s / img. ETA=0:13:28
[32m[03/29 00:31:25 d2.evaluation.evaluator]: [0mInference done 584/3489. 0.2400 s / img. ETA=0:13:24
[32m[03/29 00:31:30 d2.evaluation.evaluator]: [0mInference done 602/3489. 0.2401 s / img. ETA=0:13:20
[32m[03/29 00:31:35 d2.evaluation.evaluator]: [0mInference done 621/3489. 0.2401 s / img. ETA=0:13:15
[32m[03/29 00:31:40 d2.evaluation.evaluator]: [0mInference done 639/3489. 0.2403 s / img. ETA=0:13:11
[32m[03/29 00:31:46 d2.evaluation.evaluator]: [0mInference done 658/3489. 0.2402 s / img. ETA=0:13:05
[32m[03/29 00:31:51 d2.evaluation.evaluator]: [0mInference done 678/3489. 0.2401 s / img. ETA=0:12:58
[32m[03/29 00:31:56 d2.evaluation.evaluator]: [0mInference done 699/3489. 0.2398 s / img. ETA=0:12:50
[32m[03/29 00:32:01 d2.evaluation.evaluator]: [0mInference done 719/3489. 0.2397 s / img. ETA=0:12:43
[32m[03/29 00:32:06 d2.evaluation.evaluator]: [0mInference done 739/3489. 0.2395 s / img. ETA=0:12:36
[32m[03/29 00:32:11 d2.evaluation.evaluator]: [0mInference done 760/3489. 0.2393 s / img. ETA=0:12:28
[32m[03/29 00:32:16 d2.evaluation.evaluator]: [0mInference done 781/3489. 0.2390 s / img. ETA=0:12:20
[32m[03/29 00:32:22 d2.evaluation.evaluator]: [0mInference done 802/3489. 0.2387 s / img. ETA=0:12:12
[32m[03/29 00:32:27 d2.evaluation.evaluator]: [0mInference done 823/3489. 0.2385 s / img. ETA=0:12:04
[32m[03/29 00:32:32 d2.evaluation.evaluator]: [0mInference done 844/3489. 0.2383 s / img. ETA=0:11:56
[32m[03/29 00:32:37 d2.evaluation.evaluator]: [0mInference done 865/3489. 0.2381 s / img. ETA=0:11:49
[32m[03/29 00:32:42 d2.evaluation.evaluator]: [0mInference done 886/3489. 0.2380 s / img. ETA=0:11:42
[32m[03/29 00:32:47 d2.evaluation.evaluator]: [0mInference done 906/3489. 0.2379 s / img. ETA=0:11:36
[32m[03/29 00:32:52 d2.evaluation.evaluator]: [0mInference done 922/3489. 0.2383 s / img. ETA=0:11:33
[32m[03/29 00:32:57 d2.evaluation.evaluator]: [0mInference done 938/3489. 0.2385 s / img. ETA=0:11:31
[32m[03/29 00:33:02 d2.evaluation.evaluator]: [0mInference done 955/3489. 0.2388 s / img. ETA=0:11:28
[32m[03/29 00:33:08 d2.evaluation.evaluator]: [0mInference done 971/3489. 0.2391 s / img. ETA=0:11:26
[32m[03/29 00:33:13 d2.evaluation.evaluator]: [0mInference done 987/3489. 0.2393 s / img. ETA=0:11:23
[32m[03/29 00:33:18 d2.evaluation.evaluator]: [0mInference done 1003/3489. 0.2396 s / img. ETA=0:11:21
[32m[03/29 00:33:23 d2.evaluation.evaluator]: [0mInference done 1019/3489. 0.2398 s / img. ETA=0:11:18
[32m[03/29 00:33:28 d2.evaluation.evaluator]: [0mInference done 1035/3489. 0.2400 s / img. ETA=0:11:15
[32m[03/29 00:33:33 d2.evaluation.evaluator]: [0mInference done 1051/3489. 0.2402 s / img. ETA=0:11:12
[32m[03/29 00:33:38 d2.evaluation.evaluator]: [0mInference done 1067/3489. 0.2404 s / img. ETA=0:11:09
[32m[03/29 00:33:43 d2.evaluation.evaluator]: [0mInference done 1084/3489. 0.2406 s / img. ETA=0:11:05
[32m[03/29 00:33:48 d2.evaluation.evaluator]: [0mInference done 1102/3489. 0.2407 s / img. ETA=0:11:01
[32m[03/29 00:33:53 d2.evaluation.evaluator]: [0mInference done 1120/3489. 0.2407 s / img. ETA=0:10:56
[32m[03/29 00:33:59 d2.evaluation.evaluator]: [0mInference done 1137/3489. 0.2408 s / img. ETA=0:10:53
[32m[03/29 00:34:04 d2.evaluation.evaluator]: [0mInference done 1153/3489. 0.2410 s / img. ETA=0:10:49
[32m[03/29 00:34:09 d2.evaluation.evaluator]: [0mInference done 1169/3489. 0.2412 s / img. ETA=0:10:46
[32m[03/29 00:34:14 d2.evaluation.evaluator]: [0mInference done 1185/3489. 0.2414 s / img. ETA=0:10:43
[32m[03/29 00:34:19 d2.evaluation.evaluator]: [0mInference done 1202/3489. 0.2415 s / img. ETA=0:10:39
[32m[03/29 00:34:24 d2.evaluation.evaluator]: [0mInference done 1219/3489. 0.2416 s / img. ETA=0:10:35
[32m[03/29 00:34:29 d2.evaluation.evaluator]: [0mInference done 1237/3489. 0.2416 s / img. ETA=0:10:30
[32m[03/29 00:34:34 d2.evaluation.evaluator]: [0mInference done 1255/3489. 0.2416 s / img. ETA=0:10:25
[32m[03/29 00:34:39 d2.evaluation.evaluator]: [0mInference done 1277/3489. 0.2413 s / img. ETA=0:10:17
[32m[03/29 00:34:44 d2.evaluation.evaluator]: [0mInference done 1299/3489. 0.2410 s / img. ETA=0:10:09
[32m[03/29 00:34:50 d2.evaluation.evaluator]: [0mInference done 1321/3489. 0.2408 s / img. ETA=0:10:01
[32m[03/29 00:34:55 d2.evaluation.evaluator]: [0mInference done 1342/3489. 0.2406 s / img. ETA=0:09:54
[32m[03/29 00:35:00 d2.evaluation.evaluator]: [0mInference done 1364/3489. 0.2404 s / img. ETA=0:09:47
[32m[03/29 00:35:05 d2.evaluation.evaluator]: [0mInference done 1386/3489. 0.2402 s / img. ETA=0:09:39
[32m[03/29 00:35:10 d2.evaluation.evaluator]: [0mInference done 1407/3489. 0.2400 s / img. ETA=0:09:32
[32m[03/29 00:35:15 d2.evaluation.evaluator]: [0mInference done 1428/3489. 0.2399 s / img. ETA=0:09:26
[32m[03/29 00:35:20 d2.evaluation.evaluator]: [0mInference done 1449/3489. 0.2397 s / img. ETA=0:09:19
[32m[03/29 00:35:26 d2.evaluation.evaluator]: [0mInference done 1470/3489. 0.2396 s / img. ETA=0:09:12
[32m[03/29 00:35:31 d2.evaluation.evaluator]: [0mInference done 1491/3489. 0.2394 s / img. ETA=0:09:06
[32m[03/29 00:35:36 d2.evaluation.evaluator]: [0mInference done 1512/3489. 0.2393 s / img. ETA=0:08:59
[32m[03/29 00:35:41 d2.evaluation.evaluator]: [0mInference done 1533/3489. 0.2391 s / img. ETA=0:08:52
[32m[03/29 00:35:46 d2.evaluation.evaluator]: [0mInference done 1554/3489. 0.2390 s / img. ETA=0:08:46
[32m[03/29 00:35:51 d2.evaluation.evaluator]: [0mInference done 1575/3489. 0.2389 s / img. ETA=0:08:39
[32m[03/29 00:35:56 d2.evaluation.evaluator]: [0mInference done 1596/3489. 0.2388 s / img. ETA=0:08:33
[32m[03/29 00:36:01 d2.evaluation.evaluator]: [0mInference done 1614/3489. 0.2388 s / img. ETA=0:08:28
[32m[03/29 00:36:06 d2.evaluation.evaluator]: [0mInference done 1631/3489. 0.2389 s / img. ETA=0:08:24
[32m[03/29 00:36:11 d2.evaluation.evaluator]: [0mInference done 1649/3489. 0.2389 s / img. ETA=0:08:20
[32m[03/29 00:36:16 d2.evaluation.evaluator]: [0mInference done 1667/3489. 0.2390 s / img. ETA=0:08:15
[32m[03/29 00:36:21 d2.evaluation.evaluator]: [0mInference done 1683/3489. 0.2391 s / img. ETA=0:08:11
[32m[03/29 00:36:27 d2.evaluation.evaluator]: [0mInference done 1699/3489. 0.2392 s / img. ETA=0:08:08
[32m[03/29 00:36:32 d2.evaluation.evaluator]: [0mInference done 1715/3489. 0.2394 s / img. ETA=0:08:04
[32m[03/29 00:36:37 d2.evaluation.evaluator]: [0mInference done 1731/3489. 0.2396 s / img. ETA=0:08:01
[32m[03/29 00:36:42 d2.evaluation.evaluator]: [0mInference done 1747/3489. 0.2397 s / img. ETA=0:07:57
[32m[03/29 00:36:47 d2.evaluation.evaluator]: [0mInference done 1763/3489. 0.2398 s / img. ETA=0:07:53
[32m[03/29 00:36:52 d2.evaluation.evaluator]: [0mInference done 1779/3489. 0.2399 s / img. ETA=0:07:50
[32m[03/29 00:36:57 d2.evaluation.evaluator]: [0mInference done 1795/3489. 0.2400 s / img. ETA=0:07:46
[32m[03/29 00:37:02 d2.evaluation.evaluator]: [0mInference done 1811/3489. 0.2402 s / img. ETA=0:07:42
[32m[03/29 00:37:07 d2.evaluation.evaluator]: [0mInference done 1827/3489. 0.2403 s / img. ETA=0:07:39
[32m[03/29 00:37:13 d2.evaluation.evaluator]: [0mInference done 1843/3489. 0.2404 s / img. ETA=0:07:35
[32m[03/29 00:37:18 d2.evaluation.evaluator]: [0mInference done 1858/3489. 0.2405 s / img. ETA=0:07:31
[32m[03/29 00:37:23 d2.evaluation.evaluator]: [0mInference done 1874/3489. 0.2406 s / img. ETA=0:07:28
[32m[03/29 00:37:28 d2.evaluation.evaluator]: [0mInference done 1890/3489. 0.2408 s / img. ETA=0:07:24
[32m[03/29 00:37:33 d2.evaluation.evaluator]: [0mInference done 1906/3489. 0.2409 s / img. ETA=0:07:20
[32m[03/29 00:37:38 d2.evaluation.evaluator]: [0mInference done 1922/3489. 0.2410 s / img. ETA=0:07:16
[32m[03/29 00:37:43 d2.evaluation.evaluator]: [0mInference done 1938/3489. 0.2411 s / img. ETA=0:07:12
[32m[03/29 00:37:49 d2.evaluation.evaluator]: [0mInference done 1954/3489. 0.2412 s / img. ETA=0:07:08
[32m[03/29 00:37:54 d2.evaluation.evaluator]: [0mInference done 1970/3489. 0.2413 s / img. ETA=0:07:04
[32m[03/29 00:37:59 d2.evaluation.evaluator]: [0mInference done 1986/3489. 0.2414 s / img. ETA=0:07:00
[32m[03/29 00:38:04 d2.evaluation.evaluator]: [0mInference done 2003/3489. 0.2415 s / img. ETA=0:06:56
[32m[03/29 00:38:09 d2.evaluation.evaluator]: [0mInference done 2020/3489. 0.2415 s / img. ETA=0:06:51
[32m[03/29 00:38:14 d2.evaluation.evaluator]: [0mInference done 2036/3489. 0.2416 s / img. ETA=0:06:47
[32m[03/29 00:38:19 d2.evaluation.evaluator]: [0mInference done 2052/3489. 0.2417 s / img. ETA=0:06:43
[32m[03/29 00:38:24 d2.evaluation.evaluator]: [0mInference done 2068/3489. 0.2418 s / img. ETA=0:06:39
[32m[03/29 00:38:29 d2.evaluation.evaluator]: [0mInference done 2084/3489. 0.2419 s / img. ETA=0:06:35
[32m[03/29 00:38:35 d2.evaluation.evaluator]: [0mInference done 2100/3489. 0.2420 s / img. ETA=0:06:31
[32m[03/29 00:38:40 d2.evaluation.evaluator]: [0mInference done 2116/3489. 0.2421 s / img. ETA=0:06:27
[32m[03/29 00:38:45 d2.evaluation.evaluator]: [0mInference done 2132/3489. 0.2422 s / img. ETA=0:06:23
[32m[03/29 00:38:50 d2.evaluation.evaluator]: [0mInference done 2148/3489. 0.2422 s / img. ETA=0:06:18
[32m[03/29 00:38:55 d2.evaluation.evaluator]: [0mInference done 2164/3489. 0.2423 s / img. ETA=0:06:14
[32m[03/29 00:39:00 d2.evaluation.evaluator]: [0mInference done 2180/3489. 0.2424 s / img. ETA=0:06:10
[32m[03/29 00:39:05 d2.evaluation.evaluator]: [0mInference done 2196/3489. 0.2425 s / img. ETA=0:06:06
[32m[03/29 00:39:10 d2.evaluation.evaluator]: [0mInference done 2212/3489. 0.2426 s / img. ETA=0:06:02
[32m[03/29 00:39:16 d2.evaluation.evaluator]: [0mInference done 2228/3489. 0.2427 s / img. ETA=0:05:58
[32m[03/29 00:39:21 d2.evaluation.evaluator]: [0mInference done 2244/3489. 0.2427 s / img. ETA=0:05:53
[32m[03/29 00:39:26 d2.evaluation.evaluator]: [0mInference done 2259/3489. 0.2428 s / img. ETA=0:05:49
[32m[03/29 00:39:31 d2.evaluation.evaluator]: [0mInference done 2275/3489. 0.2429 s / img. ETA=0:05:45
[32m[03/29 00:39:36 d2.evaluation.evaluator]: [0mInference done 2291/3489. 0.2430 s / img. ETA=0:05:41
[32m[03/29 00:39:41 d2.evaluation.evaluator]: [0mInference done 2307/3489. 0.2431 s / img. ETA=0:05:37
[32m[03/29 00:39:46 d2.evaluation.evaluator]: [0mInference done 2323/3489. 0.2432 s / img. ETA=0:05:33
[32m[03/29 00:39:51 d2.evaluation.evaluator]: [0mInference done 2339/3489. 0.2433 s / img. ETA=0:05:28
[32m[03/29 00:39:57 d2.evaluation.evaluator]: [0mInference done 2355/3489. 0.2433 s / img. ETA=0:05:24
[32m[03/29 00:40:02 d2.evaluation.evaluator]: [0mInference done 2373/3489. 0.2433 s / img. ETA=0:05:19
[32m[03/29 00:40:07 d2.evaluation.evaluator]: [0mInference done 2392/3489. 0.2433 s / img. ETA=0:05:13
[32m[03/29 00:40:12 d2.evaluation.evaluator]: [0mInference done 2409/3489. 0.2433 s / img. ETA=0:05:08
[32m[03/29 00:40:17 d2.evaluation.evaluator]: [0mInference done 2427/3489. 0.2433 s / img. ETA=0:05:03
[32m[03/29 00:40:22 d2.evaluation.evaluator]: [0mInference done 2444/3489. 0.2434 s / img. ETA=0:04:59
[32m[03/29 00:40:27 d2.evaluation.evaluator]: [0mInference done 2460/3489. 0.2435 s / img. ETA=0:04:54
[32m[03/29 00:40:33 d2.evaluation.evaluator]: [0mInference done 2476/3489. 0.2435 s / img. ETA=0:04:50
[32m[03/29 00:40:38 d2.evaluation.evaluator]: [0mInference done 2493/3489. 0.2436 s / img. ETA=0:04:45
[32m[03/29 00:40:43 d2.evaluation.evaluator]: [0mInference done 2513/3489. 0.2435 s / img. ETA=0:04:39
[32m[03/29 00:40:48 d2.evaluation.evaluator]: [0mInference done 2532/3489. 0.2434 s / img. ETA=0:04:33
[32m[03/29 00:40:53 d2.evaluation.evaluator]: [0mInference done 2552/3489. 0.2433 s / img. ETA=0:04:28
[32m[03/29 00:40:58 d2.evaluation.evaluator]: [0mInference done 2571/3489. 0.2433 s / img. ETA=0:04:22
[32m[03/29 00:41:03 d2.evaluation.evaluator]: [0mInference done 2592/3489. 0.2432 s / img. ETA=0:04:16
[32m[03/29 00:41:08 d2.evaluation.evaluator]: [0mInference done 2612/3489. 0.2431 s / img. ETA=0:04:10
[32m[03/29 00:41:13 d2.evaluation.evaluator]: [0mInference done 2633/3489. 0.2430 s / img. ETA=0:04:03
[32m[03/29 00:41:18 d2.evaluation.evaluator]: [0mInference done 2654/3489. 0.2429 s / img. ETA=0:03:57
[32m[03/29 00:41:23 d2.evaluation.evaluator]: [0mInference done 2674/3489. 0.2428 s / img. ETA=0:03:51
[32m[03/29 00:41:28 d2.evaluation.evaluator]: [0mInference done 2694/3489. 0.2427 s / img. ETA=0:03:45
[32m[03/29 00:41:33 d2.evaluation.evaluator]: [0mInference done 2714/3489. 0.2426 s / img. ETA=0:03:40
[32m[03/29 00:41:39 d2.evaluation.evaluator]: [0mInference done 2735/3489. 0.2425 s / img. ETA=0:03:33
[32m[03/29 00:41:44 d2.evaluation.evaluator]: [0mInference done 2755/3489. 0.2425 s / img. ETA=0:03:28
[32m[03/29 00:41:49 d2.evaluation.evaluator]: [0mInference done 2775/3489. 0.2424 s / img. ETA=0:03:22
[32m[03/29 00:41:54 d2.evaluation.evaluator]: [0mInference done 2795/3489. 0.2423 s / img. ETA=0:03:16
[32m[03/29 00:41:59 d2.evaluation.evaluator]: [0mInference done 2815/3489. 0.2423 s / img. ETA=0:03:10
[32m[03/29 00:42:04 d2.evaluation.evaluator]: [0mInference done 2835/3489. 0.2422 s / img. ETA=0:03:04
[32m[03/29 00:42:09 d2.evaluation.evaluator]: [0mInference done 2855/3489. 0.2421 s / img. ETA=0:02:59
[32m[03/29 00:42:14 d2.evaluation.evaluator]: [0mInference done 2875/3489. 0.2420 s / img. ETA=0:02:53
[32m[03/29 00:42:19 d2.evaluation.evaluator]: [0mInference done 2896/3489. 0.2420 s / img. ETA=0:02:47
[32m[03/29 00:42:25 d2.evaluation.evaluator]: [0mInference done 2917/3489. 0.2419 s / img. ETA=0:02:41
[32m[03/29 00:42:30 d2.evaluation.evaluator]: [0mInference done 2938/3489. 0.2418 s / img. ETA=0:02:35
[32m[03/29 00:42:35 d2.evaluation.evaluator]: [0mInference done 2959/3489. 0.2417 s / img. ETA=0:02:28
[32m[03/29 00:42:40 d2.evaluation.evaluator]: [0mInference done 2980/3489. 0.2416 s / img. ETA=0:02:22
[32m[03/29 00:42:45 d2.evaluation.evaluator]: [0mInference done 3000/3489. 0.2415 s / img. ETA=0:02:17
[32m[03/29 00:42:50 d2.evaluation.evaluator]: [0mInference done 3020/3489. 0.2415 s / img. ETA=0:02:11
[32m[03/29 00:42:55 d2.evaluation.evaluator]: [0mInference done 3040/3489. 0.2414 s / img. ETA=0:02:05
[32m[03/29 00:43:00 d2.evaluation.evaluator]: [0mInference done 3060/3489. 0.2414 s / img. ETA=0:02:00
[32m[03/29 00:43:05 d2.evaluation.evaluator]: [0mInference done 3080/3489. 0.2413 s / img. ETA=0:01:54
[32m[03/29 00:43:11 d2.evaluation.evaluator]: [0mInference done 3100/3489. 0.2413 s / img. ETA=0:01:48
[32m[03/29 00:43:16 d2.evaluation.evaluator]: [0mInference done 3120/3489. 0.2412 s / img. ETA=0:01:43
[32m[03/29 00:43:21 d2.evaluation.evaluator]: [0mInference done 3140/3489. 0.2412 s / img. ETA=0:01:37
[32m[03/29 00:43:26 d2.evaluation.evaluator]: [0mInference done 3160/3489. 0.2411 s / img. ETA=0:01:31
[32m[03/29 00:43:31 d2.evaluation.evaluator]: [0mInference done 3181/3489. 0.2410 s / img. ETA=0:01:25
[32m[03/29 00:43:36 d2.evaluation.evaluator]: [0mInference done 3202/3489. 0.2409 s / img. ETA=0:01:20
[32m[03/29 00:43:41 d2.evaluation.evaluator]: [0mInference done 3222/3489. 0.2409 s / img. ETA=0:01:14
[32m[03/29 00:43:46 d2.evaluation.evaluator]: [0mInference done 3242/3489. 0.2408 s / img. ETA=0:01:08
[32m[03/29 00:43:52 d2.evaluation.evaluator]: [0mInference done 3263/3489. 0.2408 s / img. ETA=0:01:02
[32m[03/29 00:43:57 d2.evaluation.evaluator]: [0mInference done 3284/3489. 0.2407 s / img. ETA=0:00:57
[32m[03/29 00:44:02 d2.evaluation.evaluator]: [0mInference done 3306/3489. 0.2406 s / img. ETA=0:00:50
[32m[03/29 00:44:07 d2.evaluation.evaluator]: [0mInference done 3328/3489. 0.2405 s / img. ETA=0:00:44
[32m[03/29 00:44:12 d2.evaluation.evaluator]: [0mInference done 3350/3489. 0.2404 s / img. ETA=0:00:38
[32m[03/29 00:44:17 d2.evaluation.evaluator]: [0mInference done 3372/3489. 0.2403 s / img. ETA=0:00:32
[32m[03/29 00:44:22 d2.evaluation.evaluator]: [0mInference done 3394/3489. 0.2402 s / img. ETA=0:00:26
[32m[03/29 00:44:27 d2.evaluation.evaluator]: [0mInference done 3415/3489. 0.2402 s / img. ETA=0:00:20
[32m[03/29 00:44:33 d2.evaluation.evaluator]: [0mInference done 3436/3489. 0.2401 s / img. ETA=0:00:14
[32m[03/29 00:44:38 d2.evaluation.evaluator]: [0mInference done 3457/3489. 0.2400 s / img. ETA=0:00:08
[32m[03/29 00:44:43 d2.evaluation.evaluator]: [0mInference done 3478/3489. 0.2400 s / img. ETA=0:00:03
[32m[03/29 00:44:46 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:01.331898 (0.275928 s / img per device, on 1 devices)
[32m[03/29 00:44:46 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:55 (0.239936 s / img per device, on 1 devices)
[32m[03/29 00:44:48 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 00:44:48 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.500000_0.500000/coco_instances_results.json
[32m[03/29 00:44:49 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.94 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.803
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850
[32m[03/29 00:44:52 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.056 | 80.327 | 54.018 | 30.377 | 62.548 | 66.744 |
[32m[03/29 00:44:52 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.887 | Pedestrian | 40.226 |
Loading and preparing results...
DONE (t=2.05s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.43 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.59 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[32m[03/29 00:45:02 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.337 | 76.236 | 44.003 | 23.029 | 54.781 | 70.131 |
[32m[03/29 00:45:02 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.131 | Pedestrian | 26.542 |
[32m[03/29 00:45:03 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: 52.0563,80.3266,54.0175,30.3771,62.5480,66.7438
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 00:45:03 d2.evaluation.testing]: [0mcopypaste: 45.3367,76.2357,44.0029,23.0294,54.7810,70.1314
evaluated
Test [0.500000, 0.700000]
[32m[03/29 00:45:03 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 00:45:03 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/29 00:45:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:45:03 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:45:03 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/29 00:45:04 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/29 00:45:04 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 00:45:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 00:45:04 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 00:45:04 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 00:45:04 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 00:45:04 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 00:45:29 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 2.016  loss_cls: 0.8481  loss_box_reg: 0.3756  loss_mask: 0.6579  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.009239  total_val_loss: 1.993  val_loss_cls: 0.8252  val_loss_box_reg: 0.4804  val_loss_mask: 0.6775  val_loss_rpn_cls: 0.0425  val_loss_rpn_loc: 0.01123  time: 0.8450  data_time: 0.0281  lr: 0.00019981  max_mem: 4748M
[32m[03/29 00:45:53 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.8621  loss_cls: 0.1627  loss_box_reg: 0.2606  loss_mask: 0.3826  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.005333  total_val_loss: 1.407  val_loss_cls: 0.3271  val_loss_box_reg: 0.4642  val_loss_mask: 0.5013  val_loss_rpn_cls: 0.03565  val_loss_rpn_loc: 0.01405  time: 0.8485  data_time: 0.0058  lr: 0.00039961  max_mem: 4748M
[32m[03/29 00:46:18 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.6987  loss_cls: 0.1016  loss_box_reg: 0.3338  loss_mask: 0.2049  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.008424  total_val_loss: 1.157  val_loss_cls: 0.2436  val_loss_box_reg: 0.513  val_loss_mask: 0.4049  val_loss_rpn_cls: 0.02883  val_loss_rpn_loc: 0.0136  time: 0.8543  data_time: 0.0067  lr: 0.00059941  max_mem: 4748M
[32m[03/29 00:46:42 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.5245  loss_cls: 0.05521  loss_box_reg: 0.2186  loss_mask: 0.1811  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.01016  total_val_loss: 0.9936  val_loss_cls: 0.1898  val_loss_box_reg: 0.429  val_loss_mask: 0.3366  val_loss_rpn_cls: 0.01433  val_loss_rpn_loc: 0.01238  time: 0.8571  data_time: 0.0057  lr: 0.00079921  max_mem: 4748M
[32m[03/29 00:47:07 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:47:07 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:47:07 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:47:07 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:47:07 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.5093  loss_cls: 0.06064  loss_box_reg: 0.2175  loss_mask: 0.167  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.005105  total_val_loss: 0.9573  val_loss_cls: 0.2015  val_loss_box_reg: 0.2999  val_loss_mask: 0.3917  val_loss_rpn_cls: 0.02417  val_loss_rpn_loc: 0.01461  time: 0.8602  data_time: 0.0060  lr: 0.00099901  max_mem: 4748M
[32m[03/29 00:47:32 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3532  loss_cls: 0.04237  loss_box_reg: 0.1247  loss_mask: 0.1885  loss_rpn_cls: 0.006368  loss_rpn_loc: 0.008576  total_val_loss: 1.002  val_loss_cls: 0.2892  val_loss_box_reg: 0.2901  val_loss_mask: 0.3518  val_loss_rpn_cls: 0.01791  val_loss_rpn_loc: 0.01467  time: 0.8617  data_time: 0.0061  lr: 0.0011988  max_mem: 4748M
[32m[03/29 00:47:56 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3982  loss_cls: 0.07058  loss_box_reg: 0.1101  loss_mask: 0.1685  loss_rpn_cls: 0.009932  loss_rpn_loc: 0.01073  total_val_loss: 0.9984  val_loss_cls: 0.2161  val_loss_box_reg: 0.3248  val_loss_mask: 0.374  val_loss_rpn_cls: 0.02347  val_loss_rpn_loc: 0.01504  time: 0.8618  data_time: 0.0060  lr: 0.0013986  max_mem: 4748M
[32m[03/29 00:48:20 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.351  loss_cls: 0.05183  loss_box_reg: 0.1082  loss_mask: 0.1692  loss_rpn_cls: 0.006472  loss_rpn_loc: 0.007116  total_val_loss: 0.7564  val_loss_cls: 0.1443  val_loss_box_reg: 0.2344  val_loss_mask: 0.3254  val_loss_rpn_cls: 0.01233  val_loss_rpn_loc: 0.01198  time: 0.8621  data_time: 0.0057  lr: 0.0015984  max_mem: 4748M
[32m[03/29 00:48:45 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3409  loss_cls: 0.06049  loss_box_reg: 0.1036  loss_mask: 0.1387  loss_rpn_cls: 0.005253  loss_rpn_loc: 0.009388  total_val_loss: 0.7105  val_loss_cls: 0.1384  val_loss_box_reg: 0.1807  val_loss_mask: 0.3846  val_loss_rpn_cls: 0.009758  val_loss_rpn_loc: 0.01087  time: 0.8630  data_time: 0.0065  lr: 0.0017982  max_mem: 4748M
[32m[03/29 00:49:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:49:10 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:49:10 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:49:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 00:49:10 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3789  loss_cls: 0.05314  loss_box_reg: 0.1067  loss_mask: 0.1744  loss_rpn_cls: 0.008327  loss_rpn_loc: 0.01035  total_val_loss: 0.7929  val_loss_cls: 0.1551  val_loss_box_reg: 0.2369  val_loss_mask: 0.3435  val_loss_rpn_cls: 0.01357  val_loss_rpn_loc: 0.01187  time: 0.8637  data_time: 0.0064  lr: 0.001998  max_mem: 4748M
[32m[03/29 00:49:10 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8637 s / it)
[32m[03/29 00:49:10 d2.engine.hooks]: [0mTotal training time: 0:04:02 (0:01:11 on hooks)
[32m[03/29 00:49:11 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:49:11 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:49:11 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 00:49:11 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 00:49:11 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 00:49:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 00:49:12 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 00:49:12 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 00:49:12 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 00:49:15 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2243 s / img. ETA=0:13:48
[32m[03/29 00:49:20 d2.evaluation.evaluator]: [0mInference done 33/3489. 0.2243 s / img. ETA=0:13:39
[32m[03/29 00:49:25 d2.evaluation.evaluator]: [0mInference done 55/3489. 0.2257 s / img. ETA=0:13:33
[32m[03/29 00:49:31 d2.evaluation.evaluator]: [0mInference done 77/3489. 0.2257 s / img. ETA=0:13:25
[32m[03/29 00:49:36 d2.evaluation.evaluator]: [0mInference done 97/3489. 0.2272 s / img. ETA=0:13:34
[32m[03/29 00:49:41 d2.evaluation.evaluator]: [0mInference done 116/3489. 0.2290 s / img. ETA=0:13:46
[32m[03/29 00:49:46 d2.evaluation.evaluator]: [0mInference done 133/3489. 0.2312 s / img. ETA=0:14:05
[32m[03/29 00:49:51 d2.evaluation.evaluator]: [0mInference done 149/3489. 0.2337 s / img. ETA=0:14:25
[32m[03/29 00:49:56 d2.evaluation.evaluator]: [0mInference done 165/3489. 0.2358 s / img. ETA=0:14:42
[32m[03/29 00:50:01 d2.evaluation.evaluator]: [0mInference done 182/3489. 0.2368 s / img. ETA=0:14:48
[32m[03/29 00:50:06 d2.evaluation.evaluator]: [0mInference done 200/3489. 0.2375 s / img. ETA=0:14:47
[32m[03/29 00:50:11 d2.evaluation.evaluator]: [0mInference done 221/3489. 0.2368 s / img. ETA=0:14:35
[32m[03/29 00:50:17 d2.evaluation.evaluator]: [0mInference done 241/3489. 0.2364 s / img. ETA=0:14:26
[32m[03/29 00:50:22 d2.evaluation.evaluator]: [0mInference done 260/3489. 0.2365 s / img. ETA=0:14:21
[32m[03/29 00:50:27 d2.evaluation.evaluator]: [0mInference done 279/3489. 0.2364 s / img. ETA=0:14:15
[32m[03/29 00:50:32 d2.evaluation.evaluator]: [0mInference done 299/3489. 0.2363 s / img. ETA=0:14:09
[32m[03/29 00:50:37 d2.evaluation.evaluator]: [0mInference done 318/3489. 0.2364 s / img. ETA=0:14:06
[32m[03/29 00:50:42 d2.evaluation.evaluator]: [0mInference done 337/3489. 0.2365 s / img. ETA=0:14:02
[32m[03/29 00:50:48 d2.evaluation.evaluator]: [0mInference done 355/3489. 0.2369 s / img. ETA=0:14:01
[32m[03/29 00:50:53 d2.evaluation.evaluator]: [0mInference done 374/3489. 0.2370 s / img. ETA=0:13:57
[32m[03/29 00:50:58 d2.evaluation.evaluator]: [0mInference done 393/3489. 0.2370 s / img. ETA=0:13:52
[32m[03/29 00:51:03 d2.evaluation.evaluator]: [0mInference done 412/3489. 0.2372 s / img. ETA=0:13:48
[32m[03/29 00:51:08 d2.evaluation.evaluator]: [0mInference done 432/3489. 0.2371 s / img. ETA=0:13:41
[32m[03/29 00:51:13 d2.evaluation.evaluator]: [0mInference done 453/3489. 0.2368 s / img. ETA=0:13:32
[32m[03/29 00:51:19 d2.evaluation.evaluator]: [0mInference done 474/3489. 0.2365 s / img. ETA=0:13:23
[32m[03/29 00:51:24 d2.evaluation.evaluator]: [0mInference done 495/3489. 0.2365 s / img. ETA=0:13:15
[32m[03/29 00:51:29 d2.evaluation.evaluator]: [0mInference done 517/3489. 0.2361 s / img. ETA=0:13:06
[32m[03/29 00:51:34 d2.evaluation.evaluator]: [0mInference done 539/3489. 0.2358 s / img. ETA=0:12:56
[32m[03/29 00:51:39 d2.evaluation.evaluator]: [0mInference done 560/3489. 0.2355 s / img. ETA=0:12:49
[32m[03/29 00:51:44 d2.evaluation.evaluator]: [0mInference done 580/3489. 0.2355 s / img. ETA=0:12:43
[32m[03/29 00:51:50 d2.evaluation.evaluator]: [0mInference done 599/3489. 0.2356 s / img. ETA=0:12:39
[32m[03/29 00:51:55 d2.evaluation.evaluator]: [0mInference done 618/3489. 0.2356 s / img. ETA=0:12:34
[32m[03/29 00:52:00 d2.evaluation.evaluator]: [0mInference done 637/3489. 0.2358 s / img. ETA=0:12:30
[32m[03/29 00:52:05 d2.evaluation.evaluator]: [0mInference done 656/3489. 0.2357 s / img. ETA=0:12:25
[32m[03/29 00:52:10 d2.evaluation.evaluator]: [0mInference done 676/3489. 0.2356 s / img. ETA=0:12:19
[32m[03/29 00:52:15 d2.evaluation.evaluator]: [0mInference done 697/3489. 0.2353 s / img. ETA=0:12:11
[32m[03/29 00:52:20 d2.evaluation.evaluator]: [0mInference done 718/3489. 0.2352 s / img. ETA=0:12:04
[32m[03/29 00:52:25 d2.evaluation.evaluator]: [0mInference done 739/3489. 0.2351 s / img. ETA=0:11:58
[32m[03/29 00:52:30 d2.evaluation.evaluator]: [0mInference done 760/3489. 0.2350 s / img. ETA=0:11:51
[32m[03/29 00:52:36 d2.evaluation.evaluator]: [0mInference done 782/3489. 0.2347 s / img. ETA=0:11:43
[32m[03/29 00:52:41 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2345 s / img. ETA=0:11:35
[32m[03/29 00:52:46 d2.evaluation.evaluator]: [0mInference done 826/3489. 0.2343 s / img. ETA=0:11:28
[32m[03/29 00:52:51 d2.evaluation.evaluator]: [0mInference done 848/3489. 0.2341 s / img. ETA=0:11:20
[32m[03/29 00:52:56 d2.evaluation.evaluator]: [0mInference done 870/3489. 0.2339 s / img. ETA=0:11:13
[32m[03/29 00:53:01 d2.evaluation.evaluator]: [0mInference done 892/3489. 0.2337 s / img. ETA=0:11:06
[32m[03/29 00:53:06 d2.evaluation.evaluator]: [0mInference done 911/3489. 0.2338 s / img. ETA=0:11:02
[32m[03/29 00:53:11 d2.evaluation.evaluator]: [0mInference done 928/3489. 0.2341 s / img. ETA=0:11:00
[32m[03/29 00:53:17 d2.evaluation.evaluator]: [0mInference done 945/3489. 0.2344 s / img. ETA=0:10:57
[32m[03/29 00:53:22 d2.evaluation.evaluator]: [0mInference done 961/3489. 0.2348 s / img. ETA=0:10:56
[32m[03/29 00:53:27 d2.evaluation.evaluator]: [0mInference done 977/3489. 0.2352 s / img. ETA=0:10:54
[32m[03/29 00:53:32 d2.evaluation.evaluator]: [0mInference done 994/3489. 0.2354 s / img. ETA=0:10:52
[32m[03/29 00:53:37 d2.evaluation.evaluator]: [0mInference done 1010/3489. 0.2358 s / img. ETA=0:10:50
[32m[03/29 00:53:42 d2.evaluation.evaluator]: [0mInference done 1027/3489. 0.2360 s / img. ETA=0:10:47
[32m[03/29 00:53:48 d2.evaluation.evaluator]: [0mInference done 1044/3489. 0.2362 s / img. ETA=0:10:45
[32m[03/29 00:53:53 d2.evaluation.evaluator]: [0mInference done 1060/3489. 0.2364 s / img. ETA=0:10:42
[32m[03/29 00:53:58 d2.evaluation.evaluator]: [0mInference done 1077/3489. 0.2366 s / img. ETA=0:10:39
[32m[03/29 00:54:03 d2.evaluation.evaluator]: [0mInference done 1096/3489. 0.2366 s / img. ETA=0:10:34
[32m[03/29 00:54:08 d2.evaluation.evaluator]: [0mInference done 1116/3489. 0.2366 s / img. ETA=0:10:29
[32m[03/29 00:54:13 d2.evaluation.evaluator]: [0mInference done 1134/3489. 0.2367 s / img. ETA=0:10:25
[32m[03/29 00:54:19 d2.evaluation.evaluator]: [0mInference done 1152/3489. 0.2368 s / img. ETA=0:10:21
[32m[03/29 00:54:24 d2.evaluation.evaluator]: [0mInference done 1169/3489. 0.2370 s / img. ETA=0:10:18
[32m[03/29 00:54:29 d2.evaluation.evaluator]: [0mInference done 1187/3489. 0.2371 s / img. ETA=0:10:14
[32m[03/29 00:54:34 d2.evaluation.evaluator]: [0mInference done 1206/3489. 0.2371 s / img. ETA=0:10:09
[32m[03/29 00:54:39 d2.evaluation.evaluator]: [0mInference done 1225/3489. 0.2371 s / img. ETA=0:10:04
[32m[03/29 00:54:44 d2.evaluation.evaluator]: [0mInference done 1244/3489. 0.2371 s / img. ETA=0:09:59
[32m[03/29 00:54:49 d2.evaluation.evaluator]: [0mInference done 1265/3489. 0.2369 s / img. ETA=0:09:52
[32m[03/29 00:54:54 d2.evaluation.evaluator]: [0mInference done 1287/3489. 0.2368 s / img. ETA=0:09:45
[32m[03/29 00:55:00 d2.evaluation.evaluator]: [0mInference done 1309/3489. 0.2366 s / img. ETA=0:09:38
[32m[03/29 00:55:05 d2.evaluation.evaluator]: [0mInference done 1331/3489. 0.2364 s / img. ETA=0:09:31
[32m[03/29 00:55:10 d2.evaluation.evaluator]: [0mInference done 1353/3489. 0.2363 s / img. ETA=0:09:24
[32m[03/29 00:55:15 d2.evaluation.evaluator]: [0mInference done 1375/3489. 0.2361 s / img. ETA=0:09:17
[32m[03/29 00:55:20 d2.evaluation.evaluator]: [0mInference done 1397/3489. 0.2360 s / img. ETA=0:09:10
[32m[03/29 00:55:25 d2.evaluation.evaluator]: [0mInference done 1418/3489. 0.2359 s / img. ETA=0:09:04
[32m[03/29 00:55:30 d2.evaluation.evaluator]: [0mInference done 1439/3489. 0.2358 s / img. ETA=0:08:58
[32m[03/29 00:55:35 d2.evaluation.evaluator]: [0mInference done 1460/3489. 0.2357 s / img. ETA=0:08:52
[32m[03/29 00:55:40 d2.evaluation.evaluator]: [0mInference done 1481/3489. 0.2356 s / img. ETA=0:08:46
[32m[03/29 00:55:46 d2.evaluation.evaluator]: [0mInference done 1503/3489. 0.2354 s / img. ETA=0:08:39
[32m[03/29 00:55:51 d2.evaluation.evaluator]: [0mInference done 1525/3489. 0.2353 s / img. ETA=0:08:33
[32m[03/29 00:55:56 d2.evaluation.evaluator]: [0mInference done 1547/3489. 0.2352 s / img. ETA=0:08:26
[32m[03/29 00:56:01 d2.evaluation.evaluator]: [0mInference done 1568/3489. 0.2351 s / img. ETA=0:08:20
[32m[03/29 00:56:06 d2.evaluation.evaluator]: [0mInference done 1589/3489. 0.2351 s / img. ETA=0:08:14
[32m[03/29 00:56:11 d2.evaluation.evaluator]: [0mInference done 1609/3489. 0.2350 s / img. ETA=0:08:09
[32m[03/29 00:56:16 d2.evaluation.evaluator]: [0mInference done 1628/3489. 0.2351 s / img. ETA=0:08:04
[32m[03/29 00:56:22 d2.evaluation.evaluator]: [0mInference done 1648/3489. 0.2350 s / img. ETA=0:07:59
[32m[03/29 00:56:27 d2.evaluation.evaluator]: [0mInference done 1667/3489. 0.2350 s / img. ETA=0:07:54
[32m[03/29 00:56:32 d2.evaluation.evaluator]: [0mInference done 1685/3489. 0.2351 s / img. ETA=0:07:50
[32m[03/29 00:56:37 d2.evaluation.evaluator]: [0mInference done 1702/3489. 0.2352 s / img. ETA=0:07:46
[32m[03/29 00:56:42 d2.evaluation.evaluator]: [0mInference done 1720/3489. 0.2353 s / img. ETA=0:07:42
[32m[03/29 00:56:47 d2.evaluation.evaluator]: [0mInference done 1737/3489. 0.2355 s / img. ETA=0:07:38
[32m[03/29 00:56:52 d2.evaluation.evaluator]: [0mInference done 1754/3489. 0.2356 s / img. ETA=0:07:34
[32m[03/29 00:56:57 d2.evaluation.evaluator]: [0mInference done 1770/3489. 0.2358 s / img. ETA=0:07:31
[32m[03/29 00:57:03 d2.evaluation.evaluator]: [0mInference done 1786/3489. 0.2359 s / img. ETA=0:07:28
[32m[03/29 00:57:08 d2.evaluation.evaluator]: [0mInference done 1802/3489. 0.2361 s / img. ETA=0:07:25
[32m[03/29 00:57:13 d2.evaluation.evaluator]: [0mInference done 1818/3489. 0.2362 s / img. ETA=0:07:21
[32m[03/29 00:57:18 d2.evaluation.evaluator]: [0mInference done 1834/3489. 0.2364 s / img. ETA=0:07:18
[32m[03/29 00:57:23 d2.evaluation.evaluator]: [0mInference done 1850/3489. 0.2365 s / img. ETA=0:07:14
[32m[03/29 00:57:28 d2.evaluation.evaluator]: [0mInference done 1866/3489. 0.2367 s / img. ETA=0:07:11
[32m[03/29 00:57:33 d2.evaluation.evaluator]: [0mInference done 1882/3489. 0.2368 s / img. ETA=0:07:07
[32m[03/29 00:57:38 d2.evaluation.evaluator]: [0mInference done 1898/3489. 0.2369 s / img. ETA=0:07:04
[32m[03/29 00:57:43 d2.evaluation.evaluator]: [0mInference done 1914/3489. 0.2371 s / img. ETA=0:07:00
[32m[03/29 00:57:48 d2.evaluation.evaluator]: [0mInference done 1930/3489. 0.2372 s / img. ETA=0:06:56
[32m[03/29 00:57:54 d2.evaluation.evaluator]: [0mInference done 1946/3489. 0.2374 s / img. ETA=0:06:53
[32m[03/29 00:57:59 d2.evaluation.evaluator]: [0mInference done 1962/3489. 0.2375 s / img. ETA=0:06:49
[32m[03/29 00:58:04 d2.evaluation.evaluator]: [0mInference done 1978/3489. 0.2376 s / img. ETA=0:06:46
[32m[03/29 00:58:09 d2.evaluation.evaluator]: [0mInference done 1995/3489. 0.2377 s / img. ETA=0:06:41
[32m[03/29 00:58:14 d2.evaluation.evaluator]: [0mInference done 2013/3489. 0.2377 s / img. ETA=0:06:37
[32m[03/29 00:58:19 d2.evaluation.evaluator]: [0mInference done 2032/3489. 0.2377 s / img. ETA=0:06:32
[32m[03/29 00:58:25 d2.evaluation.evaluator]: [0mInference done 2050/3489. 0.2378 s / img. ETA=0:06:27
[32m[03/29 00:58:30 d2.evaluation.evaluator]: [0mInference done 2067/3489. 0.2379 s / img. ETA=0:06:23
[32m[03/29 00:58:35 d2.evaluation.evaluator]: [0mInference done 2083/3489. 0.2381 s / img. ETA=0:06:19
[32m[03/29 00:58:40 d2.evaluation.evaluator]: [0mInference done 2100/3489. 0.2382 s / img. ETA=0:06:15
[32m[03/29 00:58:45 d2.evaluation.evaluator]: [0mInference done 2117/3489. 0.2383 s / img. ETA=0:06:11
[32m[03/29 00:58:50 d2.evaluation.evaluator]: [0mInference done 2133/3489. 0.2384 s / img. ETA=0:06:07
[32m[03/29 00:58:55 d2.evaluation.evaluator]: [0mInference done 2149/3489. 0.2384 s / img. ETA=0:06:03
[32m[03/29 00:59:01 d2.evaluation.evaluator]: [0mInference done 2165/3489. 0.2386 s / img. ETA=0:05:59
[32m[03/29 00:59:06 d2.evaluation.evaluator]: [0mInference done 2181/3489. 0.2387 s / img. ETA=0:05:55
[32m[03/29 00:59:11 d2.evaluation.evaluator]: [0mInference done 2197/3489. 0.2388 s / img. ETA=0:05:52
[32m[03/29 00:59:16 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2389 s / img. ETA=0:05:48
[32m[03/29 00:59:21 d2.evaluation.evaluator]: [0mInference done 2229/3489. 0.2390 s / img. ETA=0:05:44
[32m[03/29 00:59:26 d2.evaluation.evaluator]: [0mInference done 2246/3489. 0.2391 s / img. ETA=0:05:39
[32m[03/29 00:59:31 d2.evaluation.evaluator]: [0mInference done 2264/3489. 0.2391 s / img. ETA=0:05:35
[32m[03/29 00:59:37 d2.evaluation.evaluator]: [0mInference done 2281/3489. 0.2392 s / img. ETA=0:05:30
[32m[03/29 00:59:42 d2.evaluation.evaluator]: [0mInference done 2298/3489. 0.2393 s / img. ETA=0:05:26
[32m[03/29 00:59:47 d2.evaluation.evaluator]: [0mInference done 2315/3489. 0.2394 s / img. ETA=0:05:21
[32m[03/29 00:59:52 d2.evaluation.evaluator]: [0mInference done 2332/3489. 0.2395 s / img. ETA=0:05:17
[32m[03/29 00:59:57 d2.evaluation.evaluator]: [0mInference done 2349/3489. 0.2395 s / img. ETA=0:05:13
[32m[03/29 01:00:02 d2.evaluation.evaluator]: [0mInference done 2367/3489. 0.2395 s / img. ETA=0:05:08
[32m[03/29 01:00:07 d2.evaluation.evaluator]: [0mInference done 2386/3489. 0.2395 s / img. ETA=0:05:02
[32m[03/29 01:00:13 d2.evaluation.evaluator]: [0mInference done 2405/3489. 0.2395 s / img. ETA=0:04:57
[32m[03/29 01:00:18 d2.evaluation.evaluator]: [0mInference done 2424/3489. 0.2395 s / img. ETA=0:04:52
[32m[03/29 01:00:23 d2.evaluation.evaluator]: [0mInference done 2442/3489. 0.2395 s / img. ETA=0:04:47
[32m[03/29 01:00:28 d2.evaluation.evaluator]: [0mInference done 2459/3489. 0.2396 s / img. ETA=0:04:42
[32m[03/29 01:00:33 d2.evaluation.evaluator]: [0mInference done 2476/3489. 0.2396 s / img. ETA=0:04:38
[32m[03/29 01:00:38 d2.evaluation.evaluator]: [0mInference done 2495/3489. 0.2396 s / img. ETA=0:04:33
[32m[03/29 01:00:43 d2.evaluation.evaluator]: [0mInference done 2516/3489. 0.2395 s / img. ETA=0:04:27
[32m[03/29 01:00:48 d2.evaluation.evaluator]: [0mInference done 2536/3489. 0.2395 s / img. ETA=0:04:21
[32m[03/29 01:00:53 d2.evaluation.evaluator]: [0mInference done 2556/3489. 0.2394 s / img. ETA=0:04:15
[32m[03/29 01:00:59 d2.evaluation.evaluator]: [0mInference done 2576/3489. 0.2394 s / img. ETA=0:04:10
[32m[03/29 01:01:04 d2.evaluation.evaluator]: [0mInference done 2597/3489. 0.2393 s / img. ETA=0:04:04
[32m[03/29 01:01:09 d2.evaluation.evaluator]: [0mInference done 2618/3489. 0.2393 s / img. ETA=0:03:58
[32m[03/29 01:01:14 d2.evaluation.evaluator]: [0mInference done 2640/3489. 0.2392 s / img. ETA=0:03:52
[32m[03/29 01:01:19 d2.evaluation.evaluator]: [0mInference done 2661/3489. 0.2391 s / img. ETA=0:03:46
[32m[03/29 01:01:24 d2.evaluation.evaluator]: [0mInference done 2681/3489. 0.2390 s / img. ETA=0:03:40
[32m[03/29 01:01:29 d2.evaluation.evaluator]: [0mInference done 2701/3489. 0.2390 s / img. ETA=0:03:35
[32m[03/29 01:01:35 d2.evaluation.evaluator]: [0mInference done 2722/3489. 0.2389 s / img. ETA=0:03:29
[32m[03/29 01:01:40 d2.evaluation.evaluator]: [0mInference done 2743/3489. 0.2388 s / img. ETA=0:03:23
[32m[03/29 01:01:45 d2.evaluation.evaluator]: [0mInference done 2764/3489. 0.2388 s / img. ETA=0:03:17
[32m[03/29 01:01:50 d2.evaluation.evaluator]: [0mInference done 2785/3489. 0.2387 s / img. ETA=0:03:11
[32m[03/29 01:01:55 d2.evaluation.evaluator]: [0mInference done 2806/3489. 0.2386 s / img. ETA=0:03:05
[32m[03/29 01:02:00 d2.evaluation.evaluator]: [0mInference done 2826/3489. 0.2386 s / img. ETA=0:03:00
[32m[03/29 01:02:05 d2.evaluation.evaluator]: [0mInference done 2846/3489. 0.2385 s / img. ETA=0:02:54
[32m[03/29 01:02:11 d2.evaluation.evaluator]: [0mInference done 2867/3489. 0.2384 s / img. ETA=0:02:48
[32m[03/29 01:02:16 d2.evaluation.evaluator]: [0mInference done 2888/3489. 0.2384 s / img. ETA=0:02:43
[32m[03/29 01:02:21 d2.evaluation.evaluator]: [0mInference done 2909/3489. 0.2383 s / img. ETA=0:02:37
[32m[03/29 01:02:26 d2.evaluation.evaluator]: [0mInference done 2930/3489. 0.2382 s / img. ETA=0:02:31
[32m[03/29 01:02:31 d2.evaluation.evaluator]: [0mInference done 2951/3489. 0.2382 s / img. ETA=0:02:25
[32m[03/29 01:02:36 d2.evaluation.evaluator]: [0mInference done 2972/3489. 0.2381 s / img. ETA=0:02:19
[32m[03/29 01:02:41 d2.evaluation.evaluator]: [0mInference done 2993/3489. 0.2380 s / img. ETA=0:02:14
[32m[03/29 01:02:46 d2.evaluation.evaluator]: [0mInference done 3013/3489. 0.2380 s / img. ETA=0:02:08
[32m[03/29 01:02:51 d2.evaluation.evaluator]: [0mInference done 3033/3489. 0.2380 s / img. ETA=0:02:03
[32m[03/29 01:02:56 d2.evaluation.evaluator]: [0mInference done 3054/3489. 0.2379 s / img. ETA=0:01:57
[32m[03/29 01:03:01 d2.evaluation.evaluator]: [0mInference done 3074/3489. 0.2379 s / img. ETA=0:01:51
[32m[03/29 01:03:07 d2.evaluation.evaluator]: [0mInference done 3093/3489. 0.2379 s / img. ETA=0:01:46
[32m[03/29 01:03:12 d2.evaluation.evaluator]: [0mInference done 3114/3489. 0.2378 s / img. ETA=0:01:41
[32m[03/29 01:03:17 d2.evaluation.evaluator]: [0mInference done 3134/3489. 0.2378 s / img. ETA=0:01:35
[32m[03/29 01:03:22 d2.evaluation.evaluator]: [0mInference done 3155/3489. 0.2377 s / img. ETA=0:01:29
[32m[03/29 01:03:27 d2.evaluation.evaluator]: [0mInference done 3175/3489. 0.2377 s / img. ETA=0:01:24
[32m[03/29 01:03:32 d2.evaluation.evaluator]: [0mInference done 3196/3489. 0.2376 s / img. ETA=0:01:18
[32m[03/29 01:03:37 d2.evaluation.evaluator]: [0mInference done 3217/3489. 0.2376 s / img. ETA=0:01:13
[32m[03/29 01:03:43 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2375 s / img. ETA=0:01:07
[32m[03/29 01:03:48 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2375 s / img. ETA=0:01:02
[32m[03/29 01:03:53 d2.evaluation.evaluator]: [0mInference done 3279/3489. 0.2374 s / img. ETA=0:00:56
[32m[03/29 01:03:58 d2.evaluation.evaluator]: [0mInference done 3301/3489. 0.2374 s / img. ETA=0:00:50
[32m[03/29 01:04:03 d2.evaluation.evaluator]: [0mInference done 3323/3489. 0.2373 s / img. ETA=0:00:44
[32m[03/29 01:04:08 d2.evaluation.evaluator]: [0mInference done 3345/3489. 0.2372 s / img. ETA=0:00:38
[32m[03/29 01:04:13 d2.evaluation.evaluator]: [0mInference done 3367/3489. 0.2372 s / img. ETA=0:00:32
[32m[03/29 01:04:18 d2.evaluation.evaluator]: [0mInference done 3389/3489. 0.2371 s / img. ETA=0:00:26
[32m[03/29 01:04:23 d2.evaluation.evaluator]: [0mInference done 3411/3489. 0.2370 s / img. ETA=0:00:20
[32m[03/29 01:04:28 d2.evaluation.evaluator]: [0mInference done 3432/3489. 0.2370 s / img. ETA=0:00:15
[32m[03/29 01:04:34 d2.evaluation.evaluator]: [0mInference done 3454/3489. 0.2369 s / img. ETA=0:00:09
[32m[03/29 01:04:39 d2.evaluation.evaluator]: [0mInference done 3475/3489. 0.2368 s / img. ETA=0:00:03
[32m[03/29 01:04:42 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:28.637810 (0.266544 s / img per device, on 1 devices)
[32m[03/29 01:04:42 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:45 (0.236811 s / img per device, on 1 devices)
[32m[03/29 01:04:44 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 01:04:44 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.500000_0.700000/coco_instances_results.json
[32m[03/29 01:04:45 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.34 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.47 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.803
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[32m[03/29 01:04:47 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.000 | 80.343 | 57.777 | 32.281 | 62.030 | 63.932 |
[32m[03/29 01:04:47 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.729 | Pedestrian | 42.271 |
Loading and preparing results...
DONE (t=1.67s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.11 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.51 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[32m[03/29 01:04:55 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.934 | 76.686 | 44.930 | 24.179 | 53.764 | 68.892 |
[32m[03/29 01:04:55 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.596 | Pedestrian | 29.273 |
[32m[03/29 01:04:56 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: 51.9998,80.3431,57.7773,32.2808,62.0303,63.9321
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 01:04:56 d2.evaluation.testing]: [0mcopypaste: 44.9345,76.6861,44.9300,24.1792,53.7639,68.8924
evaluated
Test [0.500000, 0.800000]
[32m[03/29 01:04:56 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 01:04:57 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/29 01:04:57 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 01:04:57 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 01:04:57 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/29 01:04:57 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/29 01:04:57 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 01:04:57 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 01:04:57 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 01:04:57 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 01:04:57 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 01:04:57 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 01:05:22 d2.utils.events]: [0m eta: 0:02:32  iter: 19  total_loss: 1.817  loss_cls: 0.8437  loss_box_reg: 0.3235  loss_mask: 0.6567  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.006345  total_val_loss: 1.949  val_loss_cls: 0.8019  val_loss_box_reg: 0.4842  val_loss_mask: 0.6809  val_loss_rpn_cls: 0.03725  val_loss_rpn_loc: 0.01446  time: 0.8428  data_time: 0.0250  lr: 0.00019981  max_mem: 4748M
[32m[03/29 01:05:47 d2.utils.events]: [0m eta: 0:02:16  iter: 39  total_loss: 1.104  loss_cls: 0.2662  loss_box_reg: 0.3796  loss_mask: 0.3632  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.01227  total_val_loss: 1.481  val_loss_cls: 0.3267  val_loss_box_reg: 0.536  val_loss_mask: 0.619  val_loss_rpn_cls: 0.0494  val_loss_rpn_loc: 0.01475  time: 0.8538  data_time: 0.0065  lr: 0.00039961  max_mem: 4748M
[32m[03/29 01:06:11 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.7524  loss_cls: 0.1215  loss_box_reg: 0.3977  loss_mask: 0.18  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.01182  total_val_loss: 1.214  val_loss_cls: 0.2551  val_loss_box_reg: 0.4256  val_loss_mask: 0.4678  val_loss_rpn_cls: 0.02619  val_loss_rpn_loc: 0.01375  time: 0.8572  data_time: 0.0063  lr: 0.00059941  max_mem: 4748M
[32m[03/29 01:06:36 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.5405  loss_cls: 0.06695  loss_box_reg: 0.2431  loss_mask: 0.1644  loss_rpn_cls: 0.009811  loss_rpn_loc: 0.007119  total_val_loss: 1.029  val_loss_cls: 0.1921  val_loss_box_reg: 0.2832  val_loss_mask: 0.4626  val_loss_rpn_cls: 0.02281  val_loss_rpn_loc: 0.009988  time: 0.8613  data_time: 0.0072  lr: 0.00079921  max_mem: 4748M
[32m[03/29 01:07:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:07:00 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:07:00 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:07:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 01:07:01 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.3539  loss_cls: 0.05053  loss_box_reg: 0.1074  loss_mask: 0.1555  loss_rpn_cls: 0.005859  loss_rpn_loc: 0.004532  total_val_loss: 0.8713  val_loss_cls: 0.155  val_loss_box_reg: 0.2561  val_loss_mask: 0.3806  val_loss_rpn_cls: 0.01712  val_loss_rpn_loc: 0.01299  time: 0.8626  data_time: 0.0068  lr: 0.00099901  max_mem: 4748M
[32m[03/29 01:07:25 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.2885  loss_cls: 0.03163  loss_box_reg: 0.07576  loss_mask: 0.1466  loss_rpn_cls: 0.006573  loss_rpn_loc: 0.006479  total_val_loss: 0.6405  val_loss_cls: 0.1414  val_loss_box_reg: 0.206  val_loss_mask: 0.2704  val_loss_rpn_cls: 0.02074  val_loss_rpn_loc: 0.01026  time: 0.8626  data_time: 0.0071  lr: 0.0011988  max_mem: 4748M
[32m[03/29 01:07:50 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3923  loss_cls: 0.05617  loss_box_reg: 0.1454  loss_mask: 0.1521  loss_rpn_cls: 0.007349  loss_rpn_loc: 0.01187  total_val_loss: 0.8379  val_loss_cls: 0.2201  val_loss_box_reg: 0.2837  val_loss_mask: 0.3503  val_loss_rpn_cls: 0.01641  val_loss_rpn_loc: 0.01658  time: 0.8629  data_time: 0.0061  lr: 0.0013986  max_mem: 4748M
[32m[03/29 01:08:14 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.4004  loss_cls: 0.05391  loss_box_reg: 0.1157  loss_mask: 0.1686  loss_rpn_cls: 0.008151  loss_rpn_loc: 0.01149  total_val_loss: 0.8926  val_loss_cls: 0.1885  val_loss_box_reg: 0.2608  val_loss_mask: 0.3974  val_loss_rpn_cls: 0.02509  val_loss_rpn_loc: 0.01465  time: 0.8642  data_time: 0.0071  lr: 0.0015984  max_mem: 4748M
[32m[03/29 01:08:39 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3061  loss_cls: 0.04041  loss_box_reg: 0.09723  loss_mask: 0.1483  loss_rpn_cls: 0.005107  loss_rpn_loc: 0.006934  total_val_loss: 0.6368  val_loss_cls: 0.1255  val_loss_box_reg: 0.2068  val_loss_mask: 0.3005  val_loss_rpn_cls: 0.02532  val_loss_rpn_loc: 0.0116  time: 0.8654  data_time: 0.0061  lr: 0.0017982  max_mem: 4748M
[32m[03/29 01:09:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:09:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:09:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:09:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 01:09:05 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3503  loss_cls: 0.05361  loss_box_reg: 0.09893  loss_mask: 0.1449  loss_rpn_cls: 0.006682  loss_rpn_loc: 0.008666  total_val_loss: 0.6936  val_loss_cls: 0.1  val_loss_box_reg: 0.1739  val_loss_mask: 0.2451  val_loss_rpn_cls: 0.01369  val_loss_rpn_loc: 0.01113  time: 0.8663  data_time: 0.0063  lr: 0.001998  max_mem: 4748M
[32m[03/29 01:09:05 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8663 s / it)
[32m[03/29 01:09:05 d2.engine.hooks]: [0mTotal training time: 0:04:04 (0:01:12 on hooks)
[32m[03/29 01:09:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:09:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:09:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:09:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 01:09:05 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 01:09:06 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:09:06 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:09:06 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 01:09:06 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 01:09:09 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2277 s / img. ETA=0:14:12
[32m[03/29 01:09:14 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2322 s / img. ETA=0:14:17
[32m[03/29 01:09:19 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2329 s / img. ETA=0:14:11
[32m[03/29 01:09:24 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2310 s / img. ETA=0:13:57
[32m[03/29 01:09:29 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2318 s / img. ETA=0:14:03
[32m[03/29 01:09:35 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2328 s / img. ETA=0:14:14
[32m[03/29 01:09:40 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2353 s / img. ETA=0:14:37
[32m[03/29 01:09:45 d2.evaluation.evaluator]: [0mInference done 145/3489. 0.2375 s / img. ETA=0:14:59
[32m[03/29 01:09:50 d2.evaluation.evaluator]: [0mInference done 161/3489. 0.2393 s / img. ETA=0:15:13
[32m[03/29 01:09:55 d2.evaluation.evaluator]: [0mInference done 177/3489. 0.2406 s / img. ETA=0:15:22
[32m[03/29 01:10:00 d2.evaluation.evaluator]: [0mInference done 194/3489. 0.2411 s / img. ETA=0:15:22
[32m[03/29 01:10:05 d2.evaluation.evaluator]: [0mInference done 214/3489. 0.2405 s / img. ETA=0:15:11
[32m[03/29 01:10:11 d2.evaluation.evaluator]: [0mInference done 234/3489. 0.2400 s / img. ETA=0:15:01
[32m[03/29 01:10:16 d2.evaluation.evaluator]: [0mInference done 253/3489. 0.2398 s / img. ETA=0:14:54
[32m[03/29 01:10:21 d2.evaluation.evaluator]: [0mInference done 272/3489. 0.2397 s / img. ETA=0:14:48
[32m[03/29 01:10:26 d2.evaluation.evaluator]: [0mInference done 290/3489. 0.2397 s / img. ETA=0:14:43
[32m[03/29 01:10:31 d2.evaluation.evaluator]: [0mInference done 308/3489. 0.2397 s / img. ETA=0:14:39
[32m[03/29 01:10:36 d2.evaluation.evaluator]: [0mInference done 326/3489. 0.2398 s / img. ETA=0:14:34
[32m[03/29 01:10:41 d2.evaluation.evaluator]: [0mInference done 344/3489. 0.2401 s / img. ETA=0:14:31
[32m[03/29 01:10:47 d2.evaluation.evaluator]: [0mInference done 362/3489. 0.2404 s / img. ETA=0:14:29
[32m[03/29 01:10:52 d2.evaluation.evaluator]: [0mInference done 380/3489. 0.2405 s / img. ETA=0:14:25
[32m[03/29 01:10:57 d2.evaluation.evaluator]: [0mInference done 398/3489. 0.2405 s / img. ETA=0:14:20
[32m[03/29 01:11:02 d2.evaluation.evaluator]: [0mInference done 417/3489. 0.2405 s / img. ETA=0:14:14
[32m[03/29 01:11:07 d2.evaluation.evaluator]: [0mInference done 438/3489. 0.2399 s / img. ETA=0:14:03
[32m[03/29 01:11:12 d2.evaluation.evaluator]: [0mInference done 459/3489. 0.2394 s / img. ETA=0:13:53
[32m[03/29 01:11:17 d2.evaluation.evaluator]: [0mInference done 480/3489. 0.2390 s / img. ETA=0:13:43
[32m[03/29 01:11:22 d2.evaluation.evaluator]: [0mInference done 501/3489. 0.2385 s / img. ETA=0:13:33
[32m[03/29 01:11:27 d2.evaluation.evaluator]: [0mInference done 522/3489. 0.2381 s / img. ETA=0:13:23
[32m[03/29 01:11:32 d2.evaluation.evaluator]: [0mInference done 543/3489. 0.2377 s / img. ETA=0:13:14
[32m[03/29 01:11:38 d2.evaluation.evaluator]: [0mInference done 563/3489. 0.2377 s / img. ETA=0:13:07
[32m[03/29 01:11:43 d2.evaluation.evaluator]: [0mInference done 582/3489. 0.2377 s / img. ETA=0:13:02
[32m[03/29 01:11:48 d2.evaluation.evaluator]: [0mInference done 600/3489. 0.2381 s / img. ETA=0:12:59
[32m[03/29 01:11:53 d2.evaluation.evaluator]: [0mInference done 619/3489. 0.2380 s / img. ETA=0:12:54
[32m[03/29 01:11:58 d2.evaluation.evaluator]: [0mInference done 638/3489. 0.2381 s / img. ETA=0:12:49
[32m[03/29 01:12:03 d2.evaluation.evaluator]: [0mInference done 657/3489. 0.2380 s / img. ETA=0:12:43
[32m[03/29 01:12:08 d2.evaluation.evaluator]: [0mInference done 677/3489. 0.2379 s / img. ETA=0:12:37
[32m[03/29 01:12:13 d2.evaluation.evaluator]: [0mInference done 698/3489. 0.2376 s / img. ETA=0:12:29
[32m[03/29 01:12:19 d2.evaluation.evaluator]: [0mInference done 719/3489. 0.2374 s / img. ETA=0:12:22
[32m[03/29 01:12:24 d2.evaluation.evaluator]: [0mInference done 740/3489. 0.2372 s / img. ETA=0:12:15
[32m[03/29 01:12:29 d2.evaluation.evaluator]: [0mInference done 761/3489. 0.2370 s / img. ETA=0:12:07
[32m[03/29 01:12:34 d2.evaluation.evaluator]: [0mInference done 782/3489. 0.2368 s / img. ETA=0:12:00
[32m[03/29 01:12:39 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2365 s / img. ETA=0:11:52
[32m[03/29 01:12:44 d2.evaluation.evaluator]: [0mInference done 825/3489. 0.2363 s / img. ETA=0:11:45
[32m[03/29 01:12:49 d2.evaluation.evaluator]: [0mInference done 846/3489. 0.2361 s / img. ETA=0:11:37
[32m[03/29 01:12:54 d2.evaluation.evaluator]: [0mInference done 867/3489. 0.2359 s / img. ETA=0:11:30
[32m[03/29 01:13:00 d2.evaluation.evaluator]: [0mInference done 889/3489. 0.2357 s / img. ETA=0:11:23
[32m[03/29 01:13:05 d2.evaluation.evaluator]: [0mInference done 908/3489. 0.2357 s / img. ETA=0:11:18
[32m[03/29 01:13:10 d2.evaluation.evaluator]: [0mInference done 926/3489. 0.2359 s / img. ETA=0:11:15
[32m[03/29 01:13:15 d2.evaluation.evaluator]: [0mInference done 943/3489. 0.2361 s / img. ETA=0:11:12
[32m[03/29 01:13:20 d2.evaluation.evaluator]: [0mInference done 961/3489. 0.2363 s / img. ETA=0:11:08
[32m[03/29 01:13:26 d2.evaluation.evaluator]: [0mInference done 978/3489. 0.2366 s / img. ETA=0:11:06
[32m[03/29 01:13:31 d2.evaluation.evaluator]: [0mInference done 995/3489. 0.2368 s / img. ETA=0:11:03
[32m[03/29 01:13:36 d2.evaluation.evaluator]: [0mInference done 1012/3489. 0.2370 s / img. ETA=0:11:00
[32m[03/29 01:13:41 d2.evaluation.evaluator]: [0mInference done 1028/3489. 0.2373 s / img. ETA=0:10:58
[32m[03/29 01:13:46 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2375 s / img. ETA=0:10:55
[32m[03/29 01:13:51 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2377 s / img. ETA=0:10:52
[32m[03/29 01:13:56 d2.evaluation.evaluator]: [0mInference done 1078/3489. 0.2379 s / img. ETA=0:10:49
[32m[03/29 01:14:02 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2379 s / img. ETA=0:10:44
[32m[03/29 01:14:07 d2.evaluation.evaluator]: [0mInference done 1116/3489. 0.2380 s / img. ETA=0:10:39
[32m[03/29 01:14:12 d2.evaluation.evaluator]: [0mInference done 1133/3489. 0.2382 s / img. ETA=0:10:36
[32m[03/29 01:14:17 d2.evaluation.evaluator]: [0mInference done 1150/3489. 0.2383 s / img. ETA=0:10:32
[32m[03/29 01:14:22 d2.evaluation.evaluator]: [0mInference done 1167/3489. 0.2385 s / img. ETA=0:10:29
[32m[03/29 01:14:27 d2.evaluation.evaluator]: [0mInference done 1185/3489. 0.2385 s / img. ETA=0:10:24
[32m[03/29 01:14:32 d2.evaluation.evaluator]: [0mInference done 1203/3489. 0.2385 s / img. ETA=0:10:19
[32m[03/29 01:14:37 d2.evaluation.evaluator]: [0mInference done 1221/3489. 0.2385 s / img. ETA=0:10:15
[32m[03/29 01:14:42 d2.evaluation.evaluator]: [0mInference done 1240/3489. 0.2385 s / img. ETA=0:10:10
[32m[03/29 01:14:48 d2.evaluation.evaluator]: [0mInference done 1260/3489. 0.2385 s / img. ETA=0:10:04
[32m[03/29 01:14:53 d2.evaluation.evaluator]: [0mInference done 1282/3489. 0.2382 s / img. ETA=0:09:56
[32m[03/29 01:14:58 d2.evaluation.evaluator]: [0mInference done 1304/3489. 0.2380 s / img. ETA=0:09:49
[32m[03/29 01:15:03 d2.evaluation.evaluator]: [0mInference done 1326/3489. 0.2378 s / img. ETA=0:09:42
[32m[03/29 01:15:08 d2.evaluation.evaluator]: [0mInference done 1348/3489. 0.2376 s / img. ETA=0:09:35
[32m[03/29 01:15:13 d2.evaluation.evaluator]: [0mInference done 1369/3489. 0.2375 s / img. ETA=0:09:28
[32m[03/29 01:15:18 d2.evaluation.evaluator]: [0mInference done 1390/3489. 0.2374 s / img. ETA=0:09:22
[32m[03/29 01:15:24 d2.evaluation.evaluator]: [0mInference done 1411/3489. 0.2373 s / img. ETA=0:09:16
[32m[03/29 01:15:29 d2.evaluation.evaluator]: [0mInference done 1431/3489. 0.2373 s / img. ETA=0:09:10
[32m[03/29 01:15:34 d2.evaluation.evaluator]: [0mInference done 1452/3489. 0.2371 s / img. ETA=0:09:04
[32m[03/29 01:15:39 d2.evaluation.evaluator]: [0mInference done 1473/3489. 0.2370 s / img. ETA=0:08:57
[32m[03/29 01:15:44 d2.evaluation.evaluator]: [0mInference done 1494/3489. 0.2369 s / img. ETA=0:08:51
[32m[03/29 01:15:49 d2.evaluation.evaluator]: [0mInference done 1516/3489. 0.2367 s / img. ETA=0:08:44
[32m[03/29 01:15:54 d2.evaluation.evaluator]: [0mInference done 1537/3489. 0.2367 s / img. ETA=0:08:38
[32m[03/29 01:15:59 d2.evaluation.evaluator]: [0mInference done 1558/3489. 0.2366 s / img. ETA=0:08:32
[32m[03/29 01:16:05 d2.evaluation.evaluator]: [0mInference done 1579/3489. 0.2365 s / img. ETA=0:08:26
[32m[03/29 01:16:10 d2.evaluation.evaluator]: [0mInference done 1599/3489. 0.2365 s / img. ETA=0:08:20
[32m[03/29 01:16:15 d2.evaluation.evaluator]: [0mInference done 1618/3489. 0.2365 s / img. ETA=0:08:16
[32m[03/29 01:16:20 d2.evaluation.evaluator]: [0mInference done 1636/3489. 0.2366 s / img. ETA=0:08:11
[32m[03/29 01:16:25 d2.evaluation.evaluator]: [0mInference done 1655/3489. 0.2366 s / img. ETA=0:08:07
[32m[03/29 01:16:31 d2.evaluation.evaluator]: [0mInference done 1673/3489. 0.2367 s / img. ETA=0:08:02
[32m[03/29 01:16:36 d2.evaluation.evaluator]: [0mInference done 1689/3489. 0.2369 s / img. ETA=0:07:59
[32m[03/29 01:16:41 d2.evaluation.evaluator]: [0mInference done 1705/3489. 0.2371 s / img. ETA=0:07:55
[32m[03/29 01:16:46 d2.evaluation.evaluator]: [0mInference done 1722/3489. 0.2372 s / img. ETA=0:07:51
[32m[03/29 01:16:51 d2.evaluation.evaluator]: [0mInference done 1739/3489. 0.2373 s / img. ETA=0:07:48
[32m[03/29 01:16:56 d2.evaluation.evaluator]: [0mInference done 1755/3489. 0.2374 s / img. ETA=0:07:44
[32m[03/29 01:17:01 d2.evaluation.evaluator]: [0mInference done 1771/3489. 0.2375 s / img. ETA=0:07:41
[32m[03/29 01:17:06 d2.evaluation.evaluator]: [0mInference done 1787/3489. 0.2377 s / img. ETA=0:07:37
[32m[03/29 01:17:12 d2.evaluation.evaluator]: [0mInference done 1803/3489. 0.2378 s / img. ETA=0:07:34
[32m[03/29 01:17:17 d2.evaluation.evaluator]: [0mInference done 1819/3489. 0.2379 s / img. ETA=0:07:30
[32m[03/29 01:17:22 d2.evaluation.evaluator]: [0mInference done 1835/3489. 0.2381 s / img. ETA=0:07:26
[32m[03/29 01:17:27 d2.evaluation.evaluator]: [0mInference done 1851/3489. 0.2382 s / img. ETA=0:07:23
[32m[03/29 01:17:32 d2.evaluation.evaluator]: [0mInference done 1867/3489. 0.2383 s / img. ETA=0:07:19
[32m[03/29 01:17:37 d2.evaluation.evaluator]: [0mInference done 1883/3489. 0.2384 s / img. ETA=0:07:15
[32m[03/29 01:17:42 d2.evaluation.evaluator]: [0mInference done 1899/3489. 0.2385 s / img. ETA=0:07:12
[32m[03/29 01:17:47 d2.evaluation.evaluator]: [0mInference done 1915/3489. 0.2386 s / img. ETA=0:07:08
[32m[03/29 01:17:52 d2.evaluation.evaluator]: [0mInference done 1931/3489. 0.2387 s / img. ETA=0:07:04
[32m[03/29 01:17:57 d2.evaluation.evaluator]: [0mInference done 1947/3489. 0.2389 s / img. ETA=0:07:00
[32m[03/29 01:18:02 d2.evaluation.evaluator]: [0mInference done 1963/3489. 0.2390 s / img. ETA=0:06:56
[32m[03/29 01:18:07 d2.evaluation.evaluator]: [0mInference done 1979/3489. 0.2391 s / img. ETA=0:06:53
[32m[03/29 01:18:12 d2.evaluation.evaluator]: [0mInference done 1996/3489. 0.2392 s / img. ETA=0:06:48
[32m[03/29 01:18:18 d2.evaluation.evaluator]: [0mInference done 2014/3489. 0.2392 s / img. ETA=0:06:44
[32m[03/29 01:18:23 d2.evaluation.evaluator]: [0mInference done 2032/3489. 0.2392 s / img. ETA=0:06:39
[32m[03/29 01:18:28 d2.evaluation.evaluator]: [0mInference done 2049/3489. 0.2393 s / img. ETA=0:06:35
[32m[03/29 01:18:33 d2.evaluation.evaluator]: [0mInference done 2066/3489. 0.2394 s / img. ETA=0:06:30
[32m[03/29 01:18:39 d2.evaluation.evaluator]: [0mInference done 2082/3489. 0.2395 s / img. ETA=0:06:27
[32m[03/29 01:18:44 d2.evaluation.evaluator]: [0mInference done 2098/3489. 0.2396 s / img. ETA=0:06:23
[32m[03/29 01:18:49 d2.evaluation.evaluator]: [0mInference done 2114/3489. 0.2398 s / img. ETA=0:06:19
[32m[03/29 01:18:54 d2.evaluation.evaluator]: [0mInference done 2129/3489. 0.2399 s / img. ETA=0:06:15
[32m[03/29 01:18:59 d2.evaluation.evaluator]: [0mInference done 2145/3489. 0.2400 s / img. ETA=0:06:11
[32m[03/29 01:19:04 d2.evaluation.evaluator]: [0mInference done 2161/3489. 0.2401 s / img. ETA=0:06:07
[32m[03/29 01:19:09 d2.evaluation.evaluator]: [0mInference done 2177/3489. 0.2402 s / img. ETA=0:06:03
[32m[03/29 01:19:14 d2.evaluation.evaluator]: [0mInference done 2193/3489. 0.2403 s / img. ETA=0:05:59
[32m[03/29 01:19:20 d2.evaluation.evaluator]: [0mInference done 2209/3489. 0.2403 s / img. ETA=0:05:55
[32m[03/29 01:19:25 d2.evaluation.evaluator]: [0mInference done 2226/3489. 0.2404 s / img. ETA=0:05:51
[32m[03/29 01:19:30 d2.evaluation.evaluator]: [0mInference done 2243/3489. 0.2405 s / img. ETA=0:05:46
[32m[03/29 01:19:35 d2.evaluation.evaluator]: [0mInference done 2260/3489. 0.2405 s / img. ETA=0:05:42
[32m[03/29 01:19:40 d2.evaluation.evaluator]: [0mInference done 2277/3489. 0.2406 s / img. ETA=0:05:37
[32m[03/29 01:19:45 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2406 s / img. ETA=0:05:33
[32m[03/29 01:19:51 d2.evaluation.evaluator]: [0mInference done 2311/3489. 0.2407 s / img. ETA=0:05:28
[32m[03/29 01:19:56 d2.evaluation.evaluator]: [0mInference done 2328/3489. 0.2408 s / img. ETA=0:05:24
[32m[03/29 01:20:01 d2.evaluation.evaluator]: [0mInference done 2345/3489. 0.2408 s / img. ETA=0:05:19
[32m[03/29 01:20:06 d2.evaluation.evaluator]: [0mInference done 2362/3489. 0.2409 s / img. ETA=0:05:15
[32m[03/29 01:20:11 d2.evaluation.evaluator]: [0mInference done 2381/3489. 0.2409 s / img. ETA=0:05:09
[32m[03/29 01:20:17 d2.evaluation.evaluator]: [0mInference done 2400/3489. 0.2408 s / img. ETA=0:05:04
[32m[03/29 01:20:22 d2.evaluation.evaluator]: [0mInference done 2418/3489. 0.2409 s / img. ETA=0:04:59
[32m[03/29 01:20:27 d2.evaluation.evaluator]: [0mInference done 2437/3489. 0.2408 s / img. ETA=0:04:54
[32m[03/29 01:20:32 d2.evaluation.evaluator]: [0mInference done 2454/3489. 0.2409 s / img. ETA=0:04:49
[32m[03/29 01:20:37 d2.evaluation.evaluator]: [0mInference done 2471/3489. 0.2410 s / img. ETA=0:04:44
[32m[03/29 01:20:43 d2.evaluation.evaluator]: [0mInference done 2488/3489. 0.2411 s / img. ETA=0:04:40
[32m[03/29 01:20:48 d2.evaluation.evaluator]: [0mInference done 2508/3489. 0.2410 s / img. ETA=0:04:34
[32m[03/29 01:20:53 d2.evaluation.evaluator]: [0mInference done 2527/3489. 0.2410 s / img. ETA=0:04:29
[32m[03/29 01:20:58 d2.evaluation.evaluator]: [0mInference done 2547/3489. 0.2409 s / img. ETA=0:04:23
[32m[03/29 01:21:03 d2.evaluation.evaluator]: [0mInference done 2567/3489. 0.2408 s / img. ETA=0:04:17
[32m[03/29 01:21:08 d2.evaluation.evaluator]: [0mInference done 2588/3489. 0.2408 s / img. ETA=0:04:11
[32m[03/29 01:21:13 d2.evaluation.evaluator]: [0mInference done 2608/3489. 0.2407 s / img. ETA=0:04:05
[32m[03/29 01:21:18 d2.evaluation.evaluator]: [0mInference done 2629/3489. 0.2406 s / img. ETA=0:03:59
[32m[03/29 01:21:24 d2.evaluation.evaluator]: [0mInference done 2650/3489. 0.2405 s / img. ETA=0:03:53
[32m[03/29 01:21:29 d2.evaluation.evaluator]: [0mInference done 2670/3489. 0.2405 s / img. ETA=0:03:47
[32m[03/29 01:21:34 d2.evaluation.evaluator]: [0mInference done 2690/3489. 0.2404 s / img. ETA=0:03:42
[32m[03/29 01:21:39 d2.evaluation.evaluator]: [0mInference done 2710/3489. 0.2403 s / img. ETA=0:03:36
[32m[03/29 01:21:44 d2.evaluation.evaluator]: [0mInference done 2731/3489. 0.2403 s / img. ETA=0:03:30
[32m[03/29 01:21:49 d2.evaluation.evaluator]: [0mInference done 2751/3489. 0.2402 s / img. ETA=0:03:24
[32m[03/29 01:21:54 d2.evaluation.evaluator]: [0mInference done 2771/3489. 0.2401 s / img. ETA=0:03:19
[32m[03/29 01:21:59 d2.evaluation.evaluator]: [0mInference done 2792/3489. 0.2401 s / img. ETA=0:03:13
[32m[03/29 01:22:04 d2.evaluation.evaluator]: [0mInference done 2812/3489. 0.2400 s / img. ETA=0:03:07
[32m[03/29 01:22:10 d2.evaluation.evaluator]: [0mInference done 2832/3489. 0.2399 s / img. ETA=0:03:01
[32m[03/29 01:22:15 d2.evaluation.evaluator]: [0mInference done 2852/3489. 0.2399 s / img. ETA=0:02:56
[32m[03/29 01:22:20 d2.evaluation.evaluator]: [0mInference done 2872/3489. 0.2398 s / img. ETA=0:02:50
[32m[03/29 01:22:25 d2.evaluation.evaluator]: [0mInference done 2892/3489. 0.2398 s / img. ETA=0:02:44
[32m[03/29 01:22:30 d2.evaluation.evaluator]: [0mInference done 2913/3489. 0.2397 s / img. ETA=0:02:38
[32m[03/29 01:22:35 d2.evaluation.evaluator]: [0mInference done 2934/3489. 0.2396 s / img. ETA=0:02:33
[32m[03/29 01:22:40 d2.evaluation.evaluator]: [0mInference done 2954/3489. 0.2396 s / img. ETA=0:02:27
[32m[03/29 01:22:45 d2.evaluation.evaluator]: [0mInference done 2976/3489. 0.2395 s / img. ETA=0:02:21
[32m[03/29 01:22:50 d2.evaluation.evaluator]: [0mInference done 2996/3489. 0.2394 s / img. ETA=0:02:15
[32m[03/29 01:22:56 d2.evaluation.evaluator]: [0mInference done 3016/3489. 0.2394 s / img. ETA=0:02:10
[32m[03/29 01:23:01 d2.evaluation.evaluator]: [0mInference done 3036/3489. 0.2393 s / img. ETA=0:02:04
[32m[03/29 01:23:06 d2.evaluation.evaluator]: [0mInference done 3057/3489. 0.2393 s / img. ETA=0:01:58
[32m[03/29 01:23:11 d2.evaluation.evaluator]: [0mInference done 3077/3489. 0.2392 s / img. ETA=0:01:53
[32m[03/29 01:23:16 d2.evaluation.evaluator]: [0mInference done 3096/3489. 0.2392 s / img. ETA=0:01:47
[32m[03/29 01:23:21 d2.evaluation.evaluator]: [0mInference done 3116/3489. 0.2392 s / img. ETA=0:01:42
[32m[03/29 01:23:26 d2.evaluation.evaluator]: [0mInference done 3136/3489. 0.2391 s / img. ETA=0:01:36
[32m[03/29 01:23:31 d2.evaluation.evaluator]: [0mInference done 3156/3489. 0.2391 s / img. ETA=0:01:31
[32m[03/29 01:23:37 d2.evaluation.evaluator]: [0mInference done 3176/3489. 0.2390 s / img. ETA=0:01:25
[32m[03/29 01:23:42 d2.evaluation.evaluator]: [0mInference done 3197/3489. 0.2390 s / img. ETA=0:01:19
[32m[03/29 01:23:47 d2.evaluation.evaluator]: [0mInference done 3217/3489. 0.2389 s / img. ETA=0:01:14
[32m[03/29 01:23:52 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2389 s / img. ETA=0:01:08
[32m[03/29 01:23:57 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2388 s / img. ETA=0:01:03
[32m[03/29 01:24:02 d2.evaluation.evaluator]: [0mInference done 3279/3489. 0.2388 s / img. ETA=0:00:57
[32m[03/29 01:24:08 d2.evaluation.evaluator]: [0mInference done 3301/3489. 0.2387 s / img. ETA=0:00:51
[32m[03/29 01:24:13 d2.evaluation.evaluator]: [0mInference done 3323/3489. 0.2386 s / img. ETA=0:00:45
[32m[03/29 01:24:18 d2.evaluation.evaluator]: [0mInference done 3345/3489. 0.2385 s / img. ETA=0:00:39
[32m[03/29 01:24:23 d2.evaluation.evaluator]: [0mInference done 3367/3489. 0.2384 s / img. ETA=0:00:33
[32m[03/29 01:24:28 d2.evaluation.evaluator]: [0mInference done 3388/3489. 0.2384 s / img. ETA=0:00:27
[32m[03/29 01:24:33 d2.evaluation.evaluator]: [0mInference done 3409/3489. 0.2383 s / img. ETA=0:00:21
[32m[03/29 01:24:38 d2.evaluation.evaluator]: [0mInference done 3430/3489. 0.2383 s / img. ETA=0:00:16
[32m[03/29 01:24:43 d2.evaluation.evaluator]: [0mInference done 3451/3489. 0.2382 s / img. ETA=0:00:10
[32m[03/29 01:24:49 d2.evaluation.evaluator]: [0mInference done 3471/3489. 0.2382 s / img. ETA=0:00:04
[32m[03/29 01:24:53 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:45.885067 (0.271494 s / img per device, on 1 devices)
[32m[03/29 01:24:53 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:49 (0.238141 s / img per device, on 1 devices)
[32m[03/29 01:24:55 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/29 01:24:55 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_0.500000_0.800000/coco_instances_results.json
[32m[03/29 01:24:56 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.40 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.49 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.796
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[32m[03/29 01:24:58 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.609 | 79.642 | 44.098 | 33.237 | 55.871 | 57.706 |
[32m[03/29 01:24:58 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.835 | Pedestrian | 30.384 |
Loading and preparing results...
DONE (t=1.85s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.27 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[32m[03/29 01:25:08 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.430 | 75.729 | 41.772 | 25.135 | 52.133 | 66.980 |
[32m[03/29 01:25:08 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.865 | Pedestrian | 23.996 |
[32m[03/29 01:25:08 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: 47.6093,79.6424,44.0976,33.2371,55.8706,57.7060
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/29 01:25:08 d2.evaluation.testing]: [0mcopypaste: 44.4305,75.7294,41.7723,25.1348,52.1333,66.9800
evaluated
Test [0.500000, 0.900000]
[32m[03/29 01:25:09 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/29 01:25:09 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/29 01:25:09 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 01:25:09 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 01:25:09 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/29 01:25:09 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/29 01:25:09 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/29 01:25:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/29 01:25:10 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/29 01:25:10 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/29 01:25:10 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/29 01:25:10 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/29 01:25:34 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.827  loss_cls: 0.731  loss_box_reg: 0.3317  loss_mask: 0.6585  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.01064  total_val_loss: 1.831  val_loss_cls: 0.7124  val_loss_box_reg: 0.4224  val_loss_mask: 0.6719  val_loss_rpn_cls: 0.03985  val_loss_rpn_loc: 0.01208  time: 0.8428  data_time: 0.0261  lr: 0.00019981  max_mem: 4748M
[32m[03/29 01:25:59 d2.utils.events]: [0m eta: 0:02:15  iter: 39  total_loss: 0.9431  loss_cls: 0.1934  loss_box_reg: 0.3428  loss_mask: 0.3763  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.007374  total_val_loss: 1.339  val_loss_cls: 0.2791  val_loss_box_reg: 0.4338  val_loss_mask: 0.5427  val_loss_rpn_cls: 0.04157  val_loss_rpn_loc: 0.01222  time: 0.8528  data_time: 0.0066  lr: 0.00039961  max_mem: 4748M
[32m[03/29 01:26:23 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.7162  loss_cls: 0.08378  loss_box_reg: 0.351  loss_mask: 0.2071  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01054  total_val_loss: 0.985  val_loss_cls: 0.1855  val_loss_box_reg: 0.3946  val_loss_mask: 0.4173  val_loss_rpn_cls: 0.0306  val_loss_rpn_loc: 0.009332  time: 0.8565  data_time: 0.0060  lr: 0.00059941  max_mem: 4748M
[32m[03/29 01:26:48 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.544  loss_cls: 0.06643  loss_box_reg: 0.3004  loss_mask: 0.1595  loss_rpn_cls: 0.008459  loss_rpn_loc: 0.01004  total_val_loss: 0.8465  val_loss_cls: 0.1529  val_loss_box_reg: 0.3762  val_loss_mask: 0.3009  val_loss_rpn_cls: 0.01801  val_loss_rpn_loc: 0.01208  time: 0.8585  data_time: 0.0060  lr: 0.00079921  max_mem: 4748M
[32m[03/29 01:27:13 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:27:13 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:27:13 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:27:13 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 01:27:13 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.4564  loss_cls: 0.06003  loss_box_reg: 0.1582  loss_mask: 0.2062  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.007621  total_val_loss: 0.9219  val_loss_cls: 0.2027  val_loss_box_reg: 0.3053  val_loss_mask: 0.3689  val_loss_rpn_cls: 0.02407  val_loss_rpn_loc: 0.01324  time: 0.8603  data_time: 0.0067  lr: 0.00099901  max_mem: 4748M
[32m[03/29 01:27:38 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3912  loss_cls: 0.04515  loss_box_reg: 0.1055  loss_mask: 0.1605  loss_rpn_cls: 0.005111  loss_rpn_loc: 0.008824  total_val_loss: 0.59  val_loss_cls: 0.1307  val_loss_box_reg: 0.212  val_loss_mask: 0.3004  val_loss_rpn_cls: 0.01824  val_loss_rpn_loc: 0.01209  time: 0.8612  data_time: 0.0064  lr: 0.0011988  max_mem: 4748M
[32m[03/29 01:28:02 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3678  loss_cls: 0.05501  loss_box_reg: 0.09547  loss_mask: 0.1671  loss_rpn_cls: 0.009087  loss_rpn_loc: 0.007143  total_val_loss: 0.8562  val_loss_cls: 0.176  val_loss_box_reg: 0.2406  val_loss_mask: 0.441  val_loss_rpn_cls: 0.0221  val_loss_rpn_loc: 0.01236  time: 0.8622  data_time: 0.0068  lr: 0.0013986  max_mem: 4748M
[32m[03/29 01:28:26 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3807  loss_cls: 0.04845  loss_box_reg: 0.09482  loss_mask: 0.2014  loss_rpn_cls: 0.007815  loss_rpn_loc: 0.009814  total_val_loss: 0.6801  val_loss_cls: 0.1333  val_loss_box_reg: 0.1823  val_loss_mask: 0.2739  val_loss_rpn_cls: 0.01897  val_loss_rpn_loc: 0.01508  time: 0.8632  data_time: 0.0068  lr: 0.0015984  max_mem: 4748M
[32m[03/29 01:28:51 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3277  loss_cls: 0.05203  loss_box_reg: 0.09991  loss_mask: 0.165  loss_rpn_cls: 0.00478  loss_rpn_loc: 0.007232  total_val_loss: 0.6741  val_loss_cls: 0.1039  val_loss_box_reg: 0.1821  val_loss_mask: 0.3117  val_loss_rpn_cls: 0.01514  val_loss_rpn_loc: 0.01266  time: 0.8636  data_time: 0.0067  lr: 0.0017982  max_mem: 4748M
[32m[03/29 01:29:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:29:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:29:16 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:29:16 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/29 01:29:16 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4071  loss_cls: 0.05023  loss_box_reg: 0.104  loss_mask: 0.1844  loss_rpn_cls: 0.005509  loss_rpn_loc: 0.008465  total_val_loss: 0.8938  val_loss_cls: 0.1976  val_loss_box_reg: 0.3289  val_loss_mask: 0.312  val_loss_rpn_cls: 0.01276  val_loss_rpn_loc: 0.01317  time: 0.8645  data_time: 0.0065  lr: 0.001998  max_mem: 4748M
[32m[03/29 01:29:16 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8645 s / it)
[32m[03/29 01:29:16 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[03/29 01:29:17 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:29:17 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:29:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/29 01:29:17 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/29 01:29:17 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/29 01:29:18 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/29 01:29:18 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/29 01:29:18 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/29 01:29:18 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/29 01:29:21 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2276 s / img. ETA=0:15:39
[32m[03/29 01:29:26 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2332 s / img. ETA=0:14:56
[32m[03/29 01:29:31 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2308 s / img. ETA=0:14:21
[32m[03/29 01:29:37 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2300 s / img. ETA=0:14:02
[32m[03/29 01:29:42 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2302 s / img. ETA=0:14:05
[32m[03/29 01:29:47 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2312 s / img. ETA=0:14:10
[32m[03/29 01:29:52 d2.evaluation.evaluator]: [0mInference done 131/3489. 0.2330 s / img. ETA=0:14:23
[32m[03/29 01:29:57 d2.evaluation.evaluator]: [0mInference done 148/3489. 0.2351 s / img. ETA=0:14:39
[32m[03/29 01:30:02 d2.evaluation.evaluator]: [0mInference done 164/3489. 0.2371 s / img. ETA=0:14:55
[32m[03/29 01:30:07 d2.evaluation.evaluator]: [0mInference done 180/3489. 0.2388 s / img. ETA=0:15:03
[32m[03/29 01:30:13 d2.evaluation.evaluator]: [0mInference done 198/3489. 0.2390 s / img. ETA=0:15:03
[32m[03/29 01:30:18 d2.evaluation.evaluator]: [0mInference done 218/3489. 0.2384 s / img. ETA=0:14:50
[32m[03/29 01:30:23 d2.evaluation.evaluator]: [0mInference done 238/3489. 0.2377 s / img. ETA=0:14:40
[32m[03/29 01:30:28 d2.evaluation.evaluator]: [0mInference done 257/3489. 0.2376 s / img. ETA=0:14:34
[32m[03/29 01:30:33 d2.evaluation.evaluator]: [0mInference done 277/3489. 0.2374 s / img. ETA=0:14:27
[32m[03/29 01:30:38 d2.evaluation.evaluator]: [0mInference done 297/3489. 0.2371 s / img. ETA=0:14:18
[32m[03/29 01:30:43 d2.evaluation.evaluator]: [0mInference done 315/3489. 0.2373 s / img. ETA=0:14:15
[32m[03/29 01:30:49 d2.evaluation.evaluator]: [0mInference done 334/3489. 0.2375 s / img. ETA=0:14:12
[32m[03/29 01:30:54 d2.evaluation.evaluator]: [0mInference done 351/3489. 0.2382 s / img. ETA=0:14:13
[32m[03/29 01:30:59 d2.evaluation.evaluator]: [0mInference done 370/3489. 0.2383 s / img. ETA=0:14:08
[32m[03/29 01:31:04 d2.evaluation.evaluator]: [0mInference done 389/3489. 0.2383 s / img. ETA=0:14:03
[32m[03/29 01:31:09 d2.evaluation.evaluator]: [0mInference done 408/3489. 0.2383 s / img. ETA=0:13:58
[32m[03/29 01:31:14 d2.evaluation.evaluator]: [0mInference done 427/3489. 0.2382 s / img. ETA=0:13:52
[32m[03/29 01:31:19 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2379 s / img. ETA=0:13:42
[32m[03/29 01:31:25 d2.evaluation.evaluator]: [0mInference done 469/3489. 0.2376 s / img. ETA=0:13:33
[32m[03/29 01:31:30 d2.evaluation.evaluator]: [0mInference done 490/3489. 0.2371 s / img. ETA=0:13:24
[32m[03/29 01:31:35 d2.evaluation.evaluator]: [0mInference done 511/3489. 0.2368 s / img. ETA=0:13:15
[32m[03/29 01:31:40 d2.evaluation.evaluator]: [0mInference done 533/3489. 0.2364 s / img. ETA=0:13:05
[32m[03/29 01:31:45 d2.evaluation.evaluator]: [0mInference done 555/3489. 0.2360 s / img. ETA=0:12:56
[32m[03/29 01:31:50 d2.evaluation.evaluator]: [0mInference done 575/3489. 0.2358 s / img. ETA=0:12:49
[32m[03/29 01:31:55 d2.evaluation.evaluator]: [0mInference done 594/3489. 0.2359 s / img. ETA=0:12:45
[32m[03/29 01:32:01 d2.evaluation.evaluator]: [0mInference done 613/3489. 0.2360 s / img. ETA=0:12:41
[32m[03/29 01:32:06 d2.evaluation.evaluator]: [0mInference done 632/3489. 0.2361 s / img. ETA=0:12:37
[32m[03/29 01:32:11 d2.evaluation.evaluator]: [0mInference done 651/3489. 0.2362 s / img. ETA=0:12:32
[32m[03/29 01:32:16 d2.evaluation.evaluator]: [0mInference done 671/3489. 0.2361 s / img. ETA=0:12:26
[32m[03/29 01:32:21 d2.evaluation.evaluator]: [0mInference done 692/3489. 0.2359 s / img. ETA=0:12:19
[32m[03/29 01:32:26 d2.evaluation.evaluator]: [0mInference done 713/3489. 0.2357 s / img. ETA=0:12:11
[32m[03/29 01:32:32 d2.evaluation.evaluator]: [0mInference done 734/3489. 0.2356 s / img. ETA=0:12:05
[32m[03/29 01:32:37 d2.evaluation.evaluator]: [0mInference done 755/3489. 0.2354 s / img. ETA=0:11:57
[32m[03/29 01:32:42 d2.evaluation.evaluator]: [0mInference done 777/3489. 0.2351 s / img. ETA=0:11:49
[32m[03/29 01:32:47 d2.evaluation.evaluator]: [0mInference done 799/3489. 0.2349 s / img. ETA=0:11:41
[32m[03/29 01:32:52 d2.evaluation.evaluator]: [0mInference done 821/3489. 0.2346 s / img. ETA=0:11:33
[32m[03/29 01:32:57 d2.evaluation.evaluator]: [0mInference done 843/3489. 0.2343 s / img. ETA=0:11:26
[32m[03/29 01:33:02 d2.evaluation.evaluator]: [0mInference done 865/3489. 0.2342 s / img. ETA=0:11:19
[32m[03/29 01:33:07 d2.evaluation.evaluator]: [0mInference done 887/3489. 0.2340 s / img. ETA=0:11:11
[32m[03/29 01:33:13 d2.evaluation.evaluator]: [0mInference done 907/3489. 0.2340 s / img. ETA=0:11:06
[32m[03/29 01:33:18 d2.evaluation.evaluator]: [0mInference done 924/3489. 0.2343 s / img. ETA=0:11:04
[32m[03/29 01:33:23 d2.evaluation.evaluator]: [0mInference done 941/3489. 0.2346 s / img. ETA=0:11:02
[32m[03/29 01:33:28 d2.evaluation.evaluator]: [0mInference done 958/3489. 0.2350 s / img. ETA=0:10:59
[32m[03/29 01:33:33 d2.evaluation.evaluator]: [0mInference done 975/3489. 0.2352 s / img. ETA=0:10:57
[32m[03/29 01:33:39 d2.evaluation.evaluator]: [0mInference done 991/3489. 0.2356 s / img. ETA=0:10:56
[32m[03/29 01:33:44 d2.evaluation.evaluator]: [0mInference done 1007/3489. 0.2359 s / img. ETA=0:10:54
[32m[03/29 01:33:49 d2.evaluation.evaluator]: [0mInference done 1024/3489. 0.2362 s / img. ETA=0:10:51
[32m[03/29 01:33:54 d2.evaluation.evaluator]: [0mInference done 1040/3489. 0.2364 s / img. ETA=0:10:49
[32m[03/29 01:33:59 d2.evaluation.evaluator]: [0mInference done 1056/3489. 0.2367 s / img. ETA=0:10:47
[32m[03/29 01:34:04 d2.evaluation.evaluator]: [0mInference done 1073/3489. 0.2369 s / img. ETA=0:10:44
[32m[03/29 01:34:10 d2.evaluation.evaluator]: [0mInference done 1091/3489. 0.2370 s / img. ETA=0:10:40
[32m[03/29 01:34:15 d2.evaluation.evaluator]: [0mInference done 1110/3489. 0.2370 s / img. ETA=0:10:34
[32m[03/29 01:34:20 d2.evaluation.evaluator]: [0mInference done 1127/3489. 0.2371 s / img. ETA=0:10:31
[32m[03/29 01:34:25 d2.evaluation.evaluator]: [0mInference done 1143/3489. 0.2374 s / img. ETA=0:10:28
[32m[03/29 01:34:30 d2.evaluation.evaluator]: [0mInference done 1160/3489. 0.2376 s / img. ETA=0:10:25
[32m[03/29 01:34:35 d2.evaluation.evaluator]: [0mInference done 1177/3489. 0.2378 s / img. ETA=0:10:22
[32m[03/29 01:34:40 d2.evaluation.evaluator]: [0mInference done 1194/3489. 0.2379 s / img. ETA=0:10:18
[32m[03/29 01:34:45 d2.evaluation.evaluator]: [0mInference done 1211/3489. 0.2381 s / img. ETA=0:10:15
[32m[03/29 01:34:51 d2.evaluation.evaluator]: [0mInference done 1229/3489. 0.2382 s / img. ETA=0:10:11
[32m[03/29 01:34:56 d2.evaluation.evaluator]: [0mInference done 1247/3489. 0.2383 s / img. ETA=0:10:06
[32m[03/29 01:35:01 d2.evaluation.evaluator]: [0mInference done 1267/3489. 0.2383 s / img. ETA=0:10:00
[32m[03/29 01:35:06 d2.evaluation.evaluator]: [0mInference done 1289/3489. 0.2382 s / img. ETA=0:09:53
[32m[03/29 01:35:11 d2.evaluation.evaluator]: [0mInference done 1311/3489. 0.2379 s / img. ETA=0:09:46
[32m[03/29 01:35:16 d2.evaluation.evaluator]: [0mInference done 1333/3489. 0.2377 s / img. ETA=0:09:38
[32m[03/29 01:35:21 d2.evaluation.evaluator]: [0mInference done 1354/3489. 0.2376 s / img. ETA=0:09:32
[32m[03/29 01:35:26 d2.evaluation.evaluator]: [0mInference done 1375/3489. 0.2375 s / img. ETA=0:09:25
[32m[03/29 01:35:31 d2.evaluation.evaluator]: [0mInference done 1397/3489. 0.2373 s / img. ETA=0:09:18
[32m[03/29 01:35:37 d2.evaluation.evaluator]: [0mInference done 1417/3489. 0.2373 s / img. ETA=0:09:13
[32m[03/29 01:35:42 d2.evaluation.evaluator]: [0mInference done 1438/3489. 0.2373 s / img. ETA=0:09:07
[32m[03/29 01:35:47 d2.evaluation.evaluator]: [0mInference done 1459/3489. 0.2371 s / img. ETA=0:09:00
[32m[03/29 01:35:52 d2.evaluation.evaluator]: [0mInference done 1480/3489. 0.2370 s / img. ETA=0:08:54
[32m[03/29 01:35:57 d2.evaluation.evaluator]: [0mInference done 1501/3489. 0.2369 s / img. ETA=0:08:48
[32m[03/29 01:36:02 d2.evaluation.evaluator]: [0mInference done 1522/3489. 0.2368 s / img. ETA=0:08:41
[32m[03/29 01:36:07 d2.evaluation.evaluator]: [0mInference done 1543/3489. 0.2367 s / img. ETA=0:08:35
[32m[03/29 01:36:12 d2.evaluation.evaluator]: [0mInference done 1564/3489. 0.2366 s / img. ETA=0:08:29
[32m[03/29 01:36:17 d2.evaluation.evaluator]: [0mInference done 1585/3489. 0.2365 s / img. ETA=0:08:23
[32m[03/29 01:36:22 d2.evaluation.evaluator]: [0mInference done 1605/3489. 0.2364 s / img. ETA=0:08:17
[32m[03/29 01:36:27 d2.evaluation.evaluator]: [0mInference done 1624/3489. 0.2364 s / img. ETA=0:08:12
[32m[03/29 01:36:32 d2.evaluation.evaluator]: [0mInference done 1643/3489. 0.2364 s / img. ETA=0:08:07
[32m[03/29 01:36:38 d2.evaluation.evaluator]: [0mInference done 1663/3489. 0.2364 s / img. ETA=0:08:02
[32m[03/29 01:36:43 d2.evaluation.evaluator]: [0mInference done 1682/3489. 0.2365 s / img. ETA=0:07:57
[32m[03/29 01:36:48 d2.evaluation.evaluator]: [0mInference done 1699/3489. 0.2366 s / img. ETA=0:07:53
[32m[03/29 01:36:53 d2.evaluation.evaluator]: [0mInference done 1717/3489. 0.2367 s / img. ETA=0:07:49
[32m[03/29 01:36:58 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2368 s / img. ETA=0:07:45
[32m[03/29 01:37:04 d2.evaluation.evaluator]: [0mInference done 1752/3489. 0.2369 s / img. ETA=0:07:41
[32m[03/29 01:37:09 d2.evaluation.evaluator]: [0mInference done 1768/3489. 0.2370 s / img. ETA=0:07:37
[32m[03/29 01:37:14 d2.evaluation.evaluator]: [0mInference done 1784/3489. 0.2372 s / img. ETA=0:07:34
[32m[03/29 01:37:19 d2.evaluation.evaluator]: [0mInference done 1800/3489. 0.2374 s / img. ETA=0:07:31
[32m[03/29 01:37:24 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2375 s / img. ETA=0:07:27
[32m[03/29 01:37:29 d2.evaluation.evaluator]: [0mInference done 1832/3489. 0.2376 s / img. ETA=0:07:24
[32m[03/29 01:37:34 d2.evaluation.evaluator]: [0mInference done 1848/3489. 0.2378 s / img. ETA=0:07:20
[32m[03/29 01:37:40 d2.evaluation.evaluator]: [0mInference done 1864/3489. 0.2379 s / img. ETA=0:07:16
[32m[03/29 01:37:45 d2.evaluation.evaluator]: [0mInference done 1880/3489. 0.2380 s / img. ETA=0:07:13
[32m[03/29 01:37:50 d2.evaluation.evaluator]: [0mInference done 1896/3489. 0.2382 s / img. ETA=0:07:09
[32m[03/29 01:37:55 d2.evaluation.evaluator]: [0mInference done 1912/3489. 0.2383 s / img. ETA=0:07:06
[32m[03/29 01:38:00 d2.evaluation.evaluator]: [0mInference done 1928/3489. 0.2384 s / img. ETA=0:07:02
[32m[03/29 01:38:05 d2.evaluation.evaluator]: [0mInference done 1943/3489. 0.2386 s / img. ETA=0:06:59
[32m[03/29 01:38:10 d2.evaluation.evaluator]: [0mInference done 1959/3489. 0.2387 s / img. ETA=0:06:55
[32m[03/29 01:38:15 d2.evaluation.evaluator]: [0mInference done 1975/3489. 0.2388 s / img. ETA=0:06:51
[32m[03/29 01:38:20 d2.evaluation.evaluator]: [0mInference done 1992/3489. 0.2389 s / img. ETA=0:06:47
[32m[03/29 01:38:25 d2.evaluation.evaluator]: [0mInference done 2010/3489. 0.2390 s / img. ETA=0:06:42
[32m[03/29 01:38:31 d2.evaluation.evaluator]: [0mInference done 2029/3489. 0.2390 s / img. ETA=0:06:37
[32m[03/29 01:38:36 d2.evaluation.evaluator]: [0mInference done 2047/3489. 0.2390 s / img. ETA=0:06:32
[32m[03/29 01:38:41 d2.evaluation.evaluator]: [0mInference done 2064/3489. 0.2391 s / img. ETA=0:06:28
[32m[03/29 01:38:47 d2.evaluation.evaluator]: [0mInference done 2081/3489. 0.2392 s / img. ETA=0:06:24
[32m[03/29 01:38:52 d2.evaluation.evaluator]: [0mInference done 2097/3489. 0.2394 s / img. ETA=0:06:20
[32m[03/29 01:38:57 d2.evaluation.evaluator]: [0mInference done 2113/3489. 0.2395 s / img. ETA=0:06:16
[32m[03/29 01:39:02 d2.evaluation.evaluator]: [0mInference done 2129/3489. 0.2396 s / img. ETA=0:06:12
[32m[03/29 01:39:07 d2.evaluation.evaluator]: [0mInference done 2145/3489. 0.2397 s / img. ETA=0:06:08
[32m[03/29 01:39:12 d2.evaluation.evaluator]: [0mInference done 2161/3489. 0.2399 s / img. ETA=0:06:05
