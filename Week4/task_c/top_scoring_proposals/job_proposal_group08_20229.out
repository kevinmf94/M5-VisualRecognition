Test [250]
[32m[03/28 20:22:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:22:46 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:22:47 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 16900        | Pedestrian | 690          |
|            |              |            |              |
|   total    | 17590        |            |              |[0m
[32m[03/28 20:22:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:22:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:22:47 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:22:47 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:22:47 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:22:47 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 9960         | Pedestrian | 10725        |
|            |              |            |              |
|   total    | 20685        |            |              |[0m
[32m[03/28 20:22:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:22:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:22:47 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:22:47 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:22:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 20:23:10 d2.utils.events]: [0m eta: 0:02:15  iter: 19  total_loss: 1.851  loss_cls: 0.8019  loss_box_reg: 0.3163  loss_mask: 0.6611  loss_rpn_cls: 0.02426  loss_rpn_loc: 0.009986  total_val_loss: 1.807  val_loss_cls: 0.744  val_loss_box_reg: 0.411  val_loss_mask: 0.6767  val_loss_rpn_cls: 0.04256  val_loss_rpn_loc: 0.01358  time: 0.7517  data_time: 0.0259  lr: 0.00019981  max_mem: 4738M
[32m[03/28 20:23:31 d2.utils.events]: [0m eta: 0:02:01  iter: 39  total_loss: 0.8427  loss_cls: 0.1721  loss_box_reg: 0.3154  loss_mask: 0.3859  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.00742  total_val_loss: 1.261  val_loss_cls: 0.3069  val_loss_box_reg: 0.5125  val_loss_mask: 0.4855  val_loss_rpn_cls: 0.02897  val_loss_rpn_loc: 0.0146  time: 0.7562  data_time: 0.0066  lr: 0.00039961  max_mem: 4741M
[32m[03/28 20:23:52 d2.utils.events]: [0m eta: 0:01:46  iter: 59  total_loss: 0.7949  loss_cls: 0.1226  loss_box_reg: 0.334  loss_mask: 0.2017  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.01199  total_val_loss: 0.9914  val_loss_cls: 0.1701  val_loss_box_reg: 0.378  val_loss_mask: 0.3506  val_loss_rpn_cls: 0.02663  val_loss_rpn_loc: 0.01146  time: 0.7586  data_time: 0.0067  lr: 0.00059941  max_mem: 4741M
[32m[03/28 20:24:14 d2.utils.events]: [0m eta: 0:01:31  iter: 79  total_loss: 0.5045  loss_cls: 0.06139  loss_box_reg: 0.2937  loss_mask: 0.1523  loss_rpn_cls: 0.00637  loss_rpn_loc: 0.007107  total_val_loss: 1.069  val_loss_cls: 0.1985  val_loss_box_reg: 0.3842  val_loss_mask: 0.3365  val_loss_rpn_cls: 0.03058  val_loss_rpn_loc: 0.01547  time: 0.7610  data_time: 0.0066  lr: 0.00079921  max_mem: 4741M
[32m[03/28 20:24:35 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:24:35 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:24:35 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:24:35 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:24:35 d2.utils.events]: [0m eta: 0:01:15  iter: 99  total_loss: 0.3455  loss_cls: 0.03969  loss_box_reg: 0.1092  loss_mask: 0.167  loss_rpn_cls: 0.008455  loss_rpn_loc: 0.006797  total_val_loss: 0.8004  val_loss_cls: 0.1726  val_loss_box_reg: 0.208  val_loss_mask: 0.367  val_loss_rpn_cls: 0.0224  val_loss_rpn_loc: 0.01241  time: 0.7627  data_time: 0.0067  lr: 0.00099901  max_mem: 4741M
[32m[03/28 20:24:57 d2.utils.events]: [0m eta: 0:01:00  iter: 119  total_loss: 0.4015  loss_cls: 0.05005  loss_box_reg: 0.1183  loss_mask: 0.168  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.009831  total_val_loss: 1.076  val_loss_cls: 0.2874  val_loss_box_reg: 0.3428  val_loss_mask: 0.3896  val_loss_rpn_cls: 0.02474  val_loss_rpn_loc: 0.01339  time: 0.7636  data_time: 0.0068  lr: 0.0011988  max_mem: 4741M
[32m[03/28 20:25:19 d2.utils.events]: [0m eta: 0:00:45  iter: 139  total_loss: 0.3743  loss_cls: 0.05808  loss_box_reg: 0.1247  loss_mask: 0.1496  loss_rpn_cls: 0.009133  loss_rpn_loc: 0.01022  total_val_loss: 0.8562  val_loss_cls: 0.1853  val_loss_box_reg: 0.2568  val_loss_mask: 0.3431  val_loss_rpn_cls: 0.01648  val_loss_rpn_loc: 0.01201  time: 0.7646  data_time: 0.0069  lr: 0.0013986  max_mem: 4741M
[32m[03/28 20:25:40 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.3677  loss_cls: 0.05963  loss_box_reg: 0.11  loss_mask: 0.1834  loss_rpn_cls: 0.006499  loss_rpn_loc: 0.005098  total_val_loss: 0.6845  val_loss_cls: 0.1412  val_loss_box_reg: 0.2206  val_loss_mask: 0.2804  val_loss_rpn_cls: 0.01749  val_loss_rpn_loc: 0.01148  time: 0.7661  data_time: 0.0062  lr: 0.0015984  max_mem: 4741M
[32m[03/28 20:26:02 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.2706  loss_cls: 0.04328  loss_box_reg: 0.1029  loss_mask: 0.1395  loss_rpn_cls: 0.005506  loss_rpn_loc: 0.01028  total_val_loss: 0.861  val_loss_cls: 0.1884  val_loss_box_reg: 0.3174  val_loss_mask: 0.3359  val_loss_rpn_cls: 0.0184  val_loss_rpn_loc: 0.01732  time: 0.7667  data_time: 0.0067  lr: 0.0017982  max_mem: 4742M
[32m[03/28 20:26:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:26:24 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:26:24 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:26:24 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:26:25 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3617  loss_cls: 0.05024  loss_box_reg: 0.1098  loss_mask: 0.1607  loss_rpn_cls: 0.007872  loss_rpn_loc: 0.009452  total_val_loss: 0.6422  val_loss_cls: 0.1343  val_loss_box_reg: 0.2288  val_loss_mask: 0.2689  val_loss_rpn_cls: 0.01391  val_loss_rpn_loc: 0.01152  time: 0.7675  data_time: 0.0065  lr: 0.001998  max_mem: 4742M
[32m[03/28 20:26:25 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:31 (0.7675 s / it)
[32m[03/28 20:26:25 d2.engine.hooks]: [0mTotal training time: 0:03:34 (0:01:02 on hooks)
[32m[03/28 20:26:25 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:26:25 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:26:25 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:26:25 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 20:26:25 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 20:26:25 d2.evaluation.coco_evaluation]: [0m'kittimots_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[03/28 20:26:25 d2.data.datasets.coco]: [0mConverting annotations of dataset 'kittimots_val' to COCO format ...)
[32m[03/28 20:26:25 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[03/28 20:26:25 d2.data.datasets.coco]: [0mConversion finished, #images: 3489, #annotations: 20685
[32m[03/28 20:26:25 d2.data.datasets.coco]: [0mCaching COCO format annotations at './output_250.000000/kittimots_val_coco_format.json' ...
[32m[03/28 20:26:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:26:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:26:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 20:26:27 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 20:26:29 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2007 s / img. ETA=0:12:32
[32m[03/28 20:26:35 d2.evaluation.evaluator]: [0mInference done 35/3489. 0.2007 s / img. ETA=0:12:24
[32m[03/28 20:26:40 d2.evaluation.evaluator]: [0mInference done 59/3489. 0.2002 s / img. ETA=0:12:13
[32m[03/28 20:26:45 d2.evaluation.evaluator]: [0mInference done 83/3489. 0.2002 s / img. ETA=0:12:10
[32m[03/28 20:26:50 d2.evaluation.evaluator]: [0mInference done 105/3489. 0.2015 s / img. ETA=0:12:20
[32m[03/28 20:26:55 d2.evaluation.evaluator]: [0mInference done 125/3489. 0.2031 s / img. ETA=0:12:36
[32m[03/28 20:27:00 d2.evaluation.evaluator]: [0mInference done 141/3489. 0.2053 s / img. ETA=0:13:08
[32m[03/28 20:27:05 d2.evaluation.evaluator]: [0mInference done 157/3489. 0.2072 s / img. ETA=0:13:35
[32m[03/28 20:27:10 d2.evaluation.evaluator]: [0mInference done 173/3489. 0.2086 s / img. ETA=0:13:55
[32m[03/28 20:27:16 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2090 s / img. ETA=0:13:52
[32m[03/28 20:27:21 d2.evaluation.evaluator]: [0mInference done 216/3489. 0.2084 s / img. ETA=0:13:36
[32m[03/28 20:27:26 d2.evaluation.evaluator]: [0mInference done 239/3489. 0.2080 s / img. ETA=0:13:23
[32m[03/28 20:27:31 d2.evaluation.evaluator]: [0mInference done 260/3489. 0.2080 s / img. ETA=0:13:17
[32m[03/28 20:27:36 d2.evaluation.evaluator]: [0mInference done 281/3489. 0.2081 s / img. ETA=0:13:10
[32m[03/28 20:27:41 d2.evaluation.evaluator]: [0mInference done 303/3489. 0.2080 s / img. ETA=0:13:02
[32m[03/28 20:27:47 d2.evaluation.evaluator]: [0mInference done 324/3489. 0.2081 s / img. ETA=0:12:57
[32m[03/28 20:27:52 d2.evaluation.evaluator]: [0mInference done 344/3489. 0.2083 s / img. ETA=0:12:54
[32m[03/28 20:27:57 d2.evaluation.evaluator]: [0mInference done 364/3489. 0.2084 s / img. ETA=0:12:50
[32m[03/28 20:28:02 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2085 s / img. ETA=0:12:45
[32m[03/28 20:28:07 d2.evaluation.evaluator]: [0mInference done 407/3489. 0.2084 s / img. ETA=0:12:38
[32m[03/28 20:28:12 d2.evaluation.evaluator]: [0mInference done 429/3489. 0.2083 s / img. ETA=0:12:31
[32m[03/28 20:28:17 d2.evaluation.evaluator]: [0mInference done 453/3489. 0.2079 s / img. ETA=0:12:20
[32m[03/28 20:28:23 d2.evaluation.evaluator]: [0mInference done 477/3489. 0.2076 s / img. ETA=0:12:10
[32m[03/28 20:28:28 d2.evaluation.evaluator]: [0mInference done 501/3489. 0.2073 s / img. ETA=0:11:59
[32m[03/28 20:28:33 d2.evaluation.evaluator]: [0mInference done 525/3489. 0.2070 s / img. ETA=0:11:50
[32m[03/28 20:28:38 d2.evaluation.evaluator]: [0mInference done 550/3489. 0.2066 s / img. ETA=0:11:40
[32m[03/28 20:28:43 d2.evaluation.evaluator]: [0mInference done 572/3489. 0.2066 s / img. ETA=0:11:33
[32m[03/28 20:28:48 d2.evaluation.evaluator]: [0mInference done 593/3489. 0.2067 s / img. ETA=0:11:29
[32m[03/28 20:28:53 d2.evaluation.evaluator]: [0mInference done 615/3489. 0.2068 s / img. ETA=0:11:24
[32m[03/28 20:28:58 d2.evaluation.evaluator]: [0mInference done 636/3489. 0.2068 s / img. ETA=0:11:19
[32m[03/28 20:29:04 d2.evaluation.evaluator]: [0mInference done 658/3489. 0.2068 s / img. ETA=0:11:13
[32m[03/28 20:29:09 d2.evaluation.evaluator]: [0mInference done 681/3489. 0.2067 s / img. ETA=0:11:06
[32m[03/28 20:29:14 d2.evaluation.evaluator]: [0mInference done 705/3489. 0.2065 s / img. ETA=0:10:58
[32m[03/28 20:29:19 d2.evaluation.evaluator]: [0mInference done 728/3489. 0.2064 s / img. ETA=0:10:51
[32m[03/28 20:29:24 d2.evaluation.evaluator]: [0mInference done 752/3489. 0.2062 s / img. ETA=0:10:43
[32m[03/28 20:29:29 d2.evaluation.evaluator]: [0mInference done 776/3489. 0.2061 s / img. ETA=0:10:36
[32m[03/28 20:29:34 d2.evaluation.evaluator]: [0mInference done 801/3489. 0.2059 s / img. ETA=0:10:28
[32m[03/28 20:29:39 d2.evaluation.evaluator]: [0mInference done 825/3489. 0.2057 s / img. ETA=0:10:20
[32m[03/28 20:29:44 d2.evaluation.evaluator]: [0mInference done 849/3489. 0.2055 s / img. ETA=0:10:13
[32m[03/28 20:29:49 d2.evaluation.evaluator]: [0mInference done 873/3489. 0.2054 s / img. ETA=0:10:06
[32m[03/28 20:29:54 d2.evaluation.evaluator]: [0mInference done 898/3489. 0.2052 s / img. ETA=0:09:58
[32m[03/28 20:29:59 d2.evaluation.evaluator]: [0mInference done 917/3489. 0.2054 s / img. ETA=0:09:55
[32m[03/28 20:30:05 d2.evaluation.evaluator]: [0mInference done 936/3489. 0.2056 s / img. ETA=0:09:53
[32m[03/28 20:30:10 d2.evaluation.evaluator]: [0mInference done 955/3489. 0.2058 s / img. ETA=0:09:51
[32m[03/28 20:30:15 d2.evaluation.evaluator]: [0mInference done 972/3489. 0.2060 s / img. ETA=0:09:50
[32m[03/28 20:30:20 d2.evaluation.evaluator]: [0mInference done 988/3489. 0.2063 s / img. ETA=0:09:50
[32m[03/28 20:30:25 d2.evaluation.evaluator]: [0mInference done 1004/3489. 0.2065 s / img. ETA=0:09:49
[32m[03/28 20:30:30 d2.evaluation.evaluator]: [0mInference done 1021/3489. 0.2067 s / img. ETA=0:09:47
[32m[03/28 20:30:35 d2.evaluation.evaluator]: [0mInference done 1038/3489. 0.2070 s / img. ETA=0:09:46
[32m[03/28 20:30:41 d2.evaluation.evaluator]: [0mInference done 1056/3489. 0.2071 s / img. ETA=0:09:44
[32m[03/28 20:30:46 d2.evaluation.evaluator]: [0mInference done 1074/3489. 0.2073 s / img. ETA=0:09:41
[32m[03/28 20:30:51 d2.evaluation.evaluator]: [0mInference done 1095/3489. 0.2073 s / img. ETA=0:09:36
[32m[03/28 20:30:56 d2.evaluation.evaluator]: [0mInference done 1117/3489. 0.2073 s / img. ETA=0:09:31
[32m[03/28 20:31:01 d2.evaluation.evaluator]: [0mInference done 1136/3489. 0.2075 s / img. ETA=0:09:28
[32m[03/28 20:31:06 d2.evaluation.evaluator]: [0mInference done 1155/3489. 0.2076 s / img. ETA=0:09:24
[32m[03/28 20:31:12 d2.evaluation.evaluator]: [0mInference done 1173/3489. 0.2079 s / img. ETA=0:09:22
[32m[03/28 20:31:17 d2.evaluation.evaluator]: [0mInference done 1193/3489. 0.2080 s / img. ETA=0:09:17
[32m[03/28 20:31:22 d2.evaluation.evaluator]: [0mInference done 1213/3489. 0.2080 s / img. ETA=0:09:13
[32m[03/28 20:31:27 d2.evaluation.evaluator]: [0mInference done 1234/3489. 0.2081 s / img. ETA=0:09:08
[32m[03/28 20:31:32 d2.evaluation.evaluator]: [0mInference done 1256/3489. 0.2081 s / img. ETA=0:09:02
[32m[03/28 20:31:37 d2.evaluation.evaluator]: [0mInference done 1281/3489. 0.2079 s / img. ETA=0:08:54
[32m[03/28 20:31:42 d2.evaluation.evaluator]: [0mInference done 1306/3489. 0.2077 s / img. ETA=0:08:47
[32m[03/28 20:31:48 d2.evaluation.evaluator]: [0mInference done 1331/3489. 0.2075 s / img. ETA=0:08:39
[32m[03/28 20:31:53 d2.evaluation.evaluator]: [0mInference done 1355/3489. 0.2074 s / img. ETA=0:08:32
[32m[03/28 20:31:58 d2.evaluation.evaluator]: [0mInference done 1379/3489. 0.2073 s / img. ETA=0:08:26
[32m[03/28 20:32:03 d2.evaluation.evaluator]: [0mInference done 1403/3489. 0.2072 s / img. ETA=0:08:19
[32m[03/28 20:32:08 d2.evaluation.evaluator]: [0mInference done 1426/3489. 0.2071 s / img. ETA=0:08:13
[32m[03/28 20:32:13 d2.evaluation.evaluator]: [0mInference done 1450/3489. 0.2070 s / img. ETA=0:08:06
[32m[03/28 20:32:18 d2.evaluation.evaluator]: [0mInference done 1474/3489. 0.2069 s / img. ETA=0:07:59
[32m[03/28 20:32:23 d2.evaluation.evaluator]: [0mInference done 1498/3489. 0.2068 s / img. ETA=0:07:53
[32m[03/28 20:32:28 d2.evaluation.evaluator]: [0mInference done 1523/3489. 0.2067 s / img. ETA=0:07:46
[32m[03/28 20:32:33 d2.evaluation.evaluator]: [0mInference done 1547/3489. 0.2066 s / img. ETA=0:07:39
[32m[03/28 20:32:39 d2.evaluation.evaluator]: [0mInference done 1571/3489. 0.2065 s / img. ETA=0:07:33
[32m[03/28 20:32:44 d2.evaluation.evaluator]: [0mInference done 1595/3489. 0.2064 s / img. ETA=0:07:27
[32m[03/28 20:32:49 d2.evaluation.evaluator]: [0mInference done 1616/3489. 0.2065 s / img. ETA=0:07:22
[32m[03/28 20:32:54 d2.evaluation.evaluator]: [0mInference done 1637/3489. 0.2065 s / img. ETA=0:07:17
[32m[03/28 20:32:59 d2.evaluation.evaluator]: [0mInference done 1659/3489. 0.2065 s / img. ETA=0:07:12
[32m[03/28 20:33:04 d2.evaluation.evaluator]: [0mInference done 1679/3489. 0.2067 s / img. ETA=0:07:08
[32m[03/28 20:33:09 d2.evaluation.evaluator]: [0mInference done 1696/3489. 0.2068 s / img. ETA=0:07:05
[32m[03/28 20:33:15 d2.evaluation.evaluator]: [0mInference done 1715/3489. 0.2069 s / img. ETA=0:07:01
[32m[03/28 20:33:20 d2.evaluation.evaluator]: [0mInference done 1733/3489. 0.2070 s / img. ETA=0:06:58
[32m[03/28 20:33:25 d2.evaluation.evaluator]: [0mInference done 1751/3489. 0.2071 s / img. ETA=0:06:54
[32m[03/28 20:33:30 d2.evaluation.evaluator]: [0mInference done 1767/3489. 0.2072 s / img. ETA=0:06:52
[32m[03/28 20:33:35 d2.evaluation.evaluator]: [0mInference done 1783/3489. 0.2074 s / img. ETA=0:06:49
[32m[03/28 20:33:40 d2.evaluation.evaluator]: [0mInference done 1799/3489. 0.2075 s / img. ETA=0:06:47
[32m[03/28 20:33:45 d2.evaluation.evaluator]: [0mInference done 1815/3489. 0.2077 s / img. ETA=0:06:44
[32m[03/28 20:33:51 d2.evaluation.evaluator]: [0mInference done 1831/3489. 0.2078 s / img. ETA=0:06:41
[32m[03/28 20:33:56 d2.evaluation.evaluator]: [0mInference done 1847/3489. 0.2080 s / img. ETA=0:06:39
[32m[03/28 20:34:01 d2.evaluation.evaluator]: [0mInference done 1863/3489. 0.2081 s / img. ETA=0:06:36
[32m[03/28 20:34:06 d2.evaluation.evaluator]: [0mInference done 1880/3489. 0.2082 s / img. ETA=0:06:32
[32m[03/28 20:34:11 d2.evaluation.evaluator]: [0mInference done 1897/3489. 0.2083 s / img. ETA=0:06:29
[32m[03/28 20:34:17 d2.evaluation.evaluator]: [0mInference done 1914/3489. 0.2084 s / img. ETA=0:06:26
[32m[03/28 20:34:22 d2.evaluation.evaluator]: [0mInference done 1931/3489. 0.2085 s / img. ETA=0:06:23
[32m[03/28 20:34:27 d2.evaluation.evaluator]: [0mInference done 1948/3489. 0.2086 s / img. ETA=0:06:19
[32m[03/28 20:34:32 d2.evaluation.evaluator]: [0mInference done 1965/3489. 0.2087 s / img. ETA=0:06:16
[32m[03/28 20:34:37 d2.evaluation.evaluator]: [0mInference done 1981/3489. 0.2088 s / img. ETA=0:06:13
[32m[03/28 20:34:42 d2.evaluation.evaluator]: [0mInference done 2000/3489. 0.2088 s / img. ETA=0:06:08
[32m[03/28 20:34:47 d2.evaluation.evaluator]: [0mInference done 2021/3489. 0.2088 s / img. ETA=0:06:03
[32m[03/28 20:34:52 d2.evaluation.evaluator]: [0mInference done 2041/3489. 0.2088 s / img. ETA=0:05:58
[32m[03/28 20:34:57 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2090 s / img. ETA=0:05:54
[32m[03/28 20:35:03 d2.evaluation.evaluator]: [0mInference done 2077/3489. 0.2091 s / img. ETA=0:05:50
[32m[03/28 20:35:08 d2.evaluation.evaluator]: [0mInference done 2095/3489. 0.2091 s / img. ETA=0:05:46
[32m[03/28 20:35:13 d2.evaluation.evaluator]: [0mInference done 2113/3489. 0.2092 s / img. ETA=0:05:42
[32m[03/28 20:35:18 d2.evaluation.evaluator]: [0mInference done 2130/3489. 0.2092 s / img. ETA=0:05:38
[32m[03/28 20:35:23 d2.evaluation.evaluator]: [0mInference done 2147/3489. 0.2093 s / img. ETA=0:05:35
[32m[03/28 20:35:28 d2.evaluation.evaluator]: [0mInference done 2163/3489. 0.2094 s / img. ETA=0:05:31
[32m[03/28 20:35:34 d2.evaluation.evaluator]: [0mInference done 2180/3489. 0.2095 s / img. ETA=0:05:28
[32m[03/28 20:35:39 d2.evaluation.evaluator]: [0mInference done 2196/3489. 0.2096 s / img. ETA=0:05:24
[32m[03/28 20:35:44 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2096 s / img. ETA=0:05:21
[32m[03/28 20:35:49 d2.evaluation.evaluator]: [0mInference done 2231/3489. 0.2097 s / img. ETA=0:05:16
[32m[03/28 20:35:54 d2.evaluation.evaluator]: [0mInference done 2250/3489. 0.2097 s / img. ETA=0:05:12
[32m[03/28 20:35:59 d2.evaluation.evaluator]: [0mInference done 2270/3489. 0.2097 s / img. ETA=0:05:07
[32m[03/28 20:36:04 d2.evaluation.evaluator]: [0mInference done 2290/3489. 0.2097 s / img. ETA=0:05:02
[32m[03/28 20:36:09 d2.evaluation.evaluator]: [0mInference done 2309/3489. 0.2098 s / img. ETA=0:04:57
[32m[03/28 20:36:14 d2.evaluation.evaluator]: [0mInference done 2327/3489. 0.2098 s / img. ETA=0:04:53
[32m[03/28 20:36:19 d2.evaluation.evaluator]: [0mInference done 2346/3489. 0.2099 s / img. ETA=0:04:48
[32m[03/28 20:36:24 d2.evaluation.evaluator]: [0mInference done 2366/3489. 0.2099 s / img. ETA=0:04:43
[32m[03/28 20:36:29 d2.evaluation.evaluator]: [0mInference done 2387/3489. 0.2098 s / img. ETA=0:04:38
[32m[03/28 20:36:35 d2.evaluation.evaluator]: [0mInference done 2408/3489. 0.2098 s / img. ETA=0:04:32
[32m[03/28 20:36:40 d2.evaluation.evaluator]: [0mInference done 2429/3489. 0.2098 s / img. ETA=0:04:27
[32m[03/28 20:36:45 d2.evaluation.evaluator]: [0mInference done 2449/3489. 0.2099 s / img. ETA=0:04:22
[32m[03/28 20:36:50 d2.evaluation.evaluator]: [0mInference done 2468/3489. 0.2099 s / img. ETA=0:04:17
[32m[03/28 20:36:55 d2.evaluation.evaluator]: [0mInference done 2487/3489. 0.2099 s / img. ETA=0:04:13
[32m[03/28 20:37:00 d2.evaluation.evaluator]: [0mInference done 2511/3489. 0.2098 s / img. ETA=0:04:06
[32m[03/28 20:37:05 d2.evaluation.evaluator]: [0mInference done 2534/3489. 0.2098 s / img. ETA=0:04:00
[32m[03/28 20:37:10 d2.evaluation.evaluator]: [0mInference done 2557/3489. 0.2097 s / img. ETA=0:03:54
[32m[03/28 20:37:15 d2.evaluation.evaluator]: [0mInference done 2580/3489. 0.2097 s / img. ETA=0:03:48
[32m[03/28 20:37:21 d2.evaluation.evaluator]: [0mInference done 2604/3489. 0.2096 s / img. ETA=0:03:42
[32m[03/28 20:37:26 d2.evaluation.evaluator]: [0mInference done 2628/3489. 0.2095 s / img. ETA=0:03:35
[32m[03/28 20:37:31 d2.evaluation.evaluator]: [0mInference done 2653/3489. 0.2094 s / img. ETA=0:03:29
[32m[03/28 20:37:36 d2.evaluation.evaluator]: [0mInference done 2675/3489. 0.2094 s / img. ETA=0:03:23
[32m[03/28 20:37:41 d2.evaluation.evaluator]: [0mInference done 2697/3489. 0.2093 s / img. ETA=0:03:17
[32m[03/28 20:37:46 d2.evaluation.evaluator]: [0mInference done 2720/3489. 0.2093 s / img. ETA=0:03:12
[32m[03/28 20:37:51 d2.evaluation.evaluator]: [0mInference done 2743/3489. 0.2092 s / img. ETA=0:03:06
[32m[03/28 20:37:56 d2.evaluation.evaluator]: [0mInference done 2766/3489. 0.2092 s / img. ETA=0:03:00
[32m[03/28 20:38:02 d2.evaluation.evaluator]: [0mInference done 2789/3489. 0.2092 s / img. ETA=0:02:54
[32m[03/28 20:38:07 d2.evaluation.evaluator]: [0mInference done 2812/3489. 0.2091 s / img. ETA=0:02:48
[32m[03/28 20:38:12 d2.evaluation.evaluator]: [0mInference done 2835/3489. 0.2091 s / img. ETA=0:02:42
[32m[03/28 20:38:17 d2.evaluation.evaluator]: [0mInference done 2858/3489. 0.2090 s / img. ETA=0:02:36
[32m[03/28 20:38:22 d2.evaluation.evaluator]: [0mInference done 2880/3489. 0.2091 s / img. ETA=0:02:31
[32m[03/28 20:38:27 d2.evaluation.evaluator]: [0mInference done 2904/3489. 0.2090 s / img. ETA=0:02:25
[32m[03/28 20:38:33 d2.evaluation.evaluator]: [0mInference done 2928/3489. 0.2089 s / img. ETA=0:02:19
[32m[03/28 20:38:38 d2.evaluation.evaluator]: [0mInference done 2952/3489. 0.2089 s / img. ETA=0:02:12
[32m[03/28 20:38:43 d2.evaluation.evaluator]: [0mInference done 2976/3489. 0.2088 s / img. ETA=0:02:06
[32m[03/28 20:38:48 d2.evaluation.evaluator]: [0mInference done 2999/3489. 0.2088 s / img. ETA=0:02:01
[32m[03/28 20:38:53 d2.evaluation.evaluator]: [0mInference done 3021/3489. 0.2088 s / img. ETA=0:01:55
[32m[03/28 20:38:58 d2.evaluation.evaluator]: [0mInference done 3044/3489. 0.2087 s / img. ETA=0:01:49
[32m[03/28 20:39:03 d2.evaluation.evaluator]: [0mInference done 3067/3489. 0.2087 s / img. ETA=0:01:44
[32m[03/28 20:39:09 d2.evaluation.evaluator]: [0mInference done 3089/3489. 0.2087 s / img. ETA=0:01:38
[32m[03/28 20:39:14 d2.evaluation.evaluator]: [0mInference done 3112/3489. 0.2086 s / img. ETA=0:01:32
[32m[03/28 20:39:19 d2.evaluation.evaluator]: [0mInference done 3134/3489. 0.2086 s / img. ETA=0:01:27
[32m[03/28 20:39:24 d2.evaluation.evaluator]: [0mInference done 3156/3489. 0.2086 s / img. ETA=0:01:21
[32m[03/28 20:39:29 d2.evaluation.evaluator]: [0mInference done 3179/3489. 0.2085 s / img. ETA=0:01:16
[32m[03/28 20:39:34 d2.evaluation.evaluator]: [0mInference done 3202/3489. 0.2085 s / img. ETA=0:01:10
[32m[03/28 20:39:39 d2.evaluation.evaluator]: [0mInference done 3225/3489. 0.2085 s / img. ETA=0:01:04
[32m[03/28 20:39:44 d2.evaluation.evaluator]: [0mInference done 3248/3489. 0.2084 s / img. ETA=0:00:59
[32m[03/28 20:39:50 d2.evaluation.evaluator]: [0mInference done 3272/3489. 0.2084 s / img. ETA=0:00:53
[32m[03/28 20:39:55 d2.evaluation.evaluator]: [0mInference done 3296/3489. 0.2083 s / img. ETA=0:00:47
[32m[03/28 20:40:00 d2.evaluation.evaluator]: [0mInference done 3321/3489. 0.2082 s / img. ETA=0:00:41
[32m[03/28 20:40:05 d2.evaluation.evaluator]: [0mInference done 3346/3489. 0.2082 s / img. ETA=0:00:34
[32m[03/28 20:40:10 d2.evaluation.evaluator]: [0mInference done 3371/3489. 0.2081 s / img. ETA=0:00:28
[32m[03/28 20:40:15 d2.evaluation.evaluator]: [0mInference done 3395/3489. 0.2080 s / img. ETA=0:00:22
[32m[03/28 20:40:20 d2.evaluation.evaluator]: [0mInference done 3419/3489. 0.2080 s / img. ETA=0:00:17
[32m[03/28 20:40:25 d2.evaluation.evaluator]: [0mInference done 3443/3489. 0.2079 s / img. ETA=0:00:11
[32m[03/28 20:40:30 d2.evaluation.evaluator]: [0mInference done 3467/3489. 0.2079 s / img. ETA=0:00:05
[32m[03/28 20:40:35 d2.evaluation.evaluator]: [0mTotal inference time: 0:14:06.913025 (0.243086 s / img per device, on 1 devices)
[32m[03/28 20:40:35 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:04 (0.207828 s / img per device, on 1 devices)
[32m[03/28 20:40:37 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 20:40:37 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_250.000000/coco_instances_results.json
[32m[03/28 20:40:38 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.31 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.50 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781
[32m[03/28 20:40:40 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.634 | 80.009 | 56.198 | 32.137 | 60.579 | 65.126 |
[32m[03/28 20:40:40 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.031 | Pedestrian | 41.236 |
Loading and preparing results...
DONE (t=1.75s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.07 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[32m[03/28 20:40:48 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.252 | 75.391 | 45.657 | 25.890 | 55.440 | 67.564 |
[32m[03/28 20:40:48 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.352 | Pedestrian | 27.151 |
[32m[03/28 20:40:49 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: 50.6335,80.0086,56.1982,32.1371,60.5793,65.1264
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:40:49 d2.evaluation.testing]: [0mcopypaste: 45.2518,75.3914,45.6570,25.8895,55.4404,67.5640
evaluated
Test [500]
[32m[03/28 20:40:49 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:40:50 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:40:50 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:40:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:40:50 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:40:50 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:40:50 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:40:50 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:40:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:40:50 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:40:50 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:40:51 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 20:41:13 d2.utils.events]: [0m eta: 0:02:17  iter: 19  total_loss: 1.735  loss_cls: 0.685  loss_box_reg: 0.394  loss_mask: 0.6522  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.01079  total_val_loss: 1.828  val_loss_cls: 0.7256  val_loss_box_reg: 0.3982  val_loss_mask: 0.663  val_loss_rpn_cls: 0.02817  val_loss_rpn_loc: 0.01039  time: 0.7676  data_time: 0.0268  lr: 0.00019981  max_mem: 4742M
[32m[03/28 20:41:35 d2.utils.events]: [0m eta: 0:02:02  iter: 39  total_loss: 1.09  loss_cls: 0.2444  loss_box_reg: 0.4281  loss_mask: 0.3174  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.01168  total_val_loss: 1.175  val_loss_cls: 0.2615  val_loss_box_reg: 0.4728  val_loss_mask: 0.4878  val_loss_rpn_cls: 0.03059  val_loss_rpn_loc: 0.01232  time: 0.7692  data_time: 0.0061  lr: 0.00039961  max_mem: 4743M
[32m[03/28 20:41:56 d2.utils.events]: [0m eta: 0:01:47  iter: 59  total_loss: 0.5409  loss_cls: 0.06915  loss_box_reg: 0.2173  loss_mask: 0.2254  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.005941  total_val_loss: 0.9187  val_loss_cls: 0.1538  val_loss_box_reg: 0.3956  val_loss_mask: 0.3281  val_loss_rpn_cls: 0.01893  val_loss_rpn_loc: 0.01283  time: 0.7684  data_time: 0.0064  lr: 0.00059941  max_mem: 4743M
[32m[03/28 20:42:18 d2.utils.events]: [0m eta: 0:01:31  iter: 79  total_loss: 0.5792  loss_cls: 0.07389  loss_box_reg: 0.3273  loss_mask: 0.1596  loss_rpn_cls: 0.006365  loss_rpn_loc: 0.008066  total_val_loss: 0.9738  val_loss_cls: 0.2005  val_loss_box_reg: 0.3286  val_loss_mask: 0.3579  val_loss_rpn_cls: 0.02515  val_loss_rpn_loc: 0.01375  time: 0.7695  data_time: 0.0062  lr: 0.00079921  max_mem: 4743M
[32m[03/28 20:42:40 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:42:40 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:42:40 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:42:40 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:42:40 d2.utils.events]: [0m eta: 0:01:16  iter: 99  total_loss: 0.3077  loss_cls: 0.04076  loss_box_reg: 0.1173  loss_mask: 0.1552  loss_rpn_cls: 0.009447  loss_rpn_loc: 0.007708  total_val_loss: 0.7554  val_loss_cls: 0.1415  val_loss_box_reg: 0.2408  val_loss_mask: 0.3318  val_loss_rpn_cls: 0.01943  val_loss_rpn_loc: 0.01292  time: 0.7700  data_time: 0.0079  lr: 0.00099901  max_mem: 4743M
[32m[03/28 20:43:02 d2.utils.events]: [0m eta: 0:01:01  iter: 119  total_loss: 0.3187  loss_cls: 0.03666  loss_box_reg: 0.1127  loss_mask: 0.159  loss_rpn_cls: 0.005424  loss_rpn_loc: 0.008417  total_val_loss: 0.8318  val_loss_cls: 0.1702  val_loss_box_reg: 0.2307  val_loss_mask: 0.314  val_loss_rpn_cls: 0.01638  val_loss_rpn_loc: 0.01351  time: 0.7702  data_time: 0.0062  lr: 0.0011988  max_mem: 4743M
[32m[03/28 20:43:23 d2.utils.events]: [0m eta: 0:00:46  iter: 139  total_loss: 0.3127  loss_cls: 0.04651  loss_box_reg: 0.104  loss_mask: 0.1472  loss_rpn_cls: 0.006169  loss_rpn_loc: 0.009426  total_val_loss: 0.8822  val_loss_cls: 0.2161  val_loss_box_reg: 0.2707  val_loss_mask: 0.3535  val_loss_rpn_cls: 0.01715  val_loss_rpn_loc: 0.01447  time: 0.7714  data_time: 0.0067  lr: 0.0013986  max_mem: 4743M
[32m[03/28 20:43:45 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.3391  loss_cls: 0.04756  loss_box_reg: 0.1007  loss_mask: 0.1723  loss_rpn_cls: 0.007336  loss_rpn_loc: 0.005438  total_val_loss: 0.7318  val_loss_cls: 0.1615  val_loss_box_reg: 0.2357  val_loss_mask: 0.3049  val_loss_rpn_cls: 0.02096  val_loss_rpn_loc: 0.01211  time: 0.7716  data_time: 0.0063  lr: 0.0015984  max_mem: 4743M
[32m[03/28 20:44:07 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.3883  loss_cls: 0.06615  loss_box_reg: 0.1591  loss_mask: 0.1883  loss_rpn_cls: 0.007262  loss_rpn_loc: 0.01376  total_val_loss: 0.7327  val_loss_cls: 0.187  val_loss_box_reg: 0.2104  val_loss_mask: 0.3028  val_loss_rpn_cls: 0.02549  val_loss_rpn_loc: 0.01149  time: 0.7726  data_time: 0.0074  lr: 0.0017982  max_mem: 4743M
[32m[03/28 20:44:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:44:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:44:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:44:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 20:44:30 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3999  loss_cls: 0.04586  loss_box_reg: 0.1138  loss_mask: 0.1645  loss_rpn_cls: 0.007667  loss_rpn_loc: 0.01073  total_val_loss: 0.7577  val_loss_cls: 0.1369  val_loss_box_reg: 0.1831  val_loss_mask: 0.4053  val_loss_rpn_cls: 0.01583  val_loss_rpn_loc: 0.01051  time: 0.7730  data_time: 0.0073  lr: 0.001998  max_mem: 4743M
[32m[03/28 20:44:30 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:33 (0.7731 s / it)
[32m[03/28 20:44:30 d2.engine.hooks]: [0mTotal training time: 0:03:36 (0:01:03 on hooks)
[32m[03/28 20:44:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:44:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:44:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 20:44:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 20:44:30 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 20:44:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 20:44:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 20:44:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 20:44:31 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 20:44:34 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2038 s / img. ETA=0:13:16
[32m[03/28 20:44:39 d2.evaluation.evaluator]: [0mInference done 34/3489. 0.2034 s / img. ETA=0:13:04
[32m[03/28 20:44:44 d2.evaluation.evaluator]: [0mInference done 57/3489. 0.2027 s / img. ETA=0:12:48
[32m[03/28 20:44:49 d2.evaluation.evaluator]: [0mInference done 80/3489. 0.2025 s / img. ETA=0:12:40
[32m[03/28 20:44:54 d2.evaluation.evaluator]: [0mInference done 99/3489. 0.2047 s / img. ETA=0:13:07
[32m[03/28 20:45:00 d2.evaluation.evaluator]: [0mInference done 117/3489. 0.2073 s / img. ETA=0:13:33
[32m[03/28 20:45:05 d2.evaluation.evaluator]: [0mInference done 134/3489. 0.2094 s / img. ETA=0:13:52
[32m[03/28 20:45:10 d2.evaluation.evaluator]: [0mInference done 152/3489. 0.2110 s / img. ETA=0:14:07
[32m[03/28 20:45:15 d2.evaluation.evaluator]: [0mInference done 169/3489. 0.2123 s / img. ETA=0:14:16
[32m[03/28 20:45:20 d2.evaluation.evaluator]: [0mInference done 187/3489. 0.2134 s / img. ETA=0:14:23
[32m[03/28 20:45:25 d2.evaluation.evaluator]: [0mInference done 207/3489. 0.2135 s / img. ETA=0:14:17
[32m[03/28 20:45:30 d2.evaluation.evaluator]: [0mInference done 227/3489. 0.2134 s / img. ETA=0:14:11
[32m[03/28 20:45:36 d2.evaluation.evaluator]: [0mInference done 246/3489. 0.2136 s / img. ETA=0:14:08
[32m[03/28 20:45:41 d2.evaluation.evaluator]: [0mInference done 264/3489. 0.2146 s / img. ETA=0:14:09
[32m[03/28 20:45:46 d2.evaluation.evaluator]: [0mInference done 282/3489. 0.2151 s / img. ETA=0:14:09
[32m[03/28 20:45:51 d2.evaluation.evaluator]: [0mInference done 300/3489. 0.2153 s / img. ETA=0:14:07
[32m[03/28 20:45:56 d2.evaluation.evaluator]: [0mInference done 318/3489. 0.2157 s / img. ETA=0:14:07
[32m[03/28 20:46:01 d2.evaluation.evaluator]: [0mInference done 337/3489. 0.2158 s / img. ETA=0:14:03
[32m[03/28 20:46:07 d2.evaluation.evaluator]: [0mInference done 355/3489. 0.2161 s / img. ETA=0:14:02
[32m[03/28 20:46:12 d2.evaluation.evaluator]: [0mInference done 373/3489. 0.2164 s / img. ETA=0:14:00
[32m[03/28 20:46:17 d2.evaluation.evaluator]: [0mInference done 391/3489. 0.2166 s / img. ETA=0:13:57
[32m[03/28 20:46:22 d2.evaluation.evaluator]: [0mInference done 410/3489. 0.2165 s / img. ETA=0:13:52
[32m[03/28 20:46:27 d2.evaluation.evaluator]: [0mInference done 431/3489. 0.2162 s / img. ETA=0:13:42
[32m[03/28 20:46:32 d2.evaluation.evaluator]: [0mInference done 454/3489. 0.2155 s / img. ETA=0:13:28
[32m[03/28 20:46:37 d2.evaluation.evaluator]: [0mInference done 477/3489. 0.2149 s / img. ETA=0:13:15
[32m[03/28 20:46:42 d2.evaluation.evaluator]: [0mInference done 500/3489. 0.2142 s / img. ETA=0:13:02
[32m[03/28 20:46:47 d2.evaluation.evaluator]: [0mInference done 524/3489. 0.2136 s / img. ETA=0:12:50
[32m[03/28 20:46:52 d2.evaluation.evaluator]: [0mInference done 548/3489. 0.2131 s / img. ETA=0:12:38
[32m[03/28 20:46:58 d2.evaluation.evaluator]: [0mInference done 568/3489. 0.2130 s / img. ETA=0:12:32
[32m[03/28 20:47:03 d2.evaluation.evaluator]: [0mInference done 587/3489. 0.2132 s / img. ETA=0:12:29
[32m[03/28 20:47:08 d2.evaluation.evaluator]: [0mInference done 607/3489. 0.2132 s / img. ETA=0:12:23
[32m[03/28 20:47:13 d2.evaluation.evaluator]: [0mInference done 627/3489. 0.2132 s / img. ETA=0:12:18
[32m[03/28 20:47:18 d2.evaluation.evaluator]: [0mInference done 647/3489. 0.2134 s / img. ETA=0:12:13
[32m[03/28 20:47:23 d2.evaluation.evaluator]: [0mInference done 668/3489. 0.2133 s / img. ETA=0:12:06
[32m[03/28 20:47:28 d2.evaluation.evaluator]: [0mInference done 690/3489. 0.2132 s / img. ETA=0:11:58
[32m[03/28 20:47:34 d2.evaluation.evaluator]: [0mInference done 713/3489. 0.2129 s / img. ETA=0:11:49
[32m[03/28 20:47:39 d2.evaluation.evaluator]: [0mInference done 735/3489. 0.2127 s / img. ETA=0:11:42
[32m[03/28 20:47:44 d2.evaluation.evaluator]: [0mInference done 757/3489. 0.2125 s / img. ETA=0:11:34
[32m[03/28 20:47:49 d2.evaluation.evaluator]: [0mInference done 779/3489. 0.2124 s / img. ETA=0:11:26
[32m[03/28 20:47:54 d2.evaluation.evaluator]: [0mInference done 802/3489. 0.2122 s / img. ETA=0:11:18
[32m[03/28 20:47:59 d2.evaluation.evaluator]: [0mInference done 825/3489. 0.2119 s / img. ETA=0:11:10
[32m[03/28 20:48:04 d2.evaluation.evaluator]: [0mInference done 848/3489. 0.2117 s / img. ETA=0:11:02
[32m[03/28 20:48:09 d2.evaluation.evaluator]: [0mInference done 871/3489. 0.2115 s / img. ETA=0:10:54
[32m[03/28 20:48:14 d2.evaluation.evaluator]: [0mInference done 895/3489. 0.2112 s / img. ETA=0:10:46
[32m[03/28 20:48:19 d2.evaluation.evaluator]: [0mInference done 914/3489. 0.2113 s / img. ETA=0:10:42
[32m[03/28 20:48:25 d2.evaluation.evaluator]: [0mInference done 931/3489. 0.2116 s / img. ETA=0:10:40
[32m[03/28 20:48:30 d2.evaluation.evaluator]: [0mInference done 949/3489. 0.2118 s / img. ETA=0:10:38
[32m[03/28 20:48:35 d2.evaluation.evaluator]: [0mInference done 967/3489. 0.2120 s / img. ETA=0:10:35
[32m[03/28 20:48:40 d2.evaluation.evaluator]: [0mInference done 985/3489. 0.2122 s / img. ETA=0:10:32
[32m[03/28 20:48:45 d2.evaluation.evaluator]: [0mInference done 1003/3489. 0.2124 s / img. ETA=0:10:29
[32m[03/28 20:48:51 d2.evaluation.evaluator]: [0mInference done 1021/3489. 0.2126 s / img. ETA=0:10:26
[32m[03/28 20:48:56 d2.evaluation.evaluator]: [0mInference done 1039/3489. 0.2128 s / img. ETA=0:10:23
[32m[03/28 20:49:01 d2.evaluation.evaluator]: [0mInference done 1057/3489. 0.2130 s / img. ETA=0:10:20
[32m[03/28 20:49:06 d2.evaluation.evaluator]: [0mInference done 1074/3489. 0.2132 s / img. ETA=0:10:18
[32m[03/28 20:49:11 d2.evaluation.evaluator]: [0mInference done 1093/3489. 0.2133 s / img. ETA=0:10:14
[32m[03/28 20:49:16 d2.evaluation.evaluator]: [0mInference done 1112/3489. 0.2133 s / img. ETA=0:10:09
[32m[03/28 20:49:21 d2.evaluation.evaluator]: [0mInference done 1130/3489. 0.2135 s / img. ETA=0:10:05
[32m[03/28 20:49:27 d2.evaluation.evaluator]: [0mInference done 1148/3489. 0.2136 s / img. ETA=0:10:02
[32m[03/28 20:49:32 d2.evaluation.evaluator]: [0mInference done 1165/3489. 0.2138 s / img. ETA=0:09:59
[32m[03/28 20:49:37 d2.evaluation.evaluator]: [0mInference done 1183/3489. 0.2139 s / img. ETA=0:09:55
[32m[03/28 20:49:42 d2.evaluation.evaluator]: [0mInference done 1200/3489. 0.2142 s / img. ETA=0:09:52
[32m[03/28 20:49:47 d2.evaluation.evaluator]: [0mInference done 1218/3489. 0.2143 s / img. ETA=0:09:49
[32m[03/28 20:49:52 d2.evaluation.evaluator]: [0mInference done 1236/3489. 0.2144 s / img. ETA=0:09:45
[32m[03/28 20:49:57 d2.evaluation.evaluator]: [0mInference done 1255/3489. 0.2145 s / img. ETA=0:09:40
[32m[03/28 20:50:02 d2.evaluation.evaluator]: [0mInference done 1280/3489. 0.2141 s / img. ETA=0:09:31
[32m[03/28 20:50:08 d2.evaluation.evaluator]: [0mInference done 1305/3489. 0.2138 s / img. ETA=0:09:23
[32m[03/28 20:50:13 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2135 s / img. ETA=0:09:14
[32m[03/28 20:50:18 d2.evaluation.evaluator]: [0mInference done 1354/3489. 0.2133 s / img. ETA=0:09:06
[32m[03/28 20:50:23 d2.evaluation.evaluator]: [0mInference done 1378/3489. 0.2131 s / img. ETA=0:08:59
[32m[03/28 20:50:28 d2.evaluation.evaluator]: [0mInference done 1402/3489. 0.2129 s / img. ETA=0:08:51
[32m[03/28 20:50:33 d2.evaluation.evaluator]: [0mInference done 1425/3489. 0.2127 s / img. ETA=0:08:44
[32m[03/28 20:50:38 d2.evaluation.evaluator]: [0mInference done 1448/3489. 0.2126 s / img. ETA=0:08:37
[32m[03/28 20:50:44 d2.evaluation.evaluator]: [0mInference done 1471/3489. 0.2124 s / img. ETA=0:08:30
[32m[03/28 20:50:49 d2.evaluation.evaluator]: [0mInference done 1495/3489. 0.2122 s / img. ETA=0:08:23
[32m[03/28 20:50:54 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2120 s / img. ETA=0:08:15
[32m[03/28 20:50:59 d2.evaluation.evaluator]: [0mInference done 1542/3489. 0.2119 s / img. ETA=0:08:09
[32m[03/28 20:51:04 d2.evaluation.evaluator]: [0mInference done 1565/3489. 0.2118 s / img. ETA=0:08:02
[32m[03/28 20:51:09 d2.evaluation.evaluator]: [0mInference done 1588/3489. 0.2116 s / img. ETA=0:07:55
[32m[03/28 20:51:14 d2.evaluation.evaluator]: [0mInference done 1608/3489. 0.2117 s / img. ETA=0:07:51
[32m[03/28 20:51:19 d2.evaluation.evaluator]: [0mInference done 1627/3489. 0.2118 s / img. ETA=0:07:47
[32m[03/28 20:51:25 d2.evaluation.evaluator]: [0mInference done 1646/3489. 0.2118 s / img. ETA=0:07:42
[32m[03/28 20:51:30 d2.evaluation.evaluator]: [0mInference done 1665/3489. 0.2119 s / img. ETA=0:07:38
[32m[03/28 20:51:35 d2.evaluation.evaluator]: [0mInference done 1683/3489. 0.2120 s / img. ETA=0:07:34
[32m[03/28 20:51:40 d2.evaluation.evaluator]: [0mInference done 1700/3489. 0.2121 s / img. ETA=0:07:31
[32m[03/28 20:51:45 d2.evaluation.evaluator]: [0mInference done 1717/3489. 0.2123 s / img. ETA=0:07:27
[32m[03/28 20:51:50 d2.evaluation.evaluator]: [0mInference done 1734/3489. 0.2124 s / img. ETA=0:07:24
[32m[03/28 20:51:56 d2.evaluation.evaluator]: [0mInference done 1752/3489. 0.2125 s / img. ETA=0:07:20
[32m[03/28 20:52:01 d2.evaluation.evaluator]: [0mInference done 1770/3489. 0.2126 s / img. ETA=0:07:16
[32m[03/28 20:52:06 d2.evaluation.evaluator]: [0mInference done 1787/3489. 0.2127 s / img. ETA=0:07:12
[32m[03/28 20:52:11 d2.evaluation.evaluator]: [0mInference done 1805/3489. 0.2129 s / img. ETA=0:07:09
[32m[03/28 20:52:16 d2.evaluation.evaluator]: [0mInference done 1823/3489. 0.2130 s / img. ETA=0:07:05
[32m[03/28 20:52:21 d2.evaluation.evaluator]: [0mInference done 1840/3489. 0.2131 s / img. ETA=0:07:01
[32m[03/28 20:52:26 d2.evaluation.evaluator]: [0mInference done 1857/3489. 0.2132 s / img. ETA=0:06:57
[32m[03/28 20:52:31 d2.evaluation.evaluator]: [0mInference done 1874/3489. 0.2133 s / img. ETA=0:06:53
[32m[03/28 20:52:36 d2.evaluation.evaluator]: [0mInference done 1891/3489. 0.2134 s / img. ETA=0:06:50
[32m[03/28 20:52:41 d2.evaluation.evaluator]: [0mInference done 1908/3489. 0.2135 s / img. ETA=0:06:46
[32m[03/28 20:52:47 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2136 s / img. ETA=0:06:42
[32m[03/28 20:52:52 d2.evaluation.evaluator]: [0mInference done 1944/3489. 0.2137 s / img. ETA=0:06:38
[32m[03/28 20:52:57 d2.evaluation.evaluator]: [0mInference done 1961/3489. 0.2138 s / img. ETA=0:06:34
[32m[03/28 20:53:02 d2.evaluation.evaluator]: [0mInference done 1979/3489. 0.2138 s / img. ETA=0:06:29
[32m[03/28 20:53:08 d2.evaluation.evaluator]: [0mInference done 1997/3489. 0.2139 s / img. ETA=0:06:25
[32m[03/28 20:53:13 d2.evaluation.evaluator]: [0mInference done 2015/3489. 0.2140 s / img. ETA=0:06:21
[32m[03/28 20:53:18 d2.evaluation.evaluator]: [0mInference done 2033/3489. 0.2141 s / img. ETA=0:06:17
[32m[03/28 20:53:23 d2.evaluation.evaluator]: [0mInference done 2050/3489. 0.2142 s / img. ETA=0:06:13
[32m[03/28 20:53:28 d2.evaluation.evaluator]: [0mInference done 2067/3489. 0.2143 s / img. ETA=0:06:09
[32m[03/28 20:53:33 d2.evaluation.evaluator]: [0mInference done 2084/3489. 0.2144 s / img. ETA=0:06:05
[32m[03/28 20:53:38 d2.evaluation.evaluator]: [0mInference done 2101/3489. 0.2144 s / img. ETA=0:06:01
[32m[03/28 20:53:44 d2.evaluation.evaluator]: [0mInference done 2119/3489. 0.2145 s / img. ETA=0:05:57
[32m[03/28 20:53:49 d2.evaluation.evaluator]: [0mInference done 2136/3489. 0.2146 s / img. ETA=0:05:53
[32m[03/28 20:53:54 d2.evaluation.evaluator]: [0mInference done 2154/3489. 0.2147 s / img. ETA=0:05:48
[32m[03/28 20:53:59 d2.evaluation.evaluator]: [0mInference done 2171/3489. 0.2147 s / img. ETA=0:05:44
[32m[03/28 20:54:04 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2148 s / img. ETA=0:05:40
[32m[03/28 20:54:10 d2.evaluation.evaluator]: [0mInference done 2207/3489. 0.2149 s / img. ETA=0:05:35
[32m[03/28 20:54:15 d2.evaluation.evaluator]: [0mInference done 2225/3489. 0.2150 s / img. ETA=0:05:31
[32m[03/28 20:54:20 d2.evaluation.evaluator]: [0mInference done 2243/3489. 0.2150 s / img. ETA=0:05:27
[32m[03/28 20:54:25 d2.evaluation.evaluator]: [0mInference done 2261/3489. 0.2151 s / img. ETA=0:05:22
[32m[03/28 20:54:31 d2.evaluation.evaluator]: [0mInference done 2279/3489. 0.2151 s / img. ETA=0:05:18
[32m[03/28 20:54:36 d2.evaluation.evaluator]: [0mInference done 2297/3489. 0.2152 s / img. ETA=0:05:13
[32m[03/28 20:54:41 d2.evaluation.evaluator]: [0mInference done 2314/3489. 0.2153 s / img. ETA=0:05:09
[32m[03/28 20:54:46 d2.evaluation.evaluator]: [0mInference done 2332/3489. 0.2153 s / img. ETA=0:05:05
[32m[03/28 20:54:51 d2.evaluation.evaluator]: [0mInference done 2350/3489. 0.2154 s / img. ETA=0:05:00
[32m[03/28 20:54:56 d2.evaluation.evaluator]: [0mInference done 2369/3489. 0.2154 s / img. ETA=0:04:55
[32m[03/28 20:55:02 d2.evaluation.evaluator]: [0mInference done 2389/3489. 0.2154 s / img. ETA=0:04:50
[32m[03/28 20:55:07 d2.evaluation.evaluator]: [0mInference done 2407/3489. 0.2154 s / img. ETA=0:04:45
[32m[03/28 20:55:12 d2.evaluation.evaluator]: [0mInference done 2425/3489. 0.2155 s / img. ETA=0:04:41
[32m[03/28 20:55:17 d2.evaluation.evaluator]: [0mInference done 2443/3489. 0.2156 s / img. ETA=0:04:36
[32m[03/28 20:55:22 d2.evaluation.evaluator]: [0mInference done 2461/3489. 0.2156 s / img. ETA=0:04:32
[32m[03/28 20:55:28 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2157 s / img. ETA=0:04:27
[32m[03/28 20:55:33 d2.evaluation.evaluator]: [0mInference done 2499/3489. 0.2157 s / img. ETA=0:04:22
[32m[03/28 20:55:38 d2.evaluation.evaluator]: [0mInference done 2520/3489. 0.2156 s / img. ETA=0:04:16
[32m[03/28 20:55:43 d2.evaluation.evaluator]: [0mInference done 2542/3489. 0.2155 s / img. ETA=0:04:10
[32m[03/28 20:55:48 d2.evaluation.evaluator]: [0mInference done 2564/3489. 0.2155 s / img. ETA=0:04:04
[32m[03/28 20:55:53 d2.evaluation.evaluator]: [0mInference done 2587/3489. 0.2154 s / img. ETA=0:03:57
[32m[03/28 20:55:58 d2.evaluation.evaluator]: [0mInference done 2610/3489. 0.2153 s / img. ETA=0:03:51
[32m[03/28 20:56:04 d2.evaluation.evaluator]: [0mInference done 2634/3489. 0.2151 s / img. ETA=0:03:44
[32m[03/28 20:56:09 d2.evaluation.evaluator]: [0mInference done 2657/3489. 0.2150 s / img. ETA=0:03:38
[32m[03/28 20:56:14 d2.evaluation.evaluator]: [0mInference done 2679/3489. 0.2149 s / img. ETA=0:03:32
[32m[03/28 20:56:19 d2.evaluation.evaluator]: [0mInference done 2700/3489. 0.2149 s / img. ETA=0:03:26
[32m[03/28 20:56:24 d2.evaluation.evaluator]: [0mInference done 2722/3489. 0.2149 s / img. ETA=0:03:20
[32m[03/28 20:56:29 d2.evaluation.evaluator]: [0mInference done 2744/3489. 0.2148 s / img. ETA=0:03:14
[32m[03/28 20:56:34 d2.evaluation.evaluator]: [0mInference done 2764/3489. 0.2147 s / img. ETA=0:03:09
[32m[03/28 20:56:39 d2.evaluation.evaluator]: [0mInference done 2786/3489. 0.2146 s / img. ETA=0:03:03
[32m[03/28 20:56:44 d2.evaluation.evaluator]: [0mInference done 2807/3489. 0.2146 s / img. ETA=0:02:58
[32m[03/28 20:56:50 d2.evaluation.evaluator]: [0mInference done 2829/3489. 0.2146 s / img. ETA=0:02:52
[32m[03/28 20:56:55 d2.evaluation.evaluator]: [0mInference done 2851/3489. 0.2145 s / img. ETA=0:02:46
[32m[03/28 20:57:00 d2.evaluation.evaluator]: [0mInference done 2873/3489. 0.2144 s / img. ETA=0:02:40
[32m[03/28 20:57:05 d2.evaluation.evaluator]: [0mInference done 2896/3489. 0.2143 s / img. ETA=0:02:34
[32m[03/28 20:57:10 d2.evaluation.evaluator]: [0mInference done 2919/3489. 0.2143 s / img. ETA=0:02:28
[32m[03/28 20:57:15 d2.evaluation.evaluator]: [0mInference done 2943/3489. 0.2142 s / img. ETA=0:02:21
[32m[03/28 20:57:20 d2.evaluation.evaluator]: [0mInference done 2967/3489. 0.2141 s / img. ETA=0:02:15
[32m[03/28 20:57:26 d2.evaluation.evaluator]: [0mInference done 2990/3489. 0.2140 s / img. ETA=0:02:09
[32m[03/28 20:57:31 d2.evaluation.evaluator]: [0mInference done 3011/3489. 0.2139 s / img. ETA=0:02:03
[32m[03/28 20:57:36 d2.evaluation.evaluator]: [0mInference done 3033/3489. 0.2139 s / img. ETA=0:01:57
[32m[03/28 20:57:41 d2.evaluation.evaluator]: [0mInference done 3055/3489. 0.2138 s / img. ETA=0:01:52
[32m[03/28 20:57:46 d2.evaluation.evaluator]: [0mInference done 3077/3489. 0.2138 s / img. ETA=0:01:46
[32m[03/28 20:57:51 d2.evaluation.evaluator]: [0mInference done 3098/3489. 0.2137 s / img. ETA=0:01:40
[32m[03/28 20:57:56 d2.evaluation.evaluator]: [0mInference done 3120/3489. 0.2137 s / img. ETA=0:01:35
[32m[03/28 20:58:01 d2.evaluation.evaluator]: [0mInference done 3141/3489. 0.2136 s / img. ETA=0:01:29
[32m[03/28 20:58:06 d2.evaluation.evaluator]: [0mInference done 3163/3489. 0.2136 s / img. ETA=0:01:24
[32m[03/28 20:58:12 d2.evaluation.evaluator]: [0mInference done 3186/3489. 0.2135 s / img. ETA=0:01:18
[32m[03/28 20:58:17 d2.evaluation.evaluator]: [0mInference done 3208/3489. 0.2134 s / img. ETA=0:01:12
[32m[03/28 20:58:22 d2.evaluation.evaluator]: [0mInference done 3230/3489. 0.2134 s / img. ETA=0:01:06
[32m[03/28 20:58:27 d2.evaluation.evaluator]: [0mInference done 3252/3489. 0.2133 s / img. ETA=0:01:00
[32m[03/28 20:58:32 d2.evaluation.evaluator]: [0mInference done 3275/3489. 0.2133 s / img. ETA=0:00:54
[32m[03/28 20:58:37 d2.evaluation.evaluator]: [0mInference done 3299/3489. 0.2132 s / img. ETA=0:00:48
[32m[03/28 20:58:42 d2.evaluation.evaluator]: [0mInference done 3324/3489. 0.2131 s / img. ETA=0:00:42
[32m[03/28 20:58:47 d2.evaluation.evaluator]: [0mInference done 3349/3489. 0.2130 s / img. ETA=0:00:35
[32m[03/28 20:58:52 d2.evaluation.evaluator]: [0mInference done 3373/3489. 0.2129 s / img. ETA=0:00:29
[32m[03/28 20:58:57 d2.evaluation.evaluator]: [0mInference done 3397/3489. 0.2128 s / img. ETA=0:00:23
[32m[03/28 20:59:02 d2.evaluation.evaluator]: [0mInference done 3420/3489. 0.2127 s / img. ETA=0:00:17
[32m[03/28 20:59:08 d2.evaluation.evaluator]: [0mInference done 3443/3489. 0.2127 s / img. ETA=0:00:11
[32m[03/28 20:59:13 d2.evaluation.evaluator]: [0mInference done 3466/3489. 0.2126 s / img. ETA=0:00:05
[32m[03/28 20:59:18 d2.evaluation.evaluator]: [0mInference done 3489/3489. 0.2125 s / img. ETA=0:00:00
[32m[03/28 20:59:18 d2.evaluation.evaluator]: [0mTotal inference time: 0:14:45.682229 (0.254214 s / img per device, on 1 devices)
[32m[03/28 20:59:18 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:20 (0.212543 s / img per device, on 1 devices)
[32m[03/28 20:59:20 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 20:59:20 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_500.000000/coco_instances_results.json
[32m[03/28 20:59:22 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.19s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.65 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.63 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.285
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[32m[03/28 20:59:25 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.331 | 73.477 | 43.612 | 28.480 | 52.344 | 55.454 |
[32m[03/28 20:59:25 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.208 | Pedestrian | 27.455 |
Loading and preparing results...
DONE (t=2.30s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.68 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.68 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723
[32m[03/28 20:59:36 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.561 | 69.452 | 40.472 | 23.581 | 51.665 | 65.904 |
[32m[03/28 20:59:36 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.087 | Pedestrian | 20.035 |
[32m[03/28 20:59:37 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: 44.3315,73.4767,43.6121,28.4796,52.3442,55.4536
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 20:59:37 d2.evaluation.testing]: [0mcopypaste: 41.5611,69.4517,40.4718,23.5813,51.6646,65.9035
evaluated
Test [1000]
[32m[03/28 20:59:37 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 20:59:37 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 20:59:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:59:38 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:59:38 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 20:59:38 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 20:59:38 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 20:59:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 20:59:38 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 20:59:38 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 20:59:38 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 20:59:38 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:00:01 d2.utils.events]: [0m eta: 0:02:17  iter: 19  total_loss: 1.875  loss_cls: 0.9037  loss_box_reg: 0.3056  loss_mask: 0.6721  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.007733  total_val_loss: 2.104  val_loss_cls: 0.852  val_loss_box_reg: 0.4567  val_loss_mask: 0.6904  val_loss_rpn_cls: 0.06088  val_loss_rpn_loc: 0.0128  time: 0.7636  data_time: 0.0308  lr: 0.00019981  max_mem: 4743M
[32m[03/28 21:00:23 d2.utils.events]: [0m eta: 0:02:02  iter: 39  total_loss: 1.092  loss_cls: 0.2668  loss_box_reg: 0.4058  loss_mask: 0.3968  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.01384  total_val_loss: 1.171  val_loss_cls: 0.2354  val_loss_box_reg: 0.3786  val_loss_mask: 0.4997  val_loss_rpn_cls: 0.03885  val_loss_rpn_loc: 0.01246  time: 0.7692  data_time: 0.0082  lr: 0.00039961  max_mem: 4743M
[32m[03/28 21:00:44 d2.utils.events]: [0m eta: 0:01:46  iter: 59  total_loss: 0.6052  loss_cls: 0.09571  loss_box_reg: 0.3049  loss_mask: 0.2006  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.008153  total_val_loss: 1.257  val_loss_cls: 0.2614  val_loss_box_reg: 0.5054  val_loss_mask: 0.482  val_loss_rpn_cls: 0.02573  val_loss_rpn_loc: 0.01594  time: 0.7699  data_time: 0.0073  lr: 0.00059941  max_mem: 4743M
[32m[03/28 21:01:06 d2.utils.events]: [0m eta: 0:01:32  iter: 79  total_loss: 0.7158  loss_cls: 0.09016  loss_box_reg: 0.4108  loss_mask: 0.1741  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.01304  total_val_loss: 1.203  val_loss_cls: 0.2783  val_loss_box_reg: 0.412  val_loss_mask: 0.4263  val_loss_rpn_cls: 0.0206  val_loss_rpn_loc: 0.0137  time: 0.7711  data_time: 0.0062  lr: 0.00079921  max_mem: 4743M
[32m[03/28 21:01:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:01:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:01:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:01:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:01:28 d2.utils.events]: [0m eta: 0:01:16  iter: 99  total_loss: 0.4183  loss_cls: 0.04966  loss_box_reg: 0.1258  loss_mask: 0.1856  loss_rpn_cls: 0.006704  loss_rpn_loc: 0.007406  total_val_loss: 1.138  val_loss_cls: 0.2599  val_loss_box_reg: 0.3474  val_loss_mask: 0.3774  val_loss_rpn_cls: 0.02218  val_loss_rpn_loc: 0.01364  time: 0.7700  data_time: 0.0061  lr: 0.00099901  max_mem: 4743M
[32m[03/28 21:01:49 d2.utils.events]: [0m eta: 0:01:01  iter: 119  total_loss: 0.4111  loss_cls: 0.07347  loss_box_reg: 0.1409  loss_mask: 0.1501  loss_rpn_cls: 0.008859  loss_rpn_loc: 0.01114  total_val_loss: 0.9889  val_loss_cls: 0.2577  val_loss_box_reg: 0.2704  val_loss_mask: 0.3777  val_loss_rpn_cls: 0.02079  val_loss_rpn_loc: 0.01273  time: 0.7715  data_time: 0.0061  lr: 0.0011988  max_mem: 4743M
[32m[03/28 21:02:11 d2.utils.events]: [0m eta: 0:00:45  iter: 139  total_loss: 0.3567  loss_cls: 0.05348  loss_box_reg: 0.1062  loss_mask: 0.1441  loss_rpn_cls: 0.007095  loss_rpn_loc: 0.01219  total_val_loss: 0.9021  val_loss_cls: 0.1739  val_loss_box_reg: 0.1793  val_loss_mask: 0.3767  val_loss_rpn_cls: 0.01498  val_loss_rpn_loc: 0.01184  time: 0.7704  data_time: 0.0058  lr: 0.0013986  max_mem: 4743M
[32m[03/28 21:02:32 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.2858  loss_cls: 0.03786  loss_box_reg: 0.05915  loss_mask: 0.1505  loss_rpn_cls: 0.005641  loss_rpn_loc: 0.005416  total_val_loss: 1.074  val_loss_cls: 0.275  val_loss_box_reg: 0.3544  val_loss_mask: 0.4168  val_loss_rpn_cls: 0.01615  val_loss_rpn_loc: 0.01538  time: 0.7697  data_time: 0.0057  lr: 0.0015984  max_mem: 4743M
[32m[03/28 21:02:54 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.3146  loss_cls: 0.03967  loss_box_reg: 0.09972  loss_mask: 0.1424  loss_rpn_cls: 0.008032  loss_rpn_loc: 0.01043  total_val_loss: 0.9337  val_loss_cls: 0.1842  val_loss_box_reg: 0.2735  val_loss_mask: 0.4305  val_loss_rpn_cls: 0.01438  val_loss_rpn_loc: 0.01319  time: 0.7691  data_time: 0.0061  lr: 0.0017982  max_mem: 4743M
[32m[03/28 21:03:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:03:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:03:16 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:03:16 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:03:16 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3636  loss_cls: 0.04554  loss_box_reg: 0.08197  loss_mask: 0.1467  loss_rpn_cls: 0.005855  loss_rpn_loc: 0.00946  total_val_loss: 0.8717  val_loss_cls: 0.1856  val_loss_box_reg: 0.2651  val_loss_mask: 0.3145  val_loss_rpn_cls: 0.01301  val_loss_rpn_loc: 0.01431  time: 0.7684  data_time: 0.0058  lr: 0.001998  max_mem: 4743M
[32m[03/28 21:03:16 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:32 (0.7684 s / it)
[32m[03/28 21:03:16 d2.engine.hooks]: [0mTotal training time: 0:03:34 (0:01:02 on hooks)
[32m[03/28 21:03:17 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:03:17 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:03:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:03:17 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:03:17 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:03:17 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:03:17 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:03:18 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:03:18 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:03:20 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2016 s / img. ETA=0:12:32
[32m[03/28 21:03:26 d2.evaluation.evaluator]: [0mInference done 35/3489. 0.2006 s / img. ETA=0:12:22
[32m[03/28 21:03:31 d2.evaluation.evaluator]: [0mInference done 59/3489. 0.2003 s / img. ETA=0:12:14
[32m[03/28 21:03:36 d2.evaluation.evaluator]: [0mInference done 83/3489. 0.2003 s / img. ETA=0:12:09
[32m[03/28 21:03:41 d2.evaluation.evaluator]: [0mInference done 105/3489. 0.2014 s / img. ETA=0:12:17
[32m[03/28 21:03:46 d2.evaluation.evaluator]: [0mInference done 126/3489. 0.2028 s / img. ETA=0:12:32
[32m[03/28 21:03:51 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2052 s / img. ETA=0:12:57
[32m[03/28 21:03:57 d2.evaluation.evaluator]: [0mInference done 162/3489. 0.2069 s / img. ETA=0:13:13
[32m[03/28 21:04:02 d2.evaluation.evaluator]: [0mInference done 181/3489. 0.2078 s / img. ETA=0:13:20
[32m[03/28 21:04:07 d2.evaluation.evaluator]: [0mInference done 202/3489. 0.2078 s / img. ETA=0:13:15
[32m[03/28 21:04:12 d2.evaluation.evaluator]: [0mInference done 225/3489. 0.2073 s / img. ETA=0:13:03
[32m[03/28 21:04:17 d2.evaluation.evaluator]: [0mInference done 247/3489. 0.2071 s / img. ETA=0:12:55
[32m[03/28 21:04:22 d2.evaluation.evaluator]: [0mInference done 269/3489. 0.2069 s / img. ETA=0:12:47
[32m[03/28 21:04:27 d2.evaluation.evaluator]: [0mInference done 291/3489. 0.2068 s / img. ETA=0:12:42
[32m[03/28 21:04:32 d2.evaluation.evaluator]: [0mInference done 312/3489. 0.2069 s / img. ETA=0:12:37
[32m[03/28 21:04:37 d2.evaluation.evaluator]: [0mInference done 333/3489. 0.2069 s / img. ETA=0:12:33
[32m[03/28 21:04:42 d2.evaluation.evaluator]: [0mInference done 353/3489. 0.2071 s / img. ETA=0:12:30
[32m[03/28 21:04:48 d2.evaluation.evaluator]: [0mInference done 374/3489. 0.2071 s / img. ETA=0:12:26
[32m[03/28 21:04:53 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2071 s / img. ETA=0:12:20
[32m[03/28 21:04:58 d2.evaluation.evaluator]: [0mInference done 417/3489. 0.2071 s / img. ETA=0:12:15
[32m[03/28 21:05:03 d2.evaluation.evaluator]: [0mInference done 441/3489. 0.2068 s / img. ETA=0:12:05
[32m[03/28 21:05:08 d2.evaluation.evaluator]: [0mInference done 465/3489. 0.2065 s / img. ETA=0:11:56
[32m[03/28 21:05:13 d2.evaluation.evaluator]: [0mInference done 489/3489. 0.2062 s / img. ETA=0:11:47
[32m[03/28 21:05:18 d2.evaluation.evaluator]: [0mInference done 513/3489. 0.2059 s / img. ETA=0:11:37
[32m[03/28 21:05:23 d2.evaluation.evaluator]: [0mInference done 537/3489. 0.2056 s / img. ETA=0:11:28
[32m[03/28 21:05:28 d2.evaluation.evaluator]: [0mInference done 560/3489. 0.2055 s / img. ETA=0:11:21
[32m[03/28 21:05:34 d2.evaluation.evaluator]: [0mInference done 582/3489. 0.2055 s / img. ETA=0:11:16
[32m[03/28 21:05:39 d2.evaluation.evaluator]: [0mInference done 603/3489. 0.2056 s / img. ETA=0:11:12
[32m[03/28 21:05:44 d2.evaluation.evaluator]: [0mInference done 625/3489. 0.2057 s / img. ETA=0:11:08
[32m[03/28 21:05:49 d2.evaluation.evaluator]: [0mInference done 647/3489. 0.2057 s / img. ETA=0:11:03
[32m[03/28 21:05:54 d2.evaluation.evaluator]: [0mInference done 669/3489. 0.2057 s / img. ETA=0:10:57
[32m[03/28 21:05:59 d2.evaluation.evaluator]: [0mInference done 693/3489. 0.2055 s / img. ETA=0:10:50
[32m[03/28 21:06:04 d2.evaluation.evaluator]: [0mInference done 717/3489. 0.2054 s / img. ETA=0:10:43
[32m[03/28 21:06:09 d2.evaluation.evaluator]: [0mInference done 739/3489. 0.2053 s / img. ETA=0:10:37
[32m[03/28 21:06:15 d2.evaluation.evaluator]: [0mInference done 763/3489. 0.2052 s / img. ETA=0:10:30
[32m[03/28 21:06:20 d2.evaluation.evaluator]: [0mInference done 787/3489. 0.2050 s / img. ETA=0:10:23
[32m[03/28 21:06:25 d2.evaluation.evaluator]: [0mInference done 812/3489. 0.2048 s / img. ETA=0:10:15
[32m[03/28 21:06:30 d2.evaluation.evaluator]: [0mInference done 837/3489. 0.2046 s / img. ETA=0:10:08
[32m[03/28 21:06:35 d2.evaluation.evaluator]: [0mInference done 861/3489. 0.2045 s / img. ETA=0:10:01
[32m[03/28 21:06:40 d2.evaluation.evaluator]: [0mInference done 886/3489. 0.2043 s / img. ETA=0:09:53
[32m[03/28 21:06:45 d2.evaluation.evaluator]: [0mInference done 909/3489. 0.2043 s / img. ETA=0:09:48
[32m[03/28 21:06:50 d2.evaluation.evaluator]: [0mInference done 929/3489. 0.2045 s / img. ETA=0:09:45
[32m[03/28 21:06:56 d2.evaluation.evaluator]: [0mInference done 949/3489. 0.2047 s / img. ETA=0:09:42
[32m[03/28 21:07:01 d2.evaluation.evaluator]: [0mInference done 969/3489. 0.2049 s / img. ETA=0:09:39
[32m[03/28 21:07:06 d2.evaluation.evaluator]: [0mInference done 988/3489. 0.2052 s / img. ETA=0:09:37
[32m[03/28 21:07:11 d2.evaluation.evaluator]: [0mInference done 1007/3489. 0.2054 s / img. ETA=0:09:35
[32m[03/28 21:07:17 d2.evaluation.evaluator]: [0mInference done 1026/3489. 0.2057 s / img. ETA=0:09:33
[32m[03/28 21:07:22 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2059 s / img. ETA=0:09:30
[32m[03/28 21:07:27 d2.evaluation.evaluator]: [0mInference done 1064/3489. 0.2061 s / img. ETA=0:09:27
[32m[03/28 21:07:32 d2.evaluation.evaluator]: [0mInference done 1084/3489. 0.2062 s / img. ETA=0:09:23
[32m[03/28 21:07:37 d2.evaluation.evaluator]: [0mInference done 1106/3489. 0.2061 s / img. ETA=0:09:18
[32m[03/28 21:07:42 d2.evaluation.evaluator]: [0mInference done 1127/3489. 0.2062 s / img. ETA=0:09:13
[32m[03/28 21:07:47 d2.evaluation.evaluator]: [0mInference done 1147/3489. 0.2063 s / img. ETA=0:09:10
[32m[03/28 21:07:53 d2.evaluation.evaluator]: [0mInference done 1167/3489. 0.2065 s / img. ETA=0:09:06
[32m[03/28 21:07:58 d2.evaluation.evaluator]: [0mInference done 1187/3489. 0.2066 s / img. ETA=0:09:02
[32m[03/28 21:08:03 d2.evaluation.evaluator]: [0mInference done 1208/3489. 0.2066 s / img. ETA=0:08:58
[32m[03/28 21:08:08 d2.evaluation.evaluator]: [0mInference done 1229/3489. 0.2067 s / img. ETA=0:08:53
[32m[03/28 21:08:13 d2.evaluation.evaluator]: [0mInference done 1250/3489. 0.2067 s / img. ETA=0:08:48
[32m[03/28 21:08:18 d2.evaluation.evaluator]: [0mInference done 1275/3489. 0.2065 s / img. ETA=0:08:41
[32m[03/28 21:08:24 d2.evaluation.evaluator]: [0mInference done 1300/3489. 0.2064 s / img. ETA=0:08:34
[32m[03/28 21:08:29 d2.evaluation.evaluator]: [0mInference done 1325/3489. 0.2062 s / img. ETA=0:08:27
[32m[03/28 21:08:34 d2.evaluation.evaluator]: [0mInference done 1349/3489. 0.2061 s / img. ETA=0:08:20
[32m[03/28 21:08:39 d2.evaluation.evaluator]: [0mInference done 1373/3489. 0.2060 s / img. ETA=0:08:14
[32m[03/28 21:08:44 d2.evaluation.evaluator]: [0mInference done 1398/3489. 0.2059 s / img. ETA=0:08:07
[32m[03/28 21:08:49 d2.evaluation.evaluator]: [0mInference done 1422/3489. 0.2058 s / img. ETA=0:08:01
[32m[03/28 21:08:54 d2.evaluation.evaluator]: [0mInference done 1446/3489. 0.2057 s / img. ETA=0:07:54
[32m[03/28 21:08:59 d2.evaluation.evaluator]: [0mInference done 1470/3489. 0.2056 s / img. ETA=0:07:48
[32m[03/28 21:09:04 d2.evaluation.evaluator]: [0mInference done 1495/3489. 0.2055 s / img. ETA=0:07:42
[32m[03/28 21:09:10 d2.evaluation.evaluator]: [0mInference done 1520/3489. 0.2054 s / img. ETA=0:07:35
[32m[03/28 21:09:15 d2.evaluation.evaluator]: [0mInference done 1544/3489. 0.2053 s / img. ETA=0:07:29
[32m[03/28 21:09:20 d2.evaluation.evaluator]: [0mInference done 1568/3489. 0.2052 s / img. ETA=0:07:23
[32m[03/28 21:09:25 d2.evaluation.evaluator]: [0mInference done 1592/3489. 0.2052 s / img. ETA=0:07:17
[32m[03/28 21:09:30 d2.evaluation.evaluator]: [0mInference done 1614/3489. 0.2052 s / img. ETA=0:07:12
[32m[03/28 21:09:35 d2.evaluation.evaluator]: [0mInference done 1635/3489. 0.2052 s / img. ETA=0:07:07
[32m[03/28 21:09:40 d2.evaluation.evaluator]: [0mInference done 1657/3489. 0.2052 s / img. ETA=0:07:02
[32m[03/28 21:09:45 d2.evaluation.evaluator]: [0mInference done 1678/3489. 0.2053 s / img. ETA=0:06:58
[32m[03/28 21:09:51 d2.evaluation.evaluator]: [0mInference done 1698/3489. 0.2054 s / img. ETA=0:06:54
[32m[03/28 21:09:56 d2.evaluation.evaluator]: [0mInference done 1718/3489. 0.2055 s / img. ETA=0:06:49
[32m[03/28 21:10:01 d2.evaluation.evaluator]: [0mInference done 1738/3489. 0.2056 s / img. ETA=0:06:45
[32m[03/28 21:10:06 d2.evaluation.evaluator]: [0mInference done 1757/3489. 0.2057 s / img. ETA=0:06:42
[32m[03/28 21:10:11 d2.evaluation.evaluator]: [0mInference done 1775/3489. 0.2058 s / img. ETA=0:06:38
[32m[03/28 21:10:16 d2.evaluation.evaluator]: [0mInference done 1792/3489. 0.2060 s / img. ETA=0:06:36
[32m[03/28 21:10:21 d2.evaluation.evaluator]: [0mInference done 1809/3489. 0.2062 s / img. ETA=0:06:33
[32m[03/28 21:10:26 d2.evaluation.evaluator]: [0mInference done 1827/3489. 0.2063 s / img. ETA=0:06:29
[32m[03/28 21:10:32 d2.evaluation.evaluator]: [0mInference done 1844/3489. 0.2065 s / img. ETA=0:06:26
[32m[03/28 21:10:37 d2.evaluation.evaluator]: [0mInference done 1862/3489. 0.2066 s / img. ETA=0:06:23
[32m[03/28 21:10:42 d2.evaluation.evaluator]: [0mInference done 1881/3489. 0.2067 s / img. ETA=0:06:19
[32m[03/28 21:10:47 d2.evaluation.evaluator]: [0mInference done 1899/3489. 0.2069 s / img. ETA=0:06:16
[32m[03/28 21:10:52 d2.evaluation.evaluator]: [0mInference done 1917/3489. 0.2070 s / img. ETA=0:06:12
[32m[03/28 21:10:57 d2.evaluation.evaluator]: [0mInference done 1936/3489. 0.2071 s / img. ETA=0:06:08
[32m[03/28 21:11:03 d2.evaluation.evaluator]: [0mInference done 1954/3489. 0.2072 s / img. ETA=0:06:04
[32m[03/28 21:11:08 d2.evaluation.evaluator]: [0mInference done 1972/3489. 0.2073 s / img. ETA=0:06:01
[32m[03/28 21:11:13 d2.evaluation.evaluator]: [0mInference done 1991/3489. 0.2074 s / img. ETA=0:05:57
[32m[03/28 21:11:18 d2.evaluation.evaluator]: [0mInference done 2012/3489. 0.2074 s / img. ETA=0:05:52
[32m[03/28 21:11:23 d2.evaluation.evaluator]: [0mInference done 2033/3489. 0.2074 s / img. ETA=0:05:47
[32m[03/28 21:11:28 d2.evaluation.evaluator]: [0mInference done 2053/3489. 0.2075 s / img. ETA=0:05:42
[32m[03/28 21:11:33 d2.evaluation.evaluator]: [0mInference done 2073/3489. 0.2075 s / img. ETA=0:05:38
[32m[03/28 21:11:39 d2.evaluation.evaluator]: [0mInference done 2093/3489. 0.2076 s / img. ETA=0:05:33
[32m[03/28 21:11:44 d2.evaluation.evaluator]: [0mInference done 2112/3489. 0.2076 s / img. ETA=0:05:29
[32m[03/28 21:11:49 d2.evaluation.evaluator]: [0mInference done 2131/3489. 0.2077 s / img. ETA=0:05:25
[32m[03/28 21:11:54 d2.evaluation.evaluator]: [0mInference done 2150/3489. 0.2078 s / img. ETA=0:05:21
[32m[03/28 21:11:59 d2.evaluation.evaluator]: [0mInference done 2169/3489. 0.2079 s / img. ETA=0:05:17
[32m[03/28 21:12:04 d2.evaluation.evaluator]: [0mInference done 2188/3489. 0.2080 s / img. ETA=0:05:13
[32m[03/28 21:12:10 d2.evaluation.evaluator]: [0mInference done 2207/3489. 0.2080 s / img. ETA=0:05:08
[32m[03/28 21:12:15 d2.evaluation.evaluator]: [0mInference done 2227/3489. 0.2081 s / img. ETA=0:05:04
[32m[03/28 21:12:20 d2.evaluation.evaluator]: [0mInference done 2247/3489. 0.2081 s / img. ETA=0:04:59
[32m[03/28 21:12:25 d2.evaluation.evaluator]: [0mInference done 2268/3489. 0.2081 s / img. ETA=0:04:54
[32m[03/28 21:12:30 d2.evaluation.evaluator]: [0mInference done 2288/3489. 0.2081 s / img. ETA=0:04:49
[32m[03/28 21:12:35 d2.evaluation.evaluator]: [0mInference done 2308/3489. 0.2082 s / img. ETA=0:04:45
[32m[03/28 21:12:41 d2.evaluation.evaluator]: [0mInference done 2328/3489. 0.2082 s / img. ETA=0:04:40
[32m[03/28 21:12:46 d2.evaluation.evaluator]: [0mInference done 2348/3489. 0.2083 s / img. ETA=0:04:35
[32m[03/28 21:12:51 d2.evaluation.evaluator]: [0mInference done 2368/3489. 0.2083 s / img. ETA=0:04:31
[32m[03/28 21:12:56 d2.evaluation.evaluator]: [0mInference done 2390/3489. 0.2082 s / img. ETA=0:04:25
[32m[03/28 21:13:01 d2.evaluation.evaluator]: [0mInference done 2411/3489. 0.2082 s / img. ETA=0:04:20
[32m[03/28 21:13:06 d2.evaluation.evaluator]: [0mInference done 2433/3489. 0.2082 s / img. ETA=0:04:15
[32m[03/28 21:13:11 d2.evaluation.evaluator]: [0mInference done 2453/3489. 0.2082 s / img. ETA=0:04:10
[32m[03/28 21:13:17 d2.evaluation.evaluator]: [0mInference done 2473/3489. 0.2083 s / img. ETA=0:04:05
[32m[03/28 21:13:22 d2.evaluation.evaluator]: [0mInference done 2493/3489. 0.2083 s / img. ETA=0:04:01
[32m[03/28 21:13:27 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2082 s / img. ETA=0:03:55
[32m[03/28 21:13:32 d2.evaluation.evaluator]: [0mInference done 2540/3489. 0.2082 s / img. ETA=0:03:49
[32m[03/28 21:13:37 d2.evaluation.evaluator]: [0mInference done 2563/3489. 0.2081 s / img. ETA=0:03:43
[32m[03/28 21:13:42 d2.evaluation.evaluator]: [0mInference done 2587/3489. 0.2081 s / img. ETA=0:03:37
[32m[03/28 21:13:47 d2.evaluation.evaluator]: [0mInference done 2611/3489. 0.2080 s / img. ETA=0:03:31
[32m[03/28 21:13:52 d2.evaluation.evaluator]: [0mInference done 2636/3489. 0.2079 s / img. ETA=0:03:25
[32m[03/28 21:13:57 d2.evaluation.evaluator]: [0mInference done 2660/3489. 0.2078 s / img. ETA=0:03:19
[32m[03/28 21:14:03 d2.evaluation.evaluator]: [0mInference done 2683/3489. 0.2078 s / img. ETA=0:03:13
[32m[03/28 21:14:08 d2.evaluation.evaluator]: [0mInference done 2706/3489. 0.2077 s / img. ETA=0:03:08
[32m[03/28 21:14:13 d2.evaluation.evaluator]: [0mInference done 2729/3489. 0.2077 s / img. ETA=0:03:02
[32m[03/28 21:14:18 d2.evaluation.evaluator]: [0mInference done 2752/3489. 0.2077 s / img. ETA=0:02:56
[32m[03/28 21:14:23 d2.evaluation.evaluator]: [0mInference done 2775/3489. 0.2076 s / img. ETA=0:02:51
[32m[03/28 21:14:28 d2.evaluation.evaluator]: [0mInference done 2798/3489. 0.2076 s / img. ETA=0:02:45
[32m[03/28 21:14:33 d2.evaluation.evaluator]: [0mInference done 2821/3489. 0.2076 s / img. ETA=0:02:39
[32m[03/28 21:14:39 d2.evaluation.evaluator]: [0mInference done 2844/3489. 0.2075 s / img. ETA=0:02:34
[32m[03/28 21:14:44 d2.evaluation.evaluator]: [0mInference done 2867/3489. 0.2075 s / img. ETA=0:02:28
[32m[03/28 21:14:49 d2.evaluation.evaluator]: [0mInference done 2890/3489. 0.2074 s / img. ETA=0:02:23
[32m[03/28 21:14:54 d2.evaluation.evaluator]: [0mInference done 2914/3489. 0.2074 s / img. ETA=0:02:17
[32m[03/28 21:14:59 d2.evaluation.evaluator]: [0mInference done 2938/3489. 0.2073 s / img. ETA=0:02:11
[32m[03/28 21:15:04 d2.evaluation.evaluator]: [0mInference done 2962/3489. 0.2073 s / img. ETA=0:02:05
[32m[03/28 21:15:09 d2.evaluation.evaluator]: [0mInference done 2986/3489. 0.2072 s / img. ETA=0:01:59
[32m[03/28 21:15:14 d2.evaluation.evaluator]: [0mInference done 3009/3489. 0.2072 s / img. ETA=0:01:54
[32m[03/28 21:15:19 d2.evaluation.evaluator]: [0mInference done 3032/3489. 0.2071 s / img. ETA=0:01:48
[32m[03/28 21:15:24 d2.evaluation.evaluator]: [0mInference done 3056/3489. 0.2071 s / img. ETA=0:01:42
[32m[03/28 21:15:30 d2.evaluation.evaluator]: [0mInference done 3079/3489. 0.2071 s / img. ETA=0:01:37
[32m[03/28 21:15:35 d2.evaluation.evaluator]: [0mInference done 3102/3489. 0.2070 s / img. ETA=0:01:31
[32m[03/28 21:15:40 d2.evaluation.evaluator]: [0mInference done 3125/3489. 0.2070 s / img. ETA=0:01:26
[32m[03/28 21:15:45 d2.evaluation.evaluator]: [0mInference done 3148/3489. 0.2070 s / img. ETA=0:01:20
[32m[03/28 21:15:50 d2.evaluation.evaluator]: [0mInference done 3171/3489. 0.2069 s / img. ETA=0:01:15
[32m[03/28 21:15:55 d2.evaluation.evaluator]: [0mInference done 3195/3489. 0.2069 s / img. ETA=0:01:09
[32m[03/28 21:16:00 d2.evaluation.evaluator]: [0mInference done 3218/3489. 0.2069 s / img. ETA=0:01:04
[32m[03/28 21:16:06 d2.evaluation.evaluator]: [0mInference done 3241/3489. 0.2068 s / img. ETA=0:00:58
[32m[03/28 21:16:11 d2.evaluation.evaluator]: [0mInference done 3265/3489. 0.2068 s / img. ETA=0:00:53
[32m[03/28 21:16:16 d2.evaluation.evaluator]: [0mInference done 3289/3489. 0.2067 s / img. ETA=0:00:47
[32m[03/28 21:16:21 d2.evaluation.evaluator]: [0mInference done 3314/3489. 0.2067 s / img. ETA=0:00:41
[32m[03/28 21:16:26 d2.evaluation.evaluator]: [0mInference done 3339/3489. 0.2066 s / img. ETA=0:00:35
[32m[03/28 21:16:31 d2.evaluation.evaluator]: [0mInference done 3364/3489. 0.2065 s / img. ETA=0:00:29
[32m[03/28 21:16:36 d2.evaluation.evaluator]: [0mInference done 3389/3489. 0.2065 s / img. ETA=0:00:23
[32m[03/28 21:16:41 d2.evaluation.evaluator]: [0mInference done 3413/3489. 0.2064 s / img. ETA=0:00:17
[32m[03/28 21:16:47 d2.evaluation.evaluator]: [0mInference done 3437/3489. 0.2064 s / img. ETA=0:00:12
[32m[03/28 21:16:52 d2.evaluation.evaluator]: [0mInference done 3461/3489. 0.2064 s / img. ETA=0:00:06
[32m[03/28 21:16:57 d2.evaluation.evaluator]: [0mInference done 3485/3489. 0.2063 s / img. ETA=0:00:00
[32m[03/28 21:16:58 d2.evaluation.evaluator]: [0mTotal inference time: 0:13:38.752889 (0.235004 s / img per device, on 1 devices)
[32m[03/28 21:16:58 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:11:58 (0.206327 s / img per device, on 1 devices)
[32m[03/28 21:16:59 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:16:59 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_1000.000000/coco_instances_results.json
[32m[03/28 21:17:01 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.32 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.46 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.807
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
[32m[03/28 21:17:03 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.797 | 80.702 | 56.867 | 31.150 | 60.465 | 62.706 |
[32m[03/28 21:17:03 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 58.482 | Pedestrian | 43.113 |
Loading and preparing results...
DONE (t=1.55s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 1.96 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.49 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[32m[03/28 21:17:11 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.765 | 77.535 | 45.199 | 24.970 | 54.674 | 69.620 |
[32m[03/28 21:17:11 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.558 | Pedestrian | 28.973 |
[32m[03/28 21:17:11 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: 50.7974,80.7020,56.8667,31.1503,60.4651,62.7057
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:17:11 d2.evaluation.testing]: [0mcopypaste: 45.7652,77.5352,45.1994,24.9701,54.6744,69.6203
evaluated
Test [2000]
[32m[03/28 21:17:12 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:17:12 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:17:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:17:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:17:12 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:17:12 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:17:12 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:17:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:17:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:17:12 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:17:12 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:17:13 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:17:35 d2.utils.events]: [0m eta: 0:02:16  iter: 19  total_loss: 2.009  loss_cls: 0.8259  loss_box_reg: 0.3477  loss_mask: 0.662  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.007501  total_val_loss: 1.83  val_loss_cls: 0.7572  val_loss_box_reg: 0.3846  val_loss_mask: 0.6783  val_loss_rpn_cls: 0.04454  val_loss_rpn_loc: 0.0134  time: 0.7635  data_time: 0.0348  lr: 0.00019981  max_mem: 4743M
[32m[03/28 21:17:56 d2.utils.events]: [0m eta: 0:02:01  iter: 39  total_loss: 0.9653  loss_cls: 0.2083  loss_box_reg: 0.3457  loss_mask: 0.3631  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.007696  total_val_loss: 1.32  val_loss_cls: 0.2903  val_loss_box_reg: 0.4004  val_loss_mask: 0.579  val_loss_rpn_cls: 0.04041  val_loss_rpn_loc: 0.01192  time: 0.7626  data_time: 0.0062  lr: 0.00039961  max_mem: 4743M
[32m[03/28 21:18:18 d2.utils.events]: [0m eta: 0:01:46  iter: 59  total_loss: 0.6052  loss_cls: 0.07788  loss_box_reg: 0.2939  loss_mask: 0.2014  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.01056  total_val_loss: 1.13  val_loss_cls: 0.2157  val_loss_box_reg: 0.4166  val_loss_mask: 0.4411  val_loss_rpn_cls: 0.03146  val_loss_rpn_loc: 0.01284  time: 0.7628  data_time: 0.0060  lr: 0.00059941  max_mem: 4743M
[32m[03/28 21:18:39 d2.utils.events]: [0m eta: 0:01:31  iter: 79  total_loss: 0.5262  loss_cls: 0.05756  loss_box_reg: 0.2473  loss_mask: 0.1795  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.006584  total_val_loss: 1.2  val_loss_cls: 0.2571  val_loss_box_reg: 0.3798  val_loss_mask: 0.3873  val_loss_rpn_cls: 0.0273  val_loss_rpn_loc: 0.01278  time: 0.7644  data_time: 0.0071  lr: 0.00079921  max_mem: 4743M
[32m[03/28 21:19:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:19:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:19:01 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:19:01 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:19:01 d2.utils.events]: [0m eta: 0:01:16  iter: 99  total_loss: 0.4207  loss_cls: 0.053  loss_box_reg: 0.1737  loss_mask: 0.16  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.005955  total_val_loss: 1.084  val_loss_cls: 0.2637  val_loss_box_reg: 0.3379  val_loss_mask: 0.404  val_loss_rpn_cls: 0.02532  val_loss_rpn_loc: 0.0139  time: 0.7663  data_time: 0.0075  lr: 0.00099901  max_mem: 4743M
[32m[03/28 21:19:23 d2.utils.events]: [0m eta: 0:01:01  iter: 119  total_loss: 0.3312  loss_cls: 0.05761  loss_box_reg: 0.1158  loss_mask: 0.1568  loss_rpn_cls: 0.007751  loss_rpn_loc: 0.00975  total_val_loss: 1.062  val_loss_cls: 0.3107  val_loss_box_reg: 0.3328  val_loss_mask: 0.4452  val_loss_rpn_cls: 0.02123  val_loss_rpn_loc: 0.01371  time: 0.7672  data_time: 0.0070  lr: 0.0011988  max_mem: 4743M
[32m[03/28 21:19:45 d2.utils.events]: [0m eta: 0:00:45  iter: 139  total_loss: 0.3504  loss_cls: 0.04816  loss_box_reg: 0.1014  loss_mask: 0.1644  loss_rpn_cls: 0.006845  loss_rpn_loc: 0.006544  total_val_loss: 0.7781  val_loss_cls: 0.1649  val_loss_box_reg: 0.241  val_loss_mask: 0.3255  val_loss_rpn_cls: 0.0195  val_loss_rpn_loc: 0.01227  time: 0.7676  data_time: 0.0069  lr: 0.0013986  max_mem: 4743M
[32m[03/28 21:20:07 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.3391  loss_cls: 0.05273  loss_box_reg: 0.1257  loss_mask: 0.1534  loss_rpn_cls: 0.005639  loss_rpn_loc: 0.01014  total_val_loss: 0.8024  val_loss_cls: 0.1726  val_loss_box_reg: 0.2269  val_loss_mask: 0.3065  val_loss_rpn_cls: 0.01331  val_loss_rpn_loc: 0.01292  time: 0.7684  data_time: 0.0060  lr: 0.0015984  max_mem: 4743M
[32m[03/28 21:20:29 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.3443  loss_cls: 0.03652  loss_box_reg: 0.08598  loss_mask: 0.1561  loss_rpn_cls: 0.003967  loss_rpn_loc: 0.006415  total_val_loss: 0.8538  val_loss_cls: 0.2048  val_loss_box_reg: 0.2556  val_loss_mask: 0.366  val_loss_rpn_cls: 0.01955  val_loss_rpn_loc: 0.01203  time: 0.7690  data_time: 0.0065  lr: 0.0017982  max_mem: 4743M
[32m[03/28 21:20:51 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:20:51 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:20:51 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:20:51 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:20:52 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4186  loss_cls: 0.069  loss_box_reg: 0.1345  loss_mask: 0.168  loss_rpn_cls: 0.006351  loss_rpn_loc: 0.01011  total_val_loss: 0.8547  val_loss_cls: 0.1717  val_loss_box_reg: 0.2678  val_loss_mask: 0.3577  val_loss_rpn_cls: 0.02193  val_loss_rpn_loc: 0.01313  time: 0.7700  data_time: 0.0083  lr: 0.001998  max_mem: 4743M
[32m[03/28 21:20:52 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:32 (0.7700 s / it)
[32m[03/28 21:20:52 d2.engine.hooks]: [0mTotal training time: 0:03:36 (0:01:03 on hooks)
[32m[03/28 21:20:52 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:20:52 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:20:52 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:20:52 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:20:52 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:20:53 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:20:53 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:20:53 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:20:53 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:20:56 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2006 s / img. ETA=0:12:26
[32m[03/28 21:21:01 d2.evaluation.evaluator]: [0mInference done 35/3489. 0.2000 s / img. ETA=0:12:15
[32m[03/28 21:21:06 d2.evaluation.evaluator]: [0mInference done 60/3489. 0.1990 s / img. ETA=0:12:00
[32m[03/28 21:21:11 d2.evaluation.evaluator]: [0mInference done 84/3489. 0.1992 s / img. ETA=0:11:55
[32m[03/28 21:21:16 d2.evaluation.evaluator]: [0mInference done 107/3489. 0.2002 s / img. ETA=0:12:01
[32m[03/28 21:21:21 d2.evaluation.evaluator]: [0mInference done 128/3489. 0.2014 s / img. ETA=0:12:11
[32m[03/28 21:21:26 d2.evaluation.evaluator]: [0mInference done 147/3489. 0.2034 s / img. ETA=0:12:32
[32m[03/28 21:21:32 d2.evaluation.evaluator]: [0mInference done 165/3489. 0.2054 s / img. ETA=0:12:51
[32m[03/28 21:21:37 d2.evaluation.evaluator]: [0mInference done 184/3489. 0.2065 s / img. ETA=0:12:59
[32m[03/28 21:21:42 d2.evaluation.evaluator]: [0mInference done 205/3489. 0.2067 s / img. ETA=0:12:56
[32m[03/28 21:21:47 d2.evaluation.evaluator]: [0mInference done 228/3489. 0.2064 s / img. ETA=0:12:45
[32m[03/28 21:21:52 d2.evaluation.evaluator]: [0mInference done 250/3489. 0.2063 s / img. ETA=0:12:39
[32m[03/28 21:21:57 d2.evaluation.evaluator]: [0mInference done 272/3489. 0.2062 s / img. ETA=0:12:32
[32m[03/28 21:22:02 d2.evaluation.evaluator]: [0mInference done 294/3489. 0.2062 s / img. ETA=0:12:27
[32m[03/28 21:22:07 d2.evaluation.evaluator]: [0mInference done 315/3489. 0.2064 s / img. ETA=0:12:23
[32m[03/28 21:22:12 d2.evaluation.evaluator]: [0mInference done 336/3489. 0.2065 s / img. ETA=0:12:20
[32m[03/28 21:22:17 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2067 s / img. ETA=0:12:18
[32m[03/28 21:22:22 d2.evaluation.evaluator]: [0mInference done 378/3489. 0.2068 s / img. ETA=0:12:14
[32m[03/28 21:22:28 d2.evaluation.evaluator]: [0mInference done 400/3489. 0.2068 s / img. ETA=0:12:09
[32m[03/28 21:22:33 d2.evaluation.evaluator]: [0mInference done 421/3489. 0.2068 s / img. ETA=0:12:04
[32m[03/28 21:22:38 d2.evaluation.evaluator]: [0mInference done 445/3489. 0.2065 s / img. ETA=0:11:54
[32m[03/28 21:22:43 d2.evaluation.evaluator]: [0mInference done 469/3489. 0.2062 s / img. ETA=0:11:45
[32m[03/28 21:22:48 d2.evaluation.evaluator]: [0mInference done 493/3489. 0.2059 s / img. ETA=0:11:37
[32m[03/28 21:22:53 d2.evaluation.evaluator]: [0mInference done 516/3489. 0.2060 s / img. ETA=0:11:29
[32m[03/28 21:22:58 d2.evaluation.evaluator]: [0mInference done 541/3489. 0.2057 s / img. ETA=0:11:20
[32m[03/28 21:23:03 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2055 s / img. ETA=0:11:12
[32m[03/28 21:23:08 d2.evaluation.evaluator]: [0mInference done 587/3489. 0.2055 s / img. ETA=0:11:08
[32m[03/28 21:23:14 d2.evaluation.evaluator]: [0mInference done 609/3489. 0.2055 s / img. ETA=0:11:03
[32m[03/28 21:23:19 d2.evaluation.evaluator]: [0mInference done 630/3489. 0.2056 s / img. ETA=0:10:59
[32m[03/28 21:23:24 d2.evaluation.evaluator]: [0mInference done 652/3489. 0.2057 s / img. ETA=0:10:55
[32m[03/28 21:23:29 d2.evaluation.evaluator]: [0mInference done 675/3489. 0.2056 s / img. ETA=0:10:49
[32m[03/28 21:23:34 d2.evaluation.evaluator]: [0mInference done 699/3489. 0.2055 s / img. ETA=0:10:41
[32m[03/28 21:23:39 d2.evaluation.evaluator]: [0mInference done 723/3489. 0.2054 s / img. ETA=0:10:35
[32m[03/28 21:23:44 d2.evaluation.evaluator]: [0mInference done 747/3489. 0.2053 s / img. ETA=0:10:28
[32m[03/28 21:23:50 d2.evaluation.evaluator]: [0mInference done 772/3489. 0.2050 s / img. ETA=0:10:20
[32m[03/28 21:23:55 d2.evaluation.evaluator]: [0mInference done 797/3489. 0.2048 s / img. ETA=0:10:12
[32m[03/28 21:24:00 d2.evaluation.evaluator]: [0mInference done 822/3489. 0.2046 s / img. ETA=0:10:05
[32m[03/28 21:24:05 d2.evaluation.evaluator]: [0mInference done 847/3489. 0.2044 s / img. ETA=0:09:57
[32m[03/28 21:24:10 d2.evaluation.evaluator]: [0mInference done 872/3489. 0.2043 s / img. ETA=0:09:50
[32m[03/28 21:24:15 d2.evaluation.evaluator]: [0mInference done 897/3489. 0.2041 s / img. ETA=0:09:43
[32m[03/28 21:24:20 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2043 s / img. ETA=0:09:40
[32m[03/28 21:24:26 d2.evaluation.evaluator]: [0mInference done 938/3489. 0.2045 s / img. ETA=0:09:37
[32m[03/28 21:24:31 d2.evaluation.evaluator]: [0mInference done 958/3489. 0.2047 s / img. ETA=0:09:34
[32m[03/28 21:24:36 d2.evaluation.evaluator]: [0mInference done 977/3489. 0.2049 s / img. ETA=0:09:32
[32m[03/28 21:24:41 d2.evaluation.evaluator]: [0mInference done 995/3489. 0.2052 s / img. ETA=0:09:30
[32m[03/28 21:24:46 d2.evaluation.evaluator]: [0mInference done 1014/3489. 0.2055 s / img. ETA=0:09:28
[32m[03/28 21:24:51 d2.evaluation.evaluator]: [0mInference done 1032/3489. 0.2057 s / img. ETA=0:09:26
[32m[03/28 21:24:56 d2.evaluation.evaluator]: [0mInference done 1051/3489. 0.2060 s / img. ETA=0:09:24
[32m[03/28 21:25:02 d2.evaluation.evaluator]: [0mInference done 1070/3489. 0.2061 s / img. ETA=0:09:21
[32m[03/28 21:25:07 d2.evaluation.evaluator]: [0mInference done 1091/3489. 0.2062 s / img. ETA=0:09:16
[32m[03/28 21:25:12 d2.evaluation.evaluator]: [0mInference done 1113/3489. 0.2063 s / img. ETA=0:09:11
[32m[03/28 21:25:17 d2.evaluation.evaluator]: [0mInference done 1134/3489. 0.2064 s / img. ETA=0:09:07
[32m[03/28 21:25:22 d2.evaluation.evaluator]: [0mInference done 1154/3489. 0.2065 s / img. ETA=0:09:03
[32m[03/28 21:25:27 d2.evaluation.evaluator]: [0mInference done 1174/3489. 0.2067 s / img. ETA=0:09:00
[32m[03/28 21:25:32 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2067 s / img. ETA=0:08:55
[32m[03/28 21:25:37 d2.evaluation.evaluator]: [0mInference done 1216/3489. 0.2068 s / img. ETA=0:08:51
[32m[03/28 21:25:43 d2.evaluation.evaluator]: [0mInference done 1238/3489. 0.2068 s / img. ETA=0:08:46
[32m[03/28 21:25:48 d2.evaluation.evaluator]: [0mInference done 1261/3489. 0.2067 s / img. ETA=0:08:40
[32m[03/28 21:25:53 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2066 s / img. ETA=0:08:33
[32m[03/28 21:25:58 d2.evaluation.evaluator]: [0mInference done 1311/3489. 0.2064 s / img. ETA=0:08:26
[32m[03/28 21:26:03 d2.evaluation.evaluator]: [0mInference done 1336/3489. 0.2063 s / img. ETA=0:08:19
[32m[03/28 21:26:08 d2.evaluation.evaluator]: [0mInference done 1361/3489. 0.2061 s / img. ETA=0:08:12
[32m[03/28 21:26:13 d2.evaluation.evaluator]: [0mInference done 1386/3489. 0.2060 s / img. ETA=0:08:05
[32m[03/28 21:26:19 d2.evaluation.evaluator]: [0mInference done 1410/3489. 0.2059 s / img. ETA=0:07:59
[32m[03/28 21:26:24 d2.evaluation.evaluator]: [0mInference done 1434/3489. 0.2059 s / img. ETA=0:07:53
[32m[03/28 21:26:29 d2.evaluation.evaluator]: [0mInference done 1458/3489. 0.2058 s / img. ETA=0:07:47
[32m[03/28 21:26:34 d2.evaluation.evaluator]: [0mInference done 1482/3489. 0.2057 s / img. ETA=0:07:41
[32m[03/28 21:26:39 d2.evaluation.evaluator]: [0mInference done 1507/3489. 0.2056 s / img. ETA=0:07:34
[32m[03/28 21:26:44 d2.evaluation.evaluator]: [0mInference done 1531/3489. 0.2055 s / img. ETA=0:07:28
[32m[03/28 21:26:49 d2.evaluation.evaluator]: [0mInference done 1555/3489. 0.2054 s / img. ETA=0:07:22
[32m[03/28 21:26:54 d2.evaluation.evaluator]: [0mInference done 1579/3489. 0.2053 s / img. ETA=0:07:16
[32m[03/28 21:26:59 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2053 s / img. ETA=0:07:11
[32m[03/28 21:27:04 d2.evaluation.evaluator]: [0mInference done 1624/3489. 0.2053 s / img. ETA=0:07:06
[32m[03/28 21:27:09 d2.evaluation.evaluator]: [0mInference done 1646/3489. 0.2053 s / img. ETA=0:07:01
[32m[03/28 21:27:15 d2.evaluation.evaluator]: [0mInference done 1669/3489. 0.2053 s / img. ETA=0:06:55
[32m[03/28 21:27:20 d2.evaluation.evaluator]: [0mInference done 1690/3489. 0.2053 s / img. ETA=0:06:51
[32m[03/28 21:27:25 d2.evaluation.evaluator]: [0mInference done 1710/3489. 0.2054 s / img. ETA=0:06:47
[32m[03/28 21:27:30 d2.evaluation.evaluator]: [0mInference done 1730/3489. 0.2055 s / img. ETA=0:06:43
[32m[03/28 21:27:35 d2.evaluation.evaluator]: [0mInference done 1750/3489. 0.2056 s / img. ETA=0:06:39
[32m[03/28 21:27:40 d2.evaluation.evaluator]: [0mInference done 1768/3489. 0.2058 s / img. ETA=0:06:36
[32m[03/28 21:27:46 d2.evaluation.evaluator]: [0mInference done 1786/3489. 0.2059 s / img. ETA=0:06:33
[32m[03/28 21:27:51 d2.evaluation.evaluator]: [0mInference done 1803/3489. 0.2061 s / img. ETA=0:06:30
[32m[03/28 21:27:56 d2.evaluation.evaluator]: [0mInference done 1820/3489. 0.2063 s / img. ETA=0:06:27
[32m[03/28 21:28:01 d2.evaluation.evaluator]: [0mInference done 1837/3489. 0.2065 s / img. ETA=0:06:24
[32m[03/28 21:28:06 d2.evaluation.evaluator]: [0mInference done 1854/3489. 0.2066 s / img. ETA=0:06:21
[32m[03/28 21:28:11 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2068 s / img. ETA=0:06:17
[32m[03/28 21:28:16 d2.evaluation.evaluator]: [0mInference done 1890/3489. 0.2069 s / img. ETA=0:06:14
[32m[03/28 21:28:21 d2.evaluation.evaluator]: [0mInference done 1908/3489. 0.2070 s / img. ETA=0:06:11
[32m[03/28 21:28:26 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2071 s / img. ETA=0:06:07
[32m[03/28 21:28:31 d2.evaluation.evaluator]: [0mInference done 1944/3489. 0.2073 s / img. ETA=0:06:03
[32m[03/28 21:28:36 d2.evaluation.evaluator]: [0mInference done 1962/3489. 0.2074 s / img. ETA=0:06:00
[32m[03/28 21:28:42 d2.evaluation.evaluator]: [0mInference done 1980/3489. 0.2075 s / img. ETA=0:05:56
[32m[03/28 21:28:47 d2.evaluation.evaluator]: [0mInference done 2000/3489. 0.2076 s / img. ETA=0:05:52
[32m[03/28 21:28:52 d2.evaluation.evaluator]: [0mInference done 2021/3489. 0.2076 s / img. ETA=0:05:47
[32m[03/28 21:28:57 d2.evaluation.evaluator]: [0mInference done 2042/3489. 0.2076 s / img. ETA=0:05:42
[32m[03/28 21:29:02 d2.evaluation.evaluator]: [0mInference done 2062/3489. 0.2076 s / img. ETA=0:05:38
[32m[03/28 21:29:07 d2.evaluation.evaluator]: [0mInference done 2081/3489. 0.2077 s / img. ETA=0:05:34
[32m[03/28 21:29:13 d2.evaluation.evaluator]: [0mInference done 2100/3489. 0.2078 s / img. ETA=0:05:30
[32m[03/28 21:29:18 d2.evaluation.evaluator]: [0mInference done 2119/3489. 0.2079 s / img. ETA=0:05:26
[32m[03/28 21:29:23 d2.evaluation.evaluator]: [0mInference done 2137/3489. 0.2080 s / img. ETA=0:05:22
[32m[03/28 21:29:28 d2.evaluation.evaluator]: [0mInference done 2155/3489. 0.2081 s / img. ETA=0:05:18
[32m[03/28 21:29:33 d2.evaluation.evaluator]: [0mInference done 2173/3489. 0.2082 s / img. ETA=0:05:14
[32m[03/28 21:29:38 d2.evaluation.evaluator]: [0mInference done 2192/3489. 0.2082 s / img. ETA=0:05:10
[32m[03/28 21:29:43 d2.evaluation.evaluator]: [0mInference done 2209/3489. 0.2083 s / img. ETA=0:05:07
[32m[03/28 21:29:48 d2.evaluation.evaluator]: [0mInference done 2228/3489. 0.2084 s / img. ETA=0:05:02
[32m[03/28 21:29:53 d2.evaluation.evaluator]: [0mInference done 2247/3489. 0.2085 s / img. ETA=0:04:58
[32m[03/28 21:29:59 d2.evaluation.evaluator]: [0mInference done 2267/3489. 0.2085 s / img. ETA=0:04:53
[32m[03/28 21:30:04 d2.evaluation.evaluator]: [0mInference done 2287/3489. 0.2085 s / img. ETA=0:04:49
[32m[03/28 21:30:09 d2.evaluation.evaluator]: [0mInference done 2307/3489. 0.2086 s / img. ETA=0:04:44
[32m[03/28 21:30:14 d2.evaluation.evaluator]: [0mInference done 2326/3489. 0.2086 s / img. ETA=0:04:40
[32m[03/28 21:30:19 d2.evaluation.evaluator]: [0mInference done 2345/3489. 0.2087 s / img. ETA=0:04:36
[32m[03/28 21:30:24 d2.evaluation.evaluator]: [0mInference done 2365/3489. 0.2087 s / img. ETA=0:04:31
[32m[03/28 21:30:29 d2.evaluation.evaluator]: [0mInference done 2387/3489. 0.2087 s / img. ETA=0:04:25
[32m[03/28 21:30:34 d2.evaluation.evaluator]: [0mInference done 2409/3489. 0.2087 s / img. ETA=0:04:20
[32m[03/28 21:30:39 d2.evaluation.evaluator]: [0mInference done 2431/3489. 0.2086 s / img. ETA=0:04:15
[32m[03/28 21:30:45 d2.evaluation.evaluator]: [0mInference done 2451/3489. 0.2087 s / img. ETA=0:04:10
[32m[03/28 21:30:50 d2.evaluation.evaluator]: [0mInference done 2471/3489. 0.2087 s / img. ETA=0:04:05
[32m[03/28 21:30:55 d2.evaluation.evaluator]: [0mInference done 2491/3489. 0.2088 s / img. ETA=0:04:01
[32m[03/28 21:31:00 d2.evaluation.evaluator]: [0mInference done 2515/3489. 0.2087 s / img. ETA=0:03:54
[32m[03/28 21:31:05 d2.evaluation.evaluator]: [0mInference done 2538/3489. 0.2086 s / img. ETA=0:03:49
[32m[03/28 21:31:10 d2.evaluation.evaluator]: [0mInference done 2561/3489. 0.2086 s / img. ETA=0:03:43
[32m[03/28 21:31:15 d2.evaluation.evaluator]: [0mInference done 2584/3489. 0.2086 s / img. ETA=0:03:37
[32m[03/28 21:31:20 d2.evaluation.evaluator]: [0mInference done 2608/3489. 0.2085 s / img. ETA=0:03:31
[32m[03/28 21:31:25 d2.evaluation.evaluator]: [0mInference done 2632/3489. 0.2084 s / img. ETA=0:03:25
[32m[03/28 21:31:30 d2.evaluation.evaluator]: [0mInference done 2656/3489. 0.2083 s / img. ETA=0:03:19
[32m[03/28 21:31:36 d2.evaluation.evaluator]: [0mInference done 2678/3489. 0.2083 s / img. ETA=0:03:14
[32m[03/28 21:31:41 d2.evaluation.evaluator]: [0mInference done 2701/3489. 0.2083 s / img. ETA=0:03:08
[32m[03/28 21:31:46 d2.evaluation.evaluator]: [0mInference done 2724/3489. 0.2082 s / img. ETA=0:03:03
[32m[03/28 21:31:51 d2.evaluation.evaluator]: [0mInference done 2747/3489. 0.2082 s / img. ETA=0:02:57
[32m[03/28 21:31:56 d2.evaluation.evaluator]: [0mInference done 2770/3489. 0.2081 s / img. ETA=0:02:52
[32m[03/28 21:32:01 d2.evaluation.evaluator]: [0mInference done 2793/3489. 0.2081 s / img. ETA=0:02:46
[32m[03/28 21:32:06 d2.evaluation.evaluator]: [0mInference done 2816/3489. 0.2081 s / img. ETA=0:02:40
[32m[03/28 21:32:12 d2.evaluation.evaluator]: [0mInference done 2839/3489. 0.2080 s / img. ETA=0:02:35
[32m[03/28 21:32:17 d2.evaluation.evaluator]: [0mInference done 2862/3489. 0.2080 s / img. ETA=0:02:29
[32m[03/28 21:32:22 d2.evaluation.evaluator]: [0mInference done 2885/3489. 0.2079 s / img. ETA=0:02:24
[32m[03/28 21:32:27 d2.evaluation.evaluator]: [0mInference done 2909/3489. 0.2079 s / img. ETA=0:02:18
[32m[03/28 21:32:32 d2.evaluation.evaluator]: [0mInference done 2933/3489. 0.2078 s / img. ETA=0:02:12
[32m[03/28 21:32:37 d2.evaluation.evaluator]: [0mInference done 2957/3489. 0.2078 s / img. ETA=0:02:06
[32m[03/28 21:32:42 d2.evaluation.evaluator]: [0mInference done 2981/3489. 0.2077 s / img. ETA=0:02:00
[32m[03/28 21:32:47 d2.evaluation.evaluator]: [0mInference done 3003/3489. 0.2077 s / img. ETA=0:01:55
[32m[03/28 21:32:52 d2.evaluation.evaluator]: [0mInference done 3026/3489. 0.2077 s / img. ETA=0:01:50
[32m[03/28 21:32:57 d2.evaluation.evaluator]: [0mInference done 3049/3489. 0.2076 s / img. ETA=0:01:44
[32m[03/28 21:33:03 d2.evaluation.evaluator]: [0mInference done 3072/3489. 0.2076 s / img. ETA=0:01:39
[32m[03/28 21:33:08 d2.evaluation.evaluator]: [0mInference done 3094/3489. 0.2076 s / img. ETA=0:01:33
[32m[03/28 21:33:13 d2.evaluation.evaluator]: [0mInference done 3117/3489. 0.2076 s / img. ETA=0:01:28
[32m[03/28 21:33:18 d2.evaluation.evaluator]: [0mInference done 3140/3489. 0.2075 s / img. ETA=0:01:22
[32m[03/28 21:33:23 d2.evaluation.evaluator]: [0mInference done 3163/3489. 0.2075 s / img. ETA=0:01:17
[32m[03/28 21:33:28 d2.evaluation.evaluator]: [0mInference done 3187/3489. 0.2075 s / img. ETA=0:01:11
[32m[03/28 21:33:33 d2.evaluation.evaluator]: [0mInference done 3210/3489. 0.2074 s / img. ETA=0:01:06
[32m[03/28 21:33:39 d2.evaluation.evaluator]: [0mInference done 3233/3489. 0.2074 s / img. ETA=0:01:00
[32m[03/28 21:33:44 d2.evaluation.evaluator]: [0mInference done 3256/3489. 0.2074 s / img. ETA=0:00:55
[32m[03/28 21:33:49 d2.evaluation.evaluator]: [0mInference done 3280/3489. 0.2073 s / img. ETA=0:00:49
[32m[03/28 21:33:54 d2.evaluation.evaluator]: [0mInference done 3305/3489. 0.2073 s / img. ETA=0:00:43
[32m[03/28 21:33:59 d2.evaluation.evaluator]: [0mInference done 3330/3489. 0.2072 s / img. ETA=0:00:37
[32m[03/28 21:34:04 d2.evaluation.evaluator]: [0mInference done 3355/3489. 0.2071 s / img. ETA=0:00:31
[32m[03/28 21:34:09 d2.evaluation.evaluator]: [0mInference done 3380/3489. 0.2071 s / img. ETA=0:00:25
[32m[03/28 21:34:14 d2.evaluation.evaluator]: [0mInference done 3404/3489. 0.2070 s / img. ETA=0:00:20
[32m[03/28 21:34:19 d2.evaluation.evaluator]: [0mInference done 3428/3489. 0.2070 s / img. ETA=0:00:14
[32m[03/28 21:34:24 d2.evaluation.evaluator]: [0mInference done 3452/3489. 0.2069 s / img. ETA=0:00:08
[32m[03/28 21:34:29 d2.evaluation.evaluator]: [0mInference done 3476/3489. 0.2069 s / img. ETA=0:00:03
[32m[03/28 21:34:32 d2.evaluation.evaluator]: [0mTotal inference time: 0:13:37.771920 (0.234722 s / img per device, on 1 devices)
[32m[03/28 21:34:32 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:00 (0.206849 s / img per device, on 1 devices)
[32m[03/28 21:34:34 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:34:34 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_2000.000000/coco_instances_results.json
[32m[03/28 21:34:35 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.55 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.46 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778
[32m[03/28 21:34:37 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.227 | 77.332 | 49.050 | 30.342 | 56.382 | 59.785 |
[32m[03/28 21:34:37 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 59.476 | Pedestrian | 34.978 |
Loading and preparing results...
DONE (t=1.62s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.01 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.49 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[32m[03/28 21:34:45 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.154 | 74.499 | 43.683 | 22.666 | 53.329 | 69.904 |
[32m[03/28 21:34:45 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.888 | Pedestrian | 27.421 |
[32m[03/28 21:34:45 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: 47.2271,77.3319,49.0501,30.3420,56.3822,59.7848
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:34:45 d2.evaluation.testing]: [0mcopypaste: 44.1541,74.4988,43.6827,22.6660,53.3285,69.9045
evaluated
Test [4000]
[32m[03/28 21:34:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:34:46 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:34:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:34:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:34:46 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:34:46 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:34:47 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:34:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:34:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:34:47 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:34:47 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:34:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:35:10 d2.utils.events]: [0m eta: 0:02:16  iter: 19  total_loss: 1.964  loss_cls: 0.7939  loss_box_reg: 0.2992  loss_mask: 0.6504  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.003949  total_val_loss: 2.078  val_loss_cls: 0.7739  val_loss_box_reg: 0.4923  val_loss_mask: 0.6791  val_loss_rpn_cls: 0.0399  val_loss_rpn_loc: 0.01396  time: 0.7601  data_time: 0.0291  lr: 0.00019981  max_mem: 4743M
[32m[03/28 21:35:31 d2.utils.events]: [0m eta: 0:02:01  iter: 39  total_loss: 0.9824  loss_cls: 0.188  loss_box_reg: 0.4064  loss_mask: 0.3604  loss_rpn_cls: 0.0201  loss_rpn_loc: 0.008743  total_val_loss: 1.328  val_loss_cls: 0.2676  val_loss_box_reg: 0.4514  val_loss_mask: 0.5111  val_loss_rpn_cls: 0.04798  val_loss_rpn_loc: 0.01103  time: 0.7633  data_time: 0.0069  lr: 0.00039961  max_mem: 4743M
[32m[03/28 21:35:53 d2.utils.events]: [0m eta: 0:01:46  iter: 59  total_loss: 0.506  loss_cls: 0.06571  loss_box_reg: 0.243  loss_mask: 0.2031  loss_rpn_cls: 0.009969  loss_rpn_loc: 0.006266  total_val_loss: 0.9684  val_loss_cls: 0.1588  val_loss_box_reg: 0.4839  val_loss_mask: 0.4892  val_loss_rpn_cls: 0.02921  val_loss_rpn_loc: 0.01091  time: 0.7648  data_time: 0.0067  lr: 0.00059941  max_mem: 4743M
[32m[03/28 21:36:14 d2.utils.events]: [0m eta: 0:01:31  iter: 79  total_loss: 0.6247  loss_cls: 0.07999  loss_box_reg: 0.2735  loss_mask: 0.189  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.008808  total_val_loss: 0.9749  val_loss_cls: 0.1888  val_loss_box_reg: 0.3791  val_loss_mask: 0.3945  val_loss_rpn_cls: 0.02498  val_loss_rpn_loc: 0.01133  time: 0.7667  data_time: 0.0063  lr: 0.00079921  max_mem: 4743M
[32m[03/28 21:36:36 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:36:36 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:36:36 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:36:36 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:36:36 d2.utils.events]: [0m eta: 0:01:16  iter: 99  total_loss: 0.3387  loss_cls: 0.03763  loss_box_reg: 0.1317  loss_mask: 0.1521  loss_rpn_cls: 0.005227  loss_rpn_loc: 0.005326  total_val_loss: 1.152  val_loss_cls: 0.2785  val_loss_box_reg: 0.3297  val_loss_mask: 0.4516  val_loss_rpn_cls: 0.01851  val_loss_rpn_loc: 0.014  time: 0.7671  data_time: 0.0081  lr: 0.00099901  max_mem: 4743M
[32m[03/28 21:36:58 d2.utils.events]: [0m eta: 0:01:01  iter: 119  total_loss: 0.3282  loss_cls: 0.04544  loss_box_reg: 0.1004  loss_mask: 0.1568  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.008313  total_val_loss: 0.7266  val_loss_cls: 0.1588  val_loss_box_reg: 0.2031  val_loss_mask: 0.2937  val_loss_rpn_cls: 0.01896  val_loss_rpn_loc: 0.01122  time: 0.7676  data_time: 0.0073  lr: 0.0011988  max_mem: 4743M
[32m[03/28 21:37:20 d2.utils.events]: [0m eta: 0:00:46  iter: 139  total_loss: 0.3241  loss_cls: 0.04137  loss_box_reg: 0.09929  loss_mask: 0.1469  loss_rpn_cls: 0.005479  loss_rpn_loc: 0.00878  total_val_loss: 0.7691  val_loss_cls: 0.1713  val_loss_box_reg: 0.2125  val_loss_mask: 0.3303  val_loss_rpn_cls: 0.02588  val_loss_rpn_loc: 0.009228  time: 0.7699  data_time: 0.0077  lr: 0.0013986  max_mem: 4743M
[32m[03/28 21:37:42 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.34  loss_cls: 0.03586  loss_box_reg: 0.1067  loss_mask: 0.1785  loss_rpn_cls: 0.003964  loss_rpn_loc: 0.00769  total_val_loss: 0.8488  val_loss_cls: 0.1658  val_loss_box_reg: 0.2363  val_loss_mask: 0.3768  val_loss_rpn_cls: 0.01995  val_loss_rpn_loc: 0.01422  time: 0.7711  data_time: 0.0070  lr: 0.0015984  max_mem: 4744M
[32m[03/28 21:38:04 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.3735  loss_cls: 0.05802  loss_box_reg: 0.1343  loss_mask: 0.1352  loss_rpn_cls: 0.008319  loss_rpn_loc: 0.01266  total_val_loss: 0.7826  val_loss_cls: 0.1526  val_loss_box_reg: 0.251  val_loss_mask: 0.3725  val_loss_rpn_cls: 0.01793  val_loss_rpn_loc: 0.01153  time: 0.7715  data_time: 0.0068  lr: 0.0017982  max_mem: 4744M
[32m[03/28 21:38:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:38:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:38:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:38:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:38:27 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4174  loss_cls: 0.06559  loss_box_reg: 0.141  loss_mask: 0.1964  loss_rpn_cls: 0.008066  loss_rpn_loc: 0.006737  total_val_loss: 0.751  val_loss_cls: 0.1401  val_loss_box_reg: 0.2163  val_loss_mask: 0.3101  val_loss_rpn_cls: 0.02122  val_loss_rpn_loc: 0.01508  time: 0.7728  data_time: 0.0067  lr: 0.001998  max_mem: 4744M
[32m[03/28 21:38:27 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:33 (0.7728 s / it)
[32m[03/28 21:38:27 d2.engine.hooks]: [0mTotal training time: 0:03:36 (0:01:03 on hooks)
[32m[03/28 21:38:28 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:38:28 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:38:28 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:38:28 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:38:28 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:38:28 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:38:28 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:38:28 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:38:28 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:38:31 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2027 s / img. ETA=0:12:56
[32m[03/28 21:38:36 d2.evaluation.evaluator]: [0mInference done 34/3489. 0.2025 s / img. ETA=0:12:37
[32m[03/28 21:38:41 d2.evaluation.evaluator]: [0mInference done 58/3489. 0.2016 s / img. ETA=0:12:22
[32m[03/28 21:38:46 d2.evaluation.evaluator]: [0mInference done 81/3489. 0.2020 s / img. ETA=0:12:21
[32m[03/28 21:38:51 d2.evaluation.evaluator]: [0mInference done 101/3489. 0.2038 s / img. ETA=0:12:40
[32m[03/28 21:38:57 d2.evaluation.evaluator]: [0mInference done 120/3489. 0.2060 s / img. ETA=0:13:04
[32m[03/28 21:39:02 d2.evaluation.evaluator]: [0mInference done 137/3489. 0.2084 s / img. ETA=0:13:28
[32m[03/28 21:39:07 d2.evaluation.evaluator]: [0mInference done 154/3489. 0.2103 s / img. ETA=0:13:45
[32m[03/28 21:39:12 d2.evaluation.evaluator]: [0mInference done 171/3489. 0.2118 s / img. ETA=0:13:58
[32m[03/28 21:39:17 d2.evaluation.evaluator]: [0mInference done 190/3489. 0.2125 s / img. ETA=0:14:01
[32m[03/28 21:39:22 d2.evaluation.evaluator]: [0mInference done 211/3489. 0.2122 s / img. ETA=0:13:52
[32m[03/28 21:39:27 d2.evaluation.evaluator]: [0mInference done 232/3489. 0.2119 s / img. ETA=0:13:44
[32m[03/28 21:39:33 d2.evaluation.evaluator]: [0mInference done 251/3489. 0.2128 s / img. ETA=0:13:44
[32m[03/28 21:39:38 d2.evaluation.evaluator]: [0mInference done 271/3489. 0.2128 s / img. ETA=0:13:40
[32m[03/28 21:39:43 d2.evaluation.evaluator]: [0mInference done 291/3489. 0.2129 s / img. ETA=0:13:35
[32m[03/28 21:39:48 d2.evaluation.evaluator]: [0mInference done 310/3489. 0.2133 s / img. ETA=0:13:35
[32m[03/28 21:39:53 d2.evaluation.evaluator]: [0mInference done 329/3489. 0.2134 s / img. ETA=0:13:32
[32m[03/28 21:39:58 d2.evaluation.evaluator]: [0mInference done 347/3489. 0.2139 s / img. ETA=0:13:32
[32m[03/28 21:40:04 d2.evaluation.evaluator]: [0mInference done 366/3489. 0.2141 s / img. ETA=0:13:30
[32m[03/28 21:40:09 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2142 s / img. ETA=0:13:27
[32m[03/28 21:40:14 d2.evaluation.evaluator]: [0mInference done 405/3489. 0.2143 s / img. ETA=0:13:22
[32m[03/28 21:40:19 d2.evaluation.evaluator]: [0mInference done 425/3489. 0.2142 s / img. ETA=0:13:16
[32m[03/28 21:40:24 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2136 s / img. ETA=0:13:04
[32m[03/28 21:40:29 d2.evaluation.evaluator]: [0mInference done 471/3489. 0.2132 s / img. ETA=0:12:52
[32m[03/28 21:40:34 d2.evaluation.evaluator]: [0mInference done 495/3489. 0.2126 s / img. ETA=0:12:40
[32m[03/28 21:40:39 d2.evaluation.evaluator]: [0mInference done 519/3489. 0.2121 s / img. ETA=0:12:28
[32m[03/28 21:40:44 d2.evaluation.evaluator]: [0mInference done 543/3489. 0.2115 s / img. ETA=0:12:16
[32m[03/28 21:40:50 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2113 s / img. ETA=0:12:09
[32m[03/28 21:40:55 d2.evaluation.evaluator]: [0mInference done 585/3489. 0.2114 s / img. ETA=0:12:04
[32m[03/28 21:41:00 d2.evaluation.evaluator]: [0mInference done 605/3489. 0.2114 s / img. ETA=0:11:59
[32m[03/28 21:41:05 d2.evaluation.evaluator]: [0mInference done 625/3489. 0.2114 s / img. ETA=0:11:54
[32m[03/28 21:41:10 d2.evaluation.evaluator]: [0mInference done 645/3489. 0.2114 s / img. ETA=0:11:50
[32m[03/28 21:41:15 d2.evaluation.evaluator]: [0mInference done 666/3489. 0.2113 s / img. ETA=0:11:43
[32m[03/28 21:41:20 d2.evaluation.evaluator]: [0mInference done 689/3489. 0.2111 s / img. ETA=0:11:35
[32m[03/28 21:41:25 d2.evaluation.evaluator]: [0mInference done 711/3489. 0.2108 s / img. ETA=0:11:28
[32m[03/28 21:41:30 d2.evaluation.evaluator]: [0mInference done 733/3489. 0.2106 s / img. ETA=0:11:21
[32m[03/28 21:41:35 d2.evaluation.evaluator]: [0mInference done 756/3489. 0.2104 s / img. ETA=0:11:13
[32m[03/28 21:41:40 d2.evaluation.evaluator]: [0mInference done 780/3489. 0.2101 s / img. ETA=0:11:05
[32m[03/28 21:41:45 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2099 s / img. ETA=0:10:56
[32m[03/28 21:41:50 d2.evaluation.evaluator]: [0mInference done 828/3489. 0.2096 s / img. ETA=0:10:48
[32m[03/28 21:41:55 d2.evaluation.evaluator]: [0mInference done 852/3489. 0.2093 s / img. ETA=0:10:39
[32m[03/28 21:42:01 d2.evaluation.evaluator]: [0mInference done 876/3489. 0.2091 s / img. ETA=0:10:32
[32m[03/28 21:42:06 d2.evaluation.evaluator]: [0mInference done 900/3489. 0.2089 s / img. ETA=0:10:23
[32m[03/28 21:42:11 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2091 s / img. ETA=0:10:21
[32m[03/28 21:42:16 d2.evaluation.evaluator]: [0mInference done 936/3489. 0.2094 s / img. ETA=0:10:19
[32m[03/28 21:42:21 d2.evaluation.evaluator]: [0mInference done 954/3489. 0.2096 s / img. ETA=0:10:17
[32m[03/28 21:42:26 d2.evaluation.evaluator]: [0mInference done 972/3489. 0.2099 s / img. ETA=0:10:14
[32m[03/28 21:42:31 d2.evaluation.evaluator]: [0mInference done 990/3489. 0.2102 s / img. ETA=0:10:12
[32m[03/28 21:42:37 d2.evaluation.evaluator]: [0mInference done 1008/3489. 0.2104 s / img. ETA=0:10:10
[32m[03/28 21:42:42 d2.evaluation.evaluator]: [0mInference done 1026/3489. 0.2107 s / img. ETA=0:10:07
[32m[03/28 21:42:47 d2.evaluation.evaluator]: [0mInference done 1044/3489. 0.2109 s / img. ETA=0:10:05
[32m[03/28 21:42:52 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2111 s / img. ETA=0:10:02
[32m[03/28 21:42:58 d2.evaluation.evaluator]: [0mInference done 1081/3489. 0.2113 s / img. ETA=0:09:58
[32m[03/28 21:43:03 d2.evaluation.evaluator]: [0mInference done 1102/3489. 0.2113 s / img. ETA=0:09:53
[32m[03/28 21:43:08 d2.evaluation.evaluator]: [0mInference done 1122/3489. 0.2113 s / img. ETA=0:09:49
[32m[03/28 21:43:13 d2.evaluation.evaluator]: [0mInference done 1139/3489. 0.2115 s / img. ETA=0:09:46
[32m[03/28 21:43:18 d2.evaluation.evaluator]: [0mInference done 1157/3489. 0.2116 s / img. ETA=0:09:43
[32m[03/28 21:43:23 d2.evaluation.evaluator]: [0mInference done 1175/3489. 0.2118 s / img. ETA=0:09:40
[32m[03/28 21:43:28 d2.evaluation.evaluator]: [0mInference done 1194/3489. 0.2119 s / img. ETA=0:09:35
[32m[03/28 21:43:34 d2.evaluation.evaluator]: [0mInference done 1214/3489. 0.2119 s / img. ETA=0:09:31
[32m[03/28 21:43:39 d2.evaluation.evaluator]: [0mInference done 1234/3489. 0.2119 s / img. ETA=0:09:26
[32m[03/28 21:43:44 d2.evaluation.evaluator]: [0mInference done 1254/3489. 0.2119 s / img. ETA=0:09:21
[32m[03/28 21:43:49 d2.evaluation.evaluator]: [0mInference done 1279/3489. 0.2116 s / img. ETA=0:09:13
[32m[03/28 21:43:54 d2.evaluation.evaluator]: [0mInference done 1304/3489. 0.2114 s / img. ETA=0:09:05
[32m[03/28 21:43:59 d2.evaluation.evaluator]: [0mInference done 1329/3489. 0.2112 s / img. ETA=0:08:57
[32m[03/28 21:44:04 d2.evaluation.evaluator]: [0mInference done 1354/3489. 0.2110 s / img. ETA=0:08:49
[32m[03/28 21:44:10 d2.evaluation.evaluator]: [0mInference done 1379/3489. 0.2108 s / img. ETA=0:08:41
[32m[03/28 21:44:15 d2.evaluation.evaluator]: [0mInference done 1404/3489. 0.2106 s / img. ETA=0:08:33
[32m[03/28 21:44:20 d2.evaluation.evaluator]: [0mInference done 1428/3489. 0.2104 s / img. ETA=0:08:26
[32m[03/28 21:44:25 d2.evaluation.evaluator]: [0mInference done 1452/3489. 0.2103 s / img. ETA=0:08:19
[32m[03/28 21:44:30 d2.evaluation.evaluator]: [0mInference done 1476/3489. 0.2101 s / img. ETA=0:08:12
[32m[03/28 21:44:35 d2.evaluation.evaluator]: [0mInference done 1501/3489. 0.2099 s / img. ETA=0:08:05
[32m[03/28 21:44:40 d2.evaluation.evaluator]: [0mInference done 1526/3489. 0.2098 s / img. ETA=0:07:58
[32m[03/28 21:44:46 d2.evaluation.evaluator]: [0mInference done 1550/3489. 0.2096 s / img. ETA=0:07:51
[32m[03/28 21:44:51 d2.evaluation.evaluator]: [0mInference done 1574/3489. 0.2095 s / img. ETA=0:07:44
[32m[03/28 21:44:56 d2.evaluation.evaluator]: [0mInference done 1597/3489. 0.2094 s / img. ETA=0:07:38
[32m[03/28 21:45:01 d2.evaluation.evaluator]: [0mInference done 1617/3489. 0.2095 s / img. ETA=0:07:34
[32m[03/28 21:45:06 d2.evaluation.evaluator]: [0mInference done 1637/3489. 0.2095 s / img. ETA=0:07:29
[32m[03/28 21:45:11 d2.evaluation.evaluator]: [0mInference done 1658/3489. 0.2096 s / img. ETA=0:07:24
[32m[03/28 21:45:16 d2.evaluation.evaluator]: [0mInference done 1677/3489. 0.2096 s / img. ETA=0:07:20
[32m[03/28 21:45:22 d2.evaluation.evaluator]: [0mInference done 1695/3489. 0.2098 s / img. ETA=0:07:17
[32m[03/28 21:45:27 d2.evaluation.evaluator]: [0mInference done 1713/3489. 0.2099 s / img. ETA=0:07:13
[32m[03/28 21:45:32 d2.evaluation.evaluator]: [0mInference done 1731/3489. 0.2101 s / img. ETA=0:07:10
[32m[03/28 21:45:37 d2.evaluation.evaluator]: [0mInference done 1748/3489. 0.2102 s / img. ETA=0:07:06
[32m[03/28 21:45:42 d2.evaluation.evaluator]: [0mInference done 1765/3489. 0.2104 s / img. ETA=0:07:03
[32m[03/28 21:45:47 d2.evaluation.evaluator]: [0mInference done 1782/3489. 0.2105 s / img. ETA=0:07:00
[32m[03/28 21:45:52 d2.evaluation.evaluator]: [0mInference done 1799/3489. 0.2106 s / img. ETA=0:06:56
[32m[03/28 21:45:58 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2108 s / img. ETA=0:06:53
[32m[03/28 21:46:03 d2.evaluation.evaluator]: [0mInference done 1833/3489. 0.2109 s / img. ETA=0:06:50
[32m[03/28 21:46:08 d2.evaluation.evaluator]: [0mInference done 1850/3489. 0.2110 s / img. ETA=0:06:46
[32m[03/28 21:46:13 d2.evaluation.evaluator]: [0mInference done 1867/3489. 0.2112 s / img. ETA=0:06:43
[32m[03/28 21:46:18 d2.evaluation.evaluator]: [0mInference done 1884/3489. 0.2113 s / img. ETA=0:06:39
[32m[03/28 21:46:23 d2.evaluation.evaluator]: [0mInference done 1901/3489. 0.2114 s / img. ETA=0:06:35
[32m[03/28 21:46:28 d2.evaluation.evaluator]: [0mInference done 1918/3489. 0.2115 s / img. ETA=0:06:32
[32m[03/28 21:46:33 d2.evaluation.evaluator]: [0mInference done 1935/3489. 0.2116 s / img. ETA=0:06:28
[32m[03/28 21:46:38 d2.evaluation.evaluator]: [0mInference done 1952/3489. 0.2118 s / img. ETA=0:06:25
[32m[03/28 21:46:43 d2.evaluation.evaluator]: [0mInference done 1969/3489. 0.2119 s / img. ETA=0:06:21
[32m[03/28 21:46:48 d2.evaluation.evaluator]: [0mInference done 1986/3489. 0.2120 s / img. ETA=0:06:17
[32m[03/28 21:46:53 d2.evaluation.evaluator]: [0mInference done 2004/3489. 0.2120 s / img. ETA=0:06:13
[32m[03/28 21:46:58 d2.evaluation.evaluator]: [0mInference done 2023/3489. 0.2121 s / img. ETA=0:06:09
[32m[03/28 21:47:03 d2.evaluation.evaluator]: [0mInference done 2041/3489. 0.2122 s / img. ETA=0:06:04
[32m[03/28 21:47:08 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2122 s / img. ETA=0:06:00
[32m[03/28 21:47:14 d2.evaluation.evaluator]: [0mInference done 2077/3489. 0.2124 s / img. ETA=0:05:56
[32m[03/28 21:47:19 d2.evaluation.evaluator]: [0mInference done 2095/3489. 0.2124 s / img. ETA=0:05:52
[32m[03/28 21:47:24 d2.evaluation.evaluator]: [0mInference done 2112/3489. 0.2125 s / img. ETA=0:05:48
[32m[03/28 21:47:29 d2.evaluation.evaluator]: [0mInference done 2129/3489. 0.2126 s / img. ETA=0:05:45
[32m[03/28 21:47:34 d2.evaluation.evaluator]: [0mInference done 2146/3489. 0.2127 s / img. ETA=0:05:41
[32m[03/28 21:47:39 d2.evaluation.evaluator]: [0mInference done 2163/3489. 0.2128 s / img. ETA=0:05:37
[32m[03/28 21:47:44 d2.evaluation.evaluator]: [0mInference done 2181/3489. 0.2129 s / img. ETA=0:05:33
[32m[03/28 21:47:50 d2.evaluation.evaluator]: [0mInference done 2199/3489. 0.2130 s / img. ETA=0:05:29
[32m[03/28 21:47:55 d2.evaluation.evaluator]: [0mInference done 2216/3489. 0.2131 s / img. ETA=0:05:25
[32m[03/28 21:48:00 d2.evaluation.evaluator]: [0mInference done 2234/3489. 0.2132 s / img. ETA=0:05:20
[32m[03/28 21:48:05 d2.evaluation.evaluator]: [0mInference done 2252/3489. 0.2132 s / img. ETA=0:05:16
[32m[03/28 21:48:10 d2.evaluation.evaluator]: [0mInference done 2270/3489. 0.2133 s / img. ETA=0:05:12
[32m[03/28 21:48:15 d2.evaluation.evaluator]: [0mInference done 2288/3489. 0.2133 s / img. ETA=0:05:07
[32m[03/28 21:48:20 d2.evaluation.evaluator]: [0mInference done 2306/3489. 0.2134 s / img. ETA=0:05:03
[32m[03/28 21:48:26 d2.evaluation.evaluator]: [0mInference done 2324/3489. 0.2135 s / img. ETA=0:04:59
[32m[03/28 21:48:31 d2.evaluation.evaluator]: [0mInference done 2342/3489. 0.2136 s / img. ETA=0:04:55
[32m[03/28 21:48:36 d2.evaluation.evaluator]: [0mInference done 2361/3489. 0.2136 s / img. ETA=0:04:50
[32m[03/28 21:48:41 d2.evaluation.evaluator]: [0mInference done 2382/3489. 0.2136 s / img. ETA=0:04:44
[32m[03/28 21:48:46 d2.evaluation.evaluator]: [0mInference done 2402/3489. 0.2136 s / img. ETA=0:04:39
[32m[03/28 21:48:52 d2.evaluation.evaluator]: [0mInference done 2422/3489. 0.2136 s / img. ETA=0:04:34
[32m[03/28 21:48:57 d2.evaluation.evaluator]: [0mInference done 2441/3489. 0.2136 s / img. ETA=0:04:29
[32m[03/28 21:49:02 d2.evaluation.evaluator]: [0mInference done 2460/3489. 0.2136 s / img. ETA=0:04:24
[32m[03/28 21:49:07 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2137 s / img. ETA=0:04:20
[32m[03/28 21:49:12 d2.evaluation.evaluator]: [0mInference done 2501/3489. 0.2136 s / img. ETA=0:04:14
[32m[03/28 21:49:17 d2.evaluation.evaluator]: [0mInference done 2524/3489. 0.2135 s / img. ETA=0:04:07
[32m[03/28 21:49:22 d2.evaluation.evaluator]: [0mInference done 2547/3489. 0.2134 s / img. ETA=0:04:01
[32m[03/28 21:49:28 d2.evaluation.evaluator]: [0mInference done 2569/3489. 0.2134 s / img. ETA=0:03:55
[32m[03/28 21:49:33 d2.evaluation.evaluator]: [0mInference done 2592/3489. 0.2133 s / img. ETA=0:03:49
[32m[03/28 21:49:38 d2.evaluation.evaluator]: [0mInference done 2615/3489. 0.2132 s / img. ETA=0:03:43
[32m[03/28 21:49:43 d2.evaluation.evaluator]: [0mInference done 2639/3489. 0.2131 s / img. ETA=0:03:37
[32m[03/28 21:49:48 d2.evaluation.evaluator]: [0mInference done 2663/3489. 0.2130 s / img. ETA=0:03:30
[32m[03/28 21:49:53 d2.evaluation.evaluator]: [0mInference done 2686/3489. 0.2129 s / img. ETA=0:03:24
[32m[03/28 21:49:58 d2.evaluation.evaluator]: [0mInference done 2710/3489. 0.2128 s / img. ETA=0:03:18
[32m[03/28 21:50:03 d2.evaluation.evaluator]: [0mInference done 2733/3489. 0.2127 s / img. ETA=0:03:12
[32m[03/28 21:50:08 d2.evaluation.evaluator]: [0mInference done 2756/3489. 0.2126 s / img. ETA=0:03:06
[32m[03/28 21:50:13 d2.evaluation.evaluator]: [0mInference done 2779/3489. 0.2125 s / img. ETA=0:03:00
[32m[03/28 21:50:18 d2.evaluation.evaluator]: [0mInference done 2802/3489. 0.2124 s / img. ETA=0:02:53
[32m[03/28 21:50:23 d2.evaluation.evaluator]: [0mInference done 2825/3489. 0.2124 s / img. ETA=0:02:47
[32m[03/28 21:50:28 d2.evaluation.evaluator]: [0mInference done 2848/3489. 0.2123 s / img. ETA=0:02:41
[32m[03/28 21:50:34 d2.evaluation.evaluator]: [0mInference done 2872/3489. 0.2122 s / img. ETA=0:02:35
[32m[03/28 21:50:39 d2.evaluation.evaluator]: [0mInference done 2896/3489. 0.2121 s / img. ETA=0:02:29
[32m[03/28 21:50:44 d2.evaluation.evaluator]: [0mInference done 2920/3489. 0.2120 s / img. ETA=0:02:23
[32m[03/28 21:50:49 d2.evaluation.evaluator]: [0mInference done 2944/3489. 0.2119 s / img. ETA=0:02:17
[32m[03/28 21:50:54 d2.evaluation.evaluator]: [0mInference done 2968/3489. 0.2118 s / img. ETA=0:02:10
[32m[03/28 21:50:59 d2.evaluation.evaluator]: [0mInference done 2992/3489. 0.2117 s / img. ETA=0:02:04
[32m[03/28 21:51:04 d2.evaluation.evaluator]: [0mInference done 3015/3489. 0.2117 s / img. ETA=0:01:58
[32m[03/28 21:51:09 d2.evaluation.evaluator]: [0mInference done 3039/3489. 0.2116 s / img. ETA=0:01:52
[32m[03/28 21:51:15 d2.evaluation.evaluator]: [0mInference done 3063/3489. 0.2115 s / img. ETA=0:01:46
[32m[03/28 21:51:20 d2.evaluation.evaluator]: [0mInference done 3086/3489. 0.2115 s / img. ETA=0:01:40
[32m[03/28 21:51:25 d2.evaluation.evaluator]: [0mInference done 3109/3489. 0.2114 s / img. ETA=0:01:34
[32m[03/28 21:51:30 d2.evaluation.evaluator]: [0mInference done 3132/3489. 0.2113 s / img. ETA=0:01:29
[32m[03/28 21:51:35 d2.evaluation.evaluator]: [0mInference done 3155/3489. 0.2113 s / img. ETA=0:01:23
[32m[03/28 21:51:40 d2.evaluation.evaluator]: [0mInference done 3179/3489. 0.2112 s / img. ETA=0:01:17
[32m[03/28 21:51:45 d2.evaluation.evaluator]: [0mInference done 3203/3489. 0.2111 s / img. ETA=0:01:11
[32m[03/28 21:51:50 d2.evaluation.evaluator]: [0mInference done 3226/3489. 0.2111 s / img. ETA=0:01:05
[32m[03/28 21:51:55 d2.evaluation.evaluator]: [0mInference done 3249/3489. 0.2110 s / img. ETA=0:00:59
[32m[03/28 21:52:01 d2.evaluation.evaluator]: [0mInference done 3273/3489. 0.2109 s / img. ETA=0:00:53
[32m[03/28 21:52:06 d2.evaluation.evaluator]: [0mInference done 3298/3489. 0.2109 s / img. ETA=0:00:47
[32m[03/28 21:52:11 d2.evaluation.evaluator]: [0mInference done 3323/3489. 0.2108 s / img. ETA=0:00:41
[32m[03/28 21:52:16 d2.evaluation.evaluator]: [0mInference done 3348/3489. 0.2107 s / img. ETA=0:00:34
[32m[03/28 21:52:21 d2.evaluation.evaluator]: [0mInference done 3372/3489. 0.2106 s / img. ETA=0:00:28
[32m[03/28 21:52:26 d2.evaluation.evaluator]: [0mInference done 3396/3489. 0.2105 s / img. ETA=0:00:22
[32m[03/28 21:52:31 d2.evaluation.evaluator]: [0mInference done 3420/3489. 0.2104 s / img. ETA=0:00:16
[32m[03/28 21:52:36 d2.evaluation.evaluator]: [0mInference done 3444/3489. 0.2104 s / img. ETA=0:00:11
[32m[03/28 21:52:41 d2.evaluation.evaluator]: [0mInference done 3467/3489. 0.2103 s / img. ETA=0:00:05
[32m[03/28 21:52:46 d2.evaluation.evaluator]: [0mTotal inference time: 0:14:16.212402 (0.245756 s / img per device, on 1 devices)
[32m[03/28 21:52:46 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:12 (0.210280 s / img per device, on 1 devices)
[32m[03/28 21:52:48 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 21:52:48 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_4000.000000/coco_instances_results.json
[32m[03/28 21:52:49 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.80 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.56 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832
[32m[03/28 21:52:52 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.601 | 76.491 | 49.211 | 29.739 | 56.997 | 68.689 |
[32m[03/28 21:52:52 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.970 | Pedestrian | 34.232 |
Loading and preparing results...
DONE (t=1.98s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.45 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.61 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.701
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725
[32m[03/28 21:53:02 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.723 | 70.052 | 38.796 | 21.497 | 51.062 | 68.514 |
[32m[03/28 21:53:02 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.306 | Pedestrian | 19.141 |
[32m[03/28 21:53:02 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: 48.6008,76.4912,49.2109,29.7388,56.9970,68.6895
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 21:53:02 d2.evaluation.testing]: [0mcopypaste: 40.7233,70.0518,38.7960,21.4968,51.0620,68.5143
evaluated
Test [8000]
[32m[03/28 21:53:03 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/28 21:53:03 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/28 21:53:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:53:03 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:53:03 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/28 21:53:03 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/28 21:53:04 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/28 21:53:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/28 21:53:04 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 21:53:04 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/28 21:53:04 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/28 21:53:04 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 21:53:27 d2.utils.events]: [0m eta: 0:02:14  iter: 19  total_loss: 1.785  loss_cls: 0.7971  loss_box_reg: 0.2257  loss_mask: 0.6564  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.004858  total_val_loss: 2.03  val_loss_cls: 0.7452  val_loss_box_reg: 0.4631  val_loss_mask: 0.676  val_loss_rpn_cls: 0.03716  val_loss_rpn_loc: 0.01146  time: 0.7619  data_time: 0.0297  lr: 0.00019981  max_mem: 4744M
[32m[03/28 21:53:48 d2.utils.events]: [0m eta: 0:02:01  iter: 39  total_loss: 0.8686  loss_cls: 0.1761  loss_box_reg: 0.3156  loss_mask: 0.3895  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.00776  total_val_loss: 1.426  val_loss_cls: 0.3109  val_loss_box_reg: 0.4901  val_loss_mask: 0.5438  val_loss_rpn_cls: 0.03792  val_loss_rpn_loc: 0.01775  time: 0.7642  data_time: 0.0069  lr: 0.00039961  max_mem: 4744M
[32m[03/28 21:54:10 d2.utils.events]: [0m eta: 0:01:46  iter: 59  total_loss: 0.6419  loss_cls: 0.09814  loss_box_reg: 0.2698  loss_mask: 0.2198  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.006361  total_val_loss: 1.043  val_loss_cls: 0.1841  val_loss_box_reg: 0.456  val_loss_mask: 0.3585  val_loss_rpn_cls: 0.02903  val_loss_rpn_loc: 0.01236  time: 0.7659  data_time: 0.0064  lr: 0.00059941  max_mem: 4744M
[32m[03/28 21:54:32 d2.utils.events]: [0m eta: 0:01:31  iter: 79  total_loss: 0.583  loss_cls: 0.07256  loss_box_reg: 0.2808  loss_mask: 0.1781  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.007896  total_val_loss: 0.9662  val_loss_cls: 0.1989  val_loss_box_reg: 0.3335  val_loss_mask: 0.4013  val_loss_rpn_cls: 0.02174  val_loss_rpn_loc: 0.00797  time: 0.7688  data_time: 0.0074  lr: 0.00079921  max_mem: 4744M
[32m[03/28 21:54:54 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:54:54 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:54:54 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:54:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:54:54 d2.utils.events]: [0m eta: 0:01:16  iter: 99  total_loss: 0.5139  loss_cls: 0.06953  loss_box_reg: 0.1912  loss_mask: 0.1845  loss_rpn_cls: 0.00986  loss_rpn_loc: 0.00655  total_val_loss: 0.8697  val_loss_cls: 0.1839  val_loss_box_reg: 0.2851  val_loss_mask: 0.391  val_loss_rpn_cls: 0.02978  val_loss_rpn_loc: 0.01365  time: 0.7689  data_time: 0.0061  lr: 0.00099901  max_mem: 4744M
[32m[03/28 21:55:16 d2.utils.events]: [0m eta: 0:01:01  iter: 119  total_loss: 0.3806  loss_cls: 0.06  loss_box_reg: 0.143  loss_mask: 0.1591  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.01162  total_val_loss: 0.8377  val_loss_cls: 0.1605  val_loss_box_reg: 0.265  val_loss_mask: 0.3845  val_loss_rpn_cls: 0.02374  val_loss_rpn_loc: 0.01554  time: 0.7691  data_time: 0.0065  lr: 0.0011988  max_mem: 4744M
[32m[03/28 21:55:37 d2.utils.events]: [0m eta: 0:00:46  iter: 139  total_loss: 0.3999  loss_cls: 0.07069  loss_box_reg: 0.14  loss_mask: 0.1648  loss_rpn_cls: 0.00838  loss_rpn_loc: 0.008392  total_val_loss: 0.5009  val_loss_cls: 0.1076  val_loss_box_reg: 0.2066  val_loss_mask: 0.2652  val_loss_rpn_cls: 0.01463  val_loss_rpn_loc: 0.01154  time: 0.7698  data_time: 0.0067  lr: 0.0013986  max_mem: 4744M
[32m[03/28 21:55:59 d2.utils.events]: [0m eta: 0:00:30  iter: 159  total_loss: 0.4623  loss_cls: 0.0659  loss_box_reg: 0.193  loss_mask: 0.1715  loss_rpn_cls: 0.006206  loss_rpn_loc: 0.0123  total_val_loss: 0.6761  val_loss_cls: 0.1372  val_loss_box_reg: 0.218  val_loss_mask: 0.2762  val_loss_rpn_cls: 0.02119  val_loss_rpn_loc: 0.01226  time: 0.7713  data_time: 0.0066  lr: 0.0015984  max_mem: 4744M
[32m[03/28 21:56:21 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.3865  loss_cls: 0.06063  loss_box_reg: 0.1251  loss_mask: 0.169  loss_rpn_cls: 0.007316  loss_rpn_loc: 0.009262  total_val_loss: 0.7111  val_loss_cls: 0.1169  val_loss_box_reg: 0.2189  val_loss_mask: 0.2678  val_loss_rpn_cls: 0.01946  val_loss_rpn_loc: 0.01253  time: 0.7721  data_time: 0.0064  lr: 0.0017982  max_mem: 4744M
[32m[03/28 21:56:43 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:56:43 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:56:44 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:56:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 21:56:44 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3263  loss_cls: 0.04472  loss_box_reg: 0.1055  loss_mask: 0.1523  loss_rpn_cls: 0.005805  loss_rpn_loc: 0.009401  total_val_loss: 0.9181  val_loss_cls: 0.1995  val_loss_box_reg: 0.3505  val_loss_mask: 0.3169  val_loss_rpn_cls: 0.01825  val_loss_rpn_loc: 0.01829  time: 0.7721  data_time: 0.0060  lr: 0.001998  max_mem: 4744M
[32m[03/28 21:56:44 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:32 (0.7721 s / it)
[32m[03/28 21:56:44 d2.engine.hooks]: [0mTotal training time: 0:03:36 (0:01:04 on hooks)
[32m[03/28 21:56:44 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:56:44 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:56:45 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/28 21:56:45 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/28 21:56:45 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/28 21:56:45 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 21:56:45 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/28 21:56:45 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/28 21:56:45 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/28 21:56:48 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2021 s / img. ETA=0:12:44
[32m[03/28 21:56:53 d2.evaluation.evaluator]: [0mInference done 34/3489. 0.2027 s / img. ETA=0:12:39
[32m[03/28 21:56:58 d2.evaluation.evaluator]: [0mInference done 58/3489. 0.2011 s / img. ETA=0:12:21
[32m[03/28 21:57:03 d2.evaluation.evaluator]: [0mInference done 82/3489. 0.2008 s / img. ETA=0:12:13
[32m[03/28 21:57:08 d2.evaluation.evaluator]: [0mInference done 104/3489. 0.2019 s / img. ETA=0:12:23
[32m[03/28 21:57:14 d2.evaluation.evaluator]: [0mInference done 124/3489. 0.2036 s / img. ETA=0:12:39
[32m[03/28 21:57:19 d2.evaluation.evaluator]: [0mInference done 141/3489. 0.2062 s / img. ETA=0:13:04
[32m[03/28 21:57:24 d2.evaluation.evaluator]: [0mInference done 158/3489. 0.2083 s / img. ETA=0:13:23
[32m[03/28 21:57:29 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2099 s / img. ETA=0:13:36
[32m[03/28 21:57:34 d2.evaluation.evaluator]: [0mInference done 194/3489. 0.2108 s / img. ETA=0:13:41
[32m[03/28 21:57:39 d2.evaluation.evaluator]: [0mInference done 216/3489. 0.2103 s / img. ETA=0:13:31
[32m[03/28 21:57:44 d2.evaluation.evaluator]: [0mInference done 238/3489. 0.2101 s / img. ETA=0:13:22
[32m[03/28 21:57:49 d2.evaluation.evaluator]: [0mInference done 258/3489. 0.2103 s / img. ETA=0:13:19
[32m[03/28 21:57:54 d2.evaluation.evaluator]: [0mInference done 278/3489. 0.2105 s / img. ETA=0:13:16
[32m[03/28 21:58:00 d2.evaluation.evaluator]: [0mInference done 299/3489. 0.2104 s / img. ETA=0:13:10
[32m[03/28 21:58:05 d2.evaluation.evaluator]: [0mInference done 318/3489. 0.2107 s / img. ETA=0:13:08
[32m[03/28 21:58:10 d2.evaluation.evaluator]: [0mInference done 338/3489. 0.2109 s / img. ETA=0:13:06
[32m[03/28 21:58:15 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2112 s / img. ETA=0:13:04
[32m[03/28 21:58:20 d2.evaluation.evaluator]: [0mInference done 376/3489. 0.2114 s / img. ETA=0:13:03
[32m[03/28 21:58:25 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2114 s / img. ETA=0:12:58
[32m[03/28 21:58:30 d2.evaluation.evaluator]: [0mInference done 416/3489. 0.2115 s / img. ETA=0:12:54
[32m[03/28 21:58:35 d2.evaluation.evaluator]: [0mInference done 439/3489. 0.2112 s / img. ETA=0:12:44
[32m[03/28 21:58:41 d2.evaluation.evaluator]: [0mInference done 462/3489. 0.2108 s / img. ETA=0:12:33
[32m[03/28 21:58:46 d2.evaluation.evaluator]: [0mInference done 485/3489. 0.2105 s / img. ETA=0:12:23
[32m[03/28 21:58:51 d2.evaluation.evaluator]: [0mInference done 509/3489. 0.2100 s / img. ETA=0:12:12
[32m[03/28 21:58:56 d2.evaluation.evaluator]: [0mInference done 533/3489. 0.2096 s / img. ETA=0:12:02
[32m[03/28 21:59:01 d2.evaluation.evaluator]: [0mInference done 557/3489. 0.2093 s / img. ETA=0:11:52
[32m[03/28 21:59:06 d2.evaluation.evaluator]: [0mInference done 579/3489. 0.2092 s / img. ETA=0:11:46
[32m[03/28 21:59:11 d2.evaluation.evaluator]: [0mInference done 599/3489. 0.2093 s / img. ETA=0:11:42
[32m[03/28 21:59:16 d2.evaluation.evaluator]: [0mInference done 620/3489. 0.2094 s / img. ETA=0:11:38
[32m[03/28 21:59:21 d2.evaluation.evaluator]: [0mInference done 640/3489. 0.2095 s / img. ETA=0:11:34
[32m[03/28 21:59:26 d2.evaluation.evaluator]: [0mInference done 661/3489. 0.2095 s / img. ETA=0:11:28
[32m[03/28 21:59:32 d2.evaluation.evaluator]: [0mInference done 684/3489. 0.2094 s / img. ETA=0:11:21
[32m[03/28 21:59:37 d2.evaluation.evaluator]: [0mInference done 707/3489. 0.2092 s / img. ETA=0:11:13
[32m[03/28 21:59:42 d2.evaluation.evaluator]: [0mInference done 730/3489. 0.2090 s / img. ETA=0:11:06
[32m[03/28 21:59:47 d2.evaluation.evaluator]: [0mInference done 753/3489. 0.2089 s / img. ETA=0:10:59
[32m[03/28 21:59:52 d2.evaluation.evaluator]: [0mInference done 777/3489. 0.2086 s / img. ETA=0:10:50
[32m[03/28 21:59:57 d2.evaluation.evaluator]: [0mInference done 802/3489. 0.2083 s / img. ETA=0:10:41
[32m[03/28 22:00:02 d2.evaluation.evaluator]: [0mInference done 826/3489. 0.2081 s / img. ETA=0:10:33
[32m[03/28 22:00:07 d2.evaluation.evaluator]: [0mInference done 850/3489. 0.2078 s / img. ETA=0:10:26
[32m[03/28 22:00:12 d2.evaluation.evaluator]: [0mInference done 874/3489. 0.2077 s / img. ETA=0:10:18
[32m[03/28 22:00:17 d2.evaluation.evaluator]: [0mInference done 899/3489. 0.2074 s / img. ETA=0:10:10
[32m[03/28 22:00:23 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2077 s / img. ETA=0:10:08
[32m[03/28 22:00:28 d2.evaluation.evaluator]: [0mInference done 936/3489. 0.2080 s / img. ETA=0:10:06
[32m[03/28 22:00:33 d2.evaluation.evaluator]: [0mInference done 955/3489. 0.2082 s / img. ETA=0:10:03
[32m[03/28 22:00:38 d2.evaluation.evaluator]: [0mInference done 973/3489. 0.2085 s / img. ETA=0:10:01
[32m[03/28 22:00:43 d2.evaluation.evaluator]: [0mInference done 990/3489. 0.2088 s / img. ETA=0:10:00
[32m[03/28 22:00:48 d2.evaluation.evaluator]: [0mInference done 1008/3489. 0.2090 s / img. ETA=0:09:58
[32m[03/28 22:00:54 d2.evaluation.evaluator]: [0mInference done 1026/3489. 0.2093 s / img. ETA=0:09:55
[32m[03/28 22:00:59 d2.evaluation.evaluator]: [0mInference done 1044/3489. 0.2096 s / img. ETA=0:09:53
[32m[03/28 22:01:04 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2098 s / img. ETA=0:09:51
[32m[03/28 22:01:09 d2.evaluation.evaluator]: [0mInference done 1080/3489. 0.2100 s / img. ETA=0:09:48
[32m[03/28 22:01:14 d2.evaluation.evaluator]: [0mInference done 1101/3489. 0.2100 s / img. ETA=0:09:43
[32m[03/28 22:01:20 d2.evaluation.evaluator]: [0mInference done 1122/3489. 0.2100 s / img. ETA=0:09:38
[32m[03/28 22:01:25 d2.evaluation.evaluator]: [0mInference done 1140/3489. 0.2102 s / img. ETA=0:09:35
[32m[03/28 22:01:30 d2.evaluation.evaluator]: [0mInference done 1158/3489. 0.2103 s / img. ETA=0:09:32
[32m[03/28 22:01:35 d2.evaluation.evaluator]: [0mInference done 1176/3489. 0.2105 s / img. ETA=0:09:29
[32m[03/28 22:01:40 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2105 s / img. ETA=0:09:25
[32m[03/28 22:01:45 d2.evaluation.evaluator]: [0mInference done 1214/3489. 0.2106 s / img. ETA=0:09:21
[32m[03/28 22:01:50 d2.evaluation.evaluator]: [0mInference done 1234/3489. 0.2106 s / img. ETA=0:09:16
[32m[03/28 22:01:55 d2.evaluation.evaluator]: [0mInference done 1255/3489. 0.2106 s / img. ETA=0:09:11
[32m[03/28 22:02:00 d2.evaluation.evaluator]: [0mInference done 1280/3489. 0.2104 s / img. ETA=0:09:03
[32m[03/28 22:02:06 d2.evaluation.evaluator]: [0mInference done 1305/3489. 0.2101 s / img. ETA=0:08:55
[32m[03/28 22:02:11 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2099 s / img. ETA=0:08:47
[32m[03/28 22:02:16 d2.evaluation.evaluator]: [0mInference done 1355/3489. 0.2097 s / img. ETA=0:08:40
[32m[03/28 22:02:21 d2.evaluation.evaluator]: [0mInference done 1379/3489. 0.2095 s / img. ETA=0:08:33
[32m[03/28 22:02:26 d2.evaluation.evaluator]: [0mInference done 1403/3489. 0.2093 s / img. ETA=0:08:26
[32m[03/28 22:02:31 d2.evaluation.evaluator]: [0mInference done 1426/3489. 0.2092 s / img. ETA=0:08:19
[32m[03/28 22:02:36 d2.evaluation.evaluator]: [0mInference done 1449/3489. 0.2091 s / img. ETA=0:08:13
[32m[03/28 22:02:41 d2.evaluation.evaluator]: [0mInference done 1472/3489. 0.2090 s / img. ETA=0:08:07
[32m[03/28 22:02:46 d2.evaluation.evaluator]: [0mInference done 1496/3489. 0.2089 s / img. ETA=0:08:00
[32m[03/28 22:02:51 d2.evaluation.evaluator]: [0mInference done 1520/3489. 0.2087 s / img. ETA=0:07:53
[32m[03/28 22:02:56 d2.evaluation.evaluator]: [0mInference done 1544/3489. 0.2086 s / img. ETA=0:07:47
[32m[03/28 22:03:01 d2.evaluation.evaluator]: [0mInference done 1568/3489. 0.2085 s / img. ETA=0:07:40
[32m[03/28 22:03:07 d2.evaluation.evaluator]: [0mInference done 1592/3489. 0.2084 s / img. ETA=0:07:34
[32m[03/28 22:03:12 d2.evaluation.evaluator]: [0mInference done 1612/3489. 0.2084 s / img. ETA=0:07:29
[32m[03/28 22:03:17 d2.evaluation.evaluator]: [0mInference done 1632/3489. 0.2085 s / img. ETA=0:07:25
[32m[03/28 22:03:22 d2.evaluation.evaluator]: [0mInference done 1653/3489. 0.2085 s / img. ETA=0:07:20
[32m[03/28 22:03:27 d2.evaluation.evaluator]: [0mInference done 1674/3489. 0.2085 s / img. ETA=0:07:15
[32m[03/28 22:03:32 d2.evaluation.evaluator]: [0mInference done 1692/3489. 0.2086 s / img. ETA=0:07:12
[32m[03/28 22:03:37 d2.evaluation.evaluator]: [0mInference done 1710/3489. 0.2088 s / img. ETA=0:07:08
[32m[03/28 22:03:43 d2.evaluation.evaluator]: [0mInference done 1729/3489. 0.2089 s / img. ETA=0:07:04
[32m[03/28 22:03:48 d2.evaluation.evaluator]: [0mInference done 1748/3489. 0.2090 s / img. ETA=0:07:00
[32m[03/28 22:03:53 d2.evaluation.evaluator]: [0mInference done 1766/3489. 0.2091 s / img. ETA=0:06:57
[32m[03/28 22:03:58 d2.evaluation.evaluator]: [0mInference done 1783/3489. 0.2093 s / img. ETA=0:06:53
[32m[03/28 22:04:03 d2.evaluation.evaluator]: [0mInference done 1800/3489. 0.2094 s / img. ETA=0:06:50
[32m[03/28 22:04:08 d2.evaluation.evaluator]: [0mInference done 1818/3489. 0.2096 s / img. ETA=0:06:47
[32m[03/28 22:04:14 d2.evaluation.evaluator]: [0mInference done 1836/3489. 0.2097 s / img. ETA=0:06:43
[32m[03/28 22:04:19 d2.evaluation.evaluator]: [0mInference done 1854/3489. 0.2099 s / img. ETA=0:06:39
[32m[03/28 22:04:24 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2100 s / img. ETA=0:06:36
[32m[03/28 22:04:29 d2.evaluation.evaluator]: [0mInference done 1890/3489. 0.2101 s / img. ETA=0:06:32
[32m[03/28 22:04:35 d2.evaluation.evaluator]: [0mInference done 1908/3489. 0.2103 s / img. ETA=0:06:28
[32m[03/28 22:04:40 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2104 s / img. ETA=0:06:24
[32m[03/28 22:04:45 d2.evaluation.evaluator]: [0mInference done 1944/3489. 0.2105 s / img. ETA=0:06:21
[32m[03/28 22:04:50 d2.evaluation.evaluator]: [0mInference done 1962/3489. 0.2106 s / img. ETA=0:06:17
[32m[03/28 22:04:56 d2.evaluation.evaluator]: [0mInference done 1979/3489. 0.2107 s / img. ETA=0:06:13
[32m[03/28 22:05:01 d2.evaluation.evaluator]: [0mInference done 1998/3489. 0.2108 s / img. ETA=0:06:09
[32m[03/28 22:05:06 d2.evaluation.evaluator]: [0mInference done 2018/3489. 0.2108 s / img. ETA=0:06:04
[32m[03/28 22:05:11 d2.evaluation.evaluator]: [0mInference done 2038/3489. 0.2108 s / img. ETA=0:05:59
[32m[03/28 22:05:16 d2.evaluation.evaluator]: [0mInference done 2057/3489. 0.2109 s / img. ETA=0:05:55
[32m[03/28 22:05:21 d2.evaluation.evaluator]: [0mInference done 2076/3489. 0.2110 s / img. ETA=0:05:51
[32m[03/28 22:05:27 d2.evaluation.evaluator]: [0mInference done 2094/3489. 0.2111 s / img. ETA=0:05:47
[32m[03/28 22:05:32 d2.evaluation.evaluator]: [0mInference done 2112/3489. 0.2112 s / img. ETA=0:05:43
[32m[03/28 22:05:37 d2.evaluation.evaluator]: [0mInference done 2130/3489. 0.2113 s / img. ETA=0:05:39
[32m[03/28 22:05:42 d2.evaluation.evaluator]: [0mInference done 2148/3489. 0.2114 s / img. ETA=0:05:35
[32m[03/28 22:05:48 d2.evaluation.evaluator]: [0mInference done 2166/3489. 0.2115 s / img. ETA=0:05:31
[32m[03/28 22:05:53 d2.evaluation.evaluator]: [0mInference done 2184/3489. 0.2116 s / img. ETA=0:05:27
[32m[03/28 22:05:58 d2.evaluation.evaluator]: [0mInference done 2202/3489. 0.2117 s / img. ETA=0:05:22
[32m[03/28 22:06:03 d2.evaluation.evaluator]: [0mInference done 2220/3489. 0.2118 s / img. ETA=0:05:18
[32m[03/28 22:06:09 d2.evaluation.evaluator]: [0mInference done 2238/3489. 0.2119 s / img. ETA=0:05:14
[32m[03/28 22:06:14 d2.evaluation.evaluator]: [0mInference done 2257/3489. 0.2119 s / img. ETA=0:05:10
[32m[03/28 22:06:19 d2.evaluation.evaluator]: [0mInference done 2276/3489. 0.2120 s / img. ETA=0:05:05
[32m[03/28 22:06:24 d2.evaluation.evaluator]: [0mInference done 2295/3489. 0.2120 s / img. ETA=0:05:01
[32m[03/28 22:06:29 d2.evaluation.evaluator]: [0mInference done 2313/3489. 0.2121 s / img. ETA=0:04:56
[32m[03/28 22:06:34 d2.evaluation.evaluator]: [0mInference done 2331/3489. 0.2122 s / img. ETA=0:04:52
[32m[03/28 22:06:40 d2.evaluation.evaluator]: [0mInference done 2349/3489. 0.2122 s / img. ETA=0:04:48
[32m[03/28 22:06:45 d2.evaluation.evaluator]: [0mInference done 2368/3489. 0.2123 s / img. ETA=0:04:43
[32m[03/28 22:06:50 d2.evaluation.evaluator]: [0mInference done 2389/3489. 0.2122 s / img. ETA=0:04:38
[32m[03/28 22:06:55 d2.evaluation.evaluator]: [0mInference done 2409/3489. 0.2122 s / img. ETA=0:04:33
[32m[03/28 22:07:00 d2.evaluation.evaluator]: [0mInference done 2429/3489. 0.2122 s / img. ETA=0:04:28
[32m[03/28 22:07:05 d2.evaluation.evaluator]: [0mInference done 2448/3489. 0.2123 s / img. ETA=0:04:23
[32m[03/28 22:07:10 d2.evaluation.evaluator]: [0mInference done 2465/3489. 0.2124 s / img. ETA=0:04:19
[32m[03/28 22:07:16 d2.evaluation.evaluator]: [0mInference done 2483/3489. 0.2125 s / img. ETA=0:04:15
[32m[03/28 22:07:21 d2.evaluation.evaluator]: [0mInference done 2505/3489. 0.2125 s / img. ETA=0:04:09
[32m[03/28 22:07:26 d2.evaluation.evaluator]: [0mInference done 2527/3489. 0.2124 s / img. ETA=0:04:03
[32m[03/28 22:07:31 d2.evaluation.evaluator]: [0mInference done 2549/3489. 0.2124 s / img. ETA=0:03:57
[32m[03/28 22:07:36 d2.evaluation.evaluator]: [0mInference done 2571/3489. 0.2123 s / img. ETA=0:03:52
[32m[03/28 22:07:41 d2.evaluation.evaluator]: [0mInference done 2594/3489. 0.2122 s / img. ETA=0:03:46
[32m[03/28 22:07:46 d2.evaluation.evaluator]: [0mInference done 2617/3489. 0.2122 s / img. ETA=0:03:40
[32m[03/28 22:07:51 d2.evaluation.evaluator]: [0mInference done 2641/3489. 0.2121 s / img. ETA=0:03:33
[32m[03/28 22:07:56 d2.evaluation.evaluator]: [0mInference done 2665/3489. 0.2120 s / img. ETA=0:03:27
[32m[03/28 22:08:02 d2.evaluation.evaluator]: [0mInference done 2688/3489. 0.2119 s / img. ETA=0:03:21
[32m[03/28 22:08:07 d2.evaluation.evaluator]: [0mInference done 2711/3489. 0.2118 s / img. ETA=0:03:15
[32m[03/28 22:08:12 d2.evaluation.evaluator]: [0mInference done 2734/3489. 0.2117 s / img. ETA=0:03:09
[32m[03/28 22:08:17 d2.evaluation.evaluator]: [0mInference done 2757/3489. 0.2117 s / img. ETA=0:03:03
[32m[03/28 22:08:22 d2.evaluation.evaluator]: [0mInference done 2780/3489. 0.2116 s / img. ETA=0:02:57
[32m[03/28 22:08:27 d2.evaluation.evaluator]: [0mInference done 2803/3489. 0.2115 s / img. ETA=0:02:51
[32m[03/28 22:08:32 d2.evaluation.evaluator]: [0mInference done 2826/3489. 0.2115 s / img. ETA=0:02:45
[32m[03/28 22:08:37 d2.evaluation.evaluator]: [0mInference done 2849/3489. 0.2114 s / img. ETA=0:02:39
[32m[03/28 22:08:42 d2.evaluation.evaluator]: [0mInference done 2872/3489. 0.2113 s / img. ETA=0:02:34
[32m[03/28 22:08:47 d2.evaluation.evaluator]: [0mInference done 2895/3489. 0.2112 s / img. ETA=0:02:28
[32m[03/28 22:08:53 d2.evaluation.evaluator]: [0mInference done 2919/3489. 0.2112 s / img. ETA=0:02:21
[32m[03/28 22:08:58 d2.evaluation.evaluator]: [0mInference done 2943/3489. 0.2111 s / img. ETA=0:02:15
[32m[03/28 22:09:03 d2.evaluation.evaluator]: [0mInference done 2967/3489. 0.2110 s / img. ETA=0:02:09
[32m[03/28 22:09:08 d2.evaluation.evaluator]: [0mInference done 2991/3489. 0.2109 s / img. ETA=0:02:03
[32m[03/28 22:09:13 d2.evaluation.evaluator]: [0mInference done 3013/3489. 0.2109 s / img. ETA=0:01:58
[32m[03/28 22:09:18 d2.evaluation.evaluator]: [0mInference done 3036/3489. 0.2108 s / img. ETA=0:01:52
[32m[03/28 22:09:23 d2.evaluation.evaluator]: [0mInference done 3059/3489. 0.2108 s / img. ETA=0:01:46
[32m[03/28 22:09:28 d2.evaluation.evaluator]: [0mInference done 3081/3489. 0.2107 s / img. ETA=0:01:41
[32m[03/28 22:09:33 d2.evaluation.evaluator]: [0mInference done 3104/3489. 0.2107 s / img. ETA=0:01:35
[32m[03/28 22:09:39 d2.evaluation.evaluator]: [0mInference done 3126/3489. 0.2106 s / img. ETA=0:01:29
[32m[03/28 22:09:44 d2.evaluation.evaluator]: [0mInference done 3148/3489. 0.2106 s / img. ETA=0:01:24
[32m[03/28 22:09:49 d2.evaluation.evaluator]: [0mInference done 3171/3489. 0.2105 s / img. ETA=0:01:18
[32m[03/28 22:09:54 d2.evaluation.evaluator]: [0mInference done 3194/3489. 0.2105 s / img. ETA=0:01:12
[32m[03/28 22:09:59 d2.evaluation.evaluator]: [0mInference done 3217/3489. 0.2104 s / img. ETA=0:01:07
[32m[03/28 22:10:04 d2.evaluation.evaluator]: [0mInference done 3239/3489. 0.2104 s / img. ETA=0:01:01
[32m[03/28 22:10:09 d2.evaluation.evaluator]: [0mInference done 3263/3489. 0.2103 s / img. ETA=0:00:55
[32m[03/28 22:10:14 d2.evaluation.evaluator]: [0mInference done 3287/3489. 0.2103 s / img. ETA=0:00:49
[32m[03/28 22:10:19 d2.evaluation.evaluator]: [0mInference done 3312/3489. 0.2102 s / img. ETA=0:00:43
[32m[03/28 22:10:24 d2.evaluation.evaluator]: [0mInference done 3337/3489. 0.2101 s / img. ETA=0:00:37
[32m[03/28 22:10:29 d2.evaluation.evaluator]: [0mInference done 3362/3489. 0.2100 s / img. ETA=0:00:31
[32m[03/28 22:10:34 d2.evaluation.evaluator]: [0mInference done 3387/3489. 0.2099 s / img. ETA=0:00:24
[32m[03/28 22:10:40 d2.evaluation.evaluator]: [0mInference done 3411/3489. 0.2098 s / img. ETA=0:00:19
[32m[03/28 22:10:45 d2.evaluation.evaluator]: [0mInference done 3435/3489. 0.2098 s / img. ETA=0:00:13
[32m[03/28 22:10:50 d2.evaluation.evaluator]: [0mInference done 3459/3489. 0.2097 s / img. ETA=0:00:07
[32m[03/28 22:10:55 d2.evaluation.evaluator]: [0mInference done 3483/3489. 0.2097 s / img. ETA=0:00:01
[32m[03/28 22:10:56 d2.evaluation.evaluator]: [0mTotal inference time: 0:14:09.657975 (0.243874 s / img per device, on 1 devices)
[32m[03/28 22:10:56 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:10 (0.209637 s / img per device, on 1 devices)
[32m[03/28 22:10:58 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/28 22:10:58 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_8000.000000/coco_instances_results.json
[32m[03/28 22:11:00 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.48 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.54 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[32m[03/28 22:11:02 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.067 | 77.897 | 42.810 | 32.556 | 52.718 | 55.102 |
[32m[03/28 22:11:02 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.680 | Pedestrian | 28.454 |
Loading and preparing results...
DONE (t=1.99s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.35 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.56 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746
[32m[03/28 22:11:12 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.002 | 73.852 | 41.023 | 24.053 | 51.684 | 68.414 |
[32m[03/28 22:11:12 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.177 | Pedestrian | 22.827 |
[32m[03/28 22:11:12 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: 46.0669,77.8973,42.8099,32.5562,52.7180,55.1019
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 22:11:12 d2.evaluation.testing]: [0mcopypaste: 43.0020,73.8521,41.0234,24.0529,51.6842,68.4141
evaluated
