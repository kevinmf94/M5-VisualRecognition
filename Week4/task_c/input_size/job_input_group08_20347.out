Test [32]
[32m[03/30 20:24:23 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 20:24:23 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 20:24:23 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 16900        | Pedestrian | 690          |
|            |              |            |              |
|   total    | 17590        |            |              |[0m
[32m[03/30 20:24:23 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(32,), max_size=32, sample_style='choice'), RandomFlip()]
[32m[03/30 20:24:23 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 20:24:23 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 20:24:24 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 20:24:24 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 20:24:24 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 9960         | Pedestrian | 10725        |
|            |              |            |              |
|   total    | 20685        |            |              |[0m
[32m[03/30 20:24:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(32,), max_size=32, sample_style='choice'), RandomFlip()]
[32m[03/30 20:24:24 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 20:24:24 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 20:24:24 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 20:24:24 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 20:24:29 d2.utils.events]: [0m eta: 0:00:17  iter: 19  total_loss: 1.648  loss_cls: 0.7875  loss_box_reg: 0.03928  loss_mask: 0.6867  loss_rpn_cls: 0.06519  loss_rpn_loc: 0.06004  total_val_loss: 2.044  val_loss_cls: 1.115  val_loss_box_reg: 0.06005  val_loss_mask: 0.6897  val_loss_rpn_cls: 0.08866  val_loss_rpn_loc: 0.07374  time: 0.1070  data_time: 0.0277  lr: 0.00019981  max_mem: 587M
[32m[03/30 20:24:32 d2.utils.events]: [0m eta: 0:00:15  iter: 39  total_loss: 1.455  loss_cls: 0.5836  loss_box_reg: 0.1142  loss_mask: 0.673  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.05715  total_val_loss: 1.946  val_loss_cls: 1.074  val_loss_box_reg: 0.08536  val_loss_mask: 0.6894  val_loss_rpn_cls: 0.0316  val_loss_rpn_loc: 0.0633  time: 0.1104  data_time: 0.0083  lr: 0.00039961  max_mem: 587M
[32m[03/30 20:24:35 d2.utils.events]: [0m eta: 0:00:13  iter: 59  total_loss: 1.304  loss_cls: 0.4389  loss_box_reg: 0.09353  loss_mask: 0.6629  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.05833  total_val_loss: 1.681  val_loss_cls: 0.7683  val_loss_box_reg: 0.07348  val_loss_mask: 0.691  val_loss_rpn_cls: 0.01568  val_loss_rpn_loc: 0.04052  time: 0.1114  data_time: 0.0070  lr: 0.00059941  max_mem: 587M
[32m[03/30 20:24:39 d2.utils.events]: [0m eta: 0:00:11  iter: 79  total_loss: 1.168  loss_cls: 0.3751  loss_box_reg: 0.093  loss_mask: 0.666  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.03511  total_val_loss: 1.649  val_loss_cls: 0.828  val_loss_box_reg: 0.0811  val_loss_mask: 0.6671  val_loss_rpn_cls: 0.0104  val_loss_rpn_loc: 0.04168  time: 0.1091  data_time: 0.0066  lr: 0.00079921  max_mem: 587M
[32m[03/30 20:24:42 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:24:42 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:24:42 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:24:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 20:24:42 d2.utils.events]: [0m eta: 0:00:09  iter: 99  total_loss: 1.09  loss_cls: 0.303  loss_box_reg: 0.09962  loss_mask: 0.5983  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.02921  total_val_loss: 1.467  val_loss_cls: 0.7276  val_loss_box_reg: 0.08469  val_loss_mask: 0.6412  val_loss_rpn_cls: 0.008681  val_loss_rpn_loc: 0.02655  time: 0.1081  data_time: 0.0074  lr: 0.00099901  max_mem: 587M
[32m[03/30 20:24:46 d2.utils.events]: [0m eta: 0:00:07  iter: 119  total_loss: 1.002  loss_cls: 0.3206  loss_box_reg: 0.06418  loss_mask: 0.5612  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.02358  total_val_loss: 1.696  val_loss_cls: 0.8736  val_loss_box_reg: 0.08487  val_loss_mask: 0.6366  val_loss_rpn_cls: 0.007675  val_loss_rpn_loc: 0.02398  time: 0.1070  data_time: 0.0091  lr: 0.0011988  max_mem: 587M
[32m[03/30 20:24:49 d2.utils.events]: [0m eta: 0:00:05  iter: 139  total_loss: 0.9828  loss_cls: 0.3079  loss_box_reg: 0.09031  loss_mask: 0.5931  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.02336  total_val_loss: 1.34  val_loss_cls: 0.5867  val_loss_box_reg: 0.07398  val_loss_mask: 0.673  val_loss_rpn_cls: 0.01248  val_loss_rpn_loc: 0.02403  time: 0.1067  data_time: 0.0077  lr: 0.0013986  max_mem: 587M
[32m[03/30 20:24:53 d2.utils.events]: [0m eta: 0:00:03  iter: 159  total_loss: 1.224  loss_cls: 0.3734  loss_box_reg: 0.0903  loss_mask: 0.5982  loss_rpn_cls: 0.009669  loss_rpn_loc: 0.0221  total_val_loss: 1.54  val_loss_cls: 0.7935  val_loss_box_reg: 0.05968  val_loss_mask: 0.6379  val_loss_rpn_cls: 0.008834  val_loss_rpn_loc: 0.02616  time: 0.1077  data_time: 0.0093  lr: 0.0015984  max_mem: 587M
[32m[03/30 20:24:56 d2.utils.events]: [0m eta: 0:00:02  iter: 179  total_loss: 1.132  loss_cls: 0.328  loss_box_reg: 0.1291  loss_mask: 0.6  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.02357  total_val_loss: 1.46  val_loss_cls: 0.7158  val_loss_box_reg: 0.05075  val_loss_mask: 0.6498  val_loss_rpn_cls: 0.01309  val_loss_rpn_loc: 0.02689  time: 0.1083  data_time: 0.0074  lr: 0.0017982  max_mem: 587M
[32m[03/30 20:25:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:25:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:25:01 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:25:01 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 20:25:01 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 1.008  loss_cls: 0.3562  loss_box_reg: 0.08666  loss_mask: 0.566  loss_rpn_cls: 0.009335  loss_rpn_loc: 0.02442  total_val_loss: 1.627  val_loss_cls: 0.7399  val_loss_box_reg: 0.07826  val_loss_mask: 0.6092  val_loss_rpn_cls: 0.008389  val_loss_rpn_loc: 0.02506  time: 0.1091  data_time: 0.0092  lr: 0.001998  max_mem: 587M
[32m[03/30 20:25:01 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:00:21 (0.1091 s / it)
[32m[03/30 20:25:01 d2.engine.hooks]: [0mTotal training time: 0:00:35 (0:00:13 on hooks)
[32m[03/30 20:25:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:25:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:25:01 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:25:01 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/30 20:25:01 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/30 20:25:01 d2.evaluation.coco_evaluation]: [0m'kittimots_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[03/30 20:25:01 d2.data.datasets.coco]: [0mConverting annotations of dataset 'kittimots_val' to COCO format ...)
[32m[03/30 20:25:01 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[03/30 20:25:02 d2.data.datasets.coco]: [0mConversion finished, #images: 3489, #annotations: 20685
[32m[03/30 20:25:02 d2.data.datasets.coco]: [0mCaching COCO format annotations at './output_32.000000/kittimots_val_coco_format.json' ...
[32m[03/30 20:25:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:25:03 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:25:03 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/30 20:25:03 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/30 20:25:07 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2473 s / img. ETA=0:20:52
[32m[03/30 20:25:12 d2.evaluation.evaluator]: [0mInference done 25/3489. 0.2462 s / img. ETA=0:20:45
[32m[03/30 20:25:18 d2.evaluation.evaluator]: [0mInference done 40/3489. 0.2455 s / img. ETA=0:20:27
[32m[03/30 20:25:23 d2.evaluation.evaluator]: [0mInference done 55/3489. 0.2454 s / img. ETA=0:20:22
[32m[03/30 20:25:28 d2.evaluation.evaluator]: [0mInference done 69/3489. 0.2453 s / img. ETA=0:20:18
[32m[03/30 20:25:33 d2.evaluation.evaluator]: [0mInference done 84/3489. 0.2453 s / img. ETA=0:20:12
[32m[03/30 20:25:39 d2.evaluation.evaluator]: [0mInference done 99/3489. 0.2453 s / img. ETA=0:20:07
[32m[03/30 20:25:44 d2.evaluation.evaluator]: [0mInference done 114/3489. 0.2453 s / img. ETA=0:20:02
[32m[03/30 20:25:49 d2.evaluation.evaluator]: [0mInference done 129/3489. 0.2453 s / img. ETA=0:19:56
[32m[03/30 20:25:55 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2453 s / img. ETA=0:19:51
[32m[03/30 20:26:00 d2.evaluation.evaluator]: [0mInference done 158/3489. 0.2455 s / img. ETA=0:19:50
[32m[03/30 20:26:05 d2.evaluation.evaluator]: [0mInference done 172/3489. 0.2456 s / img. ETA=0:19:45
[32m[03/30 20:26:10 d2.evaluation.evaluator]: [0mInference done 186/3489. 0.2457 s / img. ETA=0:19:41
[32m[03/30 20:26:15 d2.evaluation.evaluator]: [0mInference done 200/3489. 0.2458 s / img. ETA=0:19:36
[32m[03/30 20:26:20 d2.evaluation.evaluator]: [0mInference done 214/3489. 0.2459 s / img. ETA=0:19:31
[32m[03/30 20:26:25 d2.evaluation.evaluator]: [0mInference done 228/3489. 0.2460 s / img. ETA=0:19:26
[32m[03/30 20:26:30 d2.evaluation.evaluator]: [0mInference done 242/3489. 0.2460 s / img. ETA=0:19:21
[32m[03/30 20:26:35 d2.evaluation.evaluator]: [0mInference done 256/3489. 0.2461 s / img. ETA=0:19:16
[32m[03/30 20:26:40 d2.evaluation.evaluator]: [0mInference done 270/3489. 0.2462 s / img. ETA=0:19:12
[32m[03/30 20:26:45 d2.evaluation.evaluator]: [0mInference done 284/3489. 0.2462 s / img. ETA=0:19:07
[32m[03/30 20:26:50 d2.evaluation.evaluator]: [0mInference done 298/3489. 0.2463 s / img. ETA=0:19:02
[32m[03/30 20:26:55 d2.evaluation.evaluator]: [0mInference done 312/3489. 0.2463 s / img. ETA=0:18:57
[32m[03/30 20:27:00 d2.evaluation.evaluator]: [0mInference done 326/3489. 0.2464 s / img. ETA=0:18:52
[32m[03/30 20:27:05 d2.evaluation.evaluator]: [0mInference done 341/3489. 0.2465 s / img. ETA=0:18:46
[32m[03/30 20:27:11 d2.evaluation.evaluator]: [0mInference done 356/3489. 0.2466 s / img. ETA=0:18:40
[32m[03/30 20:27:16 d2.evaluation.evaluator]: [0mInference done 370/3489. 0.2467 s / img. ETA=0:18:35
[32m[03/30 20:27:21 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2468 s / img. ETA=0:18:29
[32m[03/30 20:27:26 d2.evaluation.evaluator]: [0mInference done 400/3489. 0.2469 s / img. ETA=0:18:23
[32m[03/30 20:27:32 d2.evaluation.evaluator]: [0mInference done 415/3489. 0.2469 s / img. ETA=0:18:17
[32m[03/30 20:27:37 d2.evaluation.evaluator]: [0mInference done 430/3489. 0.2470 s / img. ETA=0:18:11
[32m[03/30 20:27:42 d2.evaluation.evaluator]: [0mInference done 445/3489. 0.2471 s / img. ETA=0:18:04
[32m[03/30 20:27:47 d2.evaluation.evaluator]: [0mInference done 460/3489. 0.2473 s / img. ETA=0:17:58
[32m[03/30 20:27:52 d2.evaluation.evaluator]: [0mInference done 475/3489. 0.2475 s / img. ETA=0:17:52
[32m[03/30 20:27:58 d2.evaluation.evaluator]: [0mInference done 490/3489. 0.2477 s / img. ETA=0:17:47
[32m[03/30 20:28:03 d2.evaluation.evaluator]: [0mInference done 505/3489. 0.2478 s / img. ETA=0:17:40
[32m[03/30 20:28:08 d2.evaluation.evaluator]: [0mInference done 520/3489. 0.2479 s / img. ETA=0:17:34
[32m[03/30 20:28:13 d2.evaluation.evaluator]: [0mInference done 535/3489. 0.2479 s / img. ETA=0:17:28
[32m[03/30 20:28:18 d2.evaluation.evaluator]: [0mInference done 550/3489. 0.2481 s / img. ETA=0:17:22
[32m[03/30 20:28:24 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2483 s / img. ETA=0:17:17
[32m[03/30 20:28:29 d2.evaluation.evaluator]: [0mInference done 580/3489. 0.2484 s / img. ETA=0:17:11
[32m[03/30 20:28:34 d2.evaluation.evaluator]: [0mInference done 595/3489. 0.2485 s / img. ETA=0:17:05
[32m[03/30 20:28:39 d2.evaluation.evaluator]: [0mInference done 610/3489. 0.2486 s / img. ETA=0:16:59
[32m[03/30 20:28:44 d2.evaluation.evaluator]: [0mInference done 624/3489. 0.2487 s / img. ETA=0:16:55
[32m[03/30 20:28:50 d2.evaluation.evaluator]: [0mInference done 639/3489. 0.2488 s / img. ETA=0:16:49
[32m[03/30 20:28:55 d2.evaluation.evaluator]: [0mInference done 654/3489. 0.2489 s / img. ETA=0:16:43
[32m[03/30 20:29:00 d2.evaluation.evaluator]: [0mInference done 669/3489. 0.2490 s / img. ETA=0:16:38
[32m[03/30 20:29:05 d2.evaluation.evaluator]: [0mInference done 684/3489. 0.2491 s / img. ETA=0:16:32
[32m[03/30 20:29:11 d2.evaluation.evaluator]: [0mInference done 699/3489. 0.2491 s / img. ETA=0:16:27
[32m[03/30 20:29:16 d2.evaluation.evaluator]: [0mInference done 714/3489. 0.2492 s / img. ETA=0:16:21
[32m[03/30 20:29:21 d2.evaluation.evaluator]: [0mInference done 729/3489. 0.2491 s / img. ETA=0:16:15
[32m[03/30 20:29:26 d2.evaluation.evaluator]: [0mInference done 744/3489. 0.2492 s / img. ETA=0:16:09
[32m[03/30 20:29:31 d2.evaluation.evaluator]: [0mInference done 759/3489. 0.2492 s / img. ETA=0:16:04
[32m[03/30 20:29:37 d2.evaluation.evaluator]: [0mInference done 774/3489. 0.2493 s / img. ETA=0:15:58
[32m[03/30 20:29:42 d2.evaluation.evaluator]: [0mInference done 789/3489. 0.2493 s / img. ETA=0:15:53
[32m[03/30 20:29:47 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2494 s / img. ETA=0:15:47
[32m[03/30 20:29:52 d2.evaluation.evaluator]: [0mInference done 819/3489. 0.2494 s / img. ETA=0:15:42
[32m[03/30 20:29:58 d2.evaluation.evaluator]: [0mInference done 834/3489. 0.2495 s / img. ETA=0:15:37
[32m[03/30 20:30:03 d2.evaluation.evaluator]: [0mInference done 849/3489. 0.2495 s / img. ETA=0:15:31
[32m[03/30 20:30:08 d2.evaluation.evaluator]: [0mInference done 864/3489. 0.2495 s / img. ETA=0:15:26
[32m[03/30 20:30:13 d2.evaluation.evaluator]: [0mInference done 879/3489. 0.2495 s / img. ETA=0:15:20
[32m[03/30 20:30:19 d2.evaluation.evaluator]: [0mInference done 894/3489. 0.2497 s / img. ETA=0:15:15
[32m[03/30 20:30:24 d2.evaluation.evaluator]: [0mInference done 909/3489. 0.2497 s / img. ETA=0:15:09
[32m[03/30 20:30:29 d2.evaluation.evaluator]: [0mInference done 923/3489. 0.2497 s / img. ETA=0:15:04
[32m[03/30 20:30:34 d2.evaluation.evaluator]: [0mInference done 938/3489. 0.2497 s / img. ETA=0:14:59
[32m[03/30 20:30:39 d2.evaluation.evaluator]: [0mInference done 953/3489. 0.2498 s / img. ETA=0:14:54
[32m[03/30 20:30:45 d2.evaluation.evaluator]: [0mInference done 968/3489. 0.2498 s / img. ETA=0:14:48
[32m[03/30 20:30:50 d2.evaluation.evaluator]: [0mInference done 983/3489. 0.2499 s / img. ETA=0:14:43
[32m[03/30 20:30:55 d2.evaluation.evaluator]: [0mInference done 998/3489. 0.2498 s / img. ETA=0:14:37
[32m[03/30 20:31:00 d2.evaluation.evaluator]: [0mInference done 1013/3489. 0.2498 s / img. ETA=0:14:32
[32m[03/30 20:31:06 d2.evaluation.evaluator]: [0mInference done 1028/3489. 0.2499 s / img. ETA=0:14:27
[32m[03/30 20:31:11 d2.evaluation.evaluator]: [0mInference done 1043/3489. 0.2499 s / img. ETA=0:14:21
[32m[03/30 20:31:16 d2.evaluation.evaluator]: [0mInference done 1058/3489. 0.2500 s / img. ETA=0:14:16
[32m[03/30 20:31:21 d2.evaluation.evaluator]: [0mInference done 1073/3489. 0.2501 s / img. ETA=0:14:11
[32m[03/30 20:31:27 d2.evaluation.evaluator]: [0mInference done 1088/3489. 0.2501 s / img. ETA=0:14:05
[32m[03/30 20:31:32 d2.evaluation.evaluator]: [0mInference done 1103/3489. 0.2501 s / img. ETA=0:14:00
[32m[03/30 20:31:37 d2.evaluation.evaluator]: [0mInference done 1118/3489. 0.2501 s / img. ETA=0:13:55
[32m[03/30 20:31:42 d2.evaluation.evaluator]: [0mInference done 1133/3489. 0.2502 s / img. ETA=0:13:49
[32m[03/30 20:31:48 d2.evaluation.evaluator]: [0mInference done 1148/3489. 0.2502 s / img. ETA=0:13:44
[32m[03/30 20:31:53 d2.evaluation.evaluator]: [0mInference done 1163/3489. 0.2503 s / img. ETA=0:13:39
[32m[03/30 20:31:58 d2.evaluation.evaluator]: [0mInference done 1178/3489. 0.2503 s / img. ETA=0:13:33
[32m[03/30 20:32:03 d2.evaluation.evaluator]: [0mInference done 1193/3489. 0.2503 s / img. ETA=0:13:28
[32m[03/30 20:32:08 d2.evaluation.evaluator]: [0mInference done 1207/3489. 0.2503 s / img. ETA=0:13:23
[32m[03/30 20:32:13 d2.evaluation.evaluator]: [0mInference done 1221/3489. 0.2503 s / img. ETA=0:13:18
[32m[03/30 20:32:19 d2.evaluation.evaluator]: [0mInference done 1236/3489. 0.2503 s / img. ETA=0:13:13
[32m[03/30 20:32:24 d2.evaluation.evaluator]: [0mInference done 1250/3489. 0.2504 s / img. ETA=0:13:09
[32m[03/30 20:32:29 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2503 s / img. ETA=0:13:04
[32m[03/30 20:32:34 d2.evaluation.evaluator]: [0mInference done 1278/3489. 0.2504 s / img. ETA=0:12:59
[32m[03/30 20:32:39 d2.evaluation.evaluator]: [0mInference done 1292/3489. 0.2503 s / img. ETA=0:12:54
[32m[03/30 20:32:44 d2.evaluation.evaluator]: [0mInference done 1306/3489. 0.2503 s / img. ETA=0:12:50
[32m[03/30 20:32:49 d2.evaluation.evaluator]: [0mInference done 1320/3489. 0.2504 s / img. ETA=0:12:45
[32m[03/30 20:32:55 d2.evaluation.evaluator]: [0mInference done 1334/3489. 0.2504 s / img. ETA=0:12:41
[32m[03/30 20:33:00 d2.evaluation.evaluator]: [0mInference done 1348/3489. 0.2504 s / img. ETA=0:12:36
[32m[03/30 20:33:05 d2.evaluation.evaluator]: [0mInference done 1362/3489. 0.2504 s / img. ETA=0:12:31
[32m[03/30 20:33:10 d2.evaluation.evaluator]: [0mInference done 1376/3489. 0.2504 s / img. ETA=0:12:27
[32m[03/30 20:33:15 d2.evaluation.evaluator]: [0mInference done 1390/3489. 0.2504 s / img. ETA=0:12:22
[32m[03/30 20:33:20 d2.evaluation.evaluator]: [0mInference done 1404/3489. 0.2504 s / img. ETA=0:12:17
[32m[03/30 20:33:25 d2.evaluation.evaluator]: [0mInference done 1418/3489. 0.2504 s / img. ETA=0:12:12
[32m[03/30 20:33:30 d2.evaluation.evaluator]: [0mInference done 1432/3489. 0.2505 s / img. ETA=0:12:08
[32m[03/30 20:33:35 d2.evaluation.evaluator]: [0mInference done 1446/3489. 0.2505 s / img. ETA=0:12:03
[32m[03/30 20:33:40 d2.evaluation.evaluator]: [0mInference done 1460/3489. 0.2505 s / img. ETA=0:11:58
[32m[03/30 20:33:46 d2.evaluation.evaluator]: [0mInference done 1475/3489. 0.2505 s / img. ETA=0:11:53
[32m[03/30 20:33:51 d2.evaluation.evaluator]: [0mInference done 1490/3489. 0.2505 s / img. ETA=0:11:47
[32m[03/30 20:33:56 d2.evaluation.evaluator]: [0mInference done 1505/3489. 0.2505 s / img. ETA=0:11:42
[32m[03/30 20:34:01 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2505 s / img. ETA=0:11:37
[32m[03/30 20:34:07 d2.evaluation.evaluator]: [0mInference done 1534/3489. 0.2505 s / img. ETA=0:11:32
[32m[03/30 20:34:12 d2.evaluation.evaluator]: [0mInference done 1548/3489. 0.2505 s / img. ETA=0:11:27
[32m[03/30 20:34:17 d2.evaluation.evaluator]: [0mInference done 1563/3489. 0.2505 s / img. ETA=0:11:22
[32m[03/30 20:34:22 d2.evaluation.evaluator]: [0mInference done 1577/3489. 0.2506 s / img. ETA=0:11:17
[32m[03/30 20:34:28 d2.evaluation.evaluator]: [0mInference done 1592/3489. 0.2506 s / img. ETA=0:11:12
[32m[03/30 20:34:33 d2.evaluation.evaluator]: [0mInference done 1607/3489. 0.2506 s / img. ETA=0:11:07
[32m[03/30 20:34:38 d2.evaluation.evaluator]: [0mInference done 1622/3489. 0.2506 s / img. ETA=0:11:01
[32m[03/30 20:34:44 d2.evaluation.evaluator]: [0mInference done 1637/3489. 0.2506 s / img. ETA=0:10:56
[32m[03/30 20:34:49 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2506 s / img. ETA=0:10:51
[32m[03/30 20:34:54 d2.evaluation.evaluator]: [0mInference done 1667/3489. 0.2506 s / img. ETA=0:10:45
[32m[03/30 20:34:59 d2.evaluation.evaluator]: [0mInference done 1682/3489. 0.2506 s / img. ETA=0:10:40
[32m[03/30 20:35:05 d2.evaluation.evaluator]: [0mInference done 1697/3489. 0.2506 s / img. ETA=0:10:35
[32m[03/30 20:35:10 d2.evaluation.evaluator]: [0mInference done 1712/3489. 0.2507 s / img. ETA=0:10:29
[32m[03/30 20:35:15 d2.evaluation.evaluator]: [0mInference done 1727/3489. 0.2507 s / img. ETA=0:10:24
[32m[03/30 20:35:21 d2.evaluation.evaluator]: [0mInference done 1742/3489. 0.2507 s / img. ETA=0:10:19
[32m[03/30 20:35:26 d2.evaluation.evaluator]: [0mInference done 1757/3489. 0.2507 s / img. ETA=0:10:13
[32m[03/30 20:35:31 d2.evaluation.evaluator]: [0mInference done 1772/3489. 0.2508 s / img. ETA=0:10:08
[32m[03/30 20:35:37 d2.evaluation.evaluator]: [0mInference done 1786/3489. 0.2507 s / img. ETA=0:10:03
[32m[03/30 20:35:42 d2.evaluation.evaluator]: [0mInference done 1801/3489. 0.2507 s / img. ETA=0:09:58
[32m[03/30 20:35:47 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2507 s / img. ETA=0:09:53
[32m[03/30 20:35:52 d2.evaluation.evaluator]: [0mInference done 1830/3489. 0.2507 s / img. ETA=0:09:48
[32m[03/30 20:35:58 d2.evaluation.evaluator]: [0mInference done 1845/3489. 0.2508 s / img. ETA=0:09:42
[32m[03/30 20:36:03 d2.evaluation.evaluator]: [0mInference done 1860/3489. 0.2508 s / img. ETA=0:09:37
[32m[03/30 20:36:08 d2.evaluation.evaluator]: [0mInference done 1875/3489. 0.2508 s / img. ETA=0:09:32
[32m[03/30 20:36:13 d2.evaluation.evaluator]: [0mInference done 1890/3489. 0.2507 s / img. ETA=0:09:26
[32m[03/30 20:36:19 d2.evaluation.evaluator]: [0mInference done 1905/3489. 0.2508 s / img. ETA=0:09:21
[32m[03/30 20:36:24 d2.evaluation.evaluator]: [0mInference done 1919/3489. 0.2508 s / img. ETA=0:09:16
[32m[03/30 20:36:29 d2.evaluation.evaluator]: [0mInference done 1934/3489. 0.2508 s / img. ETA=0:09:11
[32m[03/30 20:36:34 d2.evaluation.evaluator]: [0mInference done 1949/3489. 0.2508 s / img. ETA=0:09:05
[32m[03/30 20:36:40 d2.evaluation.evaluator]: [0mInference done 1964/3489. 0.2508 s / img. ETA=0:09:00
[32m[03/30 20:36:45 d2.evaluation.evaluator]: [0mInference done 1979/3489. 0.2508 s / img. ETA=0:08:55
[32m[03/30 20:36:50 d2.evaluation.evaluator]: [0mInference done 1993/3489. 0.2508 s / img. ETA=0:08:50
[32m[03/30 20:36:55 d2.evaluation.evaluator]: [0mInference done 2008/3489. 0.2508 s / img. ETA=0:08:45
[32m[03/30 20:37:01 d2.evaluation.evaluator]: [0mInference done 2023/3489. 0.2509 s / img. ETA=0:08:39
[32m[03/30 20:37:06 d2.evaluation.evaluator]: [0mInference done 2037/3489. 0.2509 s / img. ETA=0:08:34
[32m[03/30 20:37:11 d2.evaluation.evaluator]: [0mInference done 2052/3489. 0.2509 s / img. ETA=0:08:29
[32m[03/30 20:37:16 d2.evaluation.evaluator]: [0mInference done 2066/3489. 0.2509 s / img. ETA=0:08:24
[32m[03/30 20:37:21 d2.evaluation.evaluator]: [0mInference done 2081/3489. 0.2509 s / img. ETA=0:08:19
[32m[03/30 20:37:26 d2.evaluation.evaluator]: [0mInference done 2096/3489. 0.2509 s / img. ETA=0:08:13
[32m[03/30 20:37:32 d2.evaluation.evaluator]: [0mInference done 2111/3489. 0.2509 s / img. ETA=0:08:08
[32m[03/30 20:37:37 d2.evaluation.evaluator]: [0mInference done 2126/3489. 0.2509 s / img. ETA=0:08:03
[32m[03/30 20:37:42 d2.evaluation.evaluator]: [0mInference done 2141/3489. 0.2509 s / img. ETA=0:07:57
[32m[03/30 20:37:48 d2.evaluation.evaluator]: [0mInference done 2156/3489. 0.2509 s / img. ETA=0:07:52
[32m[03/30 20:37:53 d2.evaluation.evaluator]: [0mInference done 2171/3489. 0.2509 s / img. ETA=0:07:47
[32m[03/30 20:37:58 d2.evaluation.evaluator]: [0mInference done 2186/3489. 0.2509 s / img. ETA=0:07:41
[32m[03/30 20:38:04 d2.evaluation.evaluator]: [0mInference done 2201/3489. 0.2509 s / img. ETA=0:07:36
[32m[03/30 20:38:09 d2.evaluation.evaluator]: [0mInference done 2216/3489. 0.2509 s / img. ETA=0:07:31
[32m[03/30 20:38:14 d2.evaluation.evaluator]: [0mInference done 2230/3489. 0.2509 s / img. ETA=0:07:26
[32m[03/30 20:38:19 d2.evaluation.evaluator]: [0mInference done 2245/3489. 0.2509 s / img. ETA=0:07:21
[32m[03/30 20:38:25 d2.evaluation.evaluator]: [0mInference done 2260/3489. 0.2510 s / img. ETA=0:07:15
[32m[03/30 20:38:30 d2.evaluation.evaluator]: [0mInference done 2275/3489. 0.2509 s / img. ETA=0:07:10
[32m[03/30 20:38:35 d2.evaluation.evaluator]: [0mInference done 2290/3489. 0.2509 s / img. ETA=0:07:04
[32m[03/30 20:38:40 d2.evaluation.evaluator]: [0mInference done 2305/3489. 0.2510 s / img. ETA=0:06:59
[32m[03/30 20:38:46 d2.evaluation.evaluator]: [0mInference done 2320/3489. 0.2509 s / img. ETA=0:06:54
[32m[03/30 20:38:51 d2.evaluation.evaluator]: [0mInference done 2335/3489. 0.2509 s / img. ETA=0:06:49
[32m[03/30 20:38:56 d2.evaluation.evaluator]: [0mInference done 2350/3489. 0.2510 s / img. ETA=0:06:43
[32m[03/30 20:39:02 d2.evaluation.evaluator]: [0mInference done 2365/3489. 0.2510 s / img. ETA=0:06:38
[32m[03/30 20:39:07 d2.evaluation.evaluator]: [0mInference done 2380/3489. 0.2510 s / img. ETA=0:06:33
[32m[03/30 20:39:12 d2.evaluation.evaluator]: [0mInference done 2394/3489. 0.2510 s / img. ETA=0:06:28
[32m[03/30 20:39:17 d2.evaluation.evaluator]: [0mInference done 2408/3489. 0.2510 s / img. ETA=0:06:23
[32m[03/30 20:39:22 d2.evaluation.evaluator]: [0mInference done 2423/3489. 0.2510 s / img. ETA=0:06:17
[32m[03/30 20:39:28 d2.evaluation.evaluator]: [0mInference done 2438/3489. 0.2510 s / img. ETA=0:06:12
[32m[03/30 20:39:33 d2.evaluation.evaluator]: [0mInference done 2453/3489. 0.2510 s / img. ETA=0:06:07
[32m[03/30 20:39:38 d2.evaluation.evaluator]: [0mInference done 2468/3489. 0.2510 s / img. ETA=0:06:01
[32m[03/30 20:39:44 d2.evaluation.evaluator]: [0mInference done 2483/3489. 0.2510 s / img. ETA=0:05:56
[32m[03/30 20:39:49 d2.evaluation.evaluator]: [0mInference done 2498/3489. 0.2510 s / img. ETA=0:05:51
[32m[03/30 20:39:54 d2.evaluation.evaluator]: [0mInference done 2513/3489. 0.2510 s / img. ETA=0:05:46
[32m[03/30 20:40:00 d2.evaluation.evaluator]: [0mInference done 2528/3489. 0.2511 s / img. ETA=0:05:40
[32m[03/30 20:40:05 d2.evaluation.evaluator]: [0mInference done 2543/3489. 0.2511 s / img. ETA=0:05:35
[32m[03/30 20:40:10 d2.evaluation.evaluator]: [0mInference done 2557/3489. 0.2511 s / img. ETA=0:05:30
[32m[03/30 20:40:15 d2.evaluation.evaluator]: [0mInference done 2572/3489. 0.2511 s / img. ETA=0:05:25
[32m[03/30 20:40:20 d2.evaluation.evaluator]: [0mInference done 2587/3489. 0.2511 s / img. ETA=0:05:19
[32m[03/30 20:40:25 d2.evaluation.evaluator]: [0mInference done 2601/3489. 0.2511 s / img. ETA=0:05:14
[32m[03/30 20:40:30 d2.evaluation.evaluator]: [0mInference done 2615/3489. 0.2511 s / img. ETA=0:05:09
[32m[03/30 20:40:36 d2.evaluation.evaluator]: [0mInference done 2630/3489. 0.2511 s / img. ETA=0:05:04
[32m[03/30 20:40:41 d2.evaluation.evaluator]: [0mInference done 2644/3489. 0.2511 s / img. ETA=0:04:59
[32m[03/30 20:40:46 d2.evaluation.evaluator]: [0mInference done 2659/3489. 0.2511 s / img. ETA=0:04:54
[32m[03/30 20:40:51 d2.evaluation.evaluator]: [0mInference done 2673/3489. 0.2511 s / img. ETA=0:04:49
[32m[03/30 20:40:56 d2.evaluation.evaluator]: [0mInference done 2687/3489. 0.2511 s / img. ETA=0:04:44
[32m[03/30 20:41:01 d2.evaluation.evaluator]: [0mInference done 2701/3489. 0.2511 s / img. ETA=0:04:39
[32m[03/30 20:41:06 d2.evaluation.evaluator]: [0mInference done 2715/3489. 0.2511 s / img. ETA=0:04:34
[32m[03/30 20:41:11 d2.evaluation.evaluator]: [0mInference done 2729/3489. 0.2511 s / img. ETA=0:04:29
[32m[03/30 20:41:17 d2.evaluation.evaluator]: [0mInference done 2743/3489. 0.2512 s / img. ETA=0:04:24
[32m[03/30 20:41:22 d2.evaluation.evaluator]: [0mInference done 2757/3489. 0.2512 s / img. ETA=0:04:19
[32m[03/30 20:41:27 d2.evaluation.evaluator]: [0mInference done 2771/3489. 0.2512 s / img. ETA=0:04:14
[32m[03/30 20:41:32 d2.evaluation.evaluator]: [0mInference done 2785/3489. 0.2511 s / img. ETA=0:04:09
[32m[03/30 20:41:37 d2.evaluation.evaluator]: [0mInference done 2799/3489. 0.2511 s / img. ETA=0:04:04
[32m[03/30 20:41:42 d2.evaluation.evaluator]: [0mInference done 2813/3489. 0.2511 s / img. ETA=0:03:59
[32m[03/30 20:41:47 d2.evaluation.evaluator]: [0mInference done 2827/3489. 0.2512 s / img. ETA=0:03:54
[32m[03/30 20:41:52 d2.evaluation.evaluator]: [0mInference done 2841/3489. 0.2512 s / img. ETA=0:03:50
[32m[03/30 20:41:57 d2.evaluation.evaluator]: [0mInference done 2856/3489. 0.2512 s / img. ETA=0:03:44
[32m[03/30 20:42:02 d2.evaluation.evaluator]: [0mInference done 2870/3489. 0.2512 s / img. ETA=0:03:39
[32m[03/30 20:42:07 d2.evaluation.evaluator]: [0mInference done 2884/3489. 0.2512 s / img. ETA=0:03:34
[32m[03/30 20:42:12 d2.evaluation.evaluator]: [0mInference done 2898/3489. 0.2512 s / img. ETA=0:03:29
[32m[03/30 20:42:17 d2.evaluation.evaluator]: [0mInference done 2912/3489. 0.2512 s / img. ETA=0:03:24
[32m[03/30 20:42:23 d2.evaluation.evaluator]: [0mInference done 2927/3489. 0.2512 s / img. ETA=0:03:19
[32m[03/30 20:42:28 d2.evaluation.evaluator]: [0mInference done 2941/3489. 0.2512 s / img. ETA=0:03:14
[32m[03/30 20:42:33 d2.evaluation.evaluator]: [0mInference done 2955/3489. 0.2512 s / img. ETA=0:03:09
[32m[03/30 20:42:38 d2.evaluation.evaluator]: [0mInference done 2969/3489. 0.2512 s / img. ETA=0:03:04
[32m[03/30 20:42:43 d2.evaluation.evaluator]: [0mInference done 2983/3489. 0.2512 s / img. ETA=0:02:59
[32m[03/30 20:42:48 d2.evaluation.evaluator]: [0mInference done 2997/3489. 0.2512 s / img. ETA=0:02:54
[32m[03/30 20:42:53 d2.evaluation.evaluator]: [0mInference done 3011/3489. 0.2512 s / img. ETA=0:02:49
[32m[03/30 20:42:58 d2.evaluation.evaluator]: [0mInference done 3025/3489. 0.2512 s / img. ETA=0:02:44
[32m[03/30 20:43:03 d2.evaluation.evaluator]: [0mInference done 3039/3489. 0.2512 s / img. ETA=0:02:39
[32m[03/30 20:43:08 d2.evaluation.evaluator]: [0mInference done 3053/3489. 0.2512 s / img. ETA=0:02:34
[32m[03/30 20:43:13 d2.evaluation.evaluator]: [0mInference done 3067/3489. 0.2512 s / img. ETA=0:02:29
[32m[03/30 20:43:18 d2.evaluation.evaluator]: [0mInference done 3081/3489. 0.2512 s / img. ETA=0:02:24
[32m[03/30 20:43:23 d2.evaluation.evaluator]: [0mInference done 3095/3489. 0.2512 s / img. ETA=0:02:20
[32m[03/30 20:43:28 d2.evaluation.evaluator]: [0mInference done 3109/3489. 0.2512 s / img. ETA=0:02:15
[32m[03/30 20:43:34 d2.evaluation.evaluator]: [0mInference done 3123/3489. 0.2512 s / img. ETA=0:02:10
[32m[03/30 20:43:39 d2.evaluation.evaluator]: [0mInference done 3137/3489. 0.2513 s / img. ETA=0:02:05
[32m[03/30 20:43:44 d2.evaluation.evaluator]: [0mInference done 3151/3489. 0.2512 s / img. ETA=0:02:00
[32m[03/30 20:43:49 d2.evaluation.evaluator]: [0mInference done 3165/3489. 0.2512 s / img. ETA=0:01:55
[32m[03/30 20:43:54 d2.evaluation.evaluator]: [0mInference done 3179/3489. 0.2512 s / img. ETA=0:01:50
[32m[03/30 20:43:59 d2.evaluation.evaluator]: [0mInference done 3193/3489. 0.2513 s / img. ETA=0:01:45
[32m[03/30 20:44:04 d2.evaluation.evaluator]: [0mInference done 3207/3489. 0.2513 s / img. ETA=0:01:40
[32m[03/30 20:44:09 d2.evaluation.evaluator]: [0mInference done 3221/3489. 0.2513 s / img. ETA=0:01:35
[32m[03/30 20:44:14 d2.evaluation.evaluator]: [0mInference done 3235/3489. 0.2512 s / img. ETA=0:01:30
[32m[03/30 20:44:19 d2.evaluation.evaluator]: [0mInference done 3249/3489. 0.2512 s / img. ETA=0:01:25
[32m[03/30 20:44:24 d2.evaluation.evaluator]: [0mInference done 3263/3489. 0.2512 s / img. ETA=0:01:20
[32m[03/30 20:44:29 d2.evaluation.evaluator]: [0mInference done 3277/3489. 0.2513 s / img. ETA=0:01:15
[32m[03/30 20:44:34 d2.evaluation.evaluator]: [0mInference done 3291/3489. 0.2513 s / img. ETA=0:01:10
[32m[03/30 20:44:39 d2.evaluation.evaluator]: [0mInference done 3305/3489. 0.2513 s / img. ETA=0:01:05
[32m[03/30 20:44:44 d2.evaluation.evaluator]: [0mInference done 3319/3489. 0.2513 s / img. ETA=0:01:00
[32m[03/30 20:44:50 d2.evaluation.evaluator]: [0mInference done 3333/3489. 0.2513 s / img. ETA=0:00:55
[32m[03/30 20:44:55 d2.evaluation.evaluator]: [0mInference done 3347/3489. 0.2513 s / img. ETA=0:00:50
[32m[03/30 20:45:00 d2.evaluation.evaluator]: [0mInference done 3361/3489. 0.2513 s / img. ETA=0:00:45
[32m[03/30 20:45:05 d2.evaluation.evaluator]: [0mInference done 3375/3489. 0.2513 s / img. ETA=0:00:40
[32m[03/30 20:45:10 d2.evaluation.evaluator]: [0mInference done 3389/3489. 0.2513 s / img. ETA=0:00:35
[32m[03/30 20:45:15 d2.evaluation.evaluator]: [0mInference done 3403/3489. 0.2513 s / img. ETA=0:00:30
[32m[03/30 20:45:20 d2.evaluation.evaluator]: [0mInference done 3417/3489. 0.2513 s / img. ETA=0:00:25
[32m[03/30 20:45:25 d2.evaluation.evaluator]: [0mInference done 3431/3489. 0.2513 s / img. ETA=0:00:20
[32m[03/30 20:45:30 d2.evaluation.evaluator]: [0mInference done 3445/3489. 0.2513 s / img. ETA=0:00:15
[32m[03/30 20:45:35 d2.evaluation.evaluator]: [0mInference done 3459/3489. 0.2513 s / img. ETA=0:00:10
[32m[03/30 20:45:40 d2.evaluation.evaluator]: [0mInference done 3473/3489. 0.2513 s / img. ETA=0:00:05
[32m[03/30 20:45:45 d2.evaluation.evaluator]: [0mInference done 3487/3489. 0.2513 s / img. ETA=0:00:00
[32m[03/30 20:45:46 d2.evaluation.evaluator]: [0mTotal inference time: 0:20:41.154063 (0.356244 s / img per device, on 1 devices)
[32m[03/30 20:45:46 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:35 (0.251295 s / img per device, on 1 devices)
[32m[03/30 20:45:50 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/30 20:45:50 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_32.000000/coco_instances_results.json
[32m[03/30 20:45:53 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 2.39 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 1.05 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[03/30 20:45:57 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[32m[03/30 20:45:57 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| Cars       | 0.000 | Pedestrian | 0.000 |
Loading and preparing results...
DONE (t=2.97s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.99 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 1.08 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[03/30 20:46:14 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[32m[03/30 20:46:14 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| Cars       | 0.000 | Pedestrian | 0.000 |
[32m[03/30 20:46:15 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: 0.0000,0.0001,0.0000,0.0000,0.0000,0.0000
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 20:46:15 d2.evaluation.testing]: [0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
evaluated
Test [200]
[32m[03/30 20:46:16 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 20:46:16 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 20:46:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(200,), max_size=200, sample_style='choice'), RandomFlip()]
[32m[03/30 20:46:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 20:46:16 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 20:46:16 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 20:46:16 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 20:46:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(200,), max_size=200, sample_style='choice'), RandomFlip()]
[32m[03/30 20:46:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 20:46:16 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 20:46:16 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 20:46:16 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 20:46:29 d2.utils.events]: [0m eta: 0:01:14  iter: 19  total_loss: 1.578  loss_cls: 0.6747  loss_box_reg: 0.06256  loss_mask: 0.6843  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.0516  total_val_loss: 1.582  val_loss_cls: 0.6375  val_loss_box_reg: 0.07514  val_loss_mask: 0.6882  val_loss_rpn_cls: 0.1478  val_loss_rpn_loc: 0.05334  time: 0.4187  data_time: 0.0238  lr: 0.00019981  max_mem: 2475M
[32m[03/30 20:46:40 d2.utils.events]: [0m eta: 0:01:07  iter: 39  total_loss: 1.019  loss_cls: 0.1785  loss_box_reg: 0.0878  loss_mask: 0.5684  loss_rpn_cls: 0.09671  loss_rpn_loc: 0.04712  total_val_loss: 1.077  val_loss_cls: 0.2051  val_loss_box_reg: 0.08016  val_loss_mask: 0.6624  val_loss_rpn_cls: 0.1106  val_loss_rpn_loc: 0.04319  time: 0.4219  data_time: 0.0053  lr: 0.00039961  max_mem: 2475M
[32m[03/30 20:46:52 d2.utils.events]: [0m eta: 0:00:59  iter: 59  total_loss: 0.8106  loss_cls: 0.1184  loss_box_reg: 0.08256  loss_mask: 0.4757  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.04057  total_val_loss: 0.9404  val_loss_cls: 0.1397  val_loss_box_reg: 0.07806  val_loss_mask: 0.5781  val_loss_rpn_cls: 0.0811  val_loss_rpn_loc: 0.03891  time: 0.4269  data_time: 0.0066  lr: 0.00059941  max_mem: 2475M
[32m[03/30 20:47:04 d2.utils.events]: [0m eta: 0:00:51  iter: 79  total_loss: 0.7527  loss_cls: 0.1134  loss_box_reg: 0.08452  loss_mask: 0.4556  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.02951  total_val_loss: 0.9075  val_loss_cls: 0.1677  val_loss_box_reg: 0.06702  val_loss_mask: 0.566  val_loss_rpn_cls: 0.06231  val_loss_rpn_loc: 0.0466  time: 0.4294  data_time: 0.0075  lr: 0.00079921  max_mem: 2475M
[32m[03/30 20:47:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:47:16 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:47:17 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:47:17 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 20:47:17 d2.utils.events]: [0m eta: 0:00:42  iter: 99  total_loss: 0.7169  loss_cls: 0.09741  loss_box_reg: 0.1072  loss_mask: 0.3796  loss_rpn_cls: 0.05553  loss_rpn_loc: 0.03428  total_val_loss: 0.8578  val_loss_cls: 0.1493  val_loss_box_reg: 0.08396  val_loss_mask: 0.5391  val_loss_rpn_cls: 0.06438  val_loss_rpn_loc: 0.04847  time: 0.4313  data_time: 0.0060  lr: 0.00099901  max_mem: 2475M
[32m[03/30 20:47:29 d2.utils.events]: [0m eta: 0:00:34  iter: 119  total_loss: 0.6615  loss_cls: 0.05981  loss_box_reg: 0.05021  loss_mask: 0.4088  loss_rpn_cls: 0.04725  loss_rpn_loc: 0.02708  total_val_loss: 0.8593  val_loss_cls: 0.09864  val_loss_box_reg: 0.06913  val_loss_mask: 0.5313  val_loss_rpn_cls: 0.05485  val_loss_rpn_loc: 0.03933  time: 0.4341  data_time: 0.0071  lr: 0.0011988  max_mem: 2475M
[32m[03/30 20:47:41 d2.utils.events]: [0m eta: 0:00:25  iter: 139  total_loss: 0.6923  loss_cls: 0.07946  loss_box_reg: 0.07948  loss_mask: 0.3988  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.03942  total_val_loss: 0.7768  val_loss_cls: 0.1137  val_loss_box_reg: 0.07485  val_loss_mask: 0.4553  val_loss_rpn_cls: 0.0704  val_loss_rpn_loc: 0.0462  time: 0.4361  data_time: 0.0075  lr: 0.0013986  max_mem: 2475M
[32m[03/30 20:47:53 d2.utils.events]: [0m eta: 0:00:17  iter: 159  total_loss: 0.7012  loss_cls: 0.0577  loss_box_reg: 0.06867  loss_mask: 0.4412  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.02404  total_val_loss: 0.7045  val_loss_cls: 0.1066  val_loss_box_reg: 0.06077  val_loss_mask: 0.4375  val_loss_rpn_cls: 0.06295  val_loss_rpn_loc: 0.03953  time: 0.4373  data_time: 0.0057  lr: 0.0015984  max_mem: 2475M
[32m[03/30 20:48:05 d2.utils.events]: [0m eta: 0:00:08  iter: 179  total_loss: 0.6865  loss_cls: 0.08213  loss_box_reg: 0.06645  loss_mask: 0.3919  loss_rpn_cls: 0.05673  loss_rpn_loc: 0.03789  total_val_loss: 0.8505  val_loss_cls: 0.1295  val_loss_box_reg: 0.1015  val_loss_mask: 0.4762  val_loss_rpn_cls: 0.0471  val_loss_rpn_loc: 0.03792  time: 0.4380  data_time: 0.0060  lr: 0.0017982  max_mem: 2475M
[32m[03/30 20:48:18 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:48:18 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:48:18 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:48:18 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 20:48:18 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.703  loss_cls: 0.07725  loss_box_reg: 0.07623  loss_mask: 0.401  loss_rpn_cls: 0.052  loss_rpn_loc: 0.03946  total_val_loss: 0.9096  val_loss_cls: 0.1604  val_loss_box_reg: 0.07186  val_loss_mask: 0.5583  val_loss_rpn_cls: 0.06334  val_loss_rpn_loc: 0.04758  time: 0.4384  data_time: 0.0058  lr: 0.001998  max_mem: 2475M
[32m[03/30 20:48:18 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:01:26 (0.4384 s / it)
[32m[03/30 20:48:18 d2.engine.hooks]: [0mTotal training time: 0:01:59 (0:00:33 on hooks)
[32m[03/30 20:48:19 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:48:19 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:48:19 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 20:48:19 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/30 20:48:19 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/30 20:48:20 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 20:48:20 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 20:48:20 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/30 20:48:20 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/30 20:48:24 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2308 s / img. ETA=0:16:31
[32m[03/30 20:48:29 d2.evaluation.evaluator]: [0mInference done 29/3489. 0.2366 s / img. ETA=0:16:32
[32m[03/30 20:48:34 d2.evaluation.evaluator]: [0mInference done 47/3489. 0.2347 s / img. ETA=0:16:14
[32m[03/30 20:48:39 d2.evaluation.evaluator]: [0mInference done 65/3489. 0.2342 s / img. ETA=0:16:10
[32m[03/30 20:48:45 d2.evaluation.evaluator]: [0mInference done 83/3489. 0.2345 s / img. ETA=0:16:11
[32m[03/30 20:48:50 d2.evaluation.evaluator]: [0mInference done 100/3489. 0.2363 s / img. ETA=0:16:20
[32m[03/30 20:48:55 d2.evaluation.evaluator]: [0mInference done 116/3489. 0.2375 s / img. ETA=0:16:29
[32m[03/30 20:49:00 d2.evaluation.evaluator]: [0mInference done 132/3489. 0.2386 s / img. ETA=0:16:35
[32m[03/30 20:49:05 d2.evaluation.evaluator]: [0mInference done 148/3489. 0.2397 s / img. ETA=0:16:39
[32m[03/30 20:49:10 d2.evaluation.evaluator]: [0mInference done 164/3489. 0.2410 s / img. ETA=0:16:43
[32m[03/30 20:49:15 d2.evaluation.evaluator]: [0mInference done 180/3489. 0.2421 s / img. ETA=0:16:45
[32m[03/30 20:49:21 d2.evaluation.evaluator]: [0mInference done 196/3489. 0.2424 s / img. ETA=0:16:44
[32m[03/30 20:49:26 d2.evaluation.evaluator]: [0mInference done 213/3489. 0.2425 s / img. ETA=0:16:41
[32m[03/30 20:49:31 d2.evaluation.evaluator]: [0mInference done 229/3489. 0.2431 s / img. ETA=0:16:39
[32m[03/30 20:49:36 d2.evaluation.evaluator]: [0mInference done 246/3489. 0.2432 s / img. ETA=0:16:35
[32m[03/30 20:49:41 d2.evaluation.evaluator]: [0mInference done 262/3489. 0.2433 s / img. ETA=0:16:31
[32m[03/30 20:49:46 d2.evaluation.evaluator]: [0mInference done 278/3489. 0.2438 s / img. ETA=0:16:29
[32m[03/30 20:49:51 d2.evaluation.evaluator]: [0mInference done 294/3489. 0.2439 s / img. ETA=0:16:25
[32m[03/30 20:49:57 d2.evaluation.evaluator]: [0mInference done 310/3489. 0.2445 s / img. ETA=0:16:23
[32m[03/30 20:50:02 d2.evaluation.evaluator]: [0mInference done 326/3489. 0.2445 s / img. ETA=0:16:19
[32m[03/30 20:50:07 d2.evaluation.evaluator]: [0mInference done 342/3489. 0.2446 s / img. ETA=0:16:15
[32m[03/30 20:50:12 d2.evaluation.evaluator]: [0mInference done 358/3489. 0.2447 s / img. ETA=0:16:12
[32m[03/30 20:50:17 d2.evaluation.evaluator]: [0mInference done 374/3489. 0.2449 s / img. ETA=0:16:08
[32m[03/30 20:50:22 d2.evaluation.evaluator]: [0mInference done 390/3489. 0.2451 s / img. ETA=0:16:04
[32m[03/30 20:50:27 d2.evaluation.evaluator]: [0mInference done 406/3489. 0.2451 s / img. ETA=0:16:00
[32m[03/30 20:50:32 d2.evaluation.evaluator]: [0mInference done 422/3489. 0.2453 s / img. ETA=0:15:55
[32m[03/30 20:50:37 d2.evaluation.evaluator]: [0mInference done 440/3489. 0.2450 s / img. ETA=0:15:46
[32m[03/30 20:50:42 d2.evaluation.evaluator]: [0mInference done 460/3489. 0.2443 s / img. ETA=0:15:32
[32m[03/30 20:50:48 d2.evaluation.evaluator]: [0mInference done 480/3489. 0.2437 s / img. ETA=0:15:20
[32m[03/30 20:50:53 d2.evaluation.evaluator]: [0mInference done 498/3489. 0.2436 s / img. ETA=0:15:13
[32m[03/30 20:50:58 d2.evaluation.evaluator]: [0mInference done 516/3489. 0.2434 s / img. ETA=0:15:06
[32m[03/30 20:51:03 d2.evaluation.evaluator]: [0mInference done 534/3489. 0.2433 s / img. ETA=0:14:58
[32m[03/30 20:51:08 d2.evaluation.evaluator]: [0mInference done 552/3489. 0.2432 s / img. ETA=0:14:52
[32m[03/30 20:51:14 d2.evaluation.evaluator]: [0mInference done 568/3489. 0.2433 s / img. ETA=0:14:48
[32m[03/30 20:51:19 d2.evaluation.evaluator]: [0mInference done 584/3489. 0.2434 s / img. ETA=0:14:44
[32m[03/30 20:51:24 d2.evaluation.evaluator]: [0mInference done 600/3489. 0.2436 s / img. ETA=0:14:40
[32m[03/30 20:51:29 d2.evaluation.evaluator]: [0mInference done 616/3489. 0.2438 s / img. ETA=0:14:36
[32m[03/30 20:51:34 d2.evaluation.evaluator]: [0mInference done 632/3489. 0.2439 s / img. ETA=0:14:33
[32m[03/30 20:51:39 d2.evaluation.evaluator]: [0mInference done 648/3489. 0.2440 s / img. ETA=0:14:29
[32m[03/30 20:51:44 d2.evaluation.evaluator]: [0mInference done 664/3489. 0.2443 s / img. ETA=0:14:25
[32m[03/30 20:51:50 d2.evaluation.evaluator]: [0mInference done 681/3489. 0.2442 s / img. ETA=0:14:20
[32m[03/30 20:51:55 d2.evaluation.evaluator]: [0mInference done 698/3489. 0.2443 s / img. ETA=0:14:15
[32m[03/30 20:52:00 d2.evaluation.evaluator]: [0mInference done 715/3489. 0.2443 s / img. ETA=0:14:10
[32m[03/30 20:52:05 d2.evaluation.evaluator]: [0mInference done 732/3489. 0.2443 s / img. ETA=0:14:05
[32m[03/30 20:52:10 d2.evaluation.evaluator]: [0mInference done 749/3489. 0.2443 s / img. ETA=0:14:00
[32m[03/30 20:52:16 d2.evaluation.evaluator]: [0mInference done 766/3489. 0.2443 s / img. ETA=0:13:55
[32m[03/30 20:52:21 d2.evaluation.evaluator]: [0mInference done 783/3489. 0.2443 s / img. ETA=0:13:49
[32m[03/30 20:52:26 d2.evaluation.evaluator]: [0mInference done 800/3489. 0.2442 s / img. ETA=0:13:43
[32m[03/30 20:52:31 d2.evaluation.evaluator]: [0mInference done 817/3489. 0.2443 s / img. ETA=0:13:38
[32m[03/30 20:52:36 d2.evaluation.evaluator]: [0mInference done 835/3489. 0.2442 s / img. ETA=0:13:31
[32m[03/30 20:52:41 d2.evaluation.evaluator]: [0mInference done 852/3489. 0.2440 s / img. ETA=0:13:26
[32m[03/30 20:52:46 d2.evaluation.evaluator]: [0mInference done 870/3489. 0.2439 s / img. ETA=0:13:19
[32m[03/30 20:52:52 d2.evaluation.evaluator]: [0mInference done 888/3489. 0.2438 s / img. ETA=0:13:13
[32m[03/30 20:52:57 d2.evaluation.evaluator]: [0mInference done 905/3489. 0.2440 s / img. ETA=0:13:08
[32m[03/30 20:53:02 d2.evaluation.evaluator]: [0mInference done 921/3489. 0.2440 s / img. ETA=0:13:04
[32m[03/30 20:53:07 d2.evaluation.evaluator]: [0mInference done 937/3489. 0.2441 s / img. ETA=0:13:00
[32m[03/30 20:53:13 d2.evaluation.evaluator]: [0mInference done 953/3489. 0.2443 s / img. ETA=0:12:56
[32m[03/30 20:53:18 d2.evaluation.evaluator]: [0mInference done 969/3489. 0.2444 s / img. ETA=0:12:52
[32m[03/30 20:53:23 d2.evaluation.evaluator]: [0mInference done 985/3489. 0.2445 s / img. ETA=0:12:48
[32m[03/30 20:53:28 d2.evaluation.evaluator]: [0mInference done 1001/3489. 0.2446 s / img. ETA=0:12:43
[32m[03/30 20:53:33 d2.evaluation.evaluator]: [0mInference done 1017/3489. 0.2446 s / img. ETA=0:12:38
[32m[03/30 20:53:38 d2.evaluation.evaluator]: [0mInference done 1033/3489. 0.2447 s / img. ETA=0:12:34
[32m[03/30 20:53:43 d2.evaluation.evaluator]: [0mInference done 1049/3489. 0.2448 s / img. ETA=0:12:29
[32m[03/30 20:53:48 d2.evaluation.evaluator]: [0mInference done 1065/3489. 0.2448 s / img. ETA=0:12:25
[32m[03/30 20:53:53 d2.evaluation.evaluator]: [0mInference done 1081/3489. 0.2449 s / img. ETA=0:12:20
[32m[03/30 20:53:58 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2450 s / img. ETA=0:12:16
[32m[03/30 20:54:04 d2.evaluation.evaluator]: [0mInference done 1114/3489. 0.2450 s / img. ETA=0:12:10
[32m[03/30 20:54:09 d2.evaluation.evaluator]: [0mInference done 1130/3489. 0.2450 s / img. ETA=0:12:06
[32m[03/30 20:54:14 d2.evaluation.evaluator]: [0mInference done 1146/3489. 0.2451 s / img. ETA=0:12:01
[32m[03/30 20:54:19 d2.evaluation.evaluator]: [0mInference done 1163/3489. 0.2451 s / img. ETA=0:11:56
[32m[03/30 20:54:24 d2.evaluation.evaluator]: [0mInference done 1179/3489. 0.2451 s / img. ETA=0:11:51
[32m[03/30 20:54:29 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2452 s / img. ETA=0:11:46
[32m[03/30 20:54:34 d2.evaluation.evaluator]: [0mInference done 1211/3489. 0.2452 s / img. ETA=0:11:42
[32m[03/30 20:54:39 d2.evaluation.evaluator]: [0mInference done 1227/3489. 0.2452 s / img. ETA=0:11:37
[32m[03/30 20:54:44 d2.evaluation.evaluator]: [0mInference done 1243/3489. 0.2453 s / img. ETA=0:11:32
[32m[03/30 20:54:49 d2.evaluation.evaluator]: [0mInference done 1260/3489. 0.2453 s / img. ETA=0:11:27
[32m[03/30 20:54:54 d2.evaluation.evaluator]: [0mInference done 1280/3489. 0.2450 s / img. ETA=0:11:19
[32m[03/30 20:54:59 d2.evaluation.evaluator]: [0mInference done 1301/3489. 0.2447 s / img. ETA=0:11:10
[32m[03/30 20:55:05 d2.evaluation.evaluator]: [0mInference done 1322/3489. 0.2444 s / img. ETA=0:11:02
[32m[03/30 20:55:10 d2.evaluation.evaluator]: [0mInference done 1341/3489. 0.2444 s / img. ETA=0:10:55
[32m[03/30 20:55:15 d2.evaluation.evaluator]: [0mInference done 1362/3489. 0.2441 s / img. ETA=0:10:46
[32m[03/30 20:55:20 d2.evaluation.evaluator]: [0mInference done 1382/3489. 0.2439 s / img. ETA=0:10:39
[32m[03/30 20:55:25 d2.evaluation.evaluator]: [0mInference done 1402/3489. 0.2437 s / img. ETA=0:10:32
[32m[03/30 20:55:30 d2.evaluation.evaluator]: [0mInference done 1421/3489. 0.2436 s / img. ETA=0:10:25
[32m[03/30 20:55:36 d2.evaluation.evaluator]: [0mInference done 1440/3489. 0.2435 s / img. ETA=0:10:18
[32m[03/30 20:55:41 d2.evaluation.evaluator]: [0mInference done 1459/3489. 0.2433 s / img. ETA=0:10:12
[32m[03/30 20:55:46 d2.evaluation.evaluator]: [0mInference done 1479/3489. 0.2432 s / img. ETA=0:10:04
[32m[03/30 20:55:51 d2.evaluation.evaluator]: [0mInference done 1499/3489. 0.2430 s / img. ETA=0:09:57
[32m[03/30 20:55:56 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2428 s / img. ETA=0:09:50
[32m[03/30 20:56:01 d2.evaluation.evaluator]: [0mInference done 1538/3489. 0.2427 s / img. ETA=0:09:44
[32m[03/30 20:56:06 d2.evaluation.evaluator]: [0mInference done 1556/3489. 0.2426 s / img. ETA=0:09:38
[32m[03/30 20:56:12 d2.evaluation.evaluator]: [0mInference done 1575/3489. 0.2425 s / img. ETA=0:09:32
[32m[03/30 20:56:17 d2.evaluation.evaluator]: [0mInference done 1594/3489. 0.2425 s / img. ETA=0:09:26
[32m[03/30 20:56:22 d2.evaluation.evaluator]: [0mInference done 1610/3489. 0.2425 s / img. ETA=0:09:21
[32m[03/30 20:56:27 d2.evaluation.evaluator]: [0mInference done 1626/3489. 0.2426 s / img. ETA=0:09:17
[32m[03/30 20:56:32 d2.evaluation.evaluator]: [0mInference done 1642/3489. 0.2426 s / img. ETA=0:09:12
[32m[03/30 20:56:38 d2.evaluation.evaluator]: [0mInference done 1658/3489. 0.2427 s / img. ETA=0:09:08
[32m[03/30 20:56:43 d2.evaluation.evaluator]: [0mInference done 1674/3489. 0.2429 s / img. ETA=0:09:04
[32m[03/30 20:56:48 d2.evaluation.evaluator]: [0mInference done 1690/3489. 0.2429 s / img. ETA=0:08:59
[32m[03/30 20:56:53 d2.evaluation.evaluator]: [0mInference done 1706/3489. 0.2430 s / img. ETA=0:08:55
[32m[03/30 20:56:58 d2.evaluation.evaluator]: [0mInference done 1722/3489. 0.2431 s / img. ETA=0:08:50
[32m[03/30 20:57:03 d2.evaluation.evaluator]: [0mInference done 1738/3489. 0.2431 s / img. ETA=0:08:46
[32m[03/30 20:57:08 d2.evaluation.evaluator]: [0mInference done 1754/3489. 0.2431 s / img. ETA=0:08:41
[32m[03/30 20:57:13 d2.evaluation.evaluator]: [0mInference done 1770/3489. 0.2432 s / img. ETA=0:08:37
[32m[03/30 20:57:19 d2.evaluation.evaluator]: [0mInference done 1786/3489. 0.2432 s / img. ETA=0:08:32
[32m[03/30 20:57:24 d2.evaluation.evaluator]: [0mInference done 1802/3489. 0.2433 s / img. ETA=0:08:28
[32m[03/30 20:57:29 d2.evaluation.evaluator]: [0mInference done 1818/3489. 0.2433 s / img. ETA=0:08:23
[32m[03/30 20:57:34 d2.evaluation.evaluator]: [0mInference done 1834/3489. 0.2434 s / img. ETA=0:08:19
[32m[03/30 20:57:39 d2.evaluation.evaluator]: [0mInference done 1850/3489. 0.2434 s / img. ETA=0:08:14
[32m[03/30 20:57:44 d2.evaluation.evaluator]: [0mInference done 1866/3489. 0.2435 s / img. ETA=0:08:09
[32m[03/30 20:57:49 d2.evaluation.evaluator]: [0mInference done 1882/3489. 0.2435 s / img. ETA=0:08:05
[32m[03/30 20:57:54 d2.evaluation.evaluator]: [0mInference done 1898/3489. 0.2436 s / img. ETA=0:08:00
[32m[03/30 20:57:59 d2.evaluation.evaluator]: [0mInference done 1914/3489. 0.2436 s / img. ETA=0:07:56
[32m[03/30 20:58:04 d2.evaluation.evaluator]: [0mInference done 1929/3489. 0.2436 s / img. ETA=0:07:51
[32m[03/30 20:58:10 d2.evaluation.evaluator]: [0mInference done 1945/3489. 0.2437 s / img. ETA=0:07:47
[32m[03/30 20:58:15 d2.evaluation.evaluator]: [0mInference done 1961/3489. 0.2437 s / img. ETA=0:07:42
[32m[03/30 20:58:20 d2.evaluation.evaluator]: [0mInference done 1977/3489. 0.2438 s / img. ETA=0:07:38
[32m[03/30 20:58:25 d2.evaluation.evaluator]: [0mInference done 1993/3489. 0.2438 s / img. ETA=0:07:33
[32m[03/30 20:58:30 d2.evaluation.evaluator]: [0mInference done 2009/3489. 0.2439 s / img. ETA=0:07:28
[32m[03/30 20:58:35 d2.evaluation.evaluator]: [0mInference done 2025/3489. 0.2439 s / img. ETA=0:07:24
[32m[03/30 20:58:40 d2.evaluation.evaluator]: [0mInference done 2041/3489. 0.2439 s / img. ETA=0:07:19
[32m[03/30 20:58:45 d2.evaluation.evaluator]: [0mInference done 2057/3489. 0.2440 s / img. ETA=0:07:14
[32m[03/30 20:58:50 d2.evaluation.evaluator]: [0mInference done 2073/3489. 0.2440 s / img. ETA=0:07:10
[32m[03/30 20:58:56 d2.evaluation.evaluator]: [0mInference done 2089/3489. 0.2441 s / img. ETA=0:07:05
[32m[03/30 20:59:01 d2.evaluation.evaluator]: [0mInference done 2105/3489. 0.2441 s / img. ETA=0:07:00
[32m[03/30 20:59:06 d2.evaluation.evaluator]: [0mInference done 2121/3489. 0.2442 s / img. ETA=0:06:56
[32m[03/30 20:59:11 d2.evaluation.evaluator]: [0mInference done 2137/3489. 0.2443 s / img. ETA=0:06:51
[32m[03/30 20:59:16 d2.evaluation.evaluator]: [0mInference done 2153/3489. 0.2443 s / img. ETA=0:06:46
[32m[03/30 20:59:21 d2.evaluation.evaluator]: [0mInference done 2169/3489. 0.2443 s / img. ETA=0:06:41
[32m[03/30 20:59:26 d2.evaluation.evaluator]: [0mInference done 2185/3489. 0.2443 s / img. ETA=0:06:37
[32m[03/30 20:59:32 d2.evaluation.evaluator]: [0mInference done 2201/3489. 0.2443 s / img. ETA=0:06:32
[32m[03/30 20:59:37 d2.evaluation.evaluator]: [0mInference done 2217/3489. 0.2443 s / img. ETA=0:06:27
[32m[03/30 20:59:42 d2.evaluation.evaluator]: [0mInference done 2233/3489. 0.2444 s / img. ETA=0:06:23
[32m[03/30 20:59:47 d2.evaluation.evaluator]: [0mInference done 2249/3489. 0.2444 s / img. ETA=0:06:18
[32m[03/30 20:59:52 d2.evaluation.evaluator]: [0mInference done 2265/3489. 0.2445 s / img. ETA=0:06:13
[32m[03/30 20:59:58 d2.evaluation.evaluator]: [0mInference done 2281/3489. 0.2445 s / img. ETA=0:06:09
[32m[03/30 21:00:03 d2.evaluation.evaluator]: [0mInference done 2297/3489. 0.2445 s / img. ETA=0:06:04
[32m[03/30 21:00:08 d2.evaluation.evaluator]: [0mInference done 2313/3489. 0.2445 s / img. ETA=0:05:59
[32m[03/30 21:00:13 d2.evaluation.evaluator]: [0mInference done 2329/3489. 0.2446 s / img. ETA=0:05:54
[32m[03/30 21:00:18 d2.evaluation.evaluator]: [0mInference done 2345/3489. 0.2446 s / img. ETA=0:05:50
[32m[03/30 21:00:24 d2.evaluation.evaluator]: [0mInference done 2361/3489. 0.2446 s / img. ETA=0:05:45
[32m[03/30 21:00:29 d2.evaluation.evaluator]: [0mInference done 2377/3489. 0.2447 s / img. ETA=0:05:40
[32m[03/30 21:00:34 d2.evaluation.evaluator]: [0mInference done 2393/3489. 0.2447 s / img. ETA=0:05:35
[32m[03/30 21:00:39 d2.evaluation.evaluator]: [0mInference done 2409/3489. 0.2447 s / img. ETA=0:05:31
[32m[03/30 21:00:44 d2.evaluation.evaluator]: [0mInference done 2425/3489. 0.2447 s / img. ETA=0:05:26
[32m[03/30 21:00:50 d2.evaluation.evaluator]: [0mInference done 2441/3489. 0.2448 s / img. ETA=0:05:21
[32m[03/30 21:00:55 d2.evaluation.evaluator]: [0mInference done 2457/3489. 0.2448 s / img. ETA=0:05:16
[32m[03/30 21:01:00 d2.evaluation.evaluator]: [0mInference done 2472/3489. 0.2448 s / img. ETA=0:05:12
[32m[03/30 21:01:05 d2.evaluation.evaluator]: [0mInference done 2488/3489. 0.2449 s / img. ETA=0:05:07
[32m[03/30 21:01:10 d2.evaluation.evaluator]: [0mInference done 2504/3489. 0.2449 s / img. ETA=0:05:02
[32m[03/30 21:01:15 d2.evaluation.evaluator]: [0mInference done 2520/3489. 0.2449 s / img. ETA=0:04:57
[32m[03/30 21:01:20 d2.evaluation.evaluator]: [0mInference done 2537/3489. 0.2449 s / img. ETA=0:04:52
[32m[03/30 21:01:26 d2.evaluation.evaluator]: [0mInference done 2555/3489. 0.2449 s / img. ETA=0:04:46
[32m[03/30 21:01:31 d2.evaluation.evaluator]: [0mInference done 2573/3489. 0.2449 s / img. ETA=0:04:41
[32m[03/30 21:01:36 d2.evaluation.evaluator]: [0mInference done 2592/3489. 0.2448 s / img. ETA=0:04:35
[32m[03/30 21:01:41 d2.evaluation.evaluator]: [0mInference done 2610/3489. 0.2447 s / img. ETA=0:04:29
[32m[03/30 21:01:46 d2.evaluation.evaluator]: [0mInference done 2628/3489. 0.2447 s / img. ETA=0:04:23
[32m[03/30 21:01:52 d2.evaluation.evaluator]: [0mInference done 2646/3489. 0.2447 s / img. ETA=0:04:18
[32m[03/30 21:01:57 d2.evaluation.evaluator]: [0mInference done 2664/3489. 0.2446 s / img. ETA=0:04:12
[32m[03/30 21:02:02 d2.evaluation.evaluator]: [0mInference done 2682/3489. 0.2445 s / img. ETA=0:04:07
[32m[03/30 21:02:07 d2.evaluation.evaluator]: [0mInference done 2700/3489. 0.2445 s / img. ETA=0:04:01
[32m[03/30 21:02:12 d2.evaluation.evaluator]: [0mInference done 2718/3489. 0.2444 s / img. ETA=0:03:55
[32m[03/30 21:02:17 d2.evaluation.evaluator]: [0mInference done 2736/3489. 0.2444 s / img. ETA=0:03:50
[32m[03/30 21:02:22 d2.evaluation.evaluator]: [0mInference done 2754/3489. 0.2443 s / img. ETA=0:03:44
[32m[03/30 21:02:28 d2.evaluation.evaluator]: [0mInference done 2772/3489. 0.2443 s / img. ETA=0:03:39
[32m[03/30 21:02:33 d2.evaluation.evaluator]: [0mInference done 2791/3489. 0.2442 s / img. ETA=0:03:33
[32m[03/30 21:02:38 d2.evaluation.evaluator]: [0mInference done 2810/3489. 0.2441 s / img. ETA=0:03:27
[32m[03/30 21:02:43 d2.evaluation.evaluator]: [0mInference done 2828/3489. 0.2441 s / img. ETA=0:03:21
[32m[03/30 21:02:48 d2.evaluation.evaluator]: [0mInference done 2847/3489. 0.2440 s / img. ETA=0:03:15
[32m[03/30 21:02:53 d2.evaluation.evaluator]: [0mInference done 2866/3489. 0.2439 s / img. ETA=0:03:09
[32m[03/30 21:02:58 d2.evaluation.evaluator]: [0mInference done 2884/3489. 0.2439 s / img. ETA=0:03:04
[32m[03/30 21:03:03 d2.evaluation.evaluator]: [0mInference done 2902/3489. 0.2438 s / img. ETA=0:02:58
[32m[03/30 21:03:09 d2.evaluation.evaluator]: [0mInference done 2921/3489. 0.2437 s / img. ETA=0:02:52
[32m[03/30 21:03:14 d2.evaluation.evaluator]: [0mInference done 2940/3489. 0.2437 s / img. ETA=0:02:46
[32m[03/30 21:03:19 d2.evaluation.evaluator]: [0mInference done 2960/3489. 0.2436 s / img. ETA=0:02:40
[32m[03/30 21:03:24 d2.evaluation.evaluator]: [0mInference done 2980/3489. 0.2435 s / img. ETA=0:02:34
[32m[03/30 21:03:29 d2.evaluation.evaluator]: [0mInference done 2998/3489. 0.2435 s / img. ETA=0:02:28
[32m[03/30 21:03:34 d2.evaluation.evaluator]: [0mInference done 3016/3489. 0.2434 s / img. ETA=0:02:23
[32m[03/30 21:03:39 d2.evaluation.evaluator]: [0mInference done 3034/3489. 0.2434 s / img. ETA=0:02:17
[32m[03/30 21:03:45 d2.evaluation.evaluator]: [0mInference done 3053/3489. 0.2433 s / img. ETA=0:02:11
[32m[03/30 21:03:50 d2.evaluation.evaluator]: [0mInference done 3071/3489. 0.2433 s / img. ETA=0:02:06
[32m[03/30 21:03:55 d2.evaluation.evaluator]: [0mInference done 3088/3489. 0.2433 s / img. ETA=0:02:01
[32m[03/30 21:04:00 d2.evaluation.evaluator]: [0mInference done 3106/3489. 0.2432 s / img. ETA=0:01:55
[32m[03/30 21:04:05 d2.evaluation.evaluator]: [0mInference done 3123/3489. 0.2432 s / img. ETA=0:01:50
[32m[03/30 21:04:10 d2.evaluation.evaluator]: [0mInference done 3141/3489. 0.2432 s / img. ETA=0:01:45
[32m[03/30 21:04:15 d2.evaluation.evaluator]: [0mInference done 3159/3489. 0.2431 s / img. ETA=0:01:39
[32m[03/30 21:04:20 d2.evaluation.evaluator]: [0mInference done 3177/3489. 0.2431 s / img. ETA=0:01:34
[32m[03/30 21:04:26 d2.evaluation.evaluator]: [0mInference done 3196/3489. 0.2431 s / img. ETA=0:01:28
[32m[03/30 21:04:31 d2.evaluation.evaluator]: [0mInference done 3214/3489. 0.2430 s / img. ETA=0:01:22
[32m[03/30 21:04:36 d2.evaluation.evaluator]: [0mInference done 3232/3489. 0.2430 s / img. ETA=0:01:17
[32m[03/30 21:04:41 d2.evaluation.evaluator]: [0mInference done 3250/3489. 0.2430 s / img. ETA=0:01:12
[32m[03/30 21:04:46 d2.evaluation.evaluator]: [0mInference done 3269/3489. 0.2430 s / img. ETA=0:01:06
[32m[03/30 21:04:51 d2.evaluation.evaluator]: [0mInference done 3289/3489. 0.2429 s / img. ETA=0:01:00
[32m[03/30 21:04:56 d2.evaluation.evaluator]: [0mInference done 3311/3489. 0.2427 s / img. ETA=0:00:53
[32m[03/30 21:05:02 d2.evaluation.evaluator]: [0mInference done 3333/3489. 0.2426 s / img. ETA=0:00:46
[32m[03/30 21:05:07 d2.evaluation.evaluator]: [0mInference done 3353/3489. 0.2426 s / img. ETA=0:00:40
[32m[03/30 21:05:12 d2.evaluation.evaluator]: [0mInference done 3372/3489. 0.2425 s / img. ETA=0:00:35
[32m[03/30 21:05:17 d2.evaluation.evaluator]: [0mInference done 3390/3489. 0.2425 s / img. ETA=0:00:29
[32m[03/30 21:05:22 d2.evaluation.evaluator]: [0mInference done 3407/3489. 0.2425 s / img. ETA=0:00:24
[32m[03/30 21:05:27 d2.evaluation.evaluator]: [0mInference done 3423/3489. 0.2425 s / img. ETA=0:00:19
[32m[03/30 21:05:32 d2.evaluation.evaluator]: [0mInference done 3439/3489. 0.2425 s / img. ETA=0:00:14
[32m[03/30 21:05:38 d2.evaluation.evaluator]: [0mInference done 3455/3489. 0.2426 s / img. ETA=0:00:10
[32m[03/30 21:05:43 d2.evaluation.evaluator]: [0mInference done 3471/3489. 0.2426 s / img. ETA=0:00:05
[32m[03/30 21:05:48 d2.evaluation.evaluator]: [0mInference done 3487/3489. 0.2426 s / img. ETA=0:00:00
[32m[03/30 21:05:49 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:26.517787 (0.300378 s / img per device, on 1 devices)
[32m[03/30 21:05:49 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:05 (0.242592 s / img per device, on 1 devices)
[32m[03/30 21:05:52 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/30 21:05:52 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_200.000000/coco_instances_results.json
[32m[03/30 21:05:54 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 2.39 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.87 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[32m[03/30 21:05:58 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.211 | 64.266 | 43.061 | 14.673 | 52.947 | 64.378 |
[32m[03/30 21:05:58 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 48.721 | Pedestrian | 29.702 |
Loading and preparing results...
DONE (t=3.36s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 3.31 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 1.00 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558
[32m[03/30 21:06:14 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.961 | 55.621 | 30.725 | 13.310 | 39.585 | 52.978 |
[32m[03/30 21:06:14 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP    |
|:-----------|:-------|:-----------|:------|
| Cars       | 51.975 | Pedestrian | 9.948 |
[32m[03/30 21:06:15 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: 39.2115,64.2664,43.0615,14.6730,52.9473,64.3784
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:06:15 d2.evaluation.testing]: [0mcopypaste: 30.9613,55.6214,30.7252,13.3102,39.5848,52.9776
evaluated
Test [400]
[32m[03/30 21:06:15 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 21:06:15 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 21:06:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(400,), max_size=400, sample_style='choice'), RandomFlip()]
[32m[03/30 21:06:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:06:16 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 21:06:16 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 21:06:16 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 21:06:16 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(400,), max_size=400, sample_style='choice'), RandomFlip()]
[32m[03/30 21:06:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:06:16 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 21:06:17 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 21:06:17 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 21:06:38 d2.utils.events]: [0m eta: 0:02:18  iter: 19  total_loss: 1.551  loss_cls: 0.6409  loss_box_reg: 0.09218  loss_mask: 0.677  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.01883  total_val_loss: 1.469  val_loss_cls: 0.5411  val_loss_box_reg: 0.1624  val_loss_mask: 0.6808  val_loss_rpn_cls: 0.07779  val_loss_rpn_loc: 0.02601  time: 0.7728  data_time: 0.0229  lr: 0.00019981  max_mem: 4175M
[32m[03/30 21:06:59 d2.utils.events]: [0m eta: 0:02:03  iter: 39  total_loss: 0.8001  loss_cls: 0.1213  loss_box_reg: 0.08632  loss_mask: 0.4955  loss_rpn_cls: 0.03424  loss_rpn_loc: 0.01677  total_val_loss: 0.8972  val_loss_cls: 0.1439  val_loss_box_reg: 0.128  val_loss_mask: 0.5761  val_loss_rpn_cls: 0.04998  val_loss_rpn_loc: 0.02295  time: 0.7791  data_time: 0.0053  lr: 0.00039961  max_mem: 4175M
[32m[03/30 21:07:19 d2.utils.events]: [0m eta: 0:01:48  iter: 59  total_loss: 0.6248  loss_cls: 0.07931  loss_box_reg: 0.095  loss_mask: 0.3964  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.01309  total_val_loss: 0.8122  val_loss_cls: 0.1178  val_loss_box_reg: 0.1247  val_loss_mask: 0.4372  val_loss_rpn_cls: 0.03477  val_loss_rpn_loc: 0.01696  time: 0.7788  data_time: 0.0049  lr: 0.00059941  max_mem: 4175M
[32m[03/30 21:07:40 d2.utils.events]: [0m eta: 0:01:33  iter: 79  total_loss: 0.4773  loss_cls: 0.05561  loss_box_reg: 0.09291  loss_mask: 0.274  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.01355  total_val_loss: 0.6851  val_loss_cls: 0.07572  val_loss_box_reg: 0.1406  val_loss_mask: 0.4035  val_loss_rpn_cls: 0.03237  val_loss_rpn_loc: 0.02241  time: 0.7815  data_time: 0.0060  lr: 0.00079921  max_mem: 4175M
[32m[03/30 21:08:01 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:08:01 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:08:01 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:08:01 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:08:01 d2.utils.events]: [0m eta: 0:01:17  iter: 99  total_loss: 0.5076  loss_cls: 0.04554  loss_box_reg: 0.08995  loss_mask: 0.3032  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.01265  total_val_loss: 0.7935  val_loss_cls: 0.1316  val_loss_box_reg: 0.1319  val_loss_mask: 0.4195  val_loss_rpn_cls: 0.03905  val_loss_rpn_loc: 0.02477  time: 0.7817  data_time: 0.0064  lr: 0.00099901  max_mem: 4175M
[32m[03/30 21:08:22 d2.utils.events]: [0m eta: 0:01:02  iter: 119  total_loss: 0.4527  loss_cls: 0.03578  loss_box_reg: 0.08184  loss_mask: 0.3152  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.01139  total_val_loss: 0.8364  val_loss_cls: 0.1322  val_loss_box_reg: 0.116  val_loss_mask: 0.5269  val_loss_rpn_cls: 0.03182  val_loss_rpn_loc: 0.02226  time: 0.7834  data_time: 0.0051  lr: 0.0011988  max_mem: 4175M
[32m[03/30 21:08:43 d2.utils.events]: [0m eta: 0:00:46  iter: 139  total_loss: 0.4757  loss_cls: 0.04383  loss_box_reg: 0.09987  loss_mask: 0.2828  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.01165  total_val_loss: 0.6823  val_loss_cls: 0.08666  val_loss_box_reg: 0.1039  val_loss_mask: 0.4536  val_loss_rpn_cls: 0.03507  val_loss_rpn_loc: 0.02398  time: 0.7835  data_time: 0.0055  lr: 0.0013986  max_mem: 4175M
[32m[03/30 21:09:04 d2.utils.events]: [0m eta: 0:00:31  iter: 159  total_loss: 0.4614  loss_cls: 0.03145  loss_box_reg: 0.06102  loss_mask: 0.323  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.01175  total_val_loss: 0.6557  val_loss_cls: 0.09316  val_loss_box_reg: 0.103  val_loss_mask: 0.4083  val_loss_rpn_cls: 0.02545  val_loss_rpn_loc: 0.02125  time: 0.7847  data_time: 0.0050  lr: 0.0015984  max_mem: 4175M
[32m[03/30 21:09:24 d2.utils.events]: [0m eta: 0:00:15  iter: 179  total_loss: 0.4631  loss_cls: 0.03714  loss_box_reg: 0.0773  loss_mask: 0.3005  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.01569  total_val_loss: 0.5229  val_loss_cls: 0.06616  val_loss_box_reg: 0.08937  val_loss_mask: 0.3249  val_loss_rpn_cls: 0.0231  val_loss_rpn_loc: 0.02176  time: 0.7847  data_time: 0.0054  lr: 0.0017982  max_mem: 4175M
[32m[03/30 21:09:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:09:46 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:09:46 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:09:46 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:09:47 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4945  loss_cls: 0.03817  loss_box_reg: 0.07412  loss_mask: 0.3036  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.01345  total_val_loss: 0.7272  val_loss_cls: 0.09848  val_loss_box_reg: 0.1045  val_loss_mask: 0.4237  val_loss_rpn_cls: 0.03179  val_loss_rpn_loc: 0.02308  time: 0.7850  data_time: 0.0054  lr: 0.001998  max_mem: 4175M
[32m[03/30 21:09:47 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:35 (0.7851 s / it)
[32m[03/30 21:09:47 d2.engine.hooks]: [0mTotal training time: 0:03:26 (0:00:51 on hooks)
[32m[03/30 21:09:47 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:09:47 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:09:47 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:09:47 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/30 21:09:47 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/30 21:09:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:09:48 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:09:48 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/30 21:09:48 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/30 21:09:51 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2319 s / img. ETA=0:14:40
[32m[03/30 21:09:56 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2255 s / img. ETA=0:14:09
[32m[03/30 21:10:02 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2271 s / img. ETA=0:14:08
[32m[03/30 21:10:07 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2269 s / img. ETA=0:14:01
[32m[03/30 21:10:12 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2273 s / img. ETA=0:13:59
[32m[03/30 21:10:17 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2278 s / img. ETA=0:14:05
[32m[03/30 21:10:22 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2295 s / img. ETA=0:14:21
[32m[03/30 21:10:27 d2.evaluation.evaluator]: [0mInference done 147/3489. 0.2317 s / img. ETA=0:14:38
[32m[03/30 21:10:32 d2.evaluation.evaluator]: [0mInference done 163/3489. 0.2330 s / img. ETA=0:14:51
[32m[03/30 21:10:37 d2.evaluation.evaluator]: [0mInference done 180/3489. 0.2343 s / img. ETA=0:14:59
[32m[03/30 21:10:42 d2.evaluation.evaluator]: [0mInference done 198/3489. 0.2347 s / img. ETA=0:14:57
[32m[03/30 21:10:48 d2.evaluation.evaluator]: [0mInference done 218/3489. 0.2345 s / img. ETA=0:14:46
[32m[03/30 21:10:53 d2.evaluation.evaluator]: [0mInference done 238/3489. 0.2337 s / img. ETA=0:14:35
[32m[03/30 21:10:58 d2.evaluation.evaluator]: [0mInference done 257/3489. 0.2340 s / img. ETA=0:14:31
[32m[03/30 21:11:03 d2.evaluation.evaluator]: [0mInference done 276/3489. 0.2342 s / img. ETA=0:14:27
[32m[03/30 21:11:08 d2.evaluation.evaluator]: [0mInference done 295/3489. 0.2344 s / img. ETA=0:14:23
[32m[03/30 21:11:13 d2.evaluation.evaluator]: [0mInference done 314/3489. 0.2346 s / img. ETA=0:14:18
[32m[03/30 21:11:19 d2.evaluation.evaluator]: [0mInference done 334/3489. 0.2343 s / img. ETA=0:14:11
[32m[03/30 21:11:24 d2.evaluation.evaluator]: [0mInference done 352/3489. 0.2346 s / img. ETA=0:14:08
[32m[03/30 21:11:29 d2.evaluation.evaluator]: [0mInference done 371/3489. 0.2344 s / img. ETA=0:14:01
[32m[03/30 21:11:34 d2.evaluation.evaluator]: [0mInference done 389/3489. 0.2347 s / img. ETA=0:13:58
[32m[03/30 21:11:39 d2.evaluation.evaluator]: [0mInference done 408/3489. 0.2347 s / img. ETA=0:13:52
[32m[03/30 21:11:44 d2.evaluation.evaluator]: [0mInference done 427/3489. 0.2349 s / img. ETA=0:13:47
[32m[03/30 21:11:49 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2347 s / img. ETA=0:13:38
[32m[03/30 21:11:54 d2.evaluation.evaluator]: [0mInference done 469/3489. 0.2346 s / img. ETA=0:13:29
[32m[03/30 21:11:59 d2.evaluation.evaluator]: [0mInference done 490/3489. 0.2344 s / img. ETA=0:13:21
[32m[03/30 21:12:05 d2.evaluation.evaluator]: [0mInference done 510/3489. 0.2345 s / img. ETA=0:13:15
[32m[03/30 21:12:10 d2.evaluation.evaluator]: [0mInference done 531/3489. 0.2341 s / img. ETA=0:13:07
[32m[03/30 21:12:15 d2.evaluation.evaluator]: [0mInference done 550/3489. 0.2342 s / img. ETA=0:13:01
[32m[03/30 21:12:20 d2.evaluation.evaluator]: [0mInference done 569/3489. 0.2342 s / img. ETA=0:12:57
[32m[03/30 21:12:25 d2.evaluation.evaluator]: [0mInference done 588/3489. 0.2342 s / img. ETA=0:12:53
[32m[03/30 21:12:30 d2.evaluation.evaluator]: [0mInference done 608/3489. 0.2341 s / img. ETA=0:12:47
[32m[03/30 21:12:35 d2.evaluation.evaluator]: [0mInference done 627/3489. 0.2341 s / img. ETA=0:12:42
[32m[03/30 21:12:40 d2.evaluation.evaluator]: [0mInference done 646/3489. 0.2340 s / img. ETA=0:12:37
[32m[03/30 21:12:46 d2.evaluation.evaluator]: [0mInference done 666/3489. 0.2339 s / img. ETA=0:12:31
[32m[03/30 21:12:51 d2.evaluation.evaluator]: [0mInference done 687/3489. 0.2337 s / img. ETA=0:12:23
[32m[03/30 21:12:56 d2.evaluation.evaluator]: [0mInference done 708/3489. 0.2335 s / img. ETA=0:12:16
[32m[03/30 21:13:01 d2.evaluation.evaluator]: [0mInference done 729/3489. 0.2333 s / img. ETA=0:12:09
[32m[03/30 21:13:06 d2.evaluation.evaluator]: [0mInference done 750/3489. 0.2331 s / img. ETA=0:12:02
[32m[03/30 21:13:11 d2.evaluation.evaluator]: [0mInference done 771/3489. 0.2329 s / img. ETA=0:11:55
[32m[03/30 21:13:17 d2.evaluation.evaluator]: [0mInference done 793/3489. 0.2326 s / img. ETA=0:11:47
[32m[03/30 21:13:22 d2.evaluation.evaluator]: [0mInference done 815/3489. 0.2324 s / img. ETA=0:11:39
[32m[03/30 21:13:27 d2.evaluation.evaluator]: [0mInference done 836/3489. 0.2322 s / img. ETA=0:11:32
[32m[03/30 21:13:32 d2.evaluation.evaluator]: [0mInference done 857/3489. 0.2320 s / img. ETA=0:11:26
[32m[03/30 21:13:37 d2.evaluation.evaluator]: [0mInference done 878/3489. 0.2319 s / img. ETA=0:11:19
[32m[03/30 21:13:42 d2.evaluation.evaluator]: [0mInference done 900/3489. 0.2316 s / img. ETA=0:11:11
[32m[03/30 21:13:47 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2317 s / img. ETA=0:11:08
[32m[03/30 21:13:52 d2.evaluation.evaluator]: [0mInference done 936/3489. 0.2318 s / img. ETA=0:11:04
[32m[03/30 21:13:58 d2.evaluation.evaluator]: [0mInference done 955/3489. 0.2319 s / img. ETA=0:11:00
[32m[03/30 21:14:03 d2.evaluation.evaluator]: [0mInference done 973/3489. 0.2320 s / img. ETA=0:10:57
[32m[03/30 21:14:08 d2.evaluation.evaluator]: [0mInference done 991/3489. 0.2321 s / img. ETA=0:10:53
[32m[03/30 21:14:13 d2.evaluation.evaluator]: [0mInference done 1009/3489. 0.2322 s / img. ETA=0:10:49
[32m[03/30 21:14:18 d2.evaluation.evaluator]: [0mInference done 1027/3489. 0.2324 s / img. ETA=0:10:46
[32m[03/30 21:14:23 d2.evaluation.evaluator]: [0mInference done 1044/3489. 0.2326 s / img. ETA=0:10:43
[32m[03/30 21:14:28 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2328 s / img. ETA=0:10:39
[32m[03/30 21:14:34 d2.evaluation.evaluator]: [0mInference done 1080/3489. 0.2329 s / img. ETA=0:10:35
[32m[03/30 21:14:39 d2.evaluation.evaluator]: [0mInference done 1099/3489. 0.2328 s / img. ETA=0:10:31
[32m[03/30 21:14:44 d2.evaluation.evaluator]: [0mInference done 1117/3489. 0.2329 s / img. ETA=0:10:26
[32m[03/30 21:14:49 d2.evaluation.evaluator]: [0mInference done 1134/3489. 0.2330 s / img. ETA=0:10:23
[32m[03/30 21:14:54 d2.evaluation.evaluator]: [0mInference done 1151/3489. 0.2332 s / img. ETA=0:10:20
[32m[03/30 21:14:59 d2.evaluation.evaluator]: [0mInference done 1168/3489. 0.2334 s / img. ETA=0:10:17
[32m[03/30 21:15:04 d2.evaluation.evaluator]: [0mInference done 1185/3489. 0.2336 s / img. ETA=0:10:14
[32m[03/30 21:15:09 d2.evaluation.evaluator]: [0mInference done 1202/3489. 0.2338 s / img. ETA=0:10:10
[32m[03/30 21:15:15 d2.evaluation.evaluator]: [0mInference done 1220/3489. 0.2338 s / img. ETA=0:10:06
[32m[03/30 21:15:20 d2.evaluation.evaluator]: [0mInference done 1237/3489. 0.2340 s / img. ETA=0:10:03
[32m[03/30 21:15:25 d2.evaluation.evaluator]: [0mInference done 1255/3489. 0.2341 s / img. ETA=0:09:58
[32m[03/30 21:15:30 d2.evaluation.evaluator]: [0mInference done 1277/3489. 0.2339 s / img. ETA=0:09:51
[32m[03/30 21:15:35 d2.evaluation.evaluator]: [0mInference done 1298/3489. 0.2338 s / img. ETA=0:09:45
[32m[03/30 21:15:40 d2.evaluation.evaluator]: [0mInference done 1318/3489. 0.2338 s / img. ETA=0:09:39
[32m[03/30 21:15:45 d2.evaluation.evaluator]: [0mInference done 1339/3489. 0.2336 s / img. ETA=0:09:32
[32m[03/30 21:15:50 d2.evaluation.evaluator]: [0mInference done 1361/3489. 0.2334 s / img. ETA=0:09:25
[32m[03/30 21:15:55 d2.evaluation.evaluator]: [0mInference done 1382/3489. 0.2333 s / img. ETA=0:09:19
[32m[03/30 21:16:00 d2.evaluation.evaluator]: [0mInference done 1403/3489. 0.2331 s / img. ETA=0:09:13
[32m[03/30 21:16:06 d2.evaluation.evaluator]: [0mInference done 1423/3489. 0.2332 s / img. ETA=0:09:07
[32m[03/30 21:16:11 d2.evaluation.evaluator]: [0mInference done 1444/3489. 0.2331 s / img. ETA=0:09:01
[32m[03/30 21:16:16 d2.evaluation.evaluator]: [0mInference done 1465/3489. 0.2330 s / img. ETA=0:08:55
[32m[03/30 21:16:21 d2.evaluation.evaluator]: [0mInference done 1487/3489. 0.2328 s / img. ETA=0:08:48
[32m[03/30 21:16:26 d2.evaluation.evaluator]: [0mInference done 1509/3489. 0.2327 s / img. ETA=0:08:42
[32m[03/30 21:16:32 d2.evaluation.evaluator]: [0mInference done 1530/3489. 0.2326 s / img. ETA=0:08:36
[32m[03/30 21:16:37 d2.evaluation.evaluator]: [0mInference done 1549/3489. 0.2326 s / img. ETA=0:08:31
[32m[03/30 21:16:42 d2.evaluation.evaluator]: [0mInference done 1569/3489. 0.2325 s / img. ETA=0:08:25
[32m[03/30 21:16:47 d2.evaluation.evaluator]: [0mInference done 1589/3489. 0.2325 s / img. ETA=0:08:20
[32m[03/30 21:16:52 d2.evaluation.evaluator]: [0mInference done 1608/3489. 0.2325 s / img. ETA=0:08:15
[32m[03/30 21:16:57 d2.evaluation.evaluator]: [0mInference done 1626/3489. 0.2326 s / img. ETA=0:08:11
[32m[03/30 21:17:02 d2.evaluation.evaluator]: [0mInference done 1644/3489. 0.2326 s / img. ETA=0:08:06
[32m[03/30 21:17:07 d2.evaluation.evaluator]: [0mInference done 1663/3489. 0.2326 s / img. ETA=0:08:01
[32m[03/30 21:17:13 d2.evaluation.evaluator]: [0mInference done 1682/3489. 0.2327 s / img. ETA=0:07:57
[32m[03/30 21:17:18 d2.evaluation.evaluator]: [0mInference done 1699/3489. 0.2328 s / img. ETA=0:07:53
[32m[03/30 21:17:23 d2.evaluation.evaluator]: [0mInference done 1717/3489. 0.2329 s / img. ETA=0:07:49
[32m[03/30 21:17:28 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2330 s / img. ETA=0:07:44
[32m[03/30 21:17:33 d2.evaluation.evaluator]: [0mInference done 1753/3489. 0.2331 s / img. ETA=0:07:40
[32m[03/30 21:17:38 d2.evaluation.evaluator]: [0mInference done 1769/3489. 0.2332 s / img. ETA=0:07:36
[32m[03/30 21:17:44 d2.evaluation.evaluator]: [0mInference done 1785/3489. 0.2333 s / img. ETA=0:07:33
[32m[03/30 21:17:49 d2.evaluation.evaluator]: [0mInference done 1801/3489. 0.2334 s / img. ETA=0:07:30
[32m[03/30 21:17:54 d2.evaluation.evaluator]: [0mInference done 1817/3489. 0.2336 s / img. ETA=0:07:26
[32m[03/30 21:17:59 d2.evaluation.evaluator]: [0mInference done 1833/3489. 0.2337 s / img. ETA=0:07:23
[32m[03/30 21:18:04 d2.evaluation.evaluator]: [0mInference done 1849/3489. 0.2338 s / img. ETA=0:07:19
[32m[03/30 21:18:09 d2.evaluation.evaluator]: [0mInference done 1866/3489. 0.2339 s / img. ETA=0:07:15
[32m[03/30 21:18:14 d2.evaluation.evaluator]: [0mInference done 1883/3489. 0.2340 s / img. ETA=0:07:11
[32m[03/30 21:18:19 d2.evaluation.evaluator]: [0mInference done 1900/3489. 0.2340 s / img. ETA=0:07:07
[32m[03/30 21:18:25 d2.evaluation.evaluator]: [0mInference done 1917/3489. 0.2341 s / img. ETA=0:07:03
[32m[03/30 21:18:30 d2.evaluation.evaluator]: [0mInference done 1934/3489. 0.2342 s / img. ETA=0:06:59
[32m[03/30 21:18:35 d2.evaluation.evaluator]: [0mInference done 1951/3489. 0.2342 s / img. ETA=0:06:54
[32m[03/30 21:18:40 d2.evaluation.evaluator]: [0mInference done 1968/3489. 0.2343 s / img. ETA=0:06:50
[32m[03/30 21:18:45 d2.evaluation.evaluator]: [0mInference done 1985/3489. 0.2344 s / img. ETA=0:06:46
[32m[03/30 21:18:50 d2.evaluation.evaluator]: [0mInference done 2003/3489. 0.2345 s / img. ETA=0:06:41
[32m[03/30 21:18:55 d2.evaluation.evaluator]: [0mInference done 2022/3489. 0.2345 s / img. ETA=0:06:36
[32m[03/30 21:19:00 d2.evaluation.evaluator]: [0mInference done 2040/3489. 0.2346 s / img. ETA=0:06:32
[32m[03/30 21:19:06 d2.evaluation.evaluator]: [0mInference done 2058/3489. 0.2346 s / img. ETA=0:06:27
[32m[03/30 21:19:11 d2.evaluation.evaluator]: [0mInference done 2075/3489. 0.2346 s / img. ETA=0:06:23
[32m[03/30 21:19:16 d2.evaluation.evaluator]: [0mInference done 2092/3489. 0.2347 s / img. ETA=0:06:18
[32m[03/30 21:19:21 d2.evaluation.evaluator]: [0mInference done 2108/3489. 0.2349 s / img. ETA=0:06:15
[32m[03/30 21:19:26 d2.evaluation.evaluator]: [0mInference done 2125/3489. 0.2349 s / img. ETA=0:06:10
[32m[03/30 21:19:31 d2.evaluation.evaluator]: [0mInference done 2141/3489. 0.2350 s / img. ETA=0:06:07
[32m[03/30 21:19:37 d2.evaluation.evaluator]: [0mInference done 2157/3489. 0.2352 s / img. ETA=0:06:03
[32m[03/30 21:19:42 d2.evaluation.evaluator]: [0mInference done 2174/3489. 0.2352 s / img. ETA=0:05:58
[32m[03/30 21:19:47 d2.evaluation.evaluator]: [0mInference done 2191/3489. 0.2353 s / img. ETA=0:05:54
[32m[03/30 21:19:52 d2.evaluation.evaluator]: [0mInference done 2208/3489. 0.2354 s / img. ETA=0:05:50
[32m[03/30 21:19:57 d2.evaluation.evaluator]: [0mInference done 2225/3489. 0.2355 s / img. ETA=0:05:45
[32m[03/30 21:20:03 d2.evaluation.evaluator]: [0mInference done 2242/3489. 0.2356 s / img. ETA=0:05:41
[32m[03/30 21:20:08 d2.evaluation.evaluator]: [0mInference done 2260/3489. 0.2356 s / img. ETA=0:05:36
[32m[03/30 21:20:13 d2.evaluation.evaluator]: [0mInference done 2277/3489. 0.2357 s / img. ETA=0:05:32
[32m[03/30 21:20:18 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2357 s / img. ETA=0:05:27
[32m[03/30 21:20:23 d2.evaluation.evaluator]: [0mInference done 2311/3489. 0.2358 s / img. ETA=0:05:23
[32m[03/30 21:20:28 d2.evaluation.evaluator]: [0mInference done 2328/3489. 0.2359 s / img. ETA=0:05:18
[32m[03/30 21:20:33 d2.evaluation.evaluator]: [0mInference done 2345/3489. 0.2359 s / img. ETA=0:05:14
[32m[03/30 21:20:38 d2.evaluation.evaluator]: [0mInference done 2362/3489. 0.2360 s / img. ETA=0:05:10
[32m[03/30 21:20:43 d2.evaluation.evaluator]: [0mInference done 2381/3489. 0.2360 s / img. ETA=0:05:04
[32m[03/30 21:20:49 d2.evaluation.evaluator]: [0mInference done 2400/3489. 0.2360 s / img. ETA=0:04:59
[32m[03/30 21:20:54 d2.evaluation.evaluator]: [0mInference done 2418/3489. 0.2360 s / img. ETA=0:04:54
[32m[03/30 21:20:59 d2.evaluation.evaluator]: [0mInference done 2437/3489. 0.2360 s / img. ETA=0:04:49
[32m[03/30 21:21:04 d2.evaluation.evaluator]: [0mInference done 2454/3489. 0.2360 s / img. ETA=0:04:44
[32m[03/30 21:21:09 d2.evaluation.evaluator]: [0mInference done 2471/3489. 0.2361 s / img. ETA=0:04:40
[32m[03/30 21:21:14 d2.evaluation.evaluator]: [0mInference done 2488/3489. 0.2362 s / img. ETA=0:04:35
[32m[03/30 21:21:19 d2.evaluation.evaluator]: [0mInference done 2508/3489. 0.2361 s / img. ETA=0:04:30
[32m[03/30 21:21:25 d2.evaluation.evaluator]: [0mInference done 2528/3489. 0.2361 s / img. ETA=0:04:24
[32m[03/30 21:21:30 d2.evaluation.evaluator]: [0mInference done 2549/3489. 0.2360 s / img. ETA=0:04:18
[32m[03/30 21:21:35 d2.evaluation.evaluator]: [0mInference done 2570/3489. 0.2359 s / img. ETA=0:04:12
[32m[03/30 21:21:40 d2.evaluation.evaluator]: [0mInference done 2592/3489. 0.2358 s / img. ETA=0:04:06
[32m[03/30 21:21:45 d2.evaluation.evaluator]: [0mInference done 2613/3489. 0.2357 s / img. ETA=0:04:00
[32m[03/30 21:21:50 d2.evaluation.evaluator]: [0mInference done 2634/3489. 0.2357 s / img. ETA=0:03:54
[32m[03/30 21:21:55 d2.evaluation.evaluator]: [0mInference done 2656/3489. 0.2356 s / img. ETA=0:03:48
[32m[03/30 21:22:01 d2.evaluation.evaluator]: [0mInference done 2676/3489. 0.2355 s / img. ETA=0:03:42
[32m[03/30 21:22:06 d2.evaluation.evaluator]: [0mInference done 2696/3489. 0.2354 s / img. ETA=0:03:36
[32m[03/30 21:22:11 d2.evaluation.evaluator]: [0mInference done 2715/3489. 0.2354 s / img. ETA=0:03:31
[32m[03/30 21:22:16 d2.evaluation.evaluator]: [0mInference done 2735/3489. 0.2354 s / img. ETA=0:03:26
[32m[03/30 21:22:21 d2.evaluation.evaluator]: [0mInference done 2754/3489. 0.2354 s / img. ETA=0:03:20
[32m[03/30 21:22:26 d2.evaluation.evaluator]: [0mInference done 2773/3489. 0.2353 s / img. ETA=0:03:15
[32m[03/30 21:22:31 d2.evaluation.evaluator]: [0mInference done 2793/3489. 0.2353 s / img. ETA=0:03:10
[32m[03/30 21:22:36 d2.evaluation.evaluator]: [0mInference done 2813/3489. 0.2352 s / img. ETA=0:03:04
[32m[03/30 21:22:42 d2.evaluation.evaluator]: [0mInference done 2833/3489. 0.2352 s / img. ETA=0:02:59
[32m[03/30 21:22:47 d2.evaluation.evaluator]: [0mInference done 2853/3489. 0.2351 s / img. ETA=0:02:53
[32m[03/30 21:22:52 d2.evaluation.evaluator]: [0mInference done 2873/3489. 0.2351 s / img. ETA=0:02:47
[32m[03/30 21:22:57 d2.evaluation.evaluator]: [0mInference done 2893/3489. 0.2351 s / img. ETA=0:02:42
[32m[03/30 21:23:02 d2.evaluation.evaluator]: [0mInference done 2914/3489. 0.2350 s / img. ETA=0:02:36
[32m[03/30 21:23:07 d2.evaluation.evaluator]: [0mInference done 2935/3489. 0.2350 s / img. ETA=0:02:30
[32m[03/30 21:23:12 d2.evaluation.evaluator]: [0mInference done 2956/3489. 0.2350 s / img. ETA=0:02:24
[32m[03/30 21:23:17 d2.evaluation.evaluator]: [0mInference done 2977/3489. 0.2349 s / img. ETA=0:02:19
[32m[03/30 21:23:23 d2.evaluation.evaluator]: [0mInference done 2997/3489. 0.2349 s / img. ETA=0:02:13
[32m[03/30 21:23:28 d2.evaluation.evaluator]: [0mInference done 3017/3489. 0.2348 s / img. ETA=0:02:08
[32m[03/30 21:23:33 d2.evaluation.evaluator]: [0mInference done 3037/3489. 0.2348 s / img. ETA=0:02:02
[32m[03/30 21:23:38 d2.evaluation.evaluator]: [0mInference done 3058/3489. 0.2347 s / img. ETA=0:01:56
[32m[03/30 21:23:43 d2.evaluation.evaluator]: [0mInference done 3077/3489. 0.2347 s / img. ETA=0:01:51
[32m[03/30 21:23:48 d2.evaluation.evaluator]: [0mInference done 3096/3489. 0.2347 s / img. ETA=0:01:46
[32m[03/30 21:23:53 d2.evaluation.evaluator]: [0mInference done 3116/3489. 0.2347 s / img. ETA=0:01:41
[32m[03/30 21:23:58 d2.evaluation.evaluator]: [0mInference done 3135/3489. 0.2347 s / img. ETA=0:01:35
[32m[03/30 21:24:03 d2.evaluation.evaluator]: [0mInference done 3155/3489. 0.2347 s / img. ETA=0:01:30
[32m[03/30 21:24:09 d2.evaluation.evaluator]: [0mInference done 3175/3489. 0.2347 s / img. ETA=0:01:25
[32m[03/30 21:24:14 d2.evaluation.evaluator]: [0mInference done 3196/3489. 0.2346 s / img. ETA=0:01:19
[32m[03/30 21:24:19 d2.evaluation.evaluator]: [0mInference done 3216/3489. 0.2346 s / img. ETA=0:01:13
[32m[03/30 21:24:24 d2.evaluation.evaluator]: [0mInference done 3235/3489. 0.2346 s / img. ETA=0:01:08
[32m[03/30 21:24:29 d2.evaluation.evaluator]: [0mInference done 3255/3489. 0.2346 s / img. ETA=0:01:03
[32m[03/30 21:24:34 d2.evaluation.evaluator]: [0mInference done 3275/3489. 0.2346 s / img. ETA=0:00:57
[32m[03/30 21:24:39 d2.evaluation.evaluator]: [0mInference done 3296/3489. 0.2345 s / img. ETA=0:00:52
[32m[03/30 21:24:44 d2.evaluation.evaluator]: [0mInference done 3318/3489. 0.2344 s / img. ETA=0:00:46
[32m[03/30 21:24:49 d2.evaluation.evaluator]: [0mInference done 3341/3489. 0.2343 s / img. ETA=0:00:39
[32m[03/30 21:24:55 d2.evaluation.evaluator]: [0mInference done 3362/3489. 0.2343 s / img. ETA=0:00:34
[32m[03/30 21:25:00 d2.evaluation.evaluator]: [0mInference done 3382/3489. 0.2343 s / img. ETA=0:00:28
[32m[03/30 21:25:05 d2.evaluation.evaluator]: [0mInference done 3402/3489. 0.2342 s / img. ETA=0:00:23
[32m[03/30 21:25:10 d2.evaluation.evaluator]: [0mInference done 3421/3489. 0.2342 s / img. ETA=0:00:18
[32m[03/30 21:25:15 d2.evaluation.evaluator]: [0mInference done 3440/3489. 0.2342 s / img. ETA=0:00:13
[32m[03/30 21:25:20 d2.evaluation.evaluator]: [0mInference done 3459/3489. 0.2342 s / img. ETA=0:00:08
[32m[03/30 21:25:25 d2.evaluation.evaluator]: [0mInference done 3477/3489. 0.2342 s / img. ETA=0:00:03
[32m[03/30 21:25:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:38.872216 (0.269481 s / img per device, on 1 devices)
[32m[03/30 21:25:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:36 (0.234224 s / img per device, on 1 devices)
[32m[03/30 21:25:31 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/30 21:25:31 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_400.000000/coco_instances_results.json
[32m[03/30 21:25:32 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.46 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.56 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
[32m[03/30 21:25:34 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.684 | 71.397 | 40.032 | 23.649 | 49.807 | 49.843 |
[32m[03/30 21:25:34 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 51.534 | Pedestrian | 27.834 |
Loading and preparing results...
DONE (t=1.89s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.16 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.59 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.337
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569
[32m[03/30 21:25:44 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.699 | 65.816 | 33.719 | 17.688 | 41.666 | 52.924 |
[32m[03/30 21:25:44 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 54.130 | Pedestrian | 15.269 |
[32m[03/30 21:25:44 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: 39.6842,71.3967,40.0315,23.6489,49.8072,49.8432
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:25:44 d2.evaluation.testing]: [0mcopypaste: 34.6993,65.8159,33.7186,17.6883,41.6663,52.9238
evaluated
Test [800]
[32m[03/30 21:25:45 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 21:25:45 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 21:25:45 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=800, sample_style='choice'), RandomFlip()]
[32m[03/30 21:25:45 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:25:45 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 21:25:45 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 21:25:46 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 21:25:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=800, sample_style='choice'), RandomFlip()]
[32m[03/30 21:25:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:25:46 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 21:25:46 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 21:25:46 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 21:26:09 d2.utils.events]: [0m eta: 0:02:24  iter: 19  total_loss: 1.739  loss_cls: 0.7361  loss_box_reg: 0.2333  loss_mask: 0.6678  loss_rpn_cls: 0.03509  loss_rpn_loc: 0.01145  total_val_loss: 1.565  val_loss_cls: 0.6839  val_loss_box_reg: 0.2685  val_loss_mask: 0.6781  val_loss_rpn_cls: 0.05155  val_loss_rpn_loc: 0.01101  time: 0.8033  data_time: 0.0231  lr: 0.00019981  max_mem: 4301M
[32m[03/30 21:26:30 d2.utils.events]: [0m eta: 0:02:07  iter: 39  total_loss: 0.7617  loss_cls: 0.1569  loss_box_reg: 0.2166  loss_mask: 0.4281  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.008978  total_val_loss: 1.189  val_loss_cls: 0.2305  val_loss_box_reg: 0.3072  val_loss_mask: 0.5514  val_loss_rpn_cls: 0.04062  val_loss_rpn_loc: 0.01497  time: 0.8039  data_time: 0.0066  lr: 0.00039961  max_mem: 4301M
[32m[03/30 21:26:53 d2.utils.events]: [0m eta: 0:01:52  iter: 59  total_loss: 0.6621  loss_cls: 0.09867  loss_box_reg: 0.2131  loss_mask: 0.2825  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.01013  total_val_loss: 0.8286  val_loss_cls: 0.1206  val_loss_box_reg: 0.2532  val_loss_mask: 0.4509  val_loss_rpn_cls: 0.02475  val_loss_rpn_loc: 0.01435  time: 0.8103  data_time: 0.0061  lr: 0.00059941  max_mem: 4301M
[32m[03/30 21:27:15 d2.utils.events]: [0m eta: 0:01:37  iter: 79  total_loss: 0.6304  loss_cls: 0.08324  loss_box_reg: 0.2796  loss_mask: 0.2056  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.01208  total_val_loss: 0.7704  val_loss_cls: 0.1094  val_loss_box_reg: 0.2665  val_loss_mask: 0.4266  val_loss_rpn_cls: 0.02411  val_loss_rpn_loc: 0.01006  time: 0.8159  data_time: 0.0070  lr: 0.00079921  max_mem: 4301M
[32m[03/30 21:27:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:27:38 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:27:38 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:27:38 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:27:38 d2.utils.events]: [0m eta: 0:01:21  iter: 99  total_loss: 0.4193  loss_cls: 0.03603  loss_box_reg: 0.1359  loss_mask: 0.2183  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.00522  total_val_loss: 0.7453  val_loss_cls: 0.1117  val_loss_box_reg: 0.1883  val_loss_mask: 0.4006  val_loss_rpn_cls: 0.02467  val_loss_rpn_loc: 0.009664  time: 0.8162  data_time: 0.0058  lr: 0.00099901  max_mem: 4301M
[32m[03/30 21:28:00 d2.utils.events]: [0m eta: 0:01:04  iter: 119  total_loss: 0.4231  loss_cls: 0.04824  loss_box_reg: 0.1189  loss_mask: 0.218  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.009517  total_val_loss: 0.8199  val_loss_cls: 0.1477  val_loss_box_reg: 0.1869  val_loss_mask: 0.3725  val_loss_rpn_cls: 0.02287  val_loss_rpn_loc: 0.0105  time: 0.8158  data_time: 0.0054  lr: 0.0011988  max_mem: 4301M
[32m[03/30 21:28:22 d2.utils.events]: [0m eta: 0:00:48  iter: 139  total_loss: 0.3882  loss_cls: 0.03843  loss_box_reg: 0.1046  loss_mask: 0.2371  loss_rpn_cls: 0.009747  loss_rpn_loc: 0.009022  total_val_loss: 0.6215  val_loss_cls: 0.1111  val_loss_box_reg: 0.1497  val_loss_mask: 0.3626  val_loss_rpn_cls: 0.02741  val_loss_rpn_loc: 0.01039  time: 0.8165  data_time: 0.0058  lr: 0.0013986  max_mem: 4301M
[32m[03/30 21:28:44 d2.utils.events]: [0m eta: 0:00:32  iter: 159  total_loss: 0.3239  loss_cls: 0.03313  loss_box_reg: 0.08316  loss_mask: 0.1767  loss_rpn_cls: 0.009981  loss_rpn_loc: 0.009373  total_val_loss: 0.8418  val_loss_cls: 0.1601  val_loss_box_reg: 0.236  val_loss_mask: 0.3899  val_loss_rpn_cls: 0.0209  val_loss_rpn_loc: 0.01495  time: 0.8171  data_time: 0.0057  lr: 0.0015984  max_mem: 4301M
[32m[03/30 21:29:06 d2.utils.events]: [0m eta: 0:00:16  iter: 179  total_loss: 0.3688  loss_cls: 0.03423  loss_box_reg: 0.08952  loss_mask: 0.2018  loss_rpn_cls: 0.007653  loss_rpn_loc: 0.009332  total_val_loss: 0.8507  val_loss_cls: 0.17  val_loss_box_reg: 0.2387  val_loss_mask: 0.373  val_loss_rpn_cls: 0.02556  val_loss_rpn_loc: 0.01605  time: 0.8179  data_time: 0.0055  lr: 0.0017982  max_mem: 4301M
[32m[03/30 21:29:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:29:29 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:29:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:29:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:29:30 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3411  loss_cls: 0.03825  loss_box_reg: 0.07024  loss_mask: 0.1954  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.007417  total_val_loss: 0.7754  val_loss_cls: 0.1072  val_loss_box_reg: 0.1447  val_loss_mask: 0.3927  val_loss_rpn_cls: 0.02431  val_loss_rpn_loc: 0.0119  time: 0.8189  data_time: 0.0061  lr: 0.001998  max_mem: 4301M
[32m[03/30 21:29:30 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:42 (0.8189 s / it)
[32m[03/30 21:29:30 d2.engine.hooks]: [0mTotal training time: 0:03:41 (0:00:58 on hooks)
[32m[03/30 21:29:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:29:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:29:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:29:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/30 21:29:30 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/30 21:29:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:29:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:29:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/30 21:29:31 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/30 21:29:35 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2224 s / img. ETA=0:14:29
[32m[03/30 21:29:40 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2280 s / img. ETA=0:14:44
[32m[03/30 21:29:45 d2.evaluation.evaluator]: [0mInference done 51/3489. 0.2298 s / img. ETA=0:14:37
[32m[03/30 21:29:50 d2.evaluation.evaluator]: [0mInference done 71/3489. 0.2304 s / img. ETA=0:14:30
[32m[03/30 21:29:55 d2.evaluation.evaluator]: [0mInference done 90/3489. 0.2314 s / img. ETA=0:14:38
[32m[03/30 21:30:00 d2.evaluation.evaluator]: [0mInference done 107/3489. 0.2334 s / img. ETA=0:15:00
[32m[03/30 21:30:06 d2.evaluation.evaluator]: [0mInference done 124/3489. 0.2347 s / img. ETA=0:15:17
[32m[03/30 21:30:11 d2.evaluation.evaluator]: [0mInference done 140/3489. 0.2359 s / img. ETA=0:15:31
[32m[03/30 21:30:16 d2.evaluation.evaluator]: [0mInference done 156/3489. 0.2376 s / img. ETA=0:15:42
[32m[03/30 21:30:21 d2.evaluation.evaluator]: [0mInference done 172/3489. 0.2389 s / img. ETA=0:15:51
[32m[03/30 21:30:26 d2.evaluation.evaluator]: [0mInference done 188/3489. 0.2397 s / img. ETA=0:15:56
[32m[03/30 21:30:31 d2.evaluation.evaluator]: [0mInference done 206/3489. 0.2395 s / img. ETA=0:15:48
[32m[03/30 21:30:36 d2.evaluation.evaluator]: [0mInference done 224/3489. 0.2397 s / img. ETA=0:15:41
[32m[03/30 21:30:42 d2.evaluation.evaluator]: [0mInference done 242/3489. 0.2398 s / img. ETA=0:15:37
[32m[03/30 21:30:47 d2.evaluation.evaluator]: [0mInference done 259/3489. 0.2402 s / img. ETA=0:15:37
[32m[03/30 21:30:52 d2.evaluation.evaluator]: [0mInference done 276/3489. 0.2405 s / img. ETA=0:15:35
[32m[03/30 21:30:57 d2.evaluation.evaluator]: [0mInference done 293/3489. 0.2406 s / img. ETA=0:15:31
[32m[03/30 21:31:02 d2.evaluation.evaluator]: [0mInference done 310/3489. 0.2407 s / img. ETA=0:15:29
[32m[03/30 21:31:07 d2.evaluation.evaluator]: [0mInference done 327/3489. 0.2408 s / img. ETA=0:15:24
[32m[03/30 21:31:12 d2.evaluation.evaluator]: [0mInference done 343/3489. 0.2409 s / img. ETA=0:15:23
[32m[03/30 21:31:17 d2.evaluation.evaluator]: [0mInference done 359/3489. 0.2412 s / img. ETA=0:15:21
[32m[03/30 21:31:22 d2.evaluation.evaluator]: [0mInference done 376/3489. 0.2411 s / img. ETA=0:15:17
[32m[03/30 21:31:28 d2.evaluation.evaluator]: [0mInference done 393/3489. 0.2414 s / img. ETA=0:15:13
[32m[03/30 21:31:33 d2.evaluation.evaluator]: [0mInference done 410/3489. 0.2412 s / img. ETA=0:15:08
[32m[03/30 21:31:38 d2.evaluation.evaluator]: [0mInference done 428/3489. 0.2409 s / img. ETA=0:15:01
[32m[03/30 21:31:43 d2.evaluation.evaluator]: [0mInference done 449/3489. 0.2402 s / img. ETA=0:14:48
[32m[03/30 21:31:48 d2.evaluation.evaluator]: [0mInference done 470/3489. 0.2395 s / img. ETA=0:14:36
[32m[03/30 21:31:53 d2.evaluation.evaluator]: [0mInference done 491/3489. 0.2390 s / img. ETA=0:14:24
[32m[03/30 21:31:58 d2.evaluation.evaluator]: [0mInference done 512/3489. 0.2384 s / img. ETA=0:14:12
[32m[03/30 21:32:03 d2.evaluation.evaluator]: [0mInference done 533/3489. 0.2378 s / img. ETA=0:14:01
[32m[03/30 21:32:09 d2.evaluation.evaluator]: [0mInference done 552/3489. 0.2377 s / img. ETA=0:13:54
[32m[03/30 21:32:14 d2.evaluation.evaluator]: [0mInference done 570/3489. 0.2378 s / img. ETA=0:13:50
[32m[03/30 21:32:19 d2.evaluation.evaluator]: [0mInference done 586/3489. 0.2381 s / img. ETA=0:13:48
[32m[03/30 21:32:24 d2.evaluation.evaluator]: [0mInference done 604/3489. 0.2381 s / img. ETA=0:13:43
[32m[03/30 21:32:29 d2.evaluation.evaluator]: [0mInference done 622/3489. 0.2382 s / img. ETA=0:13:38
[32m[03/30 21:32:34 d2.evaluation.evaluator]: [0mInference done 640/3489. 0.2383 s / img. ETA=0:13:33
[32m[03/30 21:32:40 d2.evaluation.evaluator]: [0mInference done 659/3489. 0.2381 s / img. ETA=0:13:27
[32m[03/30 21:32:45 d2.evaluation.evaluator]: [0mInference done 679/3489. 0.2380 s / img. ETA=0:13:19
[32m[03/30 21:32:50 d2.evaluation.evaluator]: [0mInference done 700/3489. 0.2376 s / img. ETA=0:13:10
[32m[03/30 21:32:55 d2.evaluation.evaluator]: [0mInference done 720/3489. 0.2374 s / img. ETA=0:13:02
[32m[03/30 21:33:00 d2.evaluation.evaluator]: [0mInference done 740/3489. 0.2371 s / img. ETA=0:12:55
[32m[03/30 21:33:05 d2.evaluation.evaluator]: [0mInference done 759/3489. 0.2369 s / img. ETA=0:12:48
[32m[03/30 21:33:11 d2.evaluation.evaluator]: [0mInference done 779/3489. 0.2367 s / img. ETA=0:12:41
[32m[03/30 21:33:16 d2.evaluation.evaluator]: [0mInference done 800/3489. 0.2365 s / img. ETA=0:12:33
[32m[03/30 21:33:21 d2.evaluation.evaluator]: [0mInference done 821/3489. 0.2362 s / img. ETA=0:12:24
[32m[03/30 21:33:26 d2.evaluation.evaluator]: [0mInference done 842/3489. 0.2359 s / img. ETA=0:12:16
[32m[03/30 21:33:31 d2.evaluation.evaluator]: [0mInference done 863/3489. 0.2356 s / img. ETA=0:12:08
[32m[03/30 21:33:36 d2.evaluation.evaluator]: [0mInference done 884/3489. 0.2354 s / img. ETA=0:12:00
[32m[03/30 21:33:41 d2.evaluation.evaluator]: [0mInference done 904/3489. 0.2353 s / img. ETA=0:11:53
[32m[03/30 21:33:46 d2.evaluation.evaluator]: [0mInference done 920/3489. 0.2355 s / img. ETA=0:11:51
[32m[03/30 21:33:51 d2.evaluation.evaluator]: [0mInference done 936/3489. 0.2357 s / img. ETA=0:11:48
[32m[03/30 21:33:57 d2.evaluation.evaluator]: [0mInference done 952/3489. 0.2359 s / img. ETA=0:11:45
[32m[03/30 21:34:02 d2.evaluation.evaluator]: [0mInference done 968/3489. 0.2361 s / img. ETA=0:11:42
[32m[03/30 21:34:07 d2.evaluation.evaluator]: [0mInference done 984/3489. 0.2363 s / img. ETA=0:11:39
[32m[03/30 21:34:12 d2.evaluation.evaluator]: [0mInference done 1000/3489. 0.2365 s / img. ETA=0:11:36
[32m[03/30 21:34:17 d2.evaluation.evaluator]: [0mInference done 1016/3489. 0.2367 s / img. ETA=0:11:33
[32m[03/30 21:34:22 d2.evaluation.evaluator]: [0mInference done 1032/3489. 0.2369 s / img. ETA=0:11:30
[32m[03/30 21:34:27 d2.evaluation.evaluator]: [0mInference done 1048/3489. 0.2370 s / img. ETA=0:11:27
[32m[03/30 21:34:32 d2.evaluation.evaluator]: [0mInference done 1064/3489. 0.2372 s / img. ETA=0:11:24
[32m[03/30 21:34:37 d2.evaluation.evaluator]: [0mInference done 1080/3489. 0.2373 s / img. ETA=0:11:21
[32m[03/30 21:34:42 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2374 s / img. ETA=0:11:17
[32m[03/30 21:34:47 d2.evaluation.evaluator]: [0mInference done 1115/3489. 0.2375 s / img. ETA=0:11:12
[32m[03/30 21:34:53 d2.evaluation.evaluator]: [0mInference done 1131/3489. 0.2377 s / img. ETA=0:11:08
[32m[03/30 21:34:58 d2.evaluation.evaluator]: [0mInference done 1147/3489. 0.2378 s / img. ETA=0:11:05
[32m[03/30 21:35:03 d2.evaluation.evaluator]: [0mInference done 1163/3489. 0.2379 s / img. ETA=0:11:02
[32m[03/30 21:35:08 d2.evaluation.evaluator]: [0mInference done 1179/3489. 0.2380 s / img. ETA=0:10:58
[32m[03/30 21:35:13 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2381 s / img. ETA=0:10:54
[32m[03/30 21:35:18 d2.evaluation.evaluator]: [0mInference done 1212/3489. 0.2382 s / img. ETA=0:10:50
[32m[03/30 21:35:23 d2.evaluation.evaluator]: [0mInference done 1229/3489. 0.2383 s / img. ETA=0:10:46
[32m[03/30 21:35:28 d2.evaluation.evaluator]: [0mInference done 1246/3489. 0.2384 s / img. ETA=0:10:42
[32m[03/30 21:35:34 d2.evaluation.evaluator]: [0mInference done 1266/3489. 0.2382 s / img. ETA=0:10:35
[32m[03/30 21:35:39 d2.evaluation.evaluator]: [0mInference done 1288/3489. 0.2380 s / img. ETA=0:10:27
[32m[03/30 21:35:44 d2.evaluation.evaluator]: [0mInference done 1309/3489. 0.2377 s / img. ETA=0:10:19
[32m[03/30 21:35:49 d2.evaluation.evaluator]: [0mInference done 1331/3489. 0.2375 s / img. ETA=0:10:11
[32m[03/30 21:35:54 d2.evaluation.evaluator]: [0mInference done 1353/3489. 0.2373 s / img. ETA=0:10:03
[32m[03/30 21:35:59 d2.evaluation.evaluator]: [0mInference done 1374/3489. 0.2370 s / img. ETA=0:09:56
[32m[03/30 21:36:04 d2.evaluation.evaluator]: [0mInference done 1395/3489. 0.2369 s / img. ETA=0:09:49
[32m[03/30 21:36:09 d2.evaluation.evaluator]: [0mInference done 1416/3489. 0.2367 s / img. ETA=0:09:42
[32m[03/30 21:36:15 d2.evaluation.evaluator]: [0mInference done 1437/3489. 0.2365 s / img. ETA=0:09:35
[32m[03/30 21:36:20 d2.evaluation.evaluator]: [0mInference done 1458/3489. 0.2364 s / img. ETA=0:09:28
[32m[03/30 21:36:25 d2.evaluation.evaluator]: [0mInference done 1480/3489. 0.2362 s / img. ETA=0:09:20
[32m[03/30 21:36:30 d2.evaluation.evaluator]: [0mInference done 1502/3489. 0.2360 s / img. ETA=0:09:13
[32m[03/30 21:36:35 d2.evaluation.evaluator]: [0mInference done 1524/3489. 0.2359 s / img. ETA=0:09:06
[32m[03/30 21:36:40 d2.evaluation.evaluator]: [0mInference done 1544/3489. 0.2358 s / img. ETA=0:08:59
[32m[03/30 21:36:45 d2.evaluation.evaluator]: [0mInference done 1564/3489. 0.2357 s / img. ETA=0:08:53
[32m[03/30 21:36:50 d2.evaluation.evaluator]: [0mInference done 1584/3489. 0.2356 s / img. ETA=0:08:47
[32m[03/30 21:36:56 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2356 s / img. ETA=0:08:42
[32m[03/30 21:37:01 d2.evaluation.evaluator]: [0mInference done 1619/3489. 0.2356 s / img. ETA=0:08:38
[32m[03/30 21:37:06 d2.evaluation.evaluator]: [0mInference done 1636/3489. 0.2358 s / img. ETA=0:08:34
[32m[03/30 21:37:11 d2.evaluation.evaluator]: [0mInference done 1653/3489. 0.2359 s / img. ETA=0:08:29
[32m[03/30 21:37:16 d2.evaluation.evaluator]: [0mInference done 1670/3489. 0.2360 s / img. ETA=0:08:25
[32m[03/30 21:37:21 d2.evaluation.evaluator]: [0mInference done 1686/3489. 0.2361 s / img. ETA=0:08:21
[32m[03/30 21:37:26 d2.evaluation.evaluator]: [0mInference done 1702/3489. 0.2361 s / img. ETA=0:08:18
[32m[03/30 21:37:31 d2.evaluation.evaluator]: [0mInference done 1718/3489. 0.2363 s / img. ETA=0:08:14
[32m[03/30 21:37:36 d2.evaluation.evaluator]: [0mInference done 1734/3489. 0.2364 s / img. ETA=0:08:10
[32m[03/30 21:37:41 d2.evaluation.evaluator]: [0mInference done 1750/3489. 0.2364 s / img. ETA=0:08:06
[32m[03/30 21:37:46 d2.evaluation.evaluator]: [0mInference done 1765/3489. 0.2365 s / img. ETA=0:08:03
[32m[03/30 21:37:51 d2.evaluation.evaluator]: [0mInference done 1781/3489. 0.2366 s / img. ETA=0:07:59
[32m[03/30 21:37:57 d2.evaluation.evaluator]: [0mInference done 1797/3489. 0.2367 s / img. ETA=0:07:55
[32m[03/30 21:38:02 d2.evaluation.evaluator]: [0mInference done 1813/3489. 0.2368 s / img. ETA=0:07:51
[32m[03/30 21:38:07 d2.evaluation.evaluator]: [0mInference done 1829/3489. 0.2369 s / img. ETA=0:07:47
[32m[03/30 21:38:12 d2.evaluation.evaluator]: [0mInference done 1845/3489. 0.2370 s / img. ETA=0:07:43
[32m[03/30 21:38:17 d2.evaluation.evaluator]: [0mInference done 1861/3489. 0.2371 s / img. ETA=0:07:39
[32m[03/30 21:38:22 d2.evaluation.evaluator]: [0mInference done 1877/3489. 0.2372 s / img. ETA=0:07:35
[32m[03/30 21:38:27 d2.evaluation.evaluator]: [0mInference done 1893/3489. 0.2373 s / img. ETA=0:07:31
[32m[03/30 21:38:32 d2.evaluation.evaluator]: [0mInference done 1909/3489. 0.2373 s / img. ETA=0:07:27
[32m[03/30 21:38:37 d2.evaluation.evaluator]: [0mInference done 1925/3489. 0.2374 s / img. ETA=0:07:23
[32m[03/30 21:38:42 d2.evaluation.evaluator]: [0mInference done 1941/3489. 0.2375 s / img. ETA=0:07:19
[32m[03/30 21:38:48 d2.evaluation.evaluator]: [0mInference done 1957/3489. 0.2376 s / img. ETA=0:07:15
[32m[03/30 21:38:53 d2.evaluation.evaluator]: [0mInference done 1973/3489. 0.2377 s / img. ETA=0:07:11
[32m[03/30 21:38:58 d2.evaluation.evaluator]: [0mInference done 1989/3489. 0.2378 s / img. ETA=0:07:06
[32m[03/30 21:39:03 d2.evaluation.evaluator]: [0mInference done 2005/3489. 0.2379 s / img. ETA=0:07:02
[32m[03/30 21:39:08 d2.evaluation.evaluator]: [0mInference done 2022/3489. 0.2379 s / img. ETA=0:06:58
[32m[03/30 21:39:13 d2.evaluation.evaluator]: [0mInference done 2038/3489. 0.2380 s / img. ETA=0:06:54
[32m[03/30 21:39:18 d2.evaluation.evaluator]: [0mInference done 2054/3489. 0.2381 s / img. ETA=0:06:49
[32m[03/30 21:39:24 d2.evaluation.evaluator]: [0mInference done 2070/3489. 0.2382 s / img. ETA=0:06:45
[32m[03/30 21:39:29 d2.evaluation.evaluator]: [0mInference done 2086/3489. 0.2382 s / img. ETA=0:06:41
[32m[03/30 21:39:34 d2.evaluation.evaluator]: [0mInference done 2102/3489. 0.2383 s / img. ETA=0:06:37
[32m[03/30 21:39:39 d2.evaluation.evaluator]: [0mInference done 2118/3489. 0.2384 s / img. ETA=0:06:33
[32m[03/30 21:39:44 d2.evaluation.evaluator]: [0mInference done 2134/3489. 0.2385 s / img. ETA=0:06:28
[32m[03/30 21:39:49 d2.evaluation.evaluator]: [0mInference done 2150/3489. 0.2386 s / img. ETA=0:06:24
[32m[03/30 21:39:54 d2.evaluation.evaluator]: [0mInference done 2166/3489. 0.2387 s / img. ETA=0:06:20
[32m[03/30 21:39:59 d2.evaluation.evaluator]: [0mInference done 2181/3489. 0.2387 s / img. ETA=0:06:16
[32m[03/30 21:40:04 d2.evaluation.evaluator]: [0mInference done 2197/3489. 0.2388 s / img. ETA=0:06:12
[32m[03/30 21:40:09 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2388 s / img. ETA=0:06:07
[32m[03/30 21:40:15 d2.evaluation.evaluator]: [0mInference done 2229/3489. 0.2389 s / img. ETA=0:06:03
[32m[03/30 21:40:20 d2.evaluation.evaluator]: [0mInference done 2245/3489. 0.2390 s / img. ETA=0:05:59
[32m[03/30 21:40:25 d2.evaluation.evaluator]: [0mInference done 2262/3489. 0.2391 s / img. ETA=0:05:54
[32m[03/30 21:40:30 d2.evaluation.evaluator]: [0mInference done 2278/3489. 0.2392 s / img. ETA=0:05:50
[32m[03/30 21:40:35 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2392 s / img. ETA=0:05:45
[32m[03/30 21:40:40 d2.evaluation.evaluator]: [0mInference done 2310/3489. 0.2393 s / img. ETA=0:05:41
[32m[03/30 21:40:45 d2.evaluation.evaluator]: [0mInference done 2326/3489. 0.2393 s / img. ETA=0:05:36
[32m[03/30 21:40:51 d2.evaluation.evaluator]: [0mInference done 2342/3489. 0.2394 s / img. ETA=0:05:32
[32m[03/30 21:40:56 d2.evaluation.evaluator]: [0mInference done 2358/3489. 0.2395 s / img. ETA=0:05:28
[32m[03/30 21:41:01 d2.evaluation.evaluator]: [0mInference done 2376/3489. 0.2395 s / img. ETA=0:05:22
[32m[03/30 21:41:06 d2.evaluation.evaluator]: [0mInference done 2393/3489. 0.2395 s / img. ETA=0:05:18
[32m[03/30 21:41:11 d2.evaluation.evaluator]: [0mInference done 2410/3489. 0.2395 s / img. ETA=0:05:13
[32m[03/30 21:41:16 d2.evaluation.evaluator]: [0mInference done 2427/3489. 0.2396 s / img. ETA=0:05:08
[32m[03/30 21:41:22 d2.evaluation.evaluator]: [0mInference done 2444/3489. 0.2396 s / img. ETA=0:05:03
[32m[03/30 21:41:27 d2.evaluation.evaluator]: [0mInference done 2460/3489. 0.2396 s / img. ETA=0:04:59
[32m[03/30 21:41:32 d2.evaluation.evaluator]: [0mInference done 2476/3489. 0.2397 s / img. ETA=0:04:54
[32m[03/30 21:41:37 d2.evaluation.evaluator]: [0mInference done 2494/3489. 0.2397 s / img. ETA=0:04:49
[32m[03/30 21:41:42 d2.evaluation.evaluator]: [0mInference done 2514/3489. 0.2396 s / img. ETA=0:04:43
[32m[03/30 21:41:47 d2.evaluation.evaluator]: [0mInference done 2533/3489. 0.2396 s / img. ETA=0:04:37
[32m[03/30 21:41:52 d2.evaluation.evaluator]: [0mInference done 2553/3489. 0.2395 s / img. ETA=0:04:31
[32m[03/30 21:41:57 d2.evaluation.evaluator]: [0mInference done 2573/3489. 0.2394 s / img. ETA=0:04:25
[32m[03/30 21:42:03 d2.evaluation.evaluator]: [0mInference done 2594/3489. 0.2393 s / img. ETA=0:04:19
[32m[03/30 21:42:08 d2.evaluation.evaluator]: [0mInference done 2614/3489. 0.2392 s / img. ETA=0:04:13
[32m[03/30 21:42:13 d2.evaluation.evaluator]: [0mInference done 2635/3489. 0.2391 s / img. ETA=0:04:06
[32m[03/30 21:42:18 d2.evaluation.evaluator]: [0mInference done 2656/3489. 0.2390 s / img. ETA=0:04:00
[32m[03/30 21:42:23 d2.evaluation.evaluator]: [0mInference done 2675/3489. 0.2389 s / img. ETA=0:03:54
[32m[03/30 21:42:28 d2.evaluation.evaluator]: [0mInference done 2694/3489. 0.2389 s / img. ETA=0:03:49
[32m[03/30 21:42:33 d2.evaluation.evaluator]: [0mInference done 2714/3489. 0.2388 s / img. ETA=0:03:43
[32m[03/30 21:42:38 d2.evaluation.evaluator]: [0mInference done 2734/3489. 0.2388 s / img. ETA=0:03:37
[32m[03/30 21:42:43 d2.evaluation.evaluator]: [0mInference done 2754/3489. 0.2387 s / img. ETA=0:03:31
[32m[03/30 21:42:49 d2.evaluation.evaluator]: [0mInference done 2774/3489. 0.2386 s / img. ETA=0:03:25
[32m[03/30 21:42:54 d2.evaluation.evaluator]: [0mInference done 2794/3489. 0.2386 s / img. ETA=0:03:19
[32m[03/30 21:42:59 d2.evaluation.evaluator]: [0mInference done 2814/3489. 0.2385 s / img. ETA=0:03:13
[32m[03/30 21:43:04 d2.evaluation.evaluator]: [0mInference done 2834/3489. 0.2385 s / img. ETA=0:03:07
[32m[03/30 21:43:09 d2.evaluation.evaluator]: [0mInference done 2854/3489. 0.2384 s / img. ETA=0:03:01
[32m[03/30 21:43:14 d2.evaluation.evaluator]: [0mInference done 2874/3489. 0.2383 s / img. ETA=0:02:55
[32m[03/30 21:43:19 d2.evaluation.evaluator]: [0mInference done 2895/3489. 0.2382 s / img. ETA=0:02:49
[32m[03/30 21:43:24 d2.evaluation.evaluator]: [0mInference done 2916/3489. 0.2381 s / img. ETA=0:02:43
[32m[03/30 21:43:30 d2.evaluation.evaluator]: [0mInference done 2937/3489. 0.2380 s / img. ETA=0:02:37
[32m[03/30 21:43:35 d2.evaluation.evaluator]: [0mInference done 2958/3489. 0.2379 s / img. ETA=0:02:31
[32m[03/30 21:43:40 d2.evaluation.evaluator]: [0mInference done 2979/3489. 0.2378 s / img. ETA=0:02:25
[32m[03/30 21:43:45 d2.evaluation.evaluator]: [0mInference done 2999/3489. 0.2378 s / img. ETA=0:02:19
[32m[03/30 21:43:50 d2.evaluation.evaluator]: [0mInference done 3019/3489. 0.2377 s / img. ETA=0:02:13
[32m[03/30 21:43:55 d2.evaluation.evaluator]: [0mInference done 3039/3489. 0.2376 s / img. ETA=0:02:07
[32m[03/30 21:44:00 d2.evaluation.evaluator]: [0mInference done 3059/3489. 0.2376 s / img. ETA=0:02:02
[32m[03/30 21:44:05 d2.evaluation.evaluator]: [0mInference done 3079/3489. 0.2375 s / img. ETA=0:01:56
[32m[03/30 21:44:10 d2.evaluation.evaluator]: [0mInference done 3098/3489. 0.2375 s / img. ETA=0:01:50
[32m[03/30 21:44:16 d2.evaluation.evaluator]: [0mInference done 3118/3489. 0.2374 s / img. ETA=0:01:45
[32m[03/30 21:44:21 d2.evaluation.evaluator]: [0mInference done 3138/3489. 0.2374 s / img. ETA=0:01:39
[32m[03/30 21:44:26 d2.evaluation.evaluator]: [0mInference done 3158/3489. 0.2373 s / img. ETA=0:01:33
[32m[03/30 21:44:31 d2.evaluation.evaluator]: [0mInference done 3177/3489. 0.2373 s / img. ETA=0:01:28
[32m[03/30 21:44:36 d2.evaluation.evaluator]: [0mInference done 3197/3489. 0.2372 s / img. ETA=0:01:22
[32m[03/30 21:44:41 d2.evaluation.evaluator]: [0mInference done 3217/3489. 0.2372 s / img. ETA=0:01:16
[32m[03/30 21:44:46 d2.evaluation.evaluator]: [0mInference done 3237/3489. 0.2372 s / img. ETA=0:01:11
[32m[03/30 21:44:52 d2.evaluation.evaluator]: [0mInference done 3258/3489. 0.2371 s / img. ETA=0:01:05
[32m[03/30 21:44:57 d2.evaluation.evaluator]: [0mInference done 3278/3489. 0.2371 s / img. ETA=0:00:59
[32m[03/30 21:45:02 d2.evaluation.evaluator]: [0mInference done 3300/3489. 0.2370 s / img. ETA=0:00:53
[32m[03/30 21:45:07 d2.evaluation.evaluator]: [0mInference done 3322/3489. 0.2369 s / img. ETA=0:00:47
[32m[03/30 21:45:12 d2.evaluation.evaluator]: [0mInference done 3344/3489. 0.2368 s / img. ETA=0:00:40
[32m[03/30 21:45:17 d2.evaluation.evaluator]: [0mInference done 3365/3489. 0.2368 s / img. ETA=0:00:34
[32m[03/30 21:45:22 d2.evaluation.evaluator]: [0mInference done 3386/3489. 0.2367 s / img. ETA=0:00:28
[32m[03/30 21:45:27 d2.evaluation.evaluator]: [0mInference done 3407/3489. 0.2366 s / img. ETA=0:00:23
[32m[03/30 21:45:33 d2.evaluation.evaluator]: [0mInference done 3427/3489. 0.2366 s / img. ETA=0:00:17
[32m[03/30 21:45:38 d2.evaluation.evaluator]: [0mInference done 3446/3489. 0.2366 s / img. ETA=0:00:12
[32m[03/30 21:45:43 d2.evaluation.evaluator]: [0mInference done 3464/3489. 0.2366 s / img. ETA=0:00:07
[32m[03/30 21:45:48 d2.evaluation.evaluator]: [0mInference done 3483/3489. 0.2367 s / img. ETA=0:00:01
[32m[03/30 21:45:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.662247 (0.280328 s / img per device, on 1 devices)
[32m[03/30 21:45:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:44 (0.236636 s / img per device, on 1 devices)
[32m[03/30 21:45:52 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/30 21:45:52 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_800.000000/coco_instances_results.json
[32m[03/30 21:45:54 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.78 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.67 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.815
[32m[03/30 21:45:57 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.491 | 78.617 | 50.889 | 28.306 | 60.074 | 64.591 |
[32m[03/30 21:45:57 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.208 | Pedestrian | 36.774 |
Loading and preparing results...
DONE (t=2.39s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.70 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.69 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[32m[03/30 21:46:08 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.589 | 73.843 | 41.780 | 22.870 | 53.582 | 68.623 |
[32m[03/30 21:46:08 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.290 | Pedestrian | 23.888 |
[32m[03/30 21:46:09 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: 49.4911,78.6167,50.8888,28.3058,60.0739,64.5906
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 21:46:09 d2.evaluation.testing]: [0mcopypaste: 43.5891,73.8428,41.7802,22.8697,53.5816,68.6229
evaluated
Test [1200]
[32m[03/30 21:46:10 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 21:46:10 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 21:46:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(1200,), max_size=1200, sample_style='choice'), RandomFlip()]
[32m[03/30 21:46:10 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:46:10 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 21:46:10 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 21:46:10 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 21:46:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(1200,), max_size=1200, sample_style='choice'), RandomFlip()]
[32m[03/30 21:46:10 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 21:46:10 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 21:46:11 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 21:46:11 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 21:46:34 d2.utils.events]: [0m eta: 0:02:26  iter: 19  total_loss: 1.847  loss_cls: 0.8315  loss_box_reg: 0.3627  loss_mask: 0.6637  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.006563  total_val_loss: 1.897  val_loss_cls: 0.8011  val_loss_box_reg: 0.4239  val_loss_mask: 0.6736  val_loss_rpn_cls: 0.03751  val_loss_rpn_loc: 0.01386  time: 0.8174  data_time: 0.0291  lr: 0.00019981  max_mem: 4550M
[32m[03/30 21:46:57 d2.utils.events]: [0m eta: 0:02:10  iter: 39  total_loss: 0.8871  loss_cls: 0.1577  loss_box_reg: 0.3269  loss_mask: 0.3809  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.00989  total_val_loss: 1.154  val_loss_cls: 0.2168  val_loss_box_reg: 0.3435  val_loss_mask: 0.4978  val_loss_rpn_cls: 0.02982  val_loss_rpn_loc: 0.01041  time: 0.8193  data_time: 0.0056  lr: 0.00039961  max_mem: 4550M
[32m[03/30 21:47:20 d2.utils.events]: [0m eta: 0:01:55  iter: 59  total_loss: 0.5444  loss_cls: 0.07572  loss_box_reg: 0.2524  loss_mask: 0.2392  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.007321  total_val_loss: 1.155  val_loss_cls: 0.2487  val_loss_box_reg: 0.4218  val_loss_mask: 0.4291  val_loss_rpn_cls: 0.03835  val_loss_rpn_loc: 0.0131  time: 0.8259  data_time: 0.0068  lr: 0.00059941  max_mem: 4550M
[32m[03/30 21:47:43 d2.utils.events]: [0m eta: 0:01:38  iter: 79  total_loss: 0.4451  loss_cls: 0.05241  loss_box_reg: 0.2185  loss_mask: 0.1781  loss_rpn_cls: 0.009211  loss_rpn_loc: 0.00731  total_val_loss: 0.9438  val_loss_cls: 0.1853  val_loss_box_reg: 0.4524  val_loss_mask: 0.3814  val_loss_rpn_cls: 0.01748  val_loss_rpn_loc: 0.01274  time: 0.8265  data_time: 0.0058  lr: 0.00079921  max_mem: 4550M
[32m[03/30 21:48:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:48:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:48:06 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:48:06 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:48:06 d2.utils.events]: [0m eta: 0:01:22  iter: 99  total_loss: 0.5148  loss_cls: 0.06879  loss_box_reg: 0.2711  loss_mask: 0.1638  loss_rpn_cls: 0.008076  loss_rpn_loc: 0.01102  total_val_loss: 0.9933  val_loss_cls: 0.1856  val_loss_box_reg: 0.2925  val_loss_mask: 0.3971  val_loss_rpn_cls: 0.02587  val_loss_rpn_loc: 0.01119  time: 0.8284  data_time: 0.0058  lr: 0.00099901  max_mem: 4552M
[32m[03/30 21:48:29 d2.utils.events]: [0m eta: 0:01:06  iter: 119  total_loss: 0.305  loss_cls: 0.05128  loss_box_reg: 0.08315  loss_mask: 0.1256  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.009121  total_val_loss: 0.83  val_loss_cls: 0.1824  val_loss_box_reg: 0.236  val_loss_mask: 0.4229  val_loss_rpn_cls: 0.02403  val_loss_rpn_loc: 0.01229  time: 0.8307  data_time: 0.0056  lr: 0.0011988  max_mem: 4552M
[32m[03/30 21:48:52 d2.utils.events]: [0m eta: 0:00:49  iter: 139  total_loss: 0.3578  loss_cls: 0.04292  loss_box_reg: 0.1105  loss_mask: 0.1945  loss_rpn_cls: 0.009188  loss_rpn_loc: 0.006498  total_val_loss: 0.8548  val_loss_cls: 0.1494  val_loss_box_reg: 0.2101  val_loss_mask: 0.3156  val_loss_rpn_cls: 0.01173  val_loss_rpn_loc: 0.01333  time: 0.8326  data_time: 0.0058  lr: 0.0013986  max_mem: 4552M
[32m[03/30 21:49:15 d2.utils.events]: [0m eta: 0:00:33  iter: 159  total_loss: 0.3706  loss_cls: 0.04245  loss_box_reg: 0.1021  loss_mask: 0.1592  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.01011  total_val_loss: 0.6861  val_loss_cls: 0.1489  val_loss_box_reg: 0.2155  val_loss_mask: 0.2665  val_loss_rpn_cls: 0.01594  val_loss_rpn_loc: 0.01353  time: 0.8335  data_time: 0.0059  lr: 0.0015984  max_mem: 4552M
[32m[03/30 21:49:39 d2.utils.events]: [0m eta: 0:00:16  iter: 179  total_loss: 0.4503  loss_cls: 0.0766  loss_box_reg: 0.1625  loss_mask: 0.2097  loss_rpn_cls: 0.008219  loss_rpn_loc: 0.01253  total_val_loss: 0.7607  val_loss_cls: 0.14  val_loss_box_reg: 0.2327  val_loss_mask: 0.3828  val_loss_rpn_cls: 0.01592  val_loss_rpn_loc: 0.01297  time: 0.8359  data_time: 0.0080  lr: 0.0017982  max_mem: 4552M
[32m[03/30 21:50:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:50:03 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:50:03 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:50:03 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 21:50:04 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3097  loss_cls: 0.03796  loss_box_reg: 0.1005  loss_mask: 0.149  loss_rpn_cls: 0.004938  loss_rpn_loc: 0.00744  total_val_loss: 0.7352  val_loss_cls: 0.1405  val_loss_box_reg: 0.2527  val_loss_mask: 0.3011  val_loss_rpn_cls: 0.008951  val_loss_rpn_loc: 0.01169  time: 0.8363  data_time: 0.0057  lr: 0.001998  max_mem: 4552M
[32m[03/30 21:50:04 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:45 (0.8363 s / it)
[32m[03/30 21:50:04 d2.engine.hooks]: [0mTotal training time: 0:03:49 (0:01:04 on hooks)
[32m[03/30 21:50:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:50:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:50:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 21:50:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[03/30 21:50:04 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[03/30 21:50:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 21:50:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 21:50:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[03/30 21:50:05 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[03/30 21:50:08 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2200 s / img. ETA=0:13:43
[32m[03/30 21:50:13 d2.evaluation.evaluator]: [0mInference done 33/3489. 0.2208 s / img. ETA=0:13:42
[32m[03/30 21:50:18 d2.evaluation.evaluator]: [0mInference done 54/3489. 0.2240 s / img. ETA=0:13:42
[32m[03/30 21:50:24 d2.evaluation.evaluator]: [0mInference done 76/3489. 0.2237 s / img. ETA=0:13:31
[32m[03/30 21:50:29 d2.evaluation.evaluator]: [0mInference done 96/3489. 0.2242 s / img. ETA=0:13:38
[32m[03/30 21:50:34 d2.evaluation.evaluator]: [0mInference done 114/3489. 0.2264 s / img. ETA=0:13:55
[32m[03/30 21:50:39 d2.evaluation.evaluator]: [0mInference done 131/3489. 0.2285 s / img. ETA=0:14:16
[32m[03/30 21:50:44 d2.evaluation.evaluator]: [0mInference done 147/3489. 0.2303 s / img. ETA=0:14:34
[32m[03/30 21:50:49 d2.evaluation.evaluator]: [0mInference done 163/3489. 0.2321 s / img. ETA=0:14:49
[32m[03/30 21:50:54 d2.evaluation.evaluator]: [0mInference done 180/3489. 0.2331 s / img. ETA=0:14:57
[32m[03/30 21:50:59 d2.evaluation.evaluator]: [0mInference done 197/3489. 0.2339 s / img. ETA=0:14:59
[32m[03/30 21:51:04 d2.evaluation.evaluator]: [0mInference done 217/3489. 0.2336 s / img. ETA=0:14:47
[32m[03/30 21:51:09 d2.evaluation.evaluator]: [0mInference done 237/3489. 0.2336 s / img. ETA=0:14:38
[32m[03/30 21:51:14 d2.evaluation.evaluator]: [0mInference done 256/3489. 0.2335 s / img. ETA=0:14:33
[32m[03/30 21:51:20 d2.evaluation.evaluator]: [0mInference done 275/3489. 0.2336 s / img. ETA=0:14:28
[32m[03/30 21:51:25 d2.evaluation.evaluator]: [0mInference done 294/3489. 0.2333 s / img. ETA=0:14:22
[32m[03/30 21:51:30 d2.evaluation.evaluator]: [0mInference done 313/3489. 0.2334 s / img. ETA=0:14:18
[32m[03/30 21:51:35 d2.evaluation.evaluator]: [0mInference done 331/3489. 0.2336 s / img. ETA=0:14:15
[32m[03/30 21:51:40 d2.evaluation.evaluator]: [0mInference done 348/3489. 0.2340 s / img. ETA=0:14:14
[32m[03/30 21:51:45 d2.evaluation.evaluator]: [0mInference done 366/3489. 0.2341 s / img. ETA=0:14:10
[32m[03/30 21:51:50 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2342 s / img. ETA=0:14:06
[32m[03/30 21:51:56 d2.evaluation.evaluator]: [0mInference done 404/3489. 0.2343 s / img. ETA=0:14:01
[32m[03/30 21:52:01 d2.evaluation.evaluator]: [0mInference done 423/3489. 0.2344 s / img. ETA=0:13:57
[32m[03/30 21:52:06 d2.evaluation.evaluator]: [0mInference done 443/3489. 0.2345 s / img. ETA=0:13:49
[32m[03/30 21:52:11 d2.evaluation.evaluator]: [0mInference done 464/3489. 0.2343 s / img. ETA=0:13:39
[32m[03/30 21:52:16 d2.evaluation.evaluator]: [0mInference done 484/3489. 0.2342 s / img. ETA=0:13:31
[32m[03/30 21:52:21 d2.evaluation.evaluator]: [0mInference done 505/3489. 0.2341 s / img. ETA=0:13:22
[32m[03/30 21:52:26 d2.evaluation.evaluator]: [0mInference done 527/3489. 0.2336 s / img. ETA=0:13:12
[32m[03/30 21:52:31 d2.evaluation.evaluator]: [0mInference done 549/3489. 0.2334 s / img. ETA=0:13:02
[32m[03/30 21:52:36 d2.evaluation.evaluator]: [0mInference done 569/3489. 0.2332 s / img. ETA=0:12:55
[32m[03/30 21:52:42 d2.evaluation.evaluator]: [0mInference done 587/3489. 0.2335 s / img. ETA=0:12:53
[32m[03/30 21:52:47 d2.evaluation.evaluator]: [0mInference done 606/3489. 0.2336 s / img. ETA=0:12:48
[32m[03/30 21:52:52 d2.evaluation.evaluator]: [0mInference done 624/3489. 0.2339 s / img. ETA=0:12:45
[32m[03/30 21:52:57 d2.evaluation.evaluator]: [0mInference done 642/3489. 0.2340 s / img. ETA=0:12:41
[32m[03/30 21:53:02 d2.evaluation.evaluator]: [0mInference done 661/3489. 0.2341 s / img. ETA=0:12:36
[32m[03/30 21:53:07 d2.evaluation.evaluator]: [0mInference done 681/3489. 0.2340 s / img. ETA=0:12:30
[32m[03/30 21:53:12 d2.evaluation.evaluator]: [0mInference done 702/3489. 0.2339 s / img. ETA=0:12:22
[32m[03/30 21:53:17 d2.evaluation.evaluator]: [0mInference done 722/3489. 0.2338 s / img. ETA=0:12:15
[32m[03/30 21:53:22 d2.evaluation.evaluator]: [0mInference done 742/3489. 0.2338 s / img. ETA=0:12:09
[32m[03/30 21:53:28 d2.evaluation.evaluator]: [0mInference done 763/3489. 0.2337 s / img. ETA=0:12:02
[32m[03/30 21:53:33 d2.evaluation.evaluator]: [0mInference done 785/3489. 0.2333 s / img. ETA=0:11:54
[32m[03/30 21:53:38 d2.evaluation.evaluator]: [0mInference done 807/3489. 0.2330 s / img. ETA=0:11:45
[32m[03/30 21:53:43 d2.evaluation.evaluator]: [0mInference done 829/3489. 0.2327 s / img. ETA=0:11:37
[32m[03/30 21:53:48 d2.evaluation.evaluator]: [0mInference done 851/3489. 0.2324 s / img. ETA=0:11:29
[32m[03/30 21:53:53 d2.evaluation.evaluator]: [0mInference done 873/3489. 0.2322 s / img. ETA=0:11:22
[32m[03/30 21:53:58 d2.evaluation.evaluator]: [0mInference done 896/3489. 0.2319 s / img. ETA=0:11:14
[32m[03/30 21:54:03 d2.evaluation.evaluator]: [0mInference done 914/3489. 0.2321 s / img. ETA=0:11:10
[32m[03/30 21:54:09 d2.evaluation.evaluator]: [0mInference done 931/3489. 0.2324 s / img. ETA=0:11:08
[32m[03/30 21:54:14 d2.evaluation.evaluator]: [0mInference done 948/3489. 0.2326 s / img. ETA=0:11:06
[32m[03/30 21:54:19 d2.evaluation.evaluator]: [0mInference done 965/3489. 0.2329 s / img. ETA=0:11:03
[32m[03/30 21:54:24 d2.evaluation.evaluator]: [0mInference done 981/3489. 0.2331 s / img. ETA=0:11:01
[32m[03/30 21:54:29 d2.evaluation.evaluator]: [0mInference done 997/3489. 0.2334 s / img. ETA=0:10:59
[32m[03/30 21:54:34 d2.evaluation.evaluator]: [0mInference done 1013/3489. 0.2336 s / img. ETA=0:10:57
[32m[03/30 21:54:39 d2.evaluation.evaluator]: [0mInference done 1029/3489. 0.2338 s / img. ETA=0:10:54
[32m[03/30 21:54:44 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2341 s / img. ETA=0:10:52
[32m[03/30 21:54:49 d2.evaluation.evaluator]: [0mInference done 1061/3489. 0.2343 s / img. ETA=0:10:50
[32m[03/30 21:54:55 d2.evaluation.evaluator]: [0mInference done 1078/3489. 0.2345 s / img. ETA=0:10:47
[32m[03/30 21:55:00 d2.evaluation.evaluator]: [0mInference done 1096/3489. 0.2346 s / img. ETA=0:10:42
[32m[03/30 21:55:05 d2.evaluation.evaluator]: [0mInference done 1115/3489. 0.2346 s / img. ETA=0:10:37
[32m[03/30 21:55:10 d2.evaluation.evaluator]: [0mInference done 1132/3489. 0.2348 s / img. ETA=0:10:34
[32m[03/30 21:55:15 d2.evaluation.evaluator]: [0mInference done 1149/3489. 0.2349 s / img. ETA=0:10:30
[32m[03/30 21:55:20 d2.evaluation.evaluator]: [0mInference done 1166/3489. 0.2351 s / img. ETA=0:10:27
[32m[03/30 21:55:25 d2.evaluation.evaluator]: [0mInference done 1184/3489. 0.2351 s / img. ETA=0:10:23
[32m[03/30 21:55:30 d2.evaluation.evaluator]: [0mInference done 1202/3489. 0.2351 s / img. ETA=0:10:18
[32m[03/30 21:55:36 d2.evaluation.evaluator]: [0mInference done 1220/3489. 0.2353 s / img. ETA=0:10:14
[32m[03/30 21:55:41 d2.evaluation.evaluator]: [0mInference done 1239/3489. 0.2353 s / img. ETA=0:10:09
[32m[03/30 21:55:46 d2.evaluation.evaluator]: [0mInference done 1259/3489. 0.2352 s / img. ETA=0:10:03
[32m[03/30 21:55:51 d2.evaluation.evaluator]: [0mInference done 1282/3489. 0.2350 s / img. ETA=0:09:55
[32m[03/30 21:55:56 d2.evaluation.evaluator]: [0mInference done 1304/3489. 0.2348 s / img. ETA=0:09:48
[32m[03/30 21:56:01 d2.evaluation.evaluator]: [0mInference done 1326/3489. 0.2346 s / img. ETA=0:09:40
[32m[03/30 21:56:06 d2.evaluation.evaluator]: [0mInference done 1348/3489. 0.2344 s / img. ETA=0:09:33
[32m[03/30 21:56:11 d2.evaluation.evaluator]: [0mInference done 1370/3489. 0.2342 s / img. ETA=0:09:26
[32m[03/30 21:56:16 d2.evaluation.evaluator]: [0mInference done 1392/3489. 0.2339 s / img. ETA=0:09:19
[32m[03/30 21:56:22 d2.evaluation.evaluator]: [0mInference done 1414/3489. 0.2338 s / img. ETA=0:09:12
[32m[03/30 21:56:27 d2.evaluation.evaluator]: [0mInference done 1435/3489. 0.2336 s / img. ETA=0:09:05
[32m[03/30 21:56:32 d2.evaluation.evaluator]: [0mInference done 1457/3489. 0.2335 s / img. ETA=0:08:59
[32m[03/30 21:56:37 d2.evaluation.evaluator]: [0mInference done 1479/3489. 0.2333 s / img. ETA=0:08:52
[32m[03/30 21:56:42 d2.evaluation.evaluator]: [0mInference done 1501/3489. 0.2331 s / img. ETA=0:08:45
[32m[03/30 21:56:47 d2.evaluation.evaluator]: [0mInference done 1523/3489. 0.2330 s / img. ETA=0:08:38
[32m[03/30 21:56:52 d2.evaluation.evaluator]: [0mInference done 1545/3489. 0.2329 s / img. ETA=0:08:31
[32m[03/30 21:56:57 d2.evaluation.evaluator]: [0mInference done 1567/3489. 0.2327 s / img. ETA=0:08:25
[32m[03/30 21:57:02 d2.evaluation.evaluator]: [0mInference done 1589/3489. 0.2326 s / img. ETA=0:08:18
[32m[03/30 21:57:08 d2.evaluation.evaluator]: [0mInference done 1609/3489. 0.2325 s / img. ETA=0:08:13
[32m[03/30 21:57:13 d2.evaluation.evaluator]: [0mInference done 1628/3489. 0.2325 s / img. ETA=0:08:08
[32m[03/30 21:57:18 d2.evaluation.evaluator]: [0mInference done 1647/3489. 0.2325 s / img. ETA=0:08:03
[32m[03/30 21:57:23 d2.evaluation.evaluator]: [0mInference done 1666/3489. 0.2325 s / img. ETA=0:07:58
[32m[03/30 21:57:28 d2.evaluation.evaluator]: [0mInference done 1684/3489. 0.2326 s / img. ETA=0:07:54
[32m[03/30 21:57:33 d2.evaluation.evaluator]: [0mInference done 1701/3489. 0.2327 s / img. ETA=0:07:50
[32m[03/30 21:57:38 d2.evaluation.evaluator]: [0mInference done 1718/3489. 0.2328 s / img. ETA=0:07:46
[32m[03/30 21:57:44 d2.evaluation.evaluator]: [0mInference done 1735/3489. 0.2329 s / img. ETA=0:07:43
[32m[03/30 21:57:49 d2.evaluation.evaluator]: [0mInference done 1752/3489. 0.2330 s / img. ETA=0:07:39
[32m[03/30 21:57:54 d2.evaluation.evaluator]: [0mInference done 1768/3489. 0.2331 s / img. ETA=0:07:35
[32m[03/30 21:57:59 d2.evaluation.evaluator]: [0mInference done 1784/3489. 0.2332 s / img. ETA=0:07:32
[32m[03/30 21:58:04 d2.evaluation.evaluator]: [0mInference done 1800/3489. 0.2333 s / img. ETA=0:07:28
[32m[03/30 21:58:09 d2.evaluation.evaluator]: [0mInference done 1816/3489. 0.2334 s / img. ETA=0:07:25
[32m[03/30 21:58:14 d2.evaluation.evaluator]: [0mInference done 1832/3489. 0.2335 s / img. ETA=0:07:21
[32m[03/30 21:58:19 d2.evaluation.evaluator]: [0mInference done 1848/3489. 0.2336 s / img. ETA=0:07:18
[32m[03/30 21:58:24 d2.evaluation.evaluator]: [0mInference done 1864/3489. 0.2337 s / img. ETA=0:07:14
[32m[03/30 21:58:29 d2.evaluation.evaluator]: [0mInference done 1880/3489. 0.2338 s / img. ETA=0:07:11
[32m[03/30 21:58:34 d2.evaluation.evaluator]: [0mInference done 1896/3489. 0.2339 s / img. ETA=0:07:07
[32m[03/30 21:58:39 d2.evaluation.evaluator]: [0mInference done 1912/3489. 0.2340 s / img. ETA=0:07:03
[32m[03/30 21:58:44 d2.evaluation.evaluator]: [0mInference done 1928/3489. 0.2341 s / img. ETA=0:07:00
[32m[03/30 21:58:49 d2.evaluation.evaluator]: [0mInference done 1944/3489. 0.2342 s / img. ETA=0:06:56
[32m[03/30 21:58:54 d2.evaluation.evaluator]: [0mInference done 1960/3489. 0.2344 s / img. ETA=0:06:52
[32m[03/30 21:59:00 d2.evaluation.evaluator]: [0mInference done 1976/3489. 0.2344 s / img. ETA=0:06:49
[32m[03/30 21:59:05 d2.evaluation.evaluator]: [0mInference done 1993/3489. 0.2345 s / img. ETA=0:06:44
[32m[03/30 21:59:10 d2.evaluation.evaluator]: [0mInference done 2012/3489. 0.2345 s / img. ETA=0:06:39
[32m[03/30 21:59:15 d2.evaluation.evaluator]: [0mInference done 2030/3489. 0.2346 s / img. ETA=0:06:35
[32m[03/30 21:59:20 d2.evaluation.evaluator]: [0mInference done 2048/3489. 0.2346 s / img. ETA=0:06:30
[32m[03/30 21:59:25 d2.evaluation.evaluator]: [0mInference done 2065/3489. 0.2347 s / img. ETA=0:06:26
[32m[03/30 21:59:31 d2.evaluation.evaluator]: [0mInference done 2082/3489. 0.2348 s / img. ETA=0:06:22
[32m[03/30 21:59:36 d2.evaluation.evaluator]: [0mInference done 2098/3489. 0.2349 s / img. ETA=0:06:18
[32m[03/30 21:59:41 d2.evaluation.evaluator]: [0mInference done 2115/3489. 0.2349 s / img. ETA=0:06:13
[32m[03/30 21:59:46 d2.evaluation.evaluator]: [0mInference done 2131/3489. 0.2350 s / img. ETA=0:06:10
[32m[03/30 21:59:51 d2.evaluation.evaluator]: [0mInference done 2147/3489. 0.2351 s / img. ETA=0:06:06
[32m[03/30 21:59:56 d2.evaluation.evaluator]: [0mInference done 2163/3489. 0.2352 s / img. ETA=0:06:02
[32m[03/30 22:00:01 d2.evaluation.evaluator]: [0mInference done 2179/3489. 0.2353 s / img. ETA=0:05:58
[32m[03/30 22:00:07 d2.evaluation.evaluator]: [0mInference done 2195/3489. 0.2354 s / img. ETA=0:05:54
[32m[03/30 22:00:12 d2.evaluation.evaluator]: [0mInference done 2211/3489. 0.2355 s / img. ETA=0:05:50
[32m[03/30 22:00:17 d2.evaluation.evaluator]: [0mInference done 2227/3489. 0.2356 s / img. ETA=0:05:46
[32m[03/30 22:00:22 d2.evaluation.evaluator]: [0mInference done 2243/3489. 0.2357 s / img. ETA=0:05:42
[32m[03/30 22:00:27 d2.evaluation.evaluator]: [0mInference done 2260/3489. 0.2357 s / img. ETA=0:05:38
[32m[03/30 22:00:32 d2.evaluation.evaluator]: [0mInference done 2277/3489. 0.2358 s / img. ETA=0:05:33
[32m[03/30 22:00:37 d2.evaluation.evaluator]: [0mInference done 2294/3489. 0.2358 s / img. ETA=0:05:29
[32m[03/30 22:00:42 d2.evaluation.evaluator]: [0mInference done 2310/3489. 0.2359 s / img. ETA=0:05:25
[32m[03/30 22:00:47 d2.evaluation.evaluator]: [0mInference done 2326/3489. 0.2360 s / img. ETA=0:05:20
[32m[03/30 22:00:52 d2.evaluation.evaluator]: [0mInference done 2342/3489. 0.2361 s / img. ETA=0:05:16
[32m[03/30 22:00:57 d2.evaluation.evaluator]: [0mInference done 2359/3489. 0.2361 s / img. ETA=0:05:12
[32m[03/30 22:01:02 d2.evaluation.evaluator]: [0mInference done 2378/3489. 0.2361 s / img. ETA=0:05:06
[32m[03/30 22:01:07 d2.evaluation.evaluator]: [0mInference done 2397/3489. 0.2361 s / img. ETA=0:05:01
[32m[03/30 22:01:13 d2.evaluation.evaluator]: [0mInference done 2416/3489. 0.2361 s / img. ETA=0:04:56
[32m[03/30 22:01:18 d2.evaluation.evaluator]: [0mInference done 2435/3489. 0.2361 s / img. ETA=0:04:51
[32m[03/30 22:01:23 d2.evaluation.evaluator]: [0mInference done 2452/3489. 0.2362 s / img. ETA=0:04:46
[32m[03/30 22:01:28 d2.evaluation.evaluator]: [0mInference done 2469/3489. 0.2362 s / img. ETA=0:04:42
[32m[03/30 22:01:33 d2.evaluation.evaluator]: [0mInference done 2485/3489. 0.2363 s / img. ETA=0:04:38
[32m[03/30 22:01:39 d2.evaluation.evaluator]: [0mInference done 2506/3489. 0.2363 s / img. ETA=0:04:31
[32m[03/30 22:01:44 d2.evaluation.evaluator]: [0mInference done 2526/3489. 0.2362 s / img. ETA=0:04:26
[32m[03/30 22:01:49 d2.evaluation.evaluator]: [0mInference done 2546/3489. 0.2362 s / img. ETA=0:04:20
[32m[03/30 22:01:54 d2.evaluation.evaluator]: [0mInference done 2566/3489. 0.2362 s / img. ETA=0:04:14
[32m[03/30 22:01:59 d2.evaluation.evaluator]: [0mInference done 2586/3489. 0.2361 s / img. ETA=0:04:09
[32m[03/30 22:02:04 d2.evaluation.evaluator]: [0mInference done 2607/3489. 0.2361 s / img. ETA=0:04:03
[32m[03/30 22:02:09 d2.evaluation.evaluator]: [0mInference done 2628/3489. 0.2360 s / img. ETA=0:03:57
[32m[03/30 22:02:15 d2.evaluation.evaluator]: [0mInference done 2650/3489. 0.2359 s / img. ETA=0:03:50
[32m[03/30 22:02:20 d2.evaluation.evaluator]: [0mInference done 2670/3489. 0.2359 s / img. ETA=0:03:45
[32m[03/30 22:02:25 d2.evaluation.evaluator]: [0mInference done 2690/3489. 0.2359 s / img. ETA=0:03:39
[32m[03/30 22:02:30 d2.evaluation.evaluator]: [0mInference done 2711/3489. 0.2358 s / img. ETA=0:03:33
[32m[03/30 22:02:35 d2.evaluation.evaluator]: [0mInference done 2732/3489. 0.2357 s / img. ETA=0:03:27
[32m[03/30 22:02:40 d2.evaluation.evaluator]: [0mInference done 2753/3489. 0.2357 s / img. ETA=0:03:21
[32m[03/30 22:02:45 d2.evaluation.evaluator]: [0mInference done 2774/3489. 0.2356 s / img. ETA=0:03:15
[32m[03/30 22:02:50 d2.evaluation.evaluator]: [0mInference done 2795/3489. 0.2355 s / img. ETA=0:03:09
[32m[03/30 22:02:55 d2.evaluation.evaluator]: [0mInference done 2816/3489. 0.2355 s / img. ETA=0:03:04
[32m[03/30 22:03:01 d2.evaluation.evaluator]: [0mInference done 2837/3489. 0.2354 s / img. ETA=0:02:58
[32m[03/30 22:03:06 d2.evaluation.evaluator]: [0mInference done 2858/3489. 0.2353 s / img. ETA=0:02:52
[32m[03/30 22:03:11 d2.evaluation.evaluator]: [0mInference done 2879/3489. 0.2352 s / img. ETA=0:02:46
[32m[03/30 22:03:16 d2.evaluation.evaluator]: [0mInference done 2900/3489. 0.2351 s / img. ETA=0:02:40
[32m[03/30 22:03:21 d2.evaluation.evaluator]: [0mInference done 2922/3489. 0.2351 s / img. ETA=0:02:34
[32m[03/30 22:03:26 d2.evaluation.evaluator]: [0mInference done 2944/3489. 0.2350 s / img. ETA=0:02:28
[32m[03/30 22:03:31 d2.evaluation.evaluator]: [0mInference done 2966/3489. 0.2349 s / img. ETA=0:02:22
[32m[03/30 22:03:36 d2.evaluation.evaluator]: [0mInference done 2987/3489. 0.2348 s / img. ETA=0:02:16
[32m[03/30 22:03:42 d2.evaluation.evaluator]: [0mInference done 3008/3489. 0.2348 s / img. ETA=0:02:10
[32m[03/30 22:03:47 d2.evaluation.evaluator]: [0mInference done 3029/3489. 0.2347 s / img. ETA=0:02:04
[32m[03/30 22:03:52 d2.evaluation.evaluator]: [0mInference done 3051/3489. 0.2346 s / img. ETA=0:01:58
[32m[03/30 22:03:57 d2.evaluation.evaluator]: [0mInference done 3071/3489. 0.2346 s / img. ETA=0:01:53
[32m[03/30 22:04:02 d2.evaluation.evaluator]: [0mInference done 3092/3489. 0.2345 s / img. ETA=0:01:47
[32m[03/30 22:04:08 d2.evaluation.evaluator]: [0mInference done 3113/3489. 0.2344 s / img. ETA=0:01:41
[32m[03/30 22:04:13 d2.evaluation.evaluator]: [0mInference done 3134/3489. 0.2344 s / img. ETA=0:01:35
[32m[03/30 22:04:18 d2.evaluation.evaluator]: [0mInference done 3155/3489. 0.2343 s / img. ETA=0:01:30
[32m[03/30 22:04:23 d2.evaluation.evaluator]: [0mInference done 3176/3489. 0.2342 s / img. ETA=0:01:24
[32m[03/30 22:04:28 d2.evaluation.evaluator]: [0mInference done 3198/3489. 0.2342 s / img. ETA=0:01:18
[32m[03/30 22:04:33 d2.evaluation.evaluator]: [0mInference done 3219/3489. 0.2341 s / img. ETA=0:01:12
[32m[03/30 22:04:38 d2.evaluation.evaluator]: [0mInference done 3240/3489. 0.2341 s / img. ETA=0:01:07
[32m[03/30 22:04:44 d2.evaluation.evaluator]: [0mInference done 3262/3489. 0.2340 s / img. ETA=0:01:01
[32m[03/30 22:04:49 d2.evaluation.evaluator]: [0mInference done 3284/3489. 0.2339 s / img. ETA=0:00:55
[32m[03/30 22:04:54 d2.evaluation.evaluator]: [0mInference done 3307/3489. 0.2338 s / img. ETA=0:00:48
[32m[03/30 22:04:59 d2.evaluation.evaluator]: [0mInference done 3330/3489. 0.2337 s / img. ETA=0:00:42
[32m[03/30 22:05:04 d2.evaluation.evaluator]: [0mInference done 3353/3489. 0.2336 s / img. ETA=0:00:36
[32m[03/30 22:05:09 d2.evaluation.evaluator]: [0mInference done 3375/3489. 0.2335 s / img. ETA=0:00:30
[32m[03/30 22:05:14 d2.evaluation.evaluator]: [0mInference done 3397/3489. 0.2334 s / img. ETA=0:00:24
[32m[03/30 22:05:20 d2.evaluation.evaluator]: [0mInference done 3419/3489. 0.2334 s / img. ETA=0:00:18
[32m[03/30 22:05:25 d2.evaluation.evaluator]: [0mInference done 3440/3489. 0.2333 s / img. ETA=0:00:13
[32m[03/30 22:05:30 d2.evaluation.evaluator]: [0mInference done 3461/3489. 0.2332 s / img. ETA=0:00:07
[32m[03/30 22:05:35 d2.evaluation.evaluator]: [0mInference done 3482/3489. 0.2332 s / img. ETA=0:00:01
[32m[03/30 22:05:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:30.038465 (0.266946 s / img per device, on 1 devices)
[32m[03/30 22:05:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:32 (0.233186 s / img per device, on 1 devices)
[32m[03/30 22:05:39 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/30 22:05:39 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_1200.000000/coco_instances_results.json
[32m[03/30 22:05:40 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.62 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737
[32m[03/30 22:05:43 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.273 | 78.541 | 44.611 | 32.735 | 54.623 | 54.740 |
[32m[03/30 22:05:43 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 60.524 | Pedestrian | 32.023 |
Loading and preparing results...
DONE (t=2.06s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.59 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.734
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.238
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.488
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
[32m[03/30 22:05:53 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.497 | 73.391 | 39.777 | 23.803 | 50.381 | 65.422 |
[32m[03/30 22:05:53 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.140 | Pedestrian | 21.855 |
[32m[03/30 22:05:53 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: 46.2733,78.5414,44.6115,32.7348,54.6228,54.7403
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/30 22:05:53 d2.evaluation.testing]: [0mcopypaste: 42.4973,73.3913,39.7767,23.8034,50.3809,65.4217
evaluated
Test [2000]
[32m[03/30 22:05:54 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/30 22:05:54 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[03/30 22:05:55 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(2000,), max_size=2000, sample_style='choice'), RandomFlip()]
[32m[03/30 22:05:55 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 22:05:55 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[03/30 22:05:55 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[03/30 22:05:55 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[03/30 22:05:55 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(2000,), max_size=2000, sample_style='choice'), RandomFlip()]
[32m[03/30 22:05:55 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/30 22:05:55 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[03/30 22:05:55 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[03/30 22:05:55 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/30 22:06:24 d2.utils.events]: [0m eta: 0:02:42  iter: 19  total_loss: 1.901  loss_cls: 0.879  loss_box_reg: 0.2905  loss_mask: 0.6501  loss_rpn_cls: 0.0317  loss_rpn_loc: 0.01325  total_val_loss: 2.26  val_loss_cls: 0.8713  val_loss_box_reg: 0.5853  val_loss_mask: 0.6787  val_loss_rpn_cls: 0.03652  val_loss_rpn_loc: 0.02407  time: 0.9073  data_time: 0.0340  lr: 0.00019981  max_mem: 5963M
[32m[03/30 22:06:51 d2.utils.events]: [0m eta: 0:02:27  iter: 39  total_loss: 0.9677  loss_cls: 0.2324  loss_box_reg: 0.3651  loss_mask: 0.3297  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.008147  total_val_loss: 1.417  val_loss_cls: 0.3514  val_loss_box_reg: 0.5185  val_loss_mask: 0.465  val_loss_rpn_cls: 0.04657  val_loss_rpn_loc: 0.03258  time: 0.9254  data_time: 0.0082  lr: 0.00039961  max_mem: 5981M
[32m[03/30 22:07:19 d2.utils.events]: [0m eta: 0:02:09  iter: 59  total_loss: 0.741  loss_cls: 0.1239  loss_box_reg: 0.3544  loss_mask: 0.1993  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.0127  total_val_loss: 1.328  val_loss_cls: 0.3061  val_loss_box_reg: 0.4675  val_loss_mask: 0.4461  val_loss_rpn_cls: 0.03397  val_loss_rpn_loc: 0.02468  time: 0.9289  data_time: 0.0086  lr: 0.00059941  max_mem: 5981M
[32m[03/30 22:07:47 d2.utils.events]: [0m eta: 0:01:51  iter: 79  total_loss: 0.5969  loss_cls: 0.07601  loss_box_reg: 0.3062  loss_mask: 0.1437  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.01798  total_val_loss: 1.269  val_loss_cls: 0.3219  val_loss_box_reg: 0.4948  val_loss_mask: 0.3735  val_loss_rpn_cls: 0.03858  val_loss_rpn_loc: 0.0311  time: 0.9323  data_time: 0.0075  lr: 0.00079921  max_mem: 5981M
[32m[03/30 22:08:15 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 22:08:15 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 22:08:15 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 22:08:15 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 22:08:16 d2.utils.events]: [0m eta: 0:01:33  iter: 99  total_loss: 0.4302  loss_cls: 0.05584  loss_box_reg: 0.1607  loss_mask: 0.1495  loss_rpn_cls: 0.009076  loss_rpn_loc: 0.01227  total_val_loss: 1.242  val_loss_cls: 0.305  val_loss_box_reg: 0.3919  val_loss_mask: 0.4006  val_loss_rpn_cls: 0.03215  val_loss_rpn_loc: 0.02481  time: 0.9357  data_time: 0.0075  lr: 0.00099901  max_mem: 5981M
[32m[03/30 22:08:44 d2.utils.events]: [0m eta: 0:01:14  iter: 119  total_loss: 0.355  loss_cls: 0.06906  loss_box_reg: 0.1417  loss_mask: 0.1407  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.01059  total_val_loss: 1.036  val_loss_cls: 0.3046  val_loss_box_reg: 0.3085  val_loss_mask: 0.3377  val_loss_rpn_cls: 0.02936  val_loss_rpn_loc: 0.02187  time: 0.9393  data_time: 0.0083  lr: 0.0011988  max_mem: 5981M
[32m[03/30 22:09:12 d2.utils.events]: [0m eta: 0:00:56  iter: 139  total_loss: 0.3962  loss_cls: 0.0667  loss_box_reg: 0.1317  loss_mask: 0.1472  loss_rpn_cls: 0.007138  loss_rpn_loc: 0.0107  total_val_loss: 1.181  val_loss_cls: 0.308  val_loss_box_reg: 0.4507  val_loss_mask: 0.3722  val_loss_rpn_cls: 0.02724  val_loss_rpn_loc: 0.03386  time: 0.9406  data_time: 0.0088  lr: 0.0013986  max_mem: 5981M
[32m[03/30 22:09:40 d2.utils.events]: [0m eta: 0:00:37  iter: 159  total_loss: 0.3583  loss_cls: 0.06673  loss_box_reg: 0.1245  loss_mask: 0.1454  loss_rpn_cls: 0.007233  loss_rpn_loc: 0.01866  total_val_loss: 0.8022  val_loss_cls: 0.1773  val_loss_box_reg: 0.2555  val_loss_mask: 0.2538  val_loss_rpn_cls: 0.02536  val_loss_rpn_loc: 0.02377  time: 0.9422  data_time: 0.0089  lr: 0.0015984  max_mem: 5981M
[32m[03/30 22:10:09 d2.utils.events]: [0m eta: 0:00:18  iter: 179  total_loss: 0.4063  loss_cls: 0.06161  loss_box_reg: 0.1314  loss_mask: 0.1408  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.02655  total_val_loss: 0.9279  val_loss_cls: 0.2251  val_loss_box_reg: 0.3169  val_loss_mask: 0.3298  val_loss_rpn_cls: 0.02503  val_loss_rpn_loc: 0.02218  time: 0.9430  data_time: 0.0084  lr: 0.0017982  max_mem: 5981M
[4m[5m[31mERROR[0m [32m[03/30 22:10:38 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 135, in train
    self.after_step()
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 165, in after_step
    h.after_step()
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 353, in after_step
    self._do_eval()
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 328, in _do_eval
    results = self._func()
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 366, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 519, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 478, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/config/config.py", line 201, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/config/config.py", line 236, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/data/build.py", line 397, in _test_loader_from_config
    else None,
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/data/build.py", line 220, in get_detection_dataset_dicts
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/data/build.py", line 220, in <listcomp>
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/group08/anaconda3/lib/python3.7/site-packages/detectron2/data/catalog.py", line 58, in get
    return f()
  File "coco_kitti.py", line 32, in load_val_dataset
    val_dict = pickle.load(val_dict_file)
  File "/home/group08/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 43453) is killed by signal: Killed. 
[32m[03/30 22:10:38 d2.engine.hooks]: [0mOverall training speed: 197 iterations in 0:03:06 (0.9490 s / it)
[32m[03/30 22:10:38 d2.engine.hooks]: [0mTotal training time: 0:04:39 (0:01:32 on hooks)
[32m[03/30 22:10:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/30 22:10:38 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[03/30 22:10:38 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[03/30 22:10:38 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/30 22:10:38 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4413  loss_cls: 0.07445  loss_box_reg: 0.1507  loss_mask: 0.1372  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.03699  total_val_loss: 0.8216  val_loss_cls: 0.1566  val_loss_box_reg: 0.2744  val_loss_mask: 0.3358  val_loss_rpn_cls: 0.02824  val_loss_rpn_loc: 0.02113  time: 0.9442  data_time: 0.0084  lr: 0.001998  max_mem: 5981M
