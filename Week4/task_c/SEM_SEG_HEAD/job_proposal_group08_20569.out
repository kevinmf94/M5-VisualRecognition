Test [1][['res2']]
[32m[04/04 23:14:26 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/04 23:14:26 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/04 23:14:26 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 16900        | Pedestrian | 690          |
|            |              |            |              |
|   total    | 17590        |            |              |[0m
[32m[04/04 23:14:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:14:26 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:14:26 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/04 23:14:26 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/04 23:14:26 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/04 23:14:26 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    Cars    | 9960         | Pedestrian | 10725        |
|            |              |            |              |
|   total    | 20685        |            |              |[0m
[32m[04/04 23:14:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:14:26 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:14:26 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/04 23:14:26 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/04 23:14:27 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/04 23:14:51 d2.utils.events]: [0m eta: 0:02:30  iter: 19  total_loss: 1.832  loss_cls: 0.8739  loss_box_reg: 0.287  loss_mask: 0.6589  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.008077  total_val_loss: 2.063  val_loss_cls: 0.8556  val_loss_box_reg: 0.4831  val_loss_mask: 0.6733  val_loss_rpn_cls: 0.03909  val_loss_rpn_loc: 0.0123  time: 0.8378  data_time: 0.0261  lr: 0.00019981  max_mem: 4743M
[32m[04/04 23:15:14 d2.utils.events]: [0m eta: 0:02:14  iter: 39  total_loss: 0.8434  loss_cls: 0.1908  loss_box_reg: 0.2621  loss_mask: 0.3773  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.005087  total_val_loss: 1.32  val_loss_cls: 0.291  val_loss_box_reg: 0.4167  val_loss_mask: 0.4815  val_loss_rpn_cls: 0.04039  val_loss_rpn_loc: 0.0143  time: 0.8399  data_time: 0.0066  lr: 0.00039961  max_mem: 4743M
[32m[04/04 23:15:38 d2.utils.events]: [0m eta: 0:01:58  iter: 59  total_loss: 0.6964  loss_cls: 0.1033  loss_box_reg: 0.3718  loss_mask: 0.1719  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.007817  total_val_loss: 1.064  val_loss_cls: 0.1773  val_loss_box_reg: 0.41  val_loss_mask: 0.3562  val_loss_rpn_cls: 0.03149  val_loss_rpn_loc: 0.01219  time: 0.8471  data_time: 0.0062  lr: 0.00059941  max_mem: 4743M
[32m[04/04 23:16:03 d2.utils.events]: [0m eta: 0:01:41  iter: 79  total_loss: 0.5903  loss_cls: 0.07646  loss_box_reg: 0.2565  loss_mask: 0.1978  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.01016  total_val_loss: 1.178  val_loss_cls: 0.26  val_loss_box_reg: 0.4074  val_loss_mask: 0.3872  val_loss_rpn_cls: 0.02841  val_loss_rpn_loc: 0.01478  time: 0.8523  data_time: 0.0076  lr: 0.00079921  max_mem: 4744M
[32m[04/04 23:16:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:16:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:16:28 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:16:28 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:16:28 d2.utils.events]: [0m eta: 0:01:25  iter: 99  total_loss: 0.5148  loss_cls: 0.06708  loss_box_reg: 0.2264  loss_mask: 0.1625  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.01202  total_val_loss: 0.9828  val_loss_cls: 0.244  val_loss_box_reg: 0.2902  val_loss_mask: 0.4641  val_loss_rpn_cls: 0.01952  val_loss_rpn_loc: 0.01224  time: 0.8586  data_time: 0.0066  lr: 0.00099901  max_mem: 4744M
[32m[04/04 23:16:52 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.3253  loss_cls: 0.04957  loss_box_reg: 0.09292  loss_mask: 0.1432  loss_rpn_cls: 0.006443  loss_rpn_loc: 0.007442  total_val_loss: 0.7226  val_loss_cls: 0.1305  val_loss_box_reg: 0.169  val_loss_mask: 0.3106  val_loss_rpn_cls: 0.01694  val_loss_rpn_loc: 0.01222  time: 0.8598  data_time: 0.0064  lr: 0.0011988  max_mem: 4744M
[32m[04/04 23:17:17 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.329  loss_cls: 0.04894  loss_box_reg: 0.09873  loss_mask: 0.1582  loss_rpn_cls: 0.008549  loss_rpn_loc: 0.009454  total_val_loss: 0.7025  val_loss_cls: 0.1628  val_loss_box_reg: 0.2189  val_loss_mask: 0.3031  val_loss_rpn_cls: 0.01306  val_loss_rpn_loc: 0.01433  time: 0.8626  data_time: 0.0066  lr: 0.0013986  max_mem: 4744M
[32m[04/04 23:17:41 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3333  loss_cls: 0.04422  loss_box_reg: 0.0867  loss_mask: 0.1591  loss_rpn_cls: 0.008722  loss_rpn_loc: 0.00723  total_val_loss: 0.6876  val_loss_cls: 0.136  val_loss_box_reg: 0.2079  val_loss_mask: 0.2649  val_loss_rpn_cls: 0.01417  val_loss_rpn_loc: 0.01447  time: 0.8635  data_time: 0.0064  lr: 0.0015984  max_mem: 4744M
[32m[04/04 23:18:06 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3659  loss_cls: 0.06015  loss_box_reg: 0.1237  loss_mask: 0.1609  loss_rpn_cls: 0.006442  loss_rpn_loc: 0.01105  total_val_loss: 0.8927  val_loss_cls: 0.174  val_loss_box_reg: 0.2589  val_loss_mask: 0.3673  val_loss_rpn_cls: 0.02081  val_loss_rpn_loc: 0.01476  time: 0.8654  data_time: 0.0068  lr: 0.0017982  max_mem: 4744M
[32m[04/04 23:18:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:18:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:18:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:18:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:18:31 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3466  loss_cls: 0.04965  loss_box_reg: 0.09234  loss_mask: 0.1614  loss_rpn_cls: 0.005175  loss_rpn_loc: 0.007259  total_val_loss: 0.8972  val_loss_cls: 0.1969  val_loss_box_reg: 0.3223  val_loss_mask: 0.3571  val_loss_rpn_cls: 0.02233  val_loss_rpn_loc: 0.01604  time: 0.8665  data_time: 0.0074  lr: 0.001998  max_mem: 4744M
[32m[04/04 23:18:31 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:51 (0.8665 s / it)
[32m[04/04 23:18:31 d2.engine.hooks]: [0mTotal training time: 0:04:01 (0:01:10 on hooks)
[32m[04/04 23:18:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:18:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:18:32 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:18:32 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/04 23:18:32 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/04 23:18:32 d2.evaluation.coco_evaluation]: [0m'kittimots_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[04/04 23:18:32 d2.data.datasets.coco]: [0mConverting annotations of dataset 'kittimots_val' to COCO format ...)
[32m[04/04 23:18:32 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[04/04 23:18:32 d2.data.datasets.coco]: [0mConversion finished, #images: 3489, #annotations: 20685
[32m[04/04 23:18:32 d2.data.datasets.coco]: [0mCaching COCO format annotations at './output_1/kittimots_val_coco_format.json' ...
[32m[04/04 23:18:33 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:18:33 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:18:33 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/04 23:18:33 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/04 23:18:36 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2249 s / img. ETA=0:13:56
[32m[04/04 23:18:42 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2285 s / img. ETA=0:14:03
[32m[04/04 23:18:47 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2290 s / img. ETA=0:13:55
[32m[04/04 23:18:52 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2295 s / img. ETA=0:13:50
[32m[04/04 23:18:57 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2302 s / img. ETA=0:13:53
[32m[04/04 23:19:02 d2.evaluation.evaluator]: [0mInference done 113/3489. 0.2319 s / img. ETA=0:14:05
[32m[04/04 23:19:07 d2.evaluation.evaluator]: [0mInference done 130/3489. 0.2339 s / img. ETA=0:14:31
[32m[04/04 23:19:13 d2.evaluation.evaluator]: [0mInference done 145/3489. 0.2364 s / img. ETA=0:15:00
[32m[04/04 23:19:18 d2.evaluation.evaluator]: [0mInference done 160/3489. 0.2384 s / img. ETA=0:15:25
[32m[04/04 23:19:23 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2397 s / img. ETA=0:15:40
[32m[04/04 23:19:28 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2398 s / img. ETA=0:15:36
[32m[04/04 23:19:34 d2.evaluation.evaluator]: [0mInference done 213/3489. 0.2393 s / img. ETA=0:15:23
[32m[04/04 23:19:39 d2.evaluation.evaluator]: [0mInference done 233/3489. 0.2390 s / img. ETA=0:15:11
[32m[04/04 23:19:44 d2.evaluation.evaluator]: [0mInference done 252/3489. 0.2388 s / img. ETA=0:15:03
[32m[04/04 23:19:49 d2.evaluation.evaluator]: [0mInference done 271/3489. 0.2390 s / img. ETA=0:14:57
[32m[04/04 23:19:54 d2.evaluation.evaluator]: [0mInference done 290/3489. 0.2389 s / img. ETA=0:14:51
[32m[04/04 23:20:00 d2.evaluation.evaluator]: [0mInference done 308/3489. 0.2392 s / img. ETA=0:14:47
[32m[04/04 23:20:05 d2.evaluation.evaluator]: [0mInference done 326/3489. 0.2394 s / img. ETA=0:14:44
[32m[04/04 23:20:10 d2.evaluation.evaluator]: [0mInference done 344/3489. 0.2396 s / img. ETA=0:14:41
[32m[04/04 23:20:15 d2.evaluation.evaluator]: [0mInference done 362/3489. 0.2398 s / img. ETA=0:14:37
[32m[04/04 23:20:20 d2.evaluation.evaluator]: [0mInference done 381/3489. 0.2397 s / img. ETA=0:14:31
[32m[04/04 23:20:26 d2.evaluation.evaluator]: [0mInference done 400/3489. 0.2397 s / img. ETA=0:14:25
[32m[04/04 23:20:31 d2.evaluation.evaluator]: [0mInference done 418/3489. 0.2397 s / img. ETA=0:14:20
[32m[04/04 23:20:36 d2.evaluation.evaluator]: [0mInference done 439/3489. 0.2392 s / img. ETA=0:14:09
[32m[04/04 23:20:41 d2.evaluation.evaluator]: [0mInference done 460/3489. 0.2388 s / img. ETA=0:13:58
[32m[04/04 23:20:46 d2.evaluation.evaluator]: [0mInference done 481/3489. 0.2385 s / img. ETA=0:13:48
[32m[04/04 23:20:51 d2.evaluation.evaluator]: [0mInference done 502/3489. 0.2383 s / img. ETA=0:13:38
[32m[04/04 23:20:56 d2.evaluation.evaluator]: [0mInference done 523/3489. 0.2379 s / img. ETA=0:13:29
[32m[04/04 23:21:01 d2.evaluation.evaluator]: [0mInference done 545/3489. 0.2375 s / img. ETA=0:13:18
[32m[04/04 23:21:07 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2374 s / img. ETA=0:13:11
[32m[04/04 23:21:12 d2.evaluation.evaluator]: [0mInference done 584/3489. 0.2374 s / img. ETA=0:13:06
[32m[04/04 23:21:17 d2.evaluation.evaluator]: [0mInference done 603/3489. 0.2375 s / img. ETA=0:13:02
[32m[04/04 23:21:22 d2.evaluation.evaluator]: [0mInference done 622/3489. 0.2375 s / img. ETA=0:12:56
[32m[04/04 23:21:27 d2.evaluation.evaluator]: [0mInference done 641/3489. 0.2377 s / img. ETA=0:12:51
[32m[04/04 23:21:32 d2.evaluation.evaluator]: [0mInference done 660/3489. 0.2376 s / img. ETA=0:12:46
[32m[04/04 23:21:38 d2.evaluation.evaluator]: [0mInference done 680/3489. 0.2375 s / img. ETA=0:12:39
[32m[04/04 23:21:43 d2.evaluation.evaluator]: [0mInference done 701/3489. 0.2373 s / img. ETA=0:12:31
[32m[04/04 23:21:48 d2.evaluation.evaluator]: [0mInference done 722/3489. 0.2371 s / img. ETA=0:12:24
[32m[04/04 23:21:53 d2.evaluation.evaluator]: [0mInference done 742/3489. 0.2370 s / img. ETA=0:12:17
[32m[04/04 23:21:58 d2.evaluation.evaluator]: [0mInference done 763/3489. 0.2367 s / img. ETA=0:12:09
[32m[04/04 23:22:03 d2.evaluation.evaluator]: [0mInference done 785/3489. 0.2364 s / img. ETA=0:12:01
[32m[04/04 23:22:08 d2.evaluation.evaluator]: [0mInference done 806/3489. 0.2363 s / img. ETA=0:11:54
[32m[04/04 23:22:13 d2.evaluation.evaluator]: [0mInference done 827/3489. 0.2361 s / img. ETA=0:11:46
[32m[04/04 23:22:18 d2.evaluation.evaluator]: [0mInference done 848/3489. 0.2359 s / img. ETA=0:11:39
[32m[04/04 23:22:23 d2.evaluation.evaluator]: [0mInference done 869/3489. 0.2359 s / img. ETA=0:11:32
[32m[04/04 23:22:29 d2.evaluation.evaluator]: [0mInference done 891/3489. 0.2356 s / img. ETA=0:11:25
[32m[04/04 23:22:34 d2.evaluation.evaluator]: [0mInference done 910/3489. 0.2357 s / img. ETA=0:11:20
[32m[04/04 23:22:39 d2.evaluation.evaluator]: [0mInference done 928/3489. 0.2359 s / img. ETA=0:11:16
[32m[04/04 23:22:44 d2.evaluation.evaluator]: [0mInference done 945/3489. 0.2361 s / img. ETA=0:11:13
[32m[04/04 23:22:49 d2.evaluation.evaluator]: [0mInference done 963/3489. 0.2363 s / img. ETA=0:11:10
[32m[04/04 23:22:54 d2.evaluation.evaluator]: [0mInference done 979/3489. 0.2365 s / img. ETA=0:11:08
[32m[04/04 23:23:00 d2.evaluation.evaluator]: [0mInference done 995/3489. 0.2368 s / img. ETA=0:11:06
[32m[04/04 23:23:05 d2.evaluation.evaluator]: [0mInference done 1012/3489. 0.2370 s / img. ETA=0:11:03
[32m[04/04 23:23:10 d2.evaluation.evaluator]: [0mInference done 1028/3489. 0.2373 s / img. ETA=0:11:01
[32m[04/04 23:23:15 d2.evaluation.evaluator]: [0mInference done 1045/3489. 0.2375 s / img. ETA=0:10:58
[32m[04/04 23:23:20 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2376 s / img. ETA=0:10:54
[32m[04/04 23:23:25 d2.evaluation.evaluator]: [0mInference done 1079/3489. 0.2378 s / img. ETA=0:10:51
[32m[04/04 23:23:30 d2.evaluation.evaluator]: [0mInference done 1098/3489. 0.2378 s / img. ETA=0:10:46
[32m[04/04 23:23:35 d2.evaluation.evaluator]: [0mInference done 1117/3489. 0.2377 s / img. ETA=0:10:40
[32m[04/04 23:23:41 d2.evaluation.evaluator]: [0mInference done 1135/3489. 0.2378 s / img. ETA=0:10:36
[32m[04/04 23:23:46 d2.evaluation.evaluator]: [0mInference done 1152/3489. 0.2379 s / img. ETA=0:10:33
[32m[04/04 23:23:51 d2.evaluation.evaluator]: [0mInference done 1169/3489. 0.2381 s / img. ETA=0:10:29
[32m[04/04 23:23:56 d2.evaluation.evaluator]: [0mInference done 1187/3489. 0.2382 s / img. ETA=0:10:24
[32m[04/04 23:24:01 d2.evaluation.evaluator]: [0mInference done 1206/3489. 0.2381 s / img. ETA=0:10:20
[32m[04/04 23:24:06 d2.evaluation.evaluator]: [0mInference done 1224/3489. 0.2382 s / img. ETA=0:10:15
[32m[04/04 23:24:11 d2.evaluation.evaluator]: [0mInference done 1243/3489. 0.2382 s / img. ETA=0:10:10
[32m[04/04 23:24:17 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2381 s / img. ETA=0:10:03
[32m[04/04 23:24:22 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2379 s / img. ETA=0:09:56
[32m[04/04 23:24:27 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2377 s / img. ETA=0:09:48
[32m[04/04 23:24:32 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2376 s / img. ETA=0:09:41
[32m[04/04 23:24:37 d2.evaluation.evaluator]: [0mInference done 1352/3489. 0.2374 s / img. ETA=0:09:34
[32m[04/04 23:24:42 d2.evaluation.evaluator]: [0mInference done 1373/3489. 0.2373 s / img. ETA=0:09:28
[32m[04/04 23:24:47 d2.evaluation.evaluator]: [0mInference done 1394/3489. 0.2372 s / img. ETA=0:09:21
[32m[04/04 23:24:52 d2.evaluation.evaluator]: [0mInference done 1414/3489. 0.2371 s / img. ETA=0:09:15
[32m[04/04 23:24:57 d2.evaluation.evaluator]: [0mInference done 1434/3489. 0.2370 s / img. ETA=0:09:10
[32m[04/04 23:25:03 d2.evaluation.evaluator]: [0mInference done 1455/3489. 0.2369 s / img. ETA=0:09:03
[32m[04/04 23:25:08 d2.evaluation.evaluator]: [0mInference done 1476/3489. 0.2368 s / img. ETA=0:08:57
[32m[04/04 23:25:13 d2.evaluation.evaluator]: [0mInference done 1497/3489. 0.2367 s / img. ETA=0:08:51
[32m[04/04 23:25:18 d2.evaluation.evaluator]: [0mInference done 1518/3489. 0.2366 s / img. ETA=0:08:44
[32m[04/04 23:25:23 d2.evaluation.evaluator]: [0mInference done 1539/3489. 0.2365 s / img. ETA=0:08:38
[32m[04/04 23:25:28 d2.evaluation.evaluator]: [0mInference done 1559/3489. 0.2366 s / img. ETA=0:08:33
[32m[04/04 23:25:33 d2.evaluation.evaluator]: [0mInference done 1580/3489. 0.2365 s / img. ETA=0:08:27
[32m[04/04 23:25:39 d2.evaluation.evaluator]: [0mInference done 1600/3489. 0.2365 s / img. ETA=0:08:21
[32m[04/04 23:25:44 d2.evaluation.evaluator]: [0mInference done 1619/3489. 0.2365 s / img. ETA=0:08:16
[32m[04/04 23:25:49 d2.evaluation.evaluator]: [0mInference done 1638/3489. 0.2365 s / img. ETA=0:08:11
[32m[04/04 23:25:54 d2.evaluation.evaluator]: [0mInference done 1657/3489. 0.2366 s / img. ETA=0:08:06
[32m[04/04 23:25:59 d2.evaluation.evaluator]: [0mInference done 1675/3489. 0.2366 s / img. ETA=0:08:02
[32m[04/04 23:26:04 d2.evaluation.evaluator]: [0mInference done 1692/3489. 0.2367 s / img. ETA=0:07:58
[32m[04/04 23:26:09 d2.evaluation.evaluator]: [0mInference done 1709/3489. 0.2368 s / img. ETA=0:07:54
[32m[04/04 23:26:14 d2.evaluation.evaluator]: [0mInference done 1726/3489. 0.2369 s / img. ETA=0:07:50
[32m[04/04 23:26:20 d2.evaluation.evaluator]: [0mInference done 1743/3489. 0.2370 s / img. ETA=0:07:46
[32m[04/04 23:26:25 d2.evaluation.evaluator]: [0mInference done 1759/3489. 0.2371 s / img. ETA=0:07:43
[32m[04/04 23:26:30 d2.evaluation.evaluator]: [0mInference done 1775/3489. 0.2373 s / img. ETA=0:07:39
[32m[04/04 23:26:35 d2.evaluation.evaluator]: [0mInference done 1791/3489. 0.2375 s / img. ETA=0:07:36
[32m[04/04 23:26:40 d2.evaluation.evaluator]: [0mInference done 1806/3489. 0.2376 s / img. ETA=0:07:33
[32m[04/04 23:26:45 d2.evaluation.evaluator]: [0mInference done 1822/3489. 0.2378 s / img. ETA=0:07:29
[32m[04/04 23:26:51 d2.evaluation.evaluator]: [0mInference done 1838/3489. 0.2379 s / img. ETA=0:07:26
[32m[04/04 23:26:56 d2.evaluation.evaluator]: [0mInference done 1854/3489. 0.2381 s / img. ETA=0:07:22
[32m[04/04 23:27:01 d2.evaluation.evaluator]: [0mInference done 1871/3489. 0.2382 s / img. ETA=0:07:18
[32m[04/04 23:27:06 d2.evaluation.evaluator]: [0mInference done 1887/3489. 0.2383 s / img. ETA=0:07:15
[32m[04/04 23:27:11 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2384 s / img. ETA=0:07:11
[32m[04/04 23:27:16 d2.evaluation.evaluator]: [0mInference done 1919/3489. 0.2385 s / img. ETA=0:07:07
[32m[04/04 23:27:22 d2.evaluation.evaluator]: [0mInference done 1935/3489. 0.2387 s / img. ETA=0:07:03
[32m[04/04 23:27:27 d2.evaluation.evaluator]: [0mInference done 1951/3489. 0.2388 s / img. ETA=0:07:00
[32m[04/04 23:27:32 d2.evaluation.evaluator]: [0mInference done 1966/3489. 0.2390 s / img. ETA=0:06:56
[32m[04/04 23:27:37 d2.evaluation.evaluator]: [0mInference done 1982/3489. 0.2391 s / img. ETA=0:06:53
[32m[04/04 23:27:42 d2.evaluation.evaluator]: [0mInference done 1999/3489. 0.2392 s / img. ETA=0:06:48
[32m[04/04 23:27:47 d2.evaluation.evaluator]: [0mInference done 2017/3489. 0.2392 s / img. ETA=0:06:44
[32m[04/04 23:27:52 d2.evaluation.evaluator]: [0mInference done 2035/3489. 0.2392 s / img. ETA=0:06:39
[32m[04/04 23:27:57 d2.evaluation.evaluator]: [0mInference done 2052/3489. 0.2393 s / img. ETA=0:06:34
[32m[04/04 23:28:03 d2.evaluation.evaluator]: [0mInference done 2069/3489. 0.2394 s / img. ETA=0:06:30
[32m[04/04 23:28:08 d2.evaluation.evaluator]: [0mInference done 2085/3489. 0.2395 s / img. ETA=0:06:26
[32m[04/04 23:28:13 d2.evaluation.evaluator]: [0mInference done 2101/3489. 0.2396 s / img. ETA=0:06:22
[32m[04/04 23:28:18 d2.evaluation.evaluator]: [0mInference done 2118/3489. 0.2396 s / img. ETA=0:06:18
[32m[04/04 23:28:23 d2.evaluation.evaluator]: [0mInference done 2134/3489. 0.2397 s / img. ETA=0:06:14
[32m[04/04 23:28:28 d2.evaluation.evaluator]: [0mInference done 2150/3489. 0.2399 s / img. ETA=0:06:10
[32m[04/04 23:28:33 d2.evaluation.evaluator]: [0mInference done 2166/3489. 0.2400 s / img. ETA=0:06:06
[32m[04/04 23:28:39 d2.evaluation.evaluator]: [0mInference done 2182/3489. 0.2400 s / img. ETA=0:06:02
[32m[04/04 23:28:44 d2.evaluation.evaluator]: [0mInference done 2198/3489. 0.2401 s / img. ETA=0:05:58
[32m[04/04 23:28:49 d2.evaluation.evaluator]: [0mInference done 2215/3489. 0.2402 s / img. ETA=0:05:53
[32m[04/04 23:28:54 d2.evaluation.evaluator]: [0mInference done 2231/3489. 0.2403 s / img. ETA=0:05:49
[32m[04/04 23:28:59 d2.evaluation.evaluator]: [0mInference done 2248/3489. 0.2403 s / img. ETA=0:05:45
[32m[04/04 23:29:04 d2.evaluation.evaluator]: [0mInference done 2266/3489. 0.2403 s / img. ETA=0:05:40
[32m[04/04 23:29:10 d2.evaluation.evaluator]: [0mInference done 2284/3489. 0.2404 s / img. ETA=0:05:35
[32m[04/04 23:29:15 d2.evaluation.evaluator]: [0mInference done 2301/3489. 0.2404 s / img. ETA=0:05:30
[32m[04/04 23:29:20 d2.evaluation.evaluator]: [0mInference done 2318/3489. 0.2405 s / img. ETA=0:05:26
[32m[04/04 23:29:25 d2.evaluation.evaluator]: [0mInference done 2335/3489. 0.2406 s / img. ETA=0:05:21
[32m[04/04 23:29:30 d2.evaluation.evaluator]: [0mInference done 2352/3489. 0.2406 s / img. ETA=0:05:17
[32m[04/04 23:29:35 d2.evaluation.evaluator]: [0mInference done 2370/3489. 0.2406 s / img. ETA=0:05:12
[32m[04/04 23:29:40 d2.evaluation.evaluator]: [0mInference done 2389/3489. 0.2406 s / img. ETA=0:05:06
[32m[04/04 23:29:46 d2.evaluation.evaluator]: [0mInference done 2408/3489. 0.2406 s / img. ETA=0:05:01
[32m[04/04 23:29:51 d2.evaluation.evaluator]: [0mInference done 2427/3489. 0.2406 s / img. ETA=0:04:56
[32m[04/04 23:29:56 d2.evaluation.evaluator]: [0mInference done 2445/3489. 0.2406 s / img. ETA=0:04:51
[32m[04/04 23:30:01 d2.evaluation.evaluator]: [0mInference done 2461/3489. 0.2408 s / img. ETA=0:04:47
[32m[04/04 23:30:06 d2.evaluation.evaluator]: [0mInference done 2478/3489. 0.2408 s / img. ETA=0:04:42
[32m[04/04 23:30:11 d2.evaluation.evaluator]: [0mInference done 2497/3489. 0.2408 s / img. ETA=0:04:37
[32m[04/04 23:30:16 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2407 s / img. ETA=0:04:31
[32m[04/04 23:30:22 d2.evaluation.evaluator]: [0mInference done 2537/3489. 0.2407 s / img. ETA=0:04:25
[32m[04/04 23:30:27 d2.evaluation.evaluator]: [0mInference done 2557/3489. 0.2406 s / img. ETA=0:04:19
[32m[04/04 23:30:32 d2.evaluation.evaluator]: [0mInference done 2577/3489. 0.2406 s / img. ETA=0:04:14
[32m[04/04 23:30:37 d2.evaluation.evaluator]: [0mInference done 2598/3489. 0.2405 s / img. ETA=0:04:08
[32m[04/04 23:30:42 d2.evaluation.evaluator]: [0mInference done 2619/3489. 0.2404 s / img. ETA=0:04:01
[32m[04/04 23:30:47 d2.evaluation.evaluator]: [0mInference done 2641/3489. 0.2403 s / img. ETA=0:03:55
[32m[04/04 23:30:52 d2.evaluation.evaluator]: [0mInference done 2662/3489. 0.2402 s / img. ETA=0:03:49
[32m[04/04 23:30:57 d2.evaluation.evaluator]: [0mInference done 2682/3489. 0.2402 s / img. ETA=0:03:43
[32m[04/04 23:31:03 d2.evaluation.evaluator]: [0mInference done 2702/3489. 0.2401 s / img. ETA=0:03:38
[32m[04/04 23:31:08 d2.evaluation.evaluator]: [0mInference done 2723/3489. 0.2400 s / img. ETA=0:03:32
[32m[04/04 23:31:13 d2.evaluation.evaluator]: [0mInference done 2743/3489. 0.2400 s / img. ETA=0:03:26
[32m[04/04 23:31:18 d2.evaluation.evaluator]: [0mInference done 2763/3489. 0.2400 s / img. ETA=0:03:20
[32m[04/04 23:31:23 d2.evaluation.evaluator]: [0mInference done 2783/3489. 0.2399 s / img. ETA=0:03:15
[32m[04/04 23:31:28 d2.evaluation.evaluator]: [0mInference done 2803/3489. 0.2399 s / img. ETA=0:03:09
[32m[04/04 23:31:34 d2.evaluation.evaluator]: [0mInference done 2823/3489. 0.2398 s / img. ETA=0:03:04
[32m[04/04 23:31:39 d2.evaluation.evaluator]: [0mInference done 2842/3489. 0.2398 s / img. ETA=0:02:58
[32m[04/04 23:31:44 d2.evaluation.evaluator]: [0mInference done 2862/3489. 0.2397 s / img. ETA=0:02:53
[32m[04/04 23:31:49 d2.evaluation.evaluator]: [0mInference done 2882/3489. 0.2397 s / img. ETA=0:02:47
[32m[04/04 23:31:54 d2.evaluation.evaluator]: [0mInference done 2903/3489. 0.2396 s / img. ETA=0:02:41
[32m[04/04 23:31:59 d2.evaluation.evaluator]: [0mInference done 2924/3489. 0.2395 s / img. ETA=0:02:35
[32m[04/04 23:32:04 d2.evaluation.evaluator]: [0mInference done 2945/3489. 0.2394 s / img. ETA=0:02:29
[32m[04/04 23:32:09 d2.evaluation.evaluator]: [0mInference done 2966/3489. 0.2394 s / img. ETA=0:02:23
[32m[04/04 23:32:14 d2.evaluation.evaluator]: [0mInference done 2987/3489. 0.2393 s / img. ETA=0:02:17
[32m[04/04 23:32:19 d2.evaluation.evaluator]: [0mInference done 3006/3489. 0.2393 s / img. ETA=0:02:12
[32m[04/04 23:32:25 d2.evaluation.evaluator]: [0mInference done 3026/3489. 0.2393 s / img. ETA=0:02:07
[32m[04/04 23:32:30 d2.evaluation.evaluator]: [0mInference done 3046/3489. 0.2392 s / img. ETA=0:02:01
[32m[04/04 23:32:35 d2.evaluation.evaluator]: [0mInference done 3066/3489. 0.2392 s / img. ETA=0:01:56
[32m[04/04 23:32:40 d2.evaluation.evaluator]: [0mInference done 3085/3489. 0.2392 s / img. ETA=0:01:50
[32m[04/04 23:32:45 d2.evaluation.evaluator]: [0mInference done 3105/3489. 0.2391 s / img. ETA=0:01:45
[32m[04/04 23:32:50 d2.evaluation.evaluator]: [0mInference done 3125/3489. 0.2391 s / img. ETA=0:01:39
[32m[04/04 23:32:56 d2.evaluation.evaluator]: [0mInference done 3145/3489. 0.2391 s / img. ETA=0:01:34
[32m[04/04 23:33:01 d2.evaluation.evaluator]: [0mInference done 3165/3489. 0.2390 s / img. ETA=0:01:28
[32m[04/04 23:33:06 d2.evaluation.evaluator]: [0mInference done 3186/3489. 0.2389 s / img. ETA=0:01:22
[32m[04/04 23:33:11 d2.evaluation.evaluator]: [0mInference done 3206/3489. 0.2389 s / img. ETA=0:01:17
[32m[04/04 23:33:16 d2.evaluation.evaluator]: [0mInference done 3226/3489. 0.2389 s / img. ETA=0:01:11
[32m[04/04 23:33:21 d2.evaluation.evaluator]: [0mInference done 3246/3489. 0.2388 s / img. ETA=0:01:06
[32m[04/04 23:33:26 d2.evaluation.evaluator]: [0mInference done 3267/3489. 0.2388 s / img. ETA=0:01:00
[32m[04/04 23:33:31 d2.evaluation.evaluator]: [0mInference done 3288/3489. 0.2387 s / img. ETA=0:00:54
[32m[04/04 23:33:37 d2.evaluation.evaluator]: [0mInference done 3310/3489. 0.2386 s / img. ETA=0:00:48
[32m[04/04 23:33:42 d2.evaluation.evaluator]: [0mInference done 3332/3489. 0.2386 s / img. ETA=0:00:42
[32m[04/04 23:33:47 d2.evaluation.evaluator]: [0mInference done 3354/3489. 0.2385 s / img. ETA=0:00:36
[32m[04/04 23:33:52 d2.evaluation.evaluator]: [0mInference done 3376/3489. 0.2384 s / img. ETA=0:00:30
[32m[04/04 23:33:57 d2.evaluation.evaluator]: [0mInference done 3397/3489. 0.2383 s / img. ETA=0:00:25
[32m[04/04 23:34:02 d2.evaluation.evaluator]: [0mInference done 3418/3489. 0.2383 s / img. ETA=0:00:19
[32m[04/04 23:34:07 d2.evaluation.evaluator]: [0mInference done 3439/3489. 0.2382 s / img. ETA=0:00:13
[32m[04/04 23:34:12 d2.evaluation.evaluator]: [0mInference done 3459/3489. 0.2382 s / img. ETA=0:00:08
[32m[04/04 23:34:17 d2.evaluation.evaluator]: [0mInference done 3480/3489. 0.2381 s / img. ETA=0:00:02
[32m[04/04 23:34:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:44.648818 (0.271139 s / img per device, on 1 devices)
[32m[04/04 23:34:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:49 (0.238099 s / img per device, on 1 devices)
[32m[04/04 23:34:21 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/04 23:34:21 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_1/coco_instances_results.json
[32m[04/04 23:34:23 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.51 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.70 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.809
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[32m[04/04 23:34:25 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.553 | 80.873 | 53.736 | 32.050 | 59.836 | 63.484 |
[32m[04/04 23:34:25 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.201 | Pedestrian | 39.904 |
Loading and preparing results...
DONE (t=1.71s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.45 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.67 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.787
[32m[04/04 23:34:34 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.786 | 77.323 | 44.578 | 23.319 | 54.629 | 73.118 |
[32m[04/04 23:34:34 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.416 | Pedestrian | 28.157 |
[32m[04/04 23:34:35 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: 50.5525,80.8729,53.7355,32.0497,59.8364,63.4839
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/04 23:34:35 d2.evaluation.testing]: [0mcopypaste: 45.7863,77.3235,44.5779,23.3191,54.6288,73.1184
evaluated
Test [2][['res3']]
[32m[04/04 23:34:35 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/04 23:34:36 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/04 23:34:36 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:34:36 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:34:36 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/04 23:34:36 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/04 23:34:36 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/04 23:34:36 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:34:36 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:34:36 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/04 23:34:36 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/04 23:34:36 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/04 23:35:01 d2.utils.events]: [0m eta: 0:02:31  iter: 19  total_loss: 1.645  loss_cls: 0.7188  loss_box_reg: 0.469  loss_mask: 0.6546  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.01147  total_val_loss: 1.846  val_loss_cls: 0.7308  val_loss_box_reg: 0.4419  val_loss_mask: 0.6644  val_loss_rpn_cls: 0.03319  val_loss_rpn_loc: 0.012  time: 0.8466  data_time: 0.0326  lr: 0.00019981  max_mem: 4744M
[32m[04/04 23:35:26 d2.utils.events]: [0m eta: 0:02:17  iter: 39  total_loss: 0.7692  loss_cls: 0.1374  loss_box_reg: 0.2839  loss_mask: 0.3681  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.008862  total_val_loss: 1.117  val_loss_cls: 0.2258  val_loss_box_reg: 0.4057  val_loss_mask: 0.4747  val_loss_rpn_cls: 0.03406  val_loss_rpn_loc: 0.01195  time: 0.8598  data_time: 0.0061  lr: 0.00039961  max_mem: 4744M
[32m[04/04 23:35:51 d2.utils.events]: [0m eta: 0:02:01  iter: 59  total_loss: 0.6273  loss_cls: 0.08268  loss_box_reg: 0.2657  loss_mask: 0.2024  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.005445  total_val_loss: 1.112  val_loss_cls: 0.1955  val_loss_box_reg: 0.3733  val_loss_mask: 0.4959  val_loss_rpn_cls: 0.02457  val_loss_rpn_loc: 0.01662  time: 0.8645  data_time: 0.0062  lr: 0.00059941  max_mem: 4744M
[32m[04/04 23:36:15 d2.utils.events]: [0m eta: 0:01:44  iter: 79  total_loss: 0.5312  loss_cls: 0.05302  loss_box_reg: 0.2723  loss_mask: 0.1666  loss_rpn_cls: 0.008818  loss_rpn_loc: 0.008664  total_val_loss: 1.075  val_loss_cls: 0.218  val_loss_box_reg: 0.3564  val_loss_mask: 0.3915  val_loss_rpn_cls: 0.02738  val_loss_rpn_loc: 0.01244  time: 0.8656  data_time: 0.0060  lr: 0.00079921  max_mem: 4745M
[32m[04/04 23:36:39 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:36:39 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:36:39 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:36:39 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:36:40 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4314  loss_cls: 0.06283  loss_box_reg: 0.172  loss_mask: 0.146  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.009463  total_val_loss: 0.755  val_loss_cls: 0.1815  val_loss_box_reg: 0.3095  val_loss_mask: 0.3119  val_loss_rpn_cls: 0.01852  val_loss_rpn_loc: 0.01131  time: 0.8636  data_time: 0.0062  lr: 0.00099901  max_mem: 4745M
[32m[04/04 23:37:04 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.3384  loss_cls: 0.04783  loss_box_reg: 0.1344  loss_mask: 0.1428  loss_rpn_cls: 0.006194  loss_rpn_loc: 0.007847  total_val_loss: 1.143  val_loss_cls: 0.3102  val_loss_box_reg: 0.4001  val_loss_mask: 0.3691  val_loss_rpn_cls: 0.02138  val_loss_rpn_loc: 0.01812  time: 0.8633  data_time: 0.0058  lr: 0.0011988  max_mem: 4745M
[32m[04/04 23:37:28 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.3636  loss_cls: 0.05683  loss_box_reg: 0.1292  loss_mask: 0.1457  loss_rpn_cls: 0.006805  loss_rpn_loc: 0.01149  total_val_loss: 0.755  val_loss_cls: 0.1528  val_loss_box_reg: 0.2383  val_loss_mask: 0.3446  val_loss_rpn_cls: 0.01913  val_loss_rpn_loc: 0.01191  time: 0.8627  data_time: 0.0060  lr: 0.0013986  max_mem: 4745M
[32m[04/04 23:37:52 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.299  loss_cls: 0.04561  loss_box_reg: 0.07912  loss_mask: 0.146  loss_rpn_cls: 0.005751  loss_rpn_loc: 0.004359  total_val_loss: 0.9061  val_loss_cls: 0.1659  val_loss_box_reg: 0.2458  val_loss_mask: 0.3566  val_loss_rpn_cls: 0.01788  val_loss_rpn_loc: 0.0123  time: 0.8621  data_time: 0.0063  lr: 0.0015984  max_mem: 4745M
[32m[04/04 23:38:16 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3664  loss_cls: 0.05884  loss_box_reg: 0.1225  loss_mask: 0.1428  loss_rpn_cls: 0.008035  loss_rpn_loc: 0.01158  total_val_loss: 0.7039  val_loss_cls: 0.1262  val_loss_box_reg: 0.2006  val_loss_mask: 0.304  val_loss_rpn_cls: 0.01774  val_loss_rpn_loc: 0.009215  time: 0.8621  data_time: 0.0062  lr: 0.0017982  max_mem: 4747M
[32m[04/04 23:38:42 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:38:42 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:38:42 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:38:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:38:42 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3415  loss_cls: 0.05321  loss_box_reg: 0.1248  loss_mask: 0.1438  loss_rpn_cls: 0.004042  loss_rpn_loc: 0.007259  total_val_loss: 0.5819  val_loss_cls: 0.09847  val_loss_box_reg: 0.1849  val_loss_mask: 0.2795  val_loss_rpn_cls: 0.01509  val_loss_rpn_loc: 0.01032  time: 0.8611  data_time: 0.0058  lr: 0.001998  max_mem: 4747M
[32m[04/04 23:38:42 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8611 s / it)
[32m[04/04 23:38:42 d2.engine.hooks]: [0mTotal training time: 0:04:02 (0:01:11 on hooks)
[32m[04/04 23:38:42 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:38:42 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:38:42 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:38:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/04 23:38:42 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/04 23:38:43 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:38:43 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:38:43 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/04 23:38:43 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/04 23:38:47 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2284 s / img. ETA=0:14:03
[32m[04/04 23:38:52 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2282 s / img. ETA=0:13:50
[32m[04/04 23:38:57 d2.evaluation.evaluator]: [0mInference done 54/3489. 0.2272 s / img. ETA=0:13:38
[32m[04/04 23:39:02 d2.evaluation.evaluator]: [0mInference done 76/3489. 0.2271 s / img. ETA=0:13:30
[32m[04/04 23:39:07 d2.evaluation.evaluator]: [0mInference done 97/3489. 0.2278 s / img. ETA=0:13:33
[32m[04/04 23:39:12 d2.evaluation.evaluator]: [0mInference done 116/3489. 0.2293 s / img. ETA=0:13:44
[32m[04/04 23:39:17 d2.evaluation.evaluator]: [0mInference done 134/3489. 0.2311 s / img. ETA=0:14:00
[32m[04/04 23:39:23 d2.evaluation.evaluator]: [0mInference done 151/3489. 0.2334 s / img. ETA=0:14:19
[32m[04/04 23:39:28 d2.evaluation.evaluator]: [0mInference done 167/3489. 0.2355 s / img. ETA=0:14:37
[32m[04/04 23:39:33 d2.evaluation.evaluator]: [0mInference done 185/3489. 0.2362 s / img. ETA=0:14:41
[32m[04/04 23:39:38 d2.evaluation.evaluator]: [0mInference done 204/3489. 0.2362 s / img. ETA=0:14:38
[32m[04/04 23:39:43 d2.evaluation.evaluator]: [0mInference done 224/3489. 0.2357 s / img. ETA=0:14:28
[32m[04/04 23:39:48 d2.evaluation.evaluator]: [0mInference done 244/3489. 0.2353 s / img. ETA=0:14:19
[32m[04/04 23:39:53 d2.evaluation.evaluator]: [0mInference done 263/3489. 0.2354 s / img. ETA=0:14:14
[32m[04/04 23:39:59 d2.evaluation.evaluator]: [0mInference done 282/3489. 0.2356 s / img. ETA=0:14:11
[32m[04/04 23:40:04 d2.evaluation.evaluator]: [0mInference done 302/3489. 0.2356 s / img. ETA=0:14:05
[32m[04/04 23:40:09 d2.evaluation.evaluator]: [0mInference done 321/3489. 0.2358 s / img. ETA=0:14:02
[32m[04/04 23:40:14 d2.evaluation.evaluator]: [0mInference done 340/3489. 0.2360 s / img. ETA=0:13:58
[32m[04/04 23:40:19 d2.evaluation.evaluator]: [0mInference done 358/3489. 0.2363 s / img. ETA=0:13:56
[32m[04/04 23:40:25 d2.evaluation.evaluator]: [0mInference done 377/3489. 0.2365 s / img. ETA=0:13:53
[32m[04/04 23:40:30 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2367 s / img. ETA=0:13:49
[32m[04/04 23:40:35 d2.evaluation.evaluator]: [0mInference done 415/3489. 0.2368 s / img. ETA=0:13:45
[32m[04/04 23:40:40 d2.evaluation.evaluator]: [0mInference done 436/3489. 0.2365 s / img. ETA=0:13:36
[32m[04/04 23:40:45 d2.evaluation.evaluator]: [0mInference done 457/3489. 0.2363 s / img. ETA=0:13:27
[32m[04/04 23:40:51 d2.evaluation.evaluator]: [0mInference done 478/3489. 0.2359 s / img. ETA=0:13:18
[32m[04/04 23:40:56 d2.evaluation.evaluator]: [0mInference done 499/3489. 0.2357 s / img. ETA=0:13:09
[32m[04/04 23:41:01 d2.evaluation.evaluator]: [0mInference done 520/3489. 0.2355 s / img. ETA=0:13:01
[32m[04/04 23:41:06 d2.evaluation.evaluator]: [0mInference done 542/3489. 0.2352 s / img. ETA=0:12:52
[32m[04/04 23:41:11 d2.evaluation.evaluator]: [0mInference done 563/3489. 0.2349 s / img. ETA=0:12:44
[32m[04/04 23:41:16 d2.evaluation.evaluator]: [0mInference done 583/3489. 0.2350 s / img. ETA=0:12:39
[32m[04/04 23:41:21 d2.evaluation.evaluator]: [0mInference done 602/3489. 0.2351 s / img. ETA=0:12:35
[32m[04/04 23:41:26 d2.evaluation.evaluator]: [0mInference done 621/3489. 0.2352 s / img. ETA=0:12:30
[32m[04/04 23:41:32 d2.evaluation.evaluator]: [0mInference done 640/3489. 0.2354 s / img. ETA=0:12:27
[32m[04/04 23:41:37 d2.evaluation.evaluator]: [0mInference done 660/3489. 0.2354 s / img. ETA=0:12:21
[32m[04/04 23:41:42 d2.evaluation.evaluator]: [0mInference done 681/3489. 0.2352 s / img. ETA=0:12:14
[32m[04/04 23:41:47 d2.evaluation.evaluator]: [0mInference done 702/3489. 0.2350 s / img. ETA=0:12:07
[32m[04/04 23:41:52 d2.evaluation.evaluator]: [0mInference done 723/3489. 0.2348 s / img. ETA=0:12:00
[32m[04/04 23:41:57 d2.evaluation.evaluator]: [0mInference done 744/3489. 0.2347 s / img. ETA=0:11:54
[32m[04/04 23:42:03 d2.evaluation.evaluator]: [0mInference done 766/3489. 0.2344 s / img. ETA=0:11:46
[32m[04/04 23:42:08 d2.evaluation.evaluator]: [0mInference done 787/3489. 0.2343 s / img. ETA=0:11:39
[32m[04/04 23:42:13 d2.evaluation.evaluator]: [0mInference done 809/3489. 0.2341 s / img. ETA=0:11:31
[32m[04/04 23:42:18 d2.evaluation.evaluator]: [0mInference done 831/3489. 0.2339 s / img. ETA=0:11:24
[32m[04/04 23:42:23 d2.evaluation.evaluator]: [0mInference done 852/3489. 0.2338 s / img. ETA=0:11:17
[32m[04/04 23:42:28 d2.evaluation.evaluator]: [0mInference done 873/3489. 0.2337 s / img. ETA=0:11:11
[32m[04/04 23:42:33 d2.evaluation.evaluator]: [0mInference done 895/3489. 0.2335 s / img. ETA=0:11:04
[32m[04/04 23:42:38 d2.evaluation.evaluator]: [0mInference done 913/3489. 0.2337 s / img. ETA=0:11:00
[32m[04/04 23:42:43 d2.evaluation.evaluator]: [0mInference done 931/3489. 0.2339 s / img. ETA=0:10:57
[32m[04/04 23:42:48 d2.evaluation.evaluator]: [0mInference done 948/3489. 0.2341 s / img. ETA=0:10:55
[32m[04/04 23:42:53 d2.evaluation.evaluator]: [0mInference done 966/3489. 0.2343 s / img. ETA=0:10:52
[32m[04/04 23:42:59 d2.evaluation.evaluator]: [0mInference done 983/3489. 0.2346 s / img. ETA=0:10:49
[32m[04/04 23:43:04 d2.evaluation.evaluator]: [0mInference done 1000/3489. 0.2349 s / img. ETA=0:10:47
[32m[04/04 23:43:09 d2.evaluation.evaluator]: [0mInference done 1016/3489. 0.2351 s / img. ETA=0:10:45
[32m[04/04 23:43:14 d2.evaluation.evaluator]: [0mInference done 1032/3489. 0.2355 s / img. ETA=0:10:44
[32m[04/04 23:43:19 d2.evaluation.evaluator]: [0mInference done 1048/3489. 0.2358 s / img. ETA=0:10:41
[32m[04/04 23:43:25 d2.evaluation.evaluator]: [0mInference done 1065/3489. 0.2360 s / img. ETA=0:10:39
[32m[04/04 23:43:30 d2.evaluation.evaluator]: [0mInference done 1083/3489. 0.2361 s / img. ETA=0:10:35
[32m[04/04 23:43:35 d2.evaluation.evaluator]: [0mInference done 1103/3489. 0.2361 s / img. ETA=0:10:29
[32m[04/04 23:43:40 d2.evaluation.evaluator]: [0mInference done 1123/3489. 0.2361 s / img. ETA=0:10:24
[32m[04/04 23:43:45 d2.evaluation.evaluator]: [0mInference done 1141/3489. 0.2362 s / img. ETA=0:10:20
[32m[04/04 23:43:51 d2.evaluation.evaluator]: [0mInference done 1159/3489. 0.2363 s / img. ETA=0:10:16
[32m[04/04 23:43:56 d2.evaluation.evaluator]: [0mInference done 1177/3489. 0.2365 s / img. ETA=0:10:13
[32m[04/04 23:44:01 d2.evaluation.evaluator]: [0mInference done 1196/3489. 0.2365 s / img. ETA=0:10:08
[32m[04/04 23:44:06 d2.evaluation.evaluator]: [0mInference done 1215/3489. 0.2365 s / img. ETA=0:10:03
[32m[04/04 23:44:11 d2.evaluation.evaluator]: [0mInference done 1234/3489. 0.2365 s / img. ETA=0:09:58
[32m[04/04 23:44:16 d2.evaluation.evaluator]: [0mInference done 1254/3489. 0.2364 s / img. ETA=0:09:52
[32m[04/04 23:44:22 d2.evaluation.evaluator]: [0mInference done 1276/3489. 0.2362 s / img. ETA=0:09:45
[32m[04/04 23:44:27 d2.evaluation.evaluator]: [0mInference done 1298/3489. 0.2361 s / img. ETA=0:09:38
[32m[04/04 23:44:32 d2.evaluation.evaluator]: [0mInference done 1320/3489. 0.2360 s / img. ETA=0:09:31
[32m[04/04 23:44:37 d2.evaluation.evaluator]: [0mInference done 1342/3489. 0.2358 s / img. ETA=0:09:24
[32m[04/04 23:44:42 d2.evaluation.evaluator]: [0mInference done 1364/3489. 0.2356 s / img. ETA=0:09:18
[32m[04/04 23:44:47 d2.evaluation.evaluator]: [0mInference done 1386/3489. 0.2355 s / img. ETA=0:09:11
[32m[04/04 23:44:52 d2.evaluation.evaluator]: [0mInference done 1408/3489. 0.2354 s / img. ETA=0:09:04
[32m[04/04 23:44:58 d2.evaluation.evaluator]: [0mInference done 1429/3489. 0.2353 s / img. ETA=0:08:58
[32m[04/04 23:45:03 d2.evaluation.evaluator]: [0mInference done 1450/3489. 0.2352 s / img. ETA=0:08:52
[32m[04/04 23:45:08 d2.evaluation.evaluator]: [0mInference done 1471/3489. 0.2351 s / img. ETA=0:08:46
[32m[04/04 23:45:13 d2.evaluation.evaluator]: [0mInference done 1493/3489. 0.2350 s / img. ETA=0:08:40
[32m[04/04 23:45:18 d2.evaluation.evaluator]: [0mInference done 1515/3489. 0.2349 s / img. ETA=0:08:33
[32m[04/04 23:45:23 d2.evaluation.evaluator]: [0mInference done 1537/3489. 0.2348 s / img. ETA=0:08:27
[32m[04/04 23:45:28 d2.evaluation.evaluator]: [0mInference done 1559/3489. 0.2347 s / img. ETA=0:08:20
[32m[04/04 23:45:33 d2.evaluation.evaluator]: [0mInference done 1580/3489. 0.2346 s / img. ETA=0:08:14
[32m[04/04 23:45:38 d2.evaluation.evaluator]: [0mInference done 1600/3489. 0.2346 s / img. ETA=0:08:09
[32m[04/04 23:45:43 d2.evaluation.evaluator]: [0mInference done 1619/3489. 0.2346 s / img. ETA=0:08:04
[32m[04/04 23:45:49 d2.evaluation.evaluator]: [0mInference done 1638/3489. 0.2347 s / img. ETA=0:07:59
[32m[04/04 23:45:54 d2.evaluation.evaluator]: [0mInference done 1658/3489. 0.2346 s / img. ETA=0:07:54
[32m[04/04 23:45:59 d2.evaluation.evaluator]: [0mInference done 1677/3489. 0.2347 s / img. ETA=0:07:50
[32m[04/04 23:46:04 d2.evaluation.evaluator]: [0mInference done 1695/3489. 0.2348 s / img. ETA=0:07:46
[32m[04/04 23:46:09 d2.evaluation.evaluator]: [0mInference done 1712/3489. 0.2349 s / img. ETA=0:07:42
[32m[04/04 23:46:14 d2.evaluation.evaluator]: [0mInference done 1730/3489. 0.2350 s / img. ETA=0:07:38
[32m[04/04 23:46:20 d2.evaluation.evaluator]: [0mInference done 1748/3489. 0.2351 s / img. ETA=0:07:33
[32m[04/04 23:46:25 d2.evaluation.evaluator]: [0mInference done 1765/3489. 0.2352 s / img. ETA=0:07:30
[32m[04/04 23:46:30 d2.evaluation.evaluator]: [0mInference done 1781/3489. 0.2353 s / img. ETA=0:07:26
[32m[04/04 23:46:35 d2.evaluation.evaluator]: [0mInference done 1797/3489. 0.2355 s / img. ETA=0:07:23
[32m[04/04 23:46:40 d2.evaluation.evaluator]: [0mInference done 1813/3489. 0.2357 s / img. ETA=0:07:20
[32m[04/04 23:46:45 d2.evaluation.evaluator]: [0mInference done 1829/3489. 0.2359 s / img. ETA=0:07:17
[32m[04/04 23:46:50 d2.evaluation.evaluator]: [0mInference done 1845/3489. 0.2360 s / img. ETA=0:07:13
[32m[04/04 23:46:56 d2.evaluation.evaluator]: [0mInference done 1861/3489. 0.2361 s / img. ETA=0:07:10
[32m[04/04 23:47:01 d2.evaluation.evaluator]: [0mInference done 1878/3489. 0.2363 s / img. ETA=0:07:06
[32m[04/04 23:47:06 d2.evaluation.evaluator]: [0mInference done 1894/3489. 0.2364 s / img. ETA=0:07:02
[32m[04/04 23:47:11 d2.evaluation.evaluator]: [0mInference done 1910/3489. 0.2365 s / img. ETA=0:06:59
[32m[04/04 23:47:16 d2.evaluation.evaluator]: [0mInference done 1926/3489. 0.2367 s / img. ETA=0:06:55
[32m[04/04 23:47:21 d2.evaluation.evaluator]: [0mInference done 1943/3489. 0.2368 s / img. ETA=0:06:51
[32m[04/04 23:47:26 d2.evaluation.evaluator]: [0mInference done 1959/3489. 0.2369 s / img. ETA=0:06:48
[32m[04/04 23:47:31 d2.evaluation.evaluator]: [0mInference done 1975/3489. 0.2370 s / img. ETA=0:06:44
[32m[04/04 23:47:37 d2.evaluation.evaluator]: [0mInference done 1992/3489. 0.2371 s / img. ETA=0:06:40
[32m[04/04 23:47:42 d2.evaluation.evaluator]: [0mInference done 2011/3489. 0.2371 s / img. ETA=0:06:35
[32m[04/04 23:47:47 d2.evaluation.evaluator]: [0mInference done 2030/3489. 0.2371 s / img. ETA=0:06:30
[32m[04/04 23:47:52 d2.evaluation.evaluator]: [0mInference done 2048/3489. 0.2372 s / img. ETA=0:06:25
[32m[04/04 23:47:57 d2.evaluation.evaluator]: [0mInference done 2066/3489. 0.2372 s / img. ETA=0:06:21
[32m[04/04 23:48:03 d2.evaluation.evaluator]: [0mInference done 2082/3489. 0.2373 s / img. ETA=0:06:17
[32m[04/04 23:48:08 d2.evaluation.evaluator]: [0mInference done 2099/3489. 0.2374 s / img. ETA=0:06:13
[32m[04/04 23:48:13 d2.evaluation.evaluator]: [0mInference done 2116/3489. 0.2375 s / img. ETA=0:06:09
[32m[04/04 23:48:18 d2.evaluation.evaluator]: [0mInference done 2132/3489. 0.2376 s / img. ETA=0:06:05
[32m[04/04 23:48:23 d2.evaluation.evaluator]: [0mInference done 2148/3489. 0.2377 s / img. ETA=0:06:01
[32m[04/04 23:48:28 d2.evaluation.evaluator]: [0mInference done 2164/3489. 0.2379 s / img. ETA=0:05:57
[32m[04/04 23:48:33 d2.evaluation.evaluator]: [0mInference done 2181/3489. 0.2380 s / img. ETA=0:05:53
[32m[04/04 23:48:38 d2.evaluation.evaluator]: [0mInference done 2197/3489. 0.2381 s / img. ETA=0:05:49
[32m[04/04 23:48:43 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2382 s / img. ETA=0:05:45
[32m[04/04 23:48:49 d2.evaluation.evaluator]: [0mInference done 2229/3489. 0.2383 s / img. ETA=0:05:41
[32m[04/04 23:48:54 d2.evaluation.evaluator]: [0mInference done 2246/3489. 0.2383 s / img. ETA=0:05:37
[32m[04/04 23:48:59 d2.evaluation.evaluator]: [0mInference done 2264/3489. 0.2384 s / img. ETA=0:05:32
[32m[04/04 23:49:04 d2.evaluation.evaluator]: [0mInference done 2282/3489. 0.2384 s / img. ETA=0:05:28
[32m[04/04 23:49:09 d2.evaluation.evaluator]: [0mInference done 2300/3489. 0.2384 s / img. ETA=0:05:23
[32m[04/04 23:49:14 d2.evaluation.evaluator]: [0mInference done 2317/3489. 0.2385 s / img. ETA=0:05:18
[32m[04/04 23:49:19 d2.evaluation.evaluator]: [0mInference done 2334/3489. 0.2385 s / img. ETA=0:05:14
[32m[04/04 23:49:24 d2.evaluation.evaluator]: [0mInference done 2352/3489. 0.2385 s / img. ETA=0:05:09
[32m[04/04 23:49:30 d2.evaluation.evaluator]: [0mInference done 2371/3489. 0.2385 s / img. ETA=0:05:04
[32m[04/04 23:49:35 d2.evaluation.evaluator]: [0mInference done 2391/3489. 0.2385 s / img. ETA=0:04:58
[32m[04/04 23:49:40 d2.evaluation.evaluator]: [0mInference done 2410/3489. 0.2385 s / img. ETA=0:04:53
[32m[04/04 23:49:45 d2.evaluation.evaluator]: [0mInference done 2429/3489. 0.2385 s / img. ETA=0:04:48
[32m[04/04 23:49:50 d2.evaluation.evaluator]: [0mInference done 2447/3489. 0.2385 s / img. ETA=0:04:43
[32m[04/04 23:49:55 d2.evaluation.evaluator]: [0mInference done 2465/3489. 0.2385 s / img. ETA=0:04:38
[32m[04/04 23:50:00 d2.evaluation.evaluator]: [0mInference done 2482/3489. 0.2385 s / img. ETA=0:04:34
[32m[04/04 23:50:05 d2.evaluation.evaluator]: [0mInference done 2502/3489. 0.2385 s / img. ETA=0:04:28
[32m[04/04 23:50:10 d2.evaluation.evaluator]: [0mInference done 2522/3489. 0.2385 s / img. ETA=0:04:23
[32m[04/04 23:50:15 d2.evaluation.evaluator]: [0mInference done 2542/3489. 0.2384 s / img. ETA=0:04:17
[32m[04/04 23:50:20 d2.evaluation.evaluator]: [0mInference done 2562/3489. 0.2384 s / img. ETA=0:04:12
[32m[04/04 23:50:26 d2.evaluation.evaluator]: [0mInference done 2583/3489. 0.2383 s / img. ETA=0:04:06
[32m[04/04 23:50:31 d2.evaluation.evaluator]: [0mInference done 2604/3489. 0.2382 s / img. ETA=0:04:00
[32m[04/04 23:50:36 d2.evaluation.evaluator]: [0mInference done 2625/3489. 0.2381 s / img. ETA=0:03:54
[32m[04/04 23:50:41 d2.evaluation.evaluator]: [0mInference done 2646/3489. 0.2381 s / img. ETA=0:03:48
[32m[04/04 23:50:46 d2.evaluation.evaluator]: [0mInference done 2666/3489. 0.2380 s / img. ETA=0:03:42
[32m[04/04 23:50:51 d2.evaluation.evaluator]: [0mInference done 2686/3489. 0.2380 s / img. ETA=0:03:37
[32m[04/04 23:50:56 d2.evaluation.evaluator]: [0mInference done 2706/3489. 0.2379 s / img. ETA=0:03:31
[32m[04/04 23:51:01 d2.evaluation.evaluator]: [0mInference done 2727/3489. 0.2379 s / img. ETA=0:03:26
[32m[04/04 23:51:06 d2.evaluation.evaluator]: [0mInference done 2747/3489. 0.2378 s / img. ETA=0:03:20
[32m[04/04 23:51:11 d2.evaluation.evaluator]: [0mInference done 2767/3489. 0.2378 s / img. ETA=0:03:15
[32m[04/04 23:51:16 d2.evaluation.evaluator]: [0mInference done 2788/3489. 0.2377 s / img. ETA=0:03:09
[32m[04/04 23:51:22 d2.evaluation.evaluator]: [0mInference done 2809/3489. 0.2377 s / img. ETA=0:03:03
[32m[04/04 23:51:27 d2.evaluation.evaluator]: [0mInference done 2829/3489. 0.2376 s / img. ETA=0:02:57
[32m[04/04 23:51:32 d2.evaluation.evaluator]: [0mInference done 2849/3489. 0.2376 s / img. ETA=0:02:52
[32m[04/04 23:51:37 d2.evaluation.evaluator]: [0mInference done 2870/3489. 0.2376 s / img. ETA=0:02:46
[32m[04/04 23:51:42 d2.evaluation.evaluator]: [0mInference done 2890/3489. 0.2376 s / img. ETA=0:02:41
[32m[04/04 23:51:47 d2.evaluation.evaluator]: [0mInference done 2911/3489. 0.2375 s / img. ETA=0:02:35
[32m[04/04 23:51:52 d2.evaluation.evaluator]: [0mInference done 2933/3489. 0.2374 s / img. ETA=0:02:29
[32m[04/04 23:51:57 d2.evaluation.evaluator]: [0mInference done 2954/3489. 0.2374 s / img. ETA=0:02:23
[32m[04/04 23:52:02 d2.evaluation.evaluator]: [0mInference done 2976/3489. 0.2373 s / img. ETA=0:02:17
[32m[04/04 23:52:07 d2.evaluation.evaluator]: [0mInference done 2997/3489. 0.2372 s / img. ETA=0:02:11
[32m[04/04 23:52:12 d2.evaluation.evaluator]: [0mInference done 3017/3489. 0.2372 s / img. ETA=0:02:06
[32m[04/04 23:52:18 d2.evaluation.evaluator]: [0mInference done 3038/3489. 0.2372 s / img. ETA=0:02:00
[32m[04/04 23:52:23 d2.evaluation.evaluator]: [0mInference done 3059/3489. 0.2371 s / img. ETA=0:01:55
[32m[04/04 23:52:28 d2.evaluation.evaluator]: [0mInference done 3079/3489. 0.2371 s / img. ETA=0:01:49
[32m[04/04 23:52:33 d2.evaluation.evaluator]: [0mInference done 3099/3489. 0.2370 s / img. ETA=0:01:44
[32m[04/04 23:52:38 d2.evaluation.evaluator]: [0mInference done 3119/3489. 0.2370 s / img. ETA=0:01:38
[32m[04/04 23:52:43 d2.evaluation.evaluator]: [0mInference done 3139/3489. 0.2370 s / img. ETA=0:01:33
[32m[04/04 23:52:48 d2.evaluation.evaluator]: [0mInference done 3160/3489. 0.2369 s / img. ETA=0:01:27
[32m[04/04 23:52:53 d2.evaluation.evaluator]: [0mInference done 3181/3489. 0.2369 s / img. ETA=0:01:22
[32m[04/04 23:52:58 d2.evaluation.evaluator]: [0mInference done 3202/3489. 0.2368 s / img. ETA=0:01:16
[32m[04/04 23:53:03 d2.evaluation.evaluator]: [0mInference done 3223/3489. 0.2368 s / img. ETA=0:01:10
[32m[04/04 23:53:09 d2.evaluation.evaluator]: [0mInference done 3243/3489. 0.2367 s / img. ETA=0:01:05
[32m[04/04 23:53:14 d2.evaluation.evaluator]: [0mInference done 3265/3489. 0.2367 s / img. ETA=0:00:59
[32m[04/04 23:53:19 d2.evaluation.evaluator]: [0mInference done 3286/3489. 0.2366 s / img. ETA=0:00:54
[32m[04/04 23:53:24 d2.evaluation.evaluator]: [0mInference done 3308/3489. 0.2366 s / img. ETA=0:00:48
[32m[04/04 23:53:29 d2.evaluation.evaluator]: [0mInference done 3330/3489. 0.2365 s / img. ETA=0:00:42
[32m[04/04 23:53:34 d2.evaluation.evaluator]: [0mInference done 3352/3489. 0.2364 s / img. ETA=0:00:36
[32m[04/04 23:53:39 d2.evaluation.evaluator]: [0mInference done 3374/3489. 0.2364 s / img. ETA=0:00:30
[32m[04/04 23:53:44 d2.evaluation.evaluator]: [0mInference done 3396/3489. 0.2363 s / img. ETA=0:00:24
[32m[04/04 23:53:50 d2.evaluation.evaluator]: [0mInference done 3418/3489. 0.2363 s / img. ETA=0:00:18
[32m[04/04 23:53:55 d2.evaluation.evaluator]: [0mInference done 3439/3489. 0.2362 s / img. ETA=0:00:13
[32m[04/04 23:54:00 d2.evaluation.evaluator]: [0mInference done 3460/3489. 0.2362 s / img. ETA=0:00:07
[32m[04/04 23:54:05 d2.evaluation.evaluator]: [0mInference done 3481/3489. 0.2361 s / img. ETA=0:00:02
[32m[04/04 23:54:07 d2.evaluation.evaluator]: [0mTotal inference time: 0:15:21.561571 (0.264513 s / img per device, on 1 devices)
[32m[04/04 23:54:07 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:42 (0.236098 s / img per device, on 1 devices)
[32m[04/04 23:54:08 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/04 23:54:08 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_2/coco_instances_results.json
[32m[04/04 23:54:09 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.26 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.43 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772
[32m[04/04 23:54:11 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.872 | 77.029 | 46.533 | 31.698 | 55.001 | 56.904 |
[32m[04/04 23:54:11 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.169 | Pedestrian | 31.575 |
Loading and preparing results...
DONE (t=1.47s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 1.90 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.46 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.727
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
[32m[04/04 23:54:18 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.713 | 72.651 | 40.299 | 22.094 | 49.730 | 67.037 |
[32m[04/04 23:54:18 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.500 | Pedestrian | 21.925 |
[32m[04/04 23:54:19 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: 46.8719,77.0287,46.5333,31.6984,55.0008,56.9035
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/04 23:54:19 d2.evaluation.testing]: [0mcopypaste: 41.7126,72.6510,40.2992,22.0939,49.7299,67.0371
evaluated
Test [3][['res4']]
[32m[04/04 23:54:19 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/04 23:54:20 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/04 23:54:20 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:54:20 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:54:20 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/04 23:54:20 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/04 23:54:20 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/04 23:54:20 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/04 23:54:20 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/04 23:54:20 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/04 23:54:20 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/04 23:54:21 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/04 23:54:46 d2.utils.events]: [0m eta: 0:02:32  iter: 19  total_loss: 1.712  loss_cls: 0.7304  loss_box_reg: 0.3489  loss_mask: 0.6619  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.009691  total_val_loss: 1.943  val_loss_cls: 0.7047  val_loss_box_reg: 0.4211  val_loss_mask: 0.663  val_loss_rpn_cls: 0.03342  val_loss_rpn_loc: 0.01866  time: 0.8502  data_time: 0.0323  lr: 0.00019981  max_mem: 4747M
[32m[04/04 23:55:10 d2.utils.events]: [0m eta: 0:02:17  iter: 39  total_loss: 0.8603  loss_cls: 0.1786  loss_box_reg: 0.3488  loss_mask: 0.3581  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.007635  total_val_loss: 1.222  val_loss_cls: 0.2943  val_loss_box_reg: 0.4987  val_loss_mask: 0.5003  val_loss_rpn_cls: 0.03782  val_loss_rpn_loc: 0.01138  time: 0.8565  data_time: 0.0080  lr: 0.00039961  max_mem: 4747M
[32m[04/04 23:55:34 d2.utils.events]: [0m eta: 0:01:59  iter: 59  total_loss: 0.5993  loss_cls: 0.09148  loss_box_reg: 0.2887  loss_mask: 0.1744  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.008021  total_val_loss: 1.296  val_loss_cls: 0.2839  val_loss_box_reg: 0.4909  val_loss_mask: 0.4713  val_loss_rpn_cls: 0.02857  val_loss_rpn_loc: 0.01338  time: 0.8566  data_time: 0.0064  lr: 0.00059941  max_mem: 4747M
[32m[04/04 23:55:59 d2.utils.events]: [0m eta: 0:01:42  iter: 79  total_loss: 0.5184  loss_cls: 0.06175  loss_box_reg: 0.2021  loss_mask: 0.1434  loss_rpn_cls: 0.008425  loss_rpn_loc: 0.006132  total_val_loss: 0.8707  val_loss_cls: 0.1472  val_loss_box_reg: 0.4331  val_loss_mask: 0.403  val_loss_rpn_cls: 0.02007  val_loss_rpn_loc: 0.01145  time: 0.8568  data_time: 0.0065  lr: 0.00079921  max_mem: 4747M
[32m[04/04 23:56:23 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:56:23 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:56:23 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:56:23 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:56:23 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.4693  loss_cls: 0.0631  loss_box_reg: 0.1913  loss_mask: 0.1541  loss_rpn_cls: 0.009127  loss_rpn_loc: 0.009748  total_val_loss: 1.047  val_loss_cls: 0.2401  val_loss_box_reg: 0.3511  val_loss_mask: 0.3885  val_loss_rpn_cls: 0.01674  val_loss_rpn_loc: 0.01175  time: 0.8610  data_time: 0.0072  lr: 0.00099901  max_mem: 4747M
[32m[04/04 23:56:48 d2.utils.events]: [0m eta: 0:01:08  iter: 119  total_loss: 0.4337  loss_cls: 0.06623  loss_box_reg: 0.1396  loss_mask: 0.1715  loss_rpn_cls: 0.007689  loss_rpn_loc: 0.009358  total_val_loss: 0.7323  val_loss_cls: 0.1434  val_loss_box_reg: 0.2142  val_loss_mask: 0.3474  val_loss_rpn_cls: 0.02007  val_loss_rpn_loc: 0.01261  time: 0.8609  data_time: 0.0068  lr: 0.0011988  max_mem: 4747M
[32m[04/04 23:57:12 d2.utils.events]: [0m eta: 0:00:51  iter: 139  total_loss: 0.4101  loss_cls: 0.0679  loss_box_reg: 0.1536  loss_mask: 0.1532  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.01235  total_val_loss: 0.799  val_loss_cls: 0.1674  val_loss_box_reg: 0.2852  val_loss_mask: 0.2829  val_loss_rpn_cls: 0.01292  val_loss_rpn_loc: 0.01454  time: 0.8608  data_time: 0.0073  lr: 0.0013986  max_mem: 4747M
[32m[04/04 23:57:36 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.461  loss_cls: 0.07178  loss_box_reg: 0.1685  loss_mask: 0.1555  loss_rpn_cls: 0.008662  loss_rpn_loc: 0.01289  total_val_loss: 0.7769  val_loss_cls: 0.1566  val_loss_box_reg: 0.2403  val_loss_mask: 0.2893  val_loss_rpn_cls: 0.01788  val_loss_rpn_loc: 0.01337  time: 0.8608  data_time: 0.0062  lr: 0.0015984  max_mem: 4747M
[32m[04/04 23:58:01 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.344  loss_cls: 0.04225  loss_box_reg: 0.102  loss_mask: 0.1562  loss_rpn_cls: 0.005093  loss_rpn_loc: 0.009256  total_val_loss: 0.7944  val_loss_cls: 0.1569  val_loss_box_reg: 0.2328  val_loss_mask: 0.3781  val_loss_rpn_cls: 0.01989  val_loss_rpn_loc: 0.01381  time: 0.8620  data_time: 0.0068  lr: 0.0017982  max_mem: 4747M
[32m[04/04 23:58:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:58:26 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:58:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:58:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/04 23:58:27 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3669  loss_cls: 0.04966  loss_box_reg: 0.1336  loss_mask: 0.1421  loss_rpn_cls: 0.008227  loss_rpn_loc: 0.01111  total_val_loss: 0.8507  val_loss_cls: 0.1514  val_loss_box_reg: 0.2367  val_loss_mask: 0.3261  val_loss_rpn_cls: 0.01568  val_loss_rpn_loc: 0.009908  time: 0.8617  data_time: 0.0061  lr: 0.001998  max_mem: 4747M
[32m[04/04 23:58:27 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:50 (0.8617 s / it)
[32m[04/04 23:58:27 d2.engine.hooks]: [0mTotal training time: 0:04:03 (0:01:12 on hooks)
[32m[04/04 23:58:27 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:58:27 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:58:27 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/04 23:58:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/04 23:58:27 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/04 23:58:28 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/04 23:58:28 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/04 23:58:28 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/04 23:58:28 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/04 23:58:32 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2309 s / img. ETA=0:14:41
[32m[04/04 23:58:37 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2298 s / img. ETA=0:14:20
[32m[04/04 23:58:42 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2293 s / img. ETA=0:14:02
[32m[04/04 23:58:47 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2291 s / img. ETA=0:13:51
[32m[04/04 23:58:52 d2.evaluation.evaluator]: [0mInference done 93/3489. 0.2308 s / img. ETA=0:14:03
[32m[04/04 23:58:57 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2329 s / img. ETA=0:14:22
[32m[04/04 23:59:02 d2.evaluation.evaluator]: [0mInference done 127/3489. 0.2352 s / img. ETA=0:14:44
[32m[04/04 23:59:07 d2.evaluation.evaluator]: [0mInference done 143/3489. 0.2378 s / img. ETA=0:15:05
[32m[04/04 23:59:13 d2.evaluation.evaluator]: [0mInference done 159/3489. 0.2397 s / img. ETA=0:15:19
[32m[04/04 23:59:18 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2410 s / img. ETA=0:15:30
[32m[04/04 23:59:23 d2.evaluation.evaluator]: [0mInference done 192/3489. 0.2418 s / img. ETA=0:15:34
[32m[04/04 23:59:28 d2.evaluation.evaluator]: [0mInference done 211/3489. 0.2413 s / img. ETA=0:15:25
[32m[04/04 23:59:33 d2.evaluation.evaluator]: [0mInference done 230/3489. 0.2409 s / img. ETA=0:15:16
[32m[04/04 23:59:39 d2.evaluation.evaluator]: [0mInference done 248/3489. 0.2409 s / img. ETA=0:15:12
[32m[04/04 23:59:44 d2.evaluation.evaluator]: [0mInference done 265/3489. 0.2412 s / img. ETA=0:15:10
[32m[04/04 23:59:49 d2.evaluation.evaluator]: [0mInference done 282/3489. 0.2417 s / img. ETA=0:15:11
[32m[04/04 23:59:54 d2.evaluation.evaluator]: [0mInference done 300/3489. 0.2416 s / img. ETA=0:15:06
[32m[04/04 23:59:59 d2.evaluation.evaluator]: [0mInference done 317/3489. 0.2420 s / img. ETA=0:15:05
[32m[04/05 00:00:04 d2.evaluation.evaluator]: [0mInference done 335/3489. 0.2422 s / img. ETA=0:15:01
[32m[04/05 00:00:10 d2.evaluation.evaluator]: [0mInference done 351/3489. 0.2428 s / img. ETA=0:15:03
[32m[04/05 00:00:15 d2.evaluation.evaluator]: [0mInference done 368/3489. 0.2431 s / img. ETA=0:15:00
[32m[04/05 00:00:20 d2.evaluation.evaluator]: [0mInference done 385/3489. 0.2435 s / img. ETA=0:14:58
[32m[04/05 00:00:25 d2.evaluation.evaluator]: [0mInference done 402/3489. 0.2434 s / img. ETA=0:14:54
[32m[04/05 00:00:30 d2.evaluation.evaluator]: [0mInference done 419/3489. 0.2436 s / img. ETA=0:14:50
[32m[04/05 00:00:35 d2.evaluation.evaluator]: [0mInference done 440/3489. 0.2430 s / img. ETA=0:14:38
[32m[04/05 00:00:41 d2.evaluation.evaluator]: [0mInference done 461/3489. 0.2425 s / img. ETA=0:14:26
[32m[04/05 00:00:46 d2.evaluation.evaluator]: [0mInference done 482/3489. 0.2418 s / img. ETA=0:14:14
[32m[04/05 00:00:51 d2.evaluation.evaluator]: [0mInference done 503/3489. 0.2414 s / img. ETA=0:14:03
[32m[04/05 00:00:56 d2.evaluation.evaluator]: [0mInference done 524/3489. 0.2408 s / img. ETA=0:13:52
[32m[04/05 00:01:01 d2.evaluation.evaluator]: [0mInference done 545/3489. 0.2404 s / img. ETA=0:13:41
[32m[04/05 00:01:06 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2403 s / img. ETA=0:13:34
[32m[04/05 00:01:11 d2.evaluation.evaluator]: [0mInference done 583/3489. 0.2403 s / img. ETA=0:13:29
[32m[04/05 00:01:16 d2.evaluation.evaluator]: [0mInference done 600/3489. 0.2406 s / img. ETA=0:13:26
[32m[04/05 00:01:21 d2.evaluation.evaluator]: [0mInference done 618/3489. 0.2406 s / img. ETA=0:13:21
[32m[04/05 00:01:26 d2.evaluation.evaluator]: [0mInference done 635/3489. 0.2407 s / img. ETA=0:13:17
[32m[04/05 00:01:31 d2.evaluation.evaluator]: [0mInference done 654/3489. 0.2407 s / img. ETA=0:13:12
[32m[04/05 00:01:37 d2.evaluation.evaluator]: [0mInference done 673/3489. 0.2405 s / img. ETA=0:13:05
[32m[04/05 00:01:42 d2.evaluation.evaluator]: [0mInference done 694/3489. 0.2402 s / img. ETA=0:12:57
[32m[04/05 00:01:47 d2.evaluation.evaluator]: [0mInference done 714/3489. 0.2400 s / img. ETA=0:12:49
[32m[04/05 00:01:52 d2.evaluation.evaluator]: [0mInference done 735/3489. 0.2397 s / img. ETA=0:12:41
[32m[04/05 00:01:57 d2.evaluation.evaluator]: [0mInference done 755/3489. 0.2396 s / img. ETA=0:12:34
[32m[04/05 00:02:02 d2.evaluation.evaluator]: [0mInference done 776/3489. 0.2392 s / img. ETA=0:12:26
[32m[04/05 00:02:07 d2.evaluation.evaluator]: [0mInference done 797/3489. 0.2390 s / img. ETA=0:12:17
[32m[04/05 00:02:12 d2.evaluation.evaluator]: [0mInference done 818/3489. 0.2387 s / img. ETA=0:12:09
[32m[04/05 00:02:17 d2.evaluation.evaluator]: [0mInference done 839/3489. 0.2385 s / img. ETA=0:12:01
[32m[04/05 00:02:22 d2.evaluation.evaluator]: [0mInference done 860/3489. 0.2382 s / img. ETA=0:11:53
[32m[04/05 00:02:27 d2.evaluation.evaluator]: [0mInference done 881/3489. 0.2380 s / img. ETA=0:11:46
[32m[04/05 00:02:33 d2.evaluation.evaluator]: [0mInference done 902/3489. 0.2379 s / img. ETA=0:11:39
[32m[04/05 00:02:38 d2.evaluation.evaluator]: [0mInference done 919/3489. 0.2381 s / img. ETA=0:11:36
[32m[04/05 00:02:43 d2.evaluation.evaluator]: [0mInference done 935/3489. 0.2384 s / img. ETA=0:11:34
[32m[04/05 00:02:48 d2.evaluation.evaluator]: [0mInference done 951/3489. 0.2387 s / img. ETA=0:11:32
[32m[04/05 00:02:53 d2.evaluation.evaluator]: [0mInference done 967/3489. 0.2389 s / img. ETA=0:11:29
[32m[04/05 00:02:58 d2.evaluation.evaluator]: [0mInference done 983/3489. 0.2392 s / img. ETA=0:11:27
[32m[04/05 00:03:03 d2.evaluation.evaluator]: [0mInference done 999/3489. 0.2394 s / img. ETA=0:11:24
[32m[04/05 00:03:08 d2.evaluation.evaluator]: [0mInference done 1015/3489. 0.2396 s / img. ETA=0:11:21
[32m[04/05 00:03:14 d2.evaluation.evaluator]: [0mInference done 1031/3489. 0.2398 s / img. ETA=0:11:18
[32m[04/05 00:03:19 d2.evaluation.evaluator]: [0mInference done 1047/3489. 0.2400 s / img. ETA=0:11:15
[32m[04/05 00:03:24 d2.evaluation.evaluator]: [0mInference done 1063/3489. 0.2402 s / img. ETA=0:11:13
[32m[04/05 00:03:29 d2.evaluation.evaluator]: [0mInference done 1079/3489. 0.2404 s / img. ETA=0:11:10
[32m[04/05 00:03:34 d2.evaluation.evaluator]: [0mInference done 1097/3489. 0.2404 s / img. ETA=0:11:05
[32m[04/05 00:03:39 d2.evaluation.evaluator]: [0mInference done 1115/3489. 0.2404 s / img. ETA=0:11:00
[32m[04/05 00:03:44 d2.evaluation.evaluator]: [0mInference done 1131/3489. 0.2406 s / img. ETA=0:10:57
[32m[04/05 00:03:49 d2.evaluation.evaluator]: [0mInference done 1147/3489. 0.2408 s / img. ETA=0:10:54
[32m[04/05 00:03:54 d2.evaluation.evaluator]: [0mInference done 1163/3489. 0.2410 s / img. ETA=0:10:51
[32m[04/05 00:03:59 d2.evaluation.evaluator]: [0mInference done 1179/3489. 0.2412 s / img. ETA=0:10:47
[32m[04/05 00:04:04 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2413 s / img. ETA=0:10:44
[32m[04/05 00:04:10 d2.evaluation.evaluator]: [0mInference done 1211/3489. 0.2415 s / img. ETA=0:10:41
[32m[04/05 00:04:15 d2.evaluation.evaluator]: [0mInference done 1228/3489. 0.2416 s / img. ETA=0:10:37
[32m[04/05 00:04:20 d2.evaluation.evaluator]: [0mInference done 1245/3489. 0.2417 s / img. ETA=0:10:33
[32m[04/05 00:04:25 d2.evaluation.evaluator]: [0mInference done 1264/3489. 0.2416 s / img. ETA=0:10:27
[32m[04/05 00:04:30 d2.evaluation.evaluator]: [0mInference done 1286/3489. 0.2413 s / img. ETA=0:10:18
[32m[04/05 00:04:35 d2.evaluation.evaluator]: [0mInference done 1308/3489. 0.2410 s / img. ETA=0:10:10
[32m[04/05 00:04:40 d2.evaluation.evaluator]: [0mInference done 1330/3489. 0.2408 s / img. ETA=0:10:03
[32m[04/05 00:04:45 d2.evaluation.evaluator]: [0mInference done 1352/3489. 0.2406 s / img. ETA=0:09:55
[32m[04/05 00:04:51 d2.evaluation.evaluator]: [0mInference done 1374/3489. 0.2404 s / img. ETA=0:09:47
[32m[04/05 00:04:56 d2.evaluation.evaluator]: [0mInference done 1396/3489. 0.2402 s / img. ETA=0:09:40
[32m[04/05 00:05:01 d2.evaluation.evaluator]: [0mInference done 1417/3489. 0.2400 s / img. ETA=0:09:33
[32m[04/05 00:05:06 d2.evaluation.evaluator]: [0mInference done 1438/3489. 0.2399 s / img. ETA=0:09:26
[32m[04/05 00:05:11 d2.evaluation.evaluator]: [0mInference done 1459/3489. 0.2398 s / img. ETA=0:09:20
[32m[04/05 00:05:16 d2.evaluation.evaluator]: [0mInference done 1480/3489. 0.2396 s / img. ETA=0:09:13
[32m[04/05 00:05:22 d2.evaluation.evaluator]: [0mInference done 1502/3489. 0.2395 s / img. ETA=0:09:06
[32m[04/05 00:05:27 d2.evaluation.evaluator]: [0mInference done 1523/3489. 0.2394 s / img. ETA=0:08:59
[32m[04/05 00:05:32 d2.evaluation.evaluator]: [0mInference done 1544/3489. 0.2393 s / img. ETA=0:08:52
[32m[04/05 00:05:37 d2.evaluation.evaluator]: [0mInference done 1565/3489. 0.2391 s / img. ETA=0:08:46
[32m[04/05 00:05:42 d2.evaluation.evaluator]: [0mInference done 1586/3489. 0.2390 s / img. ETA=0:08:39
[32m[04/05 00:05:47 d2.evaluation.evaluator]: [0mInference done 1605/3489. 0.2390 s / img. ETA=0:08:34
[32m[04/05 00:05:52 d2.evaluation.evaluator]: [0mInference done 1623/3489. 0.2390 s / img. ETA=0:08:29
[32m[04/05 00:05:57 d2.evaluation.evaluator]: [0mInference done 1640/3489. 0.2391 s / img. ETA=0:08:25
[32m[04/05 00:06:02 d2.evaluation.evaluator]: [0mInference done 1658/3489. 0.2391 s / img. ETA=0:08:20
[32m[04/05 00:06:08 d2.evaluation.evaluator]: [0mInference done 1675/3489. 0.2392 s / img. ETA=0:08:16
[32m[04/05 00:06:13 d2.evaluation.evaluator]: [0mInference done 1691/3489. 0.2393 s / img. ETA=0:08:13
[32m[04/05 00:06:18 d2.evaluation.evaluator]: [0mInference done 1707/3489. 0.2395 s / img. ETA=0:08:09
[32m[04/05 00:06:23 d2.evaluation.evaluator]: [0mInference done 1723/3489. 0.2396 s / img. ETA=0:08:05
[32m[04/05 00:06:28 d2.evaluation.evaluator]: [0mInference done 1739/3489. 0.2397 s / img. ETA=0:08:02
[32m[04/05 00:06:33 d2.evaluation.evaluator]: [0mInference done 1755/3489. 0.2399 s / img. ETA=0:07:58
[32m[04/05 00:06:38 d2.evaluation.evaluator]: [0mInference done 1771/3489. 0.2400 s / img. ETA=0:07:55
[32m[04/05 00:06:44 d2.evaluation.evaluator]: [0mInference done 1787/3489. 0.2401 s / img. ETA=0:07:51
[32m[04/05 00:06:49 d2.evaluation.evaluator]: [0mInference done 1803/3489. 0.2403 s / img. ETA=0:07:47
[32m[04/05 00:06:54 d2.evaluation.evaluator]: [0mInference done 1819/3489. 0.2404 s / img. ETA=0:07:43
[32m[04/05 00:06:59 d2.evaluation.evaluator]: [0mInference done 1835/3489. 0.2405 s / img. ETA=0:07:40
[32m[04/05 00:07:04 d2.evaluation.evaluator]: [0mInference done 1851/3489. 0.2406 s / img. ETA=0:07:36
[32m[04/05 00:07:09 d2.evaluation.evaluator]: [0mInference done 1866/3489. 0.2408 s / img. ETA=0:07:32
[32m[04/05 00:07:15 d2.evaluation.evaluator]: [0mInference done 1882/3489. 0.2409 s / img. ETA=0:07:29
[32m[04/05 00:07:20 d2.evaluation.evaluator]: [0mInference done 1898/3489. 0.2410 s / img. ETA=0:07:25
[32m[04/05 00:07:25 d2.evaluation.evaluator]: [0mInference done 1914/3489. 0.2411 s / img. ETA=0:07:21
[32m[04/05 00:07:30 d2.evaluation.evaluator]: [0mInference done 1930/3489. 0.2412 s / img. ETA=0:07:17
[32m[04/05 00:07:35 d2.evaluation.evaluator]: [0mInference done 1946/3489. 0.2413 s / img. ETA=0:07:13
[32m[04/05 00:07:40 d2.evaluation.evaluator]: [0mInference done 1962/3489. 0.2414 s / img. ETA=0:07:09
[32m[04/05 00:07:46 d2.evaluation.evaluator]: [0mInference done 1978/3489. 0.2415 s / img. ETA=0:07:05
[32m[04/05 00:07:51 d2.evaluation.evaluator]: [0mInference done 1994/3489. 0.2416 s / img. ETA=0:07:01
[32m[04/05 00:07:56 d2.evaluation.evaluator]: [0mInference done 2011/3489. 0.2417 s / img. ETA=0:06:56
[32m[04/05 00:08:01 d2.evaluation.evaluator]: [0mInference done 2027/3489. 0.2418 s / img. ETA=0:06:52
[32m[04/05 00:08:06 d2.evaluation.evaluator]: [0mInference done 2043/3489. 0.2419 s / img. ETA=0:06:48
[32m[04/05 00:08:11 d2.evaluation.evaluator]: [0mInference done 2059/3489. 0.2420 s / img. ETA=0:06:44
[32m[04/05 00:08:17 d2.evaluation.evaluator]: [0mInference done 2075/3489. 0.2421 s / img. ETA=0:06:40
[32m[04/05 00:08:22 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2422 s / img. ETA=0:06:36
[32m[04/05 00:08:27 d2.evaluation.evaluator]: [0mInference done 2107/3489. 0.2423 s / img. ETA=0:06:32
[32m[04/05 00:08:32 d2.evaluation.evaluator]: [0mInference done 2123/3489. 0.2424 s / img. ETA=0:06:28
[32m[04/05 00:08:37 d2.evaluation.evaluator]: [0mInference done 2139/3489. 0.2425 s / img. ETA=0:06:24
[32m[04/05 00:08:42 d2.evaluation.evaluator]: [0mInference done 2155/3489. 0.2426 s / img. ETA=0:06:19
[32m[04/05 00:08:47 d2.evaluation.evaluator]: [0mInference done 2171/3489. 0.2426 s / img. ETA=0:06:15
[32m[04/05 00:08:53 d2.evaluation.evaluator]: [0mInference done 2187/3489. 0.2427 s / img. ETA=0:06:11
[32m[04/05 00:08:58 d2.evaluation.evaluator]: [0mInference done 2203/3489. 0.2428 s / img. ETA=0:06:07
[32m[04/05 00:09:03 d2.evaluation.evaluator]: [0mInference done 2219/3489. 0.2429 s / img. ETA=0:06:03
[32m[04/05 00:09:08 d2.evaluation.evaluator]: [0mInference done 2235/3489. 0.2430 s / img. ETA=0:05:58
[32m[04/05 00:09:13 d2.evaluation.evaluator]: [0mInference done 2251/3489. 0.2431 s / img. ETA=0:05:54
[32m[04/05 00:09:18 d2.evaluation.evaluator]: [0mInference done 2267/3489. 0.2432 s / img. ETA=0:05:50
[32m[04/05 00:09:24 d2.evaluation.evaluator]: [0mInference done 2282/3489. 0.2433 s / img. ETA=0:05:46
[32m[04/05 00:09:29 d2.evaluation.evaluator]: [0mInference done 2298/3489. 0.2434 s / img. ETA=0:05:42
[32m[04/05 00:09:34 d2.evaluation.evaluator]: [0mInference done 2314/3489. 0.2435 s / img. ETA=0:05:37
[32m[04/05 00:09:39 d2.evaluation.evaluator]: [0mInference done 2330/3489. 0.2435 s / img. ETA=0:05:33
[32m[04/05 00:09:44 d2.evaluation.evaluator]: [0mInference done 2346/3489. 0.2436 s / img. ETA=0:05:29
[32m[04/05 00:09:50 d2.evaluation.evaluator]: [0mInference done 2362/3489. 0.2437 s / img. ETA=0:05:24
[32m[04/05 00:09:55 d2.evaluation.evaluator]: [0mInference done 2380/3489. 0.2436 s / img. ETA=0:05:19
[32m[04/05 00:10:00 d2.evaluation.evaluator]: [0mInference done 2398/3489. 0.2436 s / img. ETA=0:05:14
[32m[04/05 00:10:05 d2.evaluation.evaluator]: [0mInference done 2415/3489. 0.2436 s / img. ETA=0:05:09
[32m[04/05 00:10:10 d2.evaluation.evaluator]: [0mInference done 2432/3489. 0.2437 s / img. ETA=0:05:04
[32m[04/05 00:10:15 d2.evaluation.evaluator]: [0mInference done 2448/3489. 0.2438 s / img. ETA=0:05:00
[32m[04/05 00:10:20 d2.evaluation.evaluator]: [0mInference done 2464/3489. 0.2438 s / img. ETA=0:04:56
[32m[04/05 00:10:26 d2.evaluation.evaluator]: [0mInference done 2480/3489. 0.2439 s / img. ETA=0:04:51
[32m[04/05 00:10:31 d2.evaluation.evaluator]: [0mInference done 2498/3489. 0.2439 s / img. ETA=0:04:46
[32m[04/05 00:10:36 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2438 s / img. ETA=0:04:40
[32m[04/05 00:10:41 d2.evaluation.evaluator]: [0mInference done 2535/3489. 0.2438 s / img. ETA=0:04:35
[32m[04/05 00:10:46 d2.evaluation.evaluator]: [0mInference done 2554/3489. 0.2438 s / img. ETA=0:04:29
[32m[04/05 00:10:51 d2.evaluation.evaluator]: [0mInference done 2573/3489. 0.2437 s / img. ETA=0:04:24
[32m[04/05 00:10:56 d2.evaluation.evaluator]: [0mInference done 2593/3489. 0.2437 s / img. ETA=0:04:18
[32m[04/05 00:11:01 d2.evaluation.evaluator]: [0mInference done 2613/3489. 0.2436 s / img. ETA=0:04:12
[32m[04/05 00:11:07 d2.evaluation.evaluator]: [0mInference done 2634/3489. 0.2435 s / img. ETA=0:04:05
[32m[04/05 00:11:12 d2.evaluation.evaluator]: [0mInference done 2655/3489. 0.2434 s / img. ETA=0:03:59
[32m[04/05 00:11:17 d2.evaluation.evaluator]: [0mInference done 2675/3489. 0.2433 s / img. ETA=0:03:53
[32m[04/05 00:11:22 d2.evaluation.evaluator]: [0mInference done 2695/3489. 0.2433 s / img. ETA=0:03:47
[32m[04/05 00:11:27 d2.evaluation.evaluator]: [0mInference done 2716/3489. 0.2432 s / img. ETA=0:03:41
[32m[04/05 00:11:33 d2.evaluation.evaluator]: [0mInference done 2737/3489. 0.2431 s / img. ETA=0:03:35
[32m[04/05 00:11:38 d2.evaluation.evaluator]: [0mInference done 2757/3489. 0.2430 s / img. ETA=0:03:29
[32m[04/05 00:11:43 d2.evaluation.evaluator]: [0mInference done 2777/3489. 0.2429 s / img. ETA=0:03:23
[32m[04/05 00:11:48 d2.evaluation.evaluator]: [0mInference done 2798/3489. 0.2428 s / img. ETA=0:03:17
[32m[04/05 00:11:53 d2.evaluation.evaluator]: [0mInference done 2818/3489. 0.2428 s / img. ETA=0:03:11
[32m[04/05 00:11:58 d2.evaluation.evaluator]: [0mInference done 2838/3489. 0.2427 s / img. ETA=0:03:05
[32m[04/05 00:12:03 d2.evaluation.evaluator]: [0mInference done 2859/3489. 0.2426 s / img. ETA=0:02:59
[32m[04/05 00:12:08 d2.evaluation.evaluator]: [0mInference done 2879/3489. 0.2426 s / img. ETA=0:02:53
[32m[04/05 00:12:13 d2.evaluation.evaluator]: [0mInference done 2900/3489. 0.2425 s / img. ETA=0:02:47
[32m[04/05 00:12:19 d2.evaluation.evaluator]: [0mInference done 2921/3489. 0.2424 s / img. ETA=0:02:41
[32m[04/05 00:12:24 d2.evaluation.evaluator]: [0mInference done 2942/3489. 0.2423 s / img. ETA=0:02:35
[32m[04/05 00:12:29 d2.evaluation.evaluator]: [0mInference done 2963/3489. 0.2422 s / img. ETA=0:02:29
[32m[04/05 00:12:34 d2.evaluation.evaluator]: [0mInference done 2984/3489. 0.2421 s / img. ETA=0:02:23
[32m[04/05 00:12:39 d2.evaluation.evaluator]: [0mInference done 3004/3489. 0.2420 s / img. ETA=0:02:17
[32m[04/05 00:12:44 d2.evaluation.evaluator]: [0mInference done 3024/3489. 0.2419 s / img. ETA=0:02:11
[32m[04/05 00:12:49 d2.evaluation.evaluator]: [0mInference done 3044/3489. 0.2419 s / img. ETA=0:02:05
[32m[04/05 00:12:54 d2.evaluation.evaluator]: [0mInference done 3064/3489. 0.2418 s / img. ETA=0:02:00
[32m[04/05 00:12:59 d2.evaluation.evaluator]: [0mInference done 3084/3489. 0.2418 s / img. ETA=0:01:54
[32m[04/05 00:13:04 d2.evaluation.evaluator]: [0mInference done 3105/3489. 0.2417 s / img. ETA=0:01:48
[32m[04/05 00:13:10 d2.evaluation.evaluator]: [0mInference done 3125/3489. 0.2416 s / img. ETA=0:01:42
[32m[04/05 00:13:15 d2.evaluation.evaluator]: [0mInference done 3145/3489. 0.2416 s / img. ETA=0:01:36
[32m[04/05 00:13:20 d2.evaluation.evaluator]: [0mInference done 3166/3489. 0.2415 s / img. ETA=0:01:30
[32m[04/05 00:13:25 d2.evaluation.evaluator]: [0mInference done 3187/3489. 0.2414 s / img. ETA=0:01:24
[32m[04/05 00:13:30 d2.evaluation.evaluator]: [0mInference done 3208/3489. 0.2413 s / img. ETA=0:01:18
[32m[04/05 00:13:35 d2.evaluation.evaluator]: [0mInference done 3228/3489. 0.2412 s / img. ETA=0:01:13
[32m[04/05 00:13:40 d2.evaluation.evaluator]: [0mInference done 3249/3489. 0.2411 s / img. ETA=0:01:07
[32m[04/05 00:13:45 d2.evaluation.evaluator]: [0mInference done 3270/3489. 0.2411 s / img. ETA=0:01:01
[32m[04/05 00:13:51 d2.evaluation.evaluator]: [0mInference done 3291/3489. 0.2410 s / img. ETA=0:00:55
[32m[04/05 00:13:56 d2.evaluation.evaluator]: [0mInference done 3313/3489. 0.2409 s / img. ETA=0:00:49
[32m[04/05 00:14:01 d2.evaluation.evaluator]: [0mInference done 3335/3489. 0.2408 s / img. ETA=0:00:43
[32m[04/05 00:14:06 d2.evaluation.evaluator]: [0mInference done 3357/3489. 0.2407 s / img. ETA=0:00:36
[32m[04/05 00:14:11 d2.evaluation.evaluator]: [0mInference done 3378/3489. 0.2407 s / img. ETA=0:00:30
[32m[04/05 00:14:16 d2.evaluation.evaluator]: [0mInference done 3399/3489. 0.2406 s / img. ETA=0:00:25
[32m[04/05 00:14:21 d2.evaluation.evaluator]: [0mInference done 3421/3489. 0.2405 s / img. ETA=0:00:18
[32m[04/05 00:14:26 d2.evaluation.evaluator]: [0mInference done 3442/3489. 0.2404 s / img. ETA=0:00:13
[32m[04/05 00:14:31 d2.evaluation.evaluator]: [0mInference done 3463/3489. 0.2404 s / img. ETA=0:00:07
[32m[04/05 00:14:36 d2.evaluation.evaluator]: [0mInference done 3484/3489. 0.2403 s / img. ETA=0:00:01
[32m[04/05 00:14:38 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:07.503112 (0.277699 s / img per device, on 1 devices)
[32m[04/05 00:14:38 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:57 (0.240279 s / img per device, on 1 devices)
[32m[04/05 00:14:40 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 00:14:40 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_3/coco_instances_results.json
[32m[04/05 00:14:41 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 2.06 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.401
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746
[32m[04/05 00:14:44 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.204 | 74.330 | 38.349 | 27.985 | 47.718 | 50.840 |
[32m[04/05 00:14:44 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 58.605 | Pedestrian | 23.802 |
Loading and preparing results...
DONE (t=2.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.44 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741
[32m[04/05 00:14:54 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.154 | 70.566 | 39.116 | 21.763 | 49.278 | 68.281 |
[32m[04/05 00:14:54 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.436 | Pedestrian | 19.872 |
[32m[04/05 00:14:54 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: 41.2035,74.3302,38.3491,27.9845,47.7183,50.8403
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:14:54 d2.evaluation.testing]: [0mcopypaste: 41.1544,70.5657,39.1159,21.7630,49.2780,68.2810
evaluated
Test [4][['res5']]
[32m[04/05 00:14:55 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/05 00:14:55 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/05 00:14:55 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:14:55 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:14:55 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/05 00:14:55 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/05 00:14:56 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/05 00:14:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:14:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:14:56 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/05 00:14:56 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/05 00:14:56 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/05 00:15:21 d2.utils.events]: [0m eta: 0:02:34  iter: 19  total_loss: 1.913  loss_cls: 0.7435  loss_box_reg: 0.4648  loss_mask: 0.6605  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.01142  total_val_loss: 1.795  val_loss_cls: 0.7377  val_loss_box_reg: 0.3899  val_loss_mask: 0.679  val_loss_rpn_cls: 0.0399  val_loss_rpn_loc: 0.01305  time: 0.8564  data_time: 0.0281  lr: 0.00019981  max_mem: 4747M
[32m[04/05 00:15:46 d2.utils.events]: [0m eta: 0:02:17  iter: 39  total_loss: 0.9297  loss_cls: 0.179  loss_box_reg: 0.3681  loss_mask: 0.3934  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.00971  total_val_loss: 1.438  val_loss_cls: 0.3209  val_loss_box_reg: 0.568  val_loss_mask: 0.5379  val_loss_rpn_cls: 0.02833  val_loss_rpn_loc: 0.01739  time: 0.8612  data_time: 0.0067  lr: 0.00039961  max_mem: 4747M
[32m[04/05 00:16:10 d2.utils.events]: [0m eta: 0:02:01  iter: 59  total_loss: 0.6532  loss_cls: 0.08548  loss_box_reg: 0.347  loss_mask: 0.1853  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.009161  total_val_loss: 0.9362  val_loss_cls: 0.1686  val_loss_box_reg: 0.3683  val_loss_mask: 0.3848  val_loss_rpn_cls: 0.03868  val_loss_rpn_loc: 0.009981  time: 0.8654  data_time: 0.0071  lr: 0.00059941  max_mem: 4747M
[32m[04/05 00:16:35 d2.utils.events]: [0m eta: 0:01:44  iter: 79  total_loss: 0.5309  loss_cls: 0.05953  loss_box_reg: 0.2268  loss_mask: 0.1896  loss_rpn_cls: 0.01112  loss_rpn_loc: 0.007206  total_val_loss: 0.8432  val_loss_cls: 0.1319  val_loss_box_reg: 0.3566  val_loss_mask: 0.3273  val_loss_rpn_cls: 0.02215  val_loss_rpn_loc: 0.01014  time: 0.8661  data_time: 0.0071  lr: 0.00079921  max_mem: 4747M
[32m[04/05 00:17:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:17:00 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:17:00 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:17:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 00:17:00 d2.utils.events]: [0m eta: 0:01:26  iter: 99  total_loss: 0.377  loss_cls: 0.03341  loss_box_reg: 0.1126  loss_mask: 0.1702  loss_rpn_cls: 0.006231  loss_rpn_loc: 0.006231  total_val_loss: 0.9558  val_loss_cls: 0.2437  val_loss_box_reg: 0.3491  val_loss_mask: 0.3149  val_loss_rpn_cls: 0.02337  val_loss_rpn_loc: 0.013  time: 0.8668  data_time: 0.0063  lr: 0.00099901  max_mem: 4747M
[32m[04/05 00:17:25 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.4182  loss_cls: 0.0599  loss_box_reg: 0.1385  loss_mask: 0.1965  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.009502  total_val_loss: 0.5982  val_loss_cls: 0.1425  val_loss_box_reg: 0.2091  val_loss_mask: 0.2411  val_loss_rpn_cls: 0.02511  val_loss_rpn_loc: 0.01271  time: 0.8697  data_time: 0.0063  lr: 0.0011988  max_mem: 4747M
[32m[04/05 00:17:49 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.3102  loss_cls: 0.04137  loss_box_reg: 0.09111  loss_mask: 0.1619  loss_rpn_cls: 0.00679  loss_rpn_loc: 0.00582  total_val_loss: 1.083  val_loss_cls: 0.2496  val_loss_box_reg: 0.3434  val_loss_mask: 0.4621  val_loss_rpn_cls: 0.01688  val_loss_rpn_loc: 0.01507  time: 0.8706  data_time: 0.0063  lr: 0.0013986  max_mem: 4747M
[32m[04/05 00:18:14 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3409  loss_cls: 0.02735  loss_box_reg: 0.06676  loss_mask: 0.1492  loss_rpn_cls: 0.00349  loss_rpn_loc: 0.004677  total_val_loss: 0.7147  val_loss_cls: 0.1306  val_loss_box_reg: 0.2365  val_loss_mask: 0.294  val_loss_rpn_cls: 0.01272  val_loss_rpn_loc: 0.01347  time: 0.8713  data_time: 0.0068  lr: 0.0015984  max_mem: 4747M
[32m[04/05 00:18:38 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3337  loss_cls: 0.05243  loss_box_reg: 0.1049  loss_mask: 0.1489  loss_rpn_cls: 0.008314  loss_rpn_loc: 0.00865  total_val_loss: 0.7023  val_loss_cls: 0.1382  val_loss_box_reg: 0.2205  val_loss_mask: 0.3271  val_loss_rpn_cls: 0.01825  val_loss_rpn_loc: 0.01336  time: 0.8719  data_time: 0.0071  lr: 0.0017982  max_mem: 4747M
[32m[04/05 00:19:04 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:19:04 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:19:04 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:19:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 00:19:04 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.4157  loss_cls: 0.06583  loss_box_reg: 0.1412  loss_mask: 0.1568  loss_rpn_cls: 0.007683  loss_rpn_loc: 0.008971  total_val_loss: 0.6729  val_loss_cls: 0.1279  val_loss_box_reg: 0.1979  val_loss_mask: 0.3307  val_loss_rpn_cls: 0.01929  val_loss_rpn_loc: 0.01439  time: 0.8724  data_time: 0.0068  lr: 0.001998  max_mem: 4747M
[32m[04/05 00:19:04 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:52 (0.8724 s / it)
[32m[04/05 00:19:04 d2.engine.hooks]: [0mTotal training time: 0:04:05 (0:01:12 on hooks)
[32m[04/05 00:19:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:19:05 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:19:05 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:19:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/05 00:19:05 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/05 00:19:06 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:19:06 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:19:06 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/05 00:19:06 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/05 00:19:09 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2315 s / img. ETA=0:14:48
[32m[04/05 00:19:14 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2312 s / img. ETA=0:14:30
[32m[04/05 00:19:19 d2.evaluation.evaluator]: [0mInference done 51/3489. 0.2328 s / img. ETA=0:14:25
[32m[04/05 00:19:24 d2.evaluation.evaluator]: [0mInference done 72/3489. 0.2322 s / img. ETA=0:14:11
[32m[04/05 00:19:29 d2.evaluation.evaluator]: [0mInference done 92/3489. 0.2332 s / img. ETA=0:14:17
[32m[04/05 00:19:34 d2.evaluation.evaluator]: [0mInference done 109/3489. 0.2350 s / img. ETA=0:14:39
[32m[04/05 00:19:39 d2.evaluation.evaluator]: [0mInference done 125/3489. 0.2374 s / img. ETA=0:15:00
[32m[04/05 00:19:45 d2.evaluation.evaluator]: [0mInference done 140/3489. 0.2398 s / img. ETA=0:15:25
[32m[04/05 00:19:50 d2.evaluation.evaluator]: [0mInference done 155/3489. 0.2421 s / img. ETA=0:15:45
[32m[04/05 00:19:55 d2.evaluation.evaluator]: [0mInference done 171/3489. 0.2433 s / img. ETA=0:15:56
[32m[04/05 00:20:00 d2.evaluation.evaluator]: [0mInference done 187/3489. 0.2444 s / img. ETA=0:16:03
[32m[04/05 00:20:06 d2.evaluation.evaluator]: [0mInference done 204/3489. 0.2448 s / img. ETA=0:16:02
[32m[04/05 00:20:11 d2.evaluation.evaluator]: [0mInference done 223/3489. 0.2444 s / img. ETA=0:15:52
[32m[04/05 00:20:16 d2.evaluation.evaluator]: [0mInference done 241/3489. 0.2442 s / img. ETA=0:15:45
[32m[04/05 00:20:21 d2.evaluation.evaluator]: [0mInference done 258/3489. 0.2443 s / img. ETA=0:15:41
[32m[04/05 00:20:26 d2.evaluation.evaluator]: [0mInference done 275/3489. 0.2444 s / img. ETA=0:15:37
[32m[04/05 00:20:31 d2.evaluation.evaluator]: [0mInference done 292/3489. 0.2447 s / img. ETA=0:15:35
[32m[04/05 00:20:37 d2.evaluation.evaluator]: [0mInference done 309/3489. 0.2451 s / img. ETA=0:15:34
[32m[04/05 00:20:42 d2.evaluation.evaluator]: [0mInference done 326/3489. 0.2452 s / img. ETA=0:15:30
[32m[04/05 00:20:47 d2.evaluation.evaluator]: [0mInference done 342/3489. 0.2459 s / img. ETA=0:15:29
[32m[04/05 00:20:52 d2.evaluation.evaluator]: [0mInference done 359/3489. 0.2462 s / img. ETA=0:15:26
[32m[04/05 00:20:57 d2.evaluation.evaluator]: [0mInference done 375/3489. 0.2464 s / img. ETA=0:15:24
[32m[04/05 00:21:02 d2.evaluation.evaluator]: [0mInference done 391/3489. 0.2467 s / img. ETA=0:15:21
[32m[04/05 00:21:07 d2.evaluation.evaluator]: [0mInference done 409/3489. 0.2467 s / img. ETA=0:15:15
[32m[04/05 00:21:13 d2.evaluation.evaluator]: [0mInference done 427/3489. 0.2465 s / img. ETA=0:15:09
[32m[04/05 00:21:18 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2459 s / img. ETA=0:14:56
[32m[04/05 00:21:23 d2.evaluation.evaluator]: [0mInference done 468/3489. 0.2454 s / img. ETA=0:14:45
[32m[04/05 00:21:28 d2.evaluation.evaluator]: [0mInference done 489/3489. 0.2448 s / img. ETA=0:14:33
[32m[04/05 00:21:33 d2.evaluation.evaluator]: [0mInference done 510/3489. 0.2442 s / img. ETA=0:14:21
[32m[04/05 00:21:38 d2.evaluation.evaluator]: [0mInference done 531/3489. 0.2437 s / img. ETA=0:14:09
[32m[04/05 00:21:43 d2.evaluation.evaluator]: [0mInference done 551/3489. 0.2434 s / img. ETA=0:14:00
[32m[04/05 00:21:49 d2.evaluation.evaluator]: [0mInference done 570/3489. 0.2433 s / img. ETA=0:13:53
[32m[04/05 00:21:54 d2.evaluation.evaluator]: [0mInference done 587/3489. 0.2434 s / img. ETA=0:13:50
[32m[04/05 00:21:59 d2.evaluation.evaluator]: [0mInference done 605/3489. 0.2435 s / img. ETA=0:13:45
[32m[04/05 00:22:04 d2.evaluation.evaluator]: [0mInference done 623/3489. 0.2435 s / img. ETA=0:13:40
[32m[04/05 00:22:10 d2.evaluation.evaluator]: [0mInference done 641/3489. 0.2436 s / img. ETA=0:13:35
[32m[04/05 00:22:15 d2.evaluation.evaluator]: [0mInference done 659/3489. 0.2436 s / img. ETA=0:13:30
[32m[04/05 00:22:20 d2.evaluation.evaluator]: [0mInference done 678/3489. 0.2434 s / img. ETA=0:13:23
[32m[04/05 00:22:25 d2.evaluation.evaluator]: [0mInference done 698/3489. 0.2431 s / img. ETA=0:13:14
[32m[04/05 00:22:30 d2.evaluation.evaluator]: [0mInference done 718/3489. 0.2429 s / img. ETA=0:13:06
[32m[04/05 00:22:35 d2.evaluation.evaluator]: [0mInference done 738/3489. 0.2426 s / img. ETA=0:12:58
[32m[04/05 00:22:40 d2.evaluation.evaluator]: [0mInference done 758/3489. 0.2425 s / img. ETA=0:12:51
[32m[04/05 00:22:45 d2.evaluation.evaluator]: [0mInference done 779/3489. 0.2423 s / img. ETA=0:12:42
[32m[04/05 00:22:50 d2.evaluation.evaluator]: [0mInference done 800/3489. 0.2420 s / img. ETA=0:12:34
[32m[04/05 00:22:55 d2.evaluation.evaluator]: [0mInference done 821/3489. 0.2418 s / img. ETA=0:12:25
[32m[04/05 00:23:01 d2.evaluation.evaluator]: [0mInference done 842/3489. 0.2415 s / img. ETA=0:12:17
[32m[04/05 00:23:06 d2.evaluation.evaluator]: [0mInference done 863/3489. 0.2413 s / img. ETA=0:12:09
[32m[04/05 00:23:11 d2.evaluation.evaluator]: [0mInference done 884/3489. 0.2411 s / img. ETA=0:12:01
[32m[04/05 00:23:16 d2.evaluation.evaluator]: [0mInference done 904/3489. 0.2409 s / img. ETA=0:11:55
[32m[04/05 00:23:21 d2.evaluation.evaluator]: [0mInference done 920/3489. 0.2412 s / img. ETA=0:11:52
[32m[04/05 00:23:26 d2.evaluation.evaluator]: [0mInference done 935/3489. 0.2415 s / img. ETA=0:11:51
[32m[04/05 00:23:31 d2.evaluation.evaluator]: [0mInference done 951/3489. 0.2417 s / img. ETA=0:11:48
[32m[04/05 00:23:37 d2.evaluation.evaluator]: [0mInference done 967/3489. 0.2419 s / img. ETA=0:11:46
[32m[04/05 00:23:42 d2.evaluation.evaluator]: [0mInference done 983/3489. 0.2422 s / img. ETA=0:11:43
[32m[04/05 00:23:47 d2.evaluation.evaluator]: [0mInference done 998/3489. 0.2425 s / img. ETA=0:11:41
[32m[04/05 00:23:52 d2.evaluation.evaluator]: [0mInference done 1014/3489. 0.2427 s / img. ETA=0:11:38
[32m[04/05 00:23:58 d2.evaluation.evaluator]: [0mInference done 1030/3489. 0.2430 s / img. ETA=0:11:36
[32m[04/05 00:24:03 d2.evaluation.evaluator]: [0mInference done 1046/3489. 0.2432 s / img. ETA=0:11:33
[32m[04/05 00:24:08 d2.evaluation.evaluator]: [0mInference done 1062/3489. 0.2434 s / img. ETA=0:11:30
[32m[04/05 00:24:13 d2.evaluation.evaluator]: [0mInference done 1078/3489. 0.2436 s / img. ETA=0:11:27
[32m[04/05 00:24:18 d2.evaluation.evaluator]: [0mInference done 1095/3489. 0.2437 s / img. ETA=0:11:23
[32m[04/05 00:24:24 d2.evaluation.evaluator]: [0mInference done 1113/3489. 0.2437 s / img. ETA=0:11:18
[32m[04/05 00:24:29 d2.evaluation.evaluator]: [0mInference done 1129/3489. 0.2439 s / img. ETA=0:11:15
[32m[04/05 00:24:34 d2.evaluation.evaluator]: [0mInference done 1145/3489. 0.2441 s / img. ETA=0:11:11
[32m[04/05 00:24:39 d2.evaluation.evaluator]: [0mInference done 1161/3489. 0.2443 s / img. ETA=0:11:08
[32m[04/05 00:24:45 d2.evaluation.evaluator]: [0mInference done 1177/3489. 0.2445 s / img. ETA=0:11:05
[32m[04/05 00:24:50 d2.evaluation.evaluator]: [0mInference done 1193/3489. 0.2446 s / img. ETA=0:11:02
[32m[04/05 00:24:55 d2.evaluation.evaluator]: [0mInference done 1208/3489. 0.2448 s / img. ETA=0:10:59
[32m[04/05 00:25:00 d2.evaluation.evaluator]: [0mInference done 1224/3489. 0.2450 s / img. ETA=0:10:55
[32m[04/05 00:25:05 d2.evaluation.evaluator]: [0mInference done 1240/3489. 0.2451 s / img. ETA=0:10:52
[32m[04/05 00:25:10 d2.evaluation.evaluator]: [0mInference done 1257/3489. 0.2452 s / img. ETA=0:10:47
[32m[04/05 00:25:16 d2.evaluation.evaluator]: [0mInference done 1279/3489. 0.2449 s / img. ETA=0:10:38
[32m[04/05 00:25:21 d2.evaluation.evaluator]: [0mInference done 1300/3489. 0.2446 s / img. ETA=0:10:31
[32m[04/05 00:25:26 d2.evaluation.evaluator]: [0mInference done 1322/3489. 0.2444 s / img. ETA=0:10:22
[32m[04/05 00:25:31 d2.evaluation.evaluator]: [0mInference done 1343/3489. 0.2441 s / img. ETA=0:10:15
[32m[04/05 00:25:36 d2.evaluation.evaluator]: [0mInference done 1364/3489. 0.2440 s / img. ETA=0:10:07
[32m[04/05 00:25:41 d2.evaluation.evaluator]: [0mInference done 1385/3489. 0.2437 s / img. ETA=0:10:00
[32m[04/05 00:25:46 d2.evaluation.evaluator]: [0mInference done 1406/3489. 0.2436 s / img. ETA=0:09:53
[32m[04/05 00:25:51 d2.evaluation.evaluator]: [0mInference done 1426/3489. 0.2434 s / img. ETA=0:09:46
[32m[04/05 00:25:57 d2.evaluation.evaluator]: [0mInference done 1447/3489. 0.2433 s / img. ETA=0:09:39
[32m[04/05 00:26:02 d2.evaluation.evaluator]: [0mInference done 1468/3489. 0.2431 s / img. ETA=0:09:32
[32m[04/05 00:26:07 d2.evaluation.evaluator]: [0mInference done 1489/3489. 0.2430 s / img. ETA=0:09:25
[32m[04/05 00:26:12 d2.evaluation.evaluator]: [0mInference done 1510/3489. 0.2428 s / img. ETA=0:09:18
[32m[04/05 00:26:17 d2.evaluation.evaluator]: [0mInference done 1531/3489. 0.2427 s / img. ETA=0:09:11
[32m[04/05 00:26:22 d2.evaluation.evaluator]: [0mInference done 1552/3489. 0.2426 s / img. ETA=0:09:04
[32m[04/05 00:26:27 d2.evaluation.evaluator]: [0mInference done 1573/3489. 0.2424 s / img. ETA=0:08:57
[32m[04/05 00:26:33 d2.evaluation.evaluator]: [0mInference done 1594/3489. 0.2423 s / img. ETA=0:08:51
[32m[04/05 00:26:38 d2.evaluation.evaluator]: [0mInference done 1611/3489. 0.2423 s / img. ETA=0:08:46
[32m[04/05 00:26:43 d2.evaluation.evaluator]: [0mInference done 1628/3489. 0.2424 s / img. ETA=0:08:42
[32m[04/05 00:26:48 d2.evaluation.evaluator]: [0mInference done 1645/3489. 0.2424 s / img. ETA=0:08:37
[32m[04/05 00:26:53 d2.evaluation.evaluator]: [0mInference done 1663/3489. 0.2424 s / img. ETA=0:08:32
[32m[04/05 00:26:58 d2.evaluation.evaluator]: [0mInference done 1680/3489. 0.2425 s / img. ETA=0:08:28
[32m[04/05 00:27:04 d2.evaluation.evaluator]: [0mInference done 1696/3489. 0.2427 s / img. ETA=0:08:25
[32m[04/05 00:27:09 d2.evaluation.evaluator]: [0mInference done 1712/3489. 0.2428 s / img. ETA=0:08:21
[32m[04/05 00:27:14 d2.evaluation.evaluator]: [0mInference done 1728/3489. 0.2429 s / img. ETA=0:08:17
[32m[04/05 00:27:19 d2.evaluation.evaluator]: [0mInference done 1744/3489. 0.2430 s / img. ETA=0:08:13
[32m[04/05 00:27:24 d2.evaluation.evaluator]: [0mInference done 1759/3489. 0.2432 s / img. ETA=0:08:10
[32m[04/05 00:27:29 d2.evaluation.evaluator]: [0mInference done 1774/3489. 0.2433 s / img. ETA=0:08:06
[32m[04/05 00:27:34 d2.evaluation.evaluator]: [0mInference done 1789/3489. 0.2434 s / img. ETA=0:08:03
[32m[04/05 00:27:40 d2.evaluation.evaluator]: [0mInference done 1804/3489. 0.2435 s / img. ETA=0:07:59
[32m[04/05 00:27:45 d2.evaluation.evaluator]: [0mInference done 1819/3489. 0.2437 s / img. ETA=0:07:56
[32m[04/05 00:27:50 d2.evaluation.evaluator]: [0mInference done 1834/3489. 0.2438 s / img. ETA=0:07:52
[32m[04/05 00:27:55 d2.evaluation.evaluator]: [0mInference done 1850/3489. 0.2439 s / img. ETA=0:07:48
[32m[04/05 00:28:00 d2.evaluation.evaluator]: [0mInference done 1865/3489. 0.2440 s / img. ETA=0:07:45
[32m[04/05 00:28:05 d2.evaluation.evaluator]: [0mInference done 1881/3489. 0.2441 s / img. ETA=0:07:41
[32m[04/05 00:28:10 d2.evaluation.evaluator]: [0mInference done 1896/3489. 0.2442 s / img. ETA=0:07:37
[32m[04/05 00:28:16 d2.evaluation.evaluator]: [0mInference done 1912/3489. 0.2443 s / img. ETA=0:07:33
[32m[04/05 00:28:21 d2.evaluation.evaluator]: [0mInference done 1928/3489. 0.2444 s / img. ETA=0:07:29
[32m[04/05 00:28:26 d2.evaluation.evaluator]: [0mInference done 1943/3489. 0.2445 s / img. ETA=0:07:25
[32m[04/05 00:28:31 d2.evaluation.evaluator]: [0mInference done 1958/3489. 0.2446 s / img. ETA=0:07:21
[32m[04/05 00:28:36 d2.evaluation.evaluator]: [0mInference done 1974/3489. 0.2447 s / img. ETA=0:07:17
[32m[04/05 00:28:41 d2.evaluation.evaluator]: [0mInference done 1989/3489. 0.2449 s / img. ETA=0:07:14
[32m[04/05 00:28:47 d2.evaluation.evaluator]: [0mInference done 2005/3489. 0.2449 s / img. ETA=0:07:09
[32m[04/05 00:28:52 d2.evaluation.evaluator]: [0mInference done 2021/3489. 0.2450 s / img. ETA=0:07:05
[32m[04/05 00:28:57 d2.evaluation.evaluator]: [0mInference done 2037/3489. 0.2451 s / img. ETA=0:07:01
[32m[04/05 00:29:02 d2.evaluation.evaluator]: [0mInference done 2052/3489. 0.2452 s / img. ETA=0:06:57
[32m[04/05 00:29:07 d2.evaluation.evaluator]: [0mInference done 2067/3489. 0.2453 s / img. ETA=0:06:53
[32m[04/05 00:29:12 d2.evaluation.evaluator]: [0mInference done 2083/3489. 0.2454 s / img. ETA=0:06:49
[32m[04/05 00:29:18 d2.evaluation.evaluator]: [0mInference done 2099/3489. 0.2454 s / img. ETA=0:06:45
[32m[04/05 00:29:23 d2.evaluation.evaluator]: [0mInference done 2114/3489. 0.2455 s / img. ETA=0:06:41
[32m[04/05 00:29:28 d2.evaluation.evaluator]: [0mInference done 2129/3489. 0.2456 s / img. ETA=0:06:37
[32m[04/05 00:29:33 d2.evaluation.evaluator]: [0mInference done 2144/3489. 0.2457 s / img. ETA=0:06:33
[32m[04/05 00:29:38 d2.evaluation.evaluator]: [0mInference done 2159/3489. 0.2458 s / img. ETA=0:06:29
[32m[04/05 00:29:43 d2.evaluation.evaluator]: [0mInference done 2174/3489. 0.2459 s / img. ETA=0:06:25
[32m[04/05 00:29:48 d2.evaluation.evaluator]: [0mInference done 2189/3489. 0.2460 s / img. ETA=0:06:21
[32m[04/05 00:29:53 d2.evaluation.evaluator]: [0mInference done 2204/3489. 0.2461 s / img. ETA=0:06:17
[32m[04/05 00:29:58 d2.evaluation.evaluator]: [0mInference done 2220/3489. 0.2462 s / img. ETA=0:06:12
[32m[04/05 00:30:03 d2.evaluation.evaluator]: [0mInference done 2235/3489. 0.2463 s / img. ETA=0:06:08
[32m[04/05 00:30:08 d2.evaluation.evaluator]: [0mInference done 2251/3489. 0.2464 s / img. ETA=0:06:04
[32m[04/05 00:30:13 d2.evaluation.evaluator]: [0mInference done 2267/3489. 0.2464 s / img. ETA=0:05:59
[32m[04/05 00:30:19 d2.evaluation.evaluator]: [0mInference done 2282/3489. 0.2465 s / img. ETA=0:05:55
[32m[04/05 00:30:24 d2.evaluation.evaluator]: [0mInference done 2298/3489. 0.2465 s / img. ETA=0:05:51
[32m[04/05 00:30:29 d2.evaluation.evaluator]: [0mInference done 2313/3489. 0.2466 s / img. ETA=0:05:47
[32m[04/05 00:30:34 d2.evaluation.evaluator]: [0mInference done 2328/3489. 0.2467 s / img. ETA=0:05:43
[32m[04/05 00:30:39 d2.evaluation.evaluator]: [0mInference done 2344/3489. 0.2468 s / img. ETA=0:05:38
[32m[04/05 00:30:44 d2.evaluation.evaluator]: [0mInference done 2360/3489. 0.2468 s / img. ETA=0:05:34
[32m[04/05 00:30:49 d2.evaluation.evaluator]: [0mInference done 2378/3489. 0.2468 s / img. ETA=0:05:28
[32m[04/05 00:30:55 d2.evaluation.evaluator]: [0mInference done 2396/3489. 0.2468 s / img. ETA=0:05:23
[32m[04/05 00:31:00 d2.evaluation.evaluator]: [0mInference done 2413/3489. 0.2468 s / img. ETA=0:05:18
[32m[04/05 00:31:05 d2.evaluation.evaluator]: [0mInference done 2431/3489. 0.2468 s / img. ETA=0:05:12
[32m[04/05 00:31:10 d2.evaluation.evaluator]: [0mInference done 2447/3489. 0.2468 s / img. ETA=0:05:08
[32m[04/05 00:31:15 d2.evaluation.evaluator]: [0mInference done 2463/3489. 0.2469 s / img. ETA=0:05:03
[32m[04/05 00:31:21 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2469 s / img. ETA=0:04:59
[32m[04/05 00:31:26 d2.evaluation.evaluator]: [0mInference done 2497/3489. 0.2469 s / img. ETA=0:04:53
[32m[04/05 00:31:31 d2.evaluation.evaluator]: [0mInference done 2517/3489. 0.2469 s / img. ETA=0:04:47
[32m[04/05 00:31:36 d2.evaluation.evaluator]: [0mInference done 2536/3489. 0.2468 s / img. ETA=0:04:41
[32m[04/05 00:31:41 d2.evaluation.evaluator]: [0mInference done 2555/3489. 0.2467 s / img. ETA=0:04:36
[32m[04/05 00:31:47 d2.evaluation.evaluator]: [0mInference done 2574/3489. 0.2467 s / img. ETA=0:04:30
[32m[04/05 00:31:52 d2.evaluation.evaluator]: [0mInference done 2594/3489. 0.2466 s / img. ETA=0:04:24
[32m[04/05 00:31:57 d2.evaluation.evaluator]: [0mInference done 2614/3489. 0.2465 s / img. ETA=0:04:18
[32m[04/05 00:32:02 d2.evaluation.evaluator]: [0mInference done 2635/3489. 0.2464 s / img. ETA=0:04:11
[32m[04/05 00:32:07 d2.evaluation.evaluator]: [0mInference done 2656/3489. 0.2463 s / img. ETA=0:04:05
[32m[04/05 00:32:12 d2.evaluation.evaluator]: [0mInference done 2676/3489. 0.2462 s / img. ETA=0:03:58
[32m[04/05 00:32:18 d2.evaluation.evaluator]: [0mInference done 2696/3489. 0.2461 s / img. ETA=0:03:52
[32m[04/05 00:32:23 d2.evaluation.evaluator]: [0mInference done 2716/3489. 0.2460 s / img. ETA=0:03:46
[32m[04/05 00:32:28 d2.evaluation.evaluator]: [0mInference done 2736/3489. 0.2460 s / img. ETA=0:03:40
[32m[04/05 00:32:33 d2.evaluation.evaluator]: [0mInference done 2756/3489. 0.2458 s / img. ETA=0:03:34
[32m[04/05 00:32:38 d2.evaluation.evaluator]: [0mInference done 2776/3489. 0.2458 s / img. ETA=0:03:28
[32m[04/05 00:32:43 d2.evaluation.evaluator]: [0mInference done 2796/3489. 0.2457 s / img. ETA=0:03:22
[32m[04/05 00:32:48 d2.evaluation.evaluator]: [0mInference done 2816/3489. 0.2456 s / img. ETA=0:03:16
[32m[04/05 00:32:53 d2.evaluation.evaluator]: [0mInference done 2836/3489. 0.2455 s / img. ETA=0:03:10
[32m[04/05 00:32:58 d2.evaluation.evaluator]: [0mInference done 2856/3489. 0.2454 s / img. ETA=0:03:04
[32m[04/05 00:33:03 d2.evaluation.evaluator]: [0mInference done 2876/3489. 0.2454 s / img. ETA=0:02:58
[32m[04/05 00:33:09 d2.evaluation.evaluator]: [0mInference done 2897/3489. 0.2452 s / img. ETA=0:02:52
[32m[04/05 00:33:14 d2.evaluation.evaluator]: [0mInference done 2918/3489. 0.2452 s / img. ETA=0:02:45
[32m[04/05 00:33:19 d2.evaluation.evaluator]: [0mInference done 2939/3489. 0.2451 s / img. ETA=0:02:39
[32m[04/05 00:33:24 d2.evaluation.evaluator]: [0mInference done 2960/3489. 0.2450 s / img. ETA=0:02:33
[32m[04/05 00:33:29 d2.evaluation.evaluator]: [0mInference done 2981/3489. 0.2449 s / img. ETA=0:02:27
[32m[04/05 00:33:35 d2.evaluation.evaluator]: [0mInference done 3001/3489. 0.2448 s / img. ETA=0:02:21
[32m[04/05 00:33:40 d2.evaluation.evaluator]: [0mInference done 3021/3489. 0.2447 s / img. ETA=0:02:15
[32m[04/05 00:33:45 d2.evaluation.evaluator]: [0mInference done 3041/3489. 0.2447 s / img. ETA=0:02:09
[32m[04/05 00:33:50 d2.evaluation.evaluator]: [0mInference done 3061/3489. 0.2446 s / img. ETA=0:02:03
[32m[04/05 00:33:55 d2.evaluation.evaluator]: [0mInference done 3081/3489. 0.2445 s / img. ETA=0:01:57
[32m[04/05 00:34:00 d2.evaluation.evaluator]: [0mInference done 3101/3489. 0.2445 s / img. ETA=0:01:51
[32m[04/05 00:34:05 d2.evaluation.evaluator]: [0mInference done 3121/3489. 0.2444 s / img. ETA=0:01:46
[32m[04/05 00:34:11 d2.evaluation.evaluator]: [0mInference done 3141/3489. 0.2443 s / img. ETA=0:01:40
[32m[04/05 00:34:16 d2.evaluation.evaluator]: [0mInference done 3161/3489. 0.2443 s / img. ETA=0:01:34
[32m[04/05 00:34:21 d2.evaluation.evaluator]: [0mInference done 3181/3489. 0.2442 s / img. ETA=0:01:28
[32m[04/05 00:34:26 d2.evaluation.evaluator]: [0mInference done 3201/3489. 0.2441 s / img. ETA=0:01:22
[32m[04/05 00:34:31 d2.evaluation.evaluator]: [0mInference done 3221/3489. 0.2441 s / img. ETA=0:01:16
[32m[04/05 00:34:36 d2.evaluation.evaluator]: [0mInference done 3241/3489. 0.2440 s / img. ETA=0:01:11
[32m[04/05 00:34:41 d2.evaluation.evaluator]: [0mInference done 3262/3489. 0.2439 s / img. ETA=0:01:05
[32m[04/05 00:34:47 d2.evaluation.evaluator]: [0mInference done 3283/3489. 0.2439 s / img. ETA=0:00:59
[32m[04/05 00:34:52 d2.evaluation.evaluator]: [0mInference done 3305/3489. 0.2438 s / img. ETA=0:00:52
[32m[04/05 00:34:57 d2.evaluation.evaluator]: [0mInference done 3327/3489. 0.2437 s / img. ETA=0:00:46
[32m[04/05 00:35:02 d2.evaluation.evaluator]: [0mInference done 3349/3489. 0.2436 s / img. ETA=0:00:39
[32m[04/05 00:35:07 d2.evaluation.evaluator]: [0mInference done 3370/3489. 0.2435 s / img. ETA=0:00:33
[32m[04/05 00:35:12 d2.evaluation.evaluator]: [0mInference done 3391/3489. 0.2434 s / img. ETA=0:00:27
[32m[04/05 00:35:17 d2.evaluation.evaluator]: [0mInference done 3412/3489. 0.2433 s / img. ETA=0:00:21
[32m[04/05 00:35:22 d2.evaluation.evaluator]: [0mInference done 3432/3489. 0.2432 s / img. ETA=0:00:16
[32m[04/05 00:35:27 d2.evaluation.evaluator]: [0mInference done 3452/3489. 0.2432 s / img. ETA=0:00:10
[32m[04/05 00:35:32 d2.evaluation.evaluator]: [0mInference done 3472/3489. 0.2431 s / img. ETA=0:00:04
[32m[04/05 00:35:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:29.578009 (0.284035 s / img per device, on 1 devices)
[32m[04/05 00:35:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:06 (0.243088 s / img per device, on 1 devices)
[32m[04/05 00:35:39 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 00:35:39 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_4/coco_instances_results.json
[32m[04/05 00:35:41 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.99 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.61 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.731
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[32m[04/05 00:35:43 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.404 | 73.137 | 41.819 | 29.622 | 49.750 | 51.820 |
[32m[04/05 00:35:43 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.230 | Pedestrian | 25.577 |
Loading and preparing results...
DONE (t=2.47s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.54 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.65 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736
[32m[04/05 00:35:54 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.226 | 67.595 | 37.905 | 20.959 | 46.518 | 67.649 |
[32m[04/05 00:35:54 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 61.859 | Pedestrian | 16.592 |
[32m[04/05 00:35:55 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: 43.4036,73.1372,41.8194,29.6218,49.7499,51.8200
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:35:55 d2.evaluation.testing]: [0mcopypaste: 39.2256,67.5954,37.9054,20.9588,46.5184,67.6491
evaluated
Test [5][['res2', 'res3']]
[32m[04/05 00:35:56 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/05 00:35:56 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/05 00:35:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:35:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:35:56 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/05 00:35:56 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/05 00:35:56 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/05 00:35:56 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:35:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:35:56 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/05 00:35:56 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/05 00:35:57 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/05 00:36:22 d2.utils.events]: [0m eta: 0:02:36  iter: 19  total_loss: 1.872  loss_cls: 0.8234  loss_box_reg: 0.3233  loss_mask: 0.6551  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.009142  total_val_loss: 2.045  val_loss_cls: 0.8361  val_loss_box_reg: 0.3929  val_loss_mask: 0.6831  val_loss_rpn_cls: 0.04608  val_loss_rpn_loc: 0.01152  time: 0.8737  data_time: 0.0298  lr: 0.00019981  max_mem: 4747M
[32m[04/05 00:36:47 d2.utils.events]: [0m eta: 0:02:19  iter: 39  total_loss: 0.9304  loss_cls: 0.2052  loss_box_reg: 0.3231  loss_mask: 0.374  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.008033  total_val_loss: 1.005  val_loss_cls: 0.2335  val_loss_box_reg: 0.3479  val_loss_mask: 0.474  val_loss_rpn_cls: 0.02774  val_loss_rpn_loc: 0.009485  time: 0.8795  data_time: 0.0073  lr: 0.00039961  max_mem: 4747M
[32m[04/05 00:37:12 d2.utils.events]: [0m eta: 0:02:02  iter: 59  total_loss: 0.6248  loss_cls: 0.08124  loss_box_reg: 0.2351  loss_mask: 0.2403  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.006991  total_val_loss: 1.027  val_loss_cls: 0.171  val_loss_box_reg: 0.3955  val_loss_mask: 0.3338  val_loss_rpn_cls: 0.02609  val_loss_rpn_loc: 0.01122  time: 0.8814  data_time: 0.0074  lr: 0.00059941  max_mem: 4747M
[32m[04/05 00:37:37 d2.utils.events]: [0m eta: 0:01:44  iter: 79  total_loss: 0.5751  loss_cls: 0.07078  loss_box_reg: 0.2387  loss_mask: 0.2036  loss_rpn_cls: 0.004908  loss_rpn_loc: 0.005764  total_val_loss: 0.9373  val_loss_cls: 0.1586  val_loss_box_reg: 0.3619  val_loss_mask: 0.4037  val_loss_rpn_cls: 0.02853  val_loss_rpn_loc: 0.01292  time: 0.8810  data_time: 0.0072  lr: 0.00079921  max_mem: 4747M
[32m[04/05 00:38:03 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:38:03 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:38:03 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:38:03 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 00:38:03 d2.utils.events]: [0m eta: 0:01:27  iter: 99  total_loss: 0.4619  loss_cls: 0.05891  loss_box_reg: 0.2198  loss_mask: 0.1748  loss_rpn_cls: 0.007666  loss_rpn_loc: 0.007453  total_val_loss: 0.6373  val_loss_cls: 0.09872  val_loss_box_reg: 0.2728  val_loss_mask: 0.2323  val_loss_rpn_cls: 0.01836  val_loss_rpn_loc: 0.01221  time: 0.8805  data_time: 0.0067  lr: 0.00099901  max_mem: 4747M
[32m[04/05 00:38:28 d2.utils.events]: [0m eta: 0:01:10  iter: 119  total_loss: 0.3818  loss_cls: 0.05127  loss_box_reg: 0.1468  loss_mask: 0.1515  loss_rpn_cls: 0.005026  loss_rpn_loc: 0.009538  total_val_loss: 0.9242  val_loss_cls: 0.1961  val_loss_box_reg: 0.281  val_loss_mask: 0.4266  val_loss_rpn_cls: 0.02989  val_loss_rpn_loc: 0.01375  time: 0.8817  data_time: 0.0071  lr: 0.0011988  max_mem: 4747M
[32m[04/05 00:38:54 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.3533  loss_cls: 0.04764  loss_box_reg: 0.122  loss_mask: 0.1387  loss_rpn_cls: 0.005436  loss_rpn_loc: 0.01177  total_val_loss: 0.7402  val_loss_cls: 0.1415  val_loss_box_reg: 0.2245  val_loss_mask: 0.294  val_loss_rpn_cls: 0.01995  val_loss_rpn_loc: 0.0141  time: 0.8829  data_time: 0.0073  lr: 0.0013986  max_mem: 4747M
[32m[04/05 00:39:19 d2.utils.events]: [0m eta: 0:00:35  iter: 159  total_loss: 0.3759  loss_cls: 0.05165  loss_box_reg: 0.1124  loss_mask: 0.1717  loss_rpn_cls: 0.008466  loss_rpn_loc: 0.007662  total_val_loss: 1.02  val_loss_cls: 0.2091  val_loss_box_reg: 0.3331  val_loss_mask: 0.364  val_loss_rpn_cls: 0.02205  val_loss_rpn_loc: 0.01543  time: 0.8832  data_time: 0.0072  lr: 0.0015984  max_mem: 4747M
[32m[04/05 00:39:44 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.2649  loss_cls: 0.05036  loss_box_reg: 0.08839  loss_mask: 0.1375  loss_rpn_cls: 0.006054  loss_rpn_loc: 0.007925  total_val_loss: 0.8875  val_loss_cls: 0.1908  val_loss_box_reg: 0.2882  val_loss_mask: 0.3143  val_loss_rpn_cls: 0.01513  val_loss_rpn_loc: 0.01459  time: 0.8828  data_time: 0.0070  lr: 0.0017982  max_mem: 4747M
[32m[04/05 00:40:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:40:10 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:40:10 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:40:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 00:40:10 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3477  loss_cls: 0.05651  loss_box_reg: 0.1117  loss_mask: 0.1449  loss_rpn_cls: 0.00627  loss_rpn_loc: 0.01102  total_val_loss: 0.9193  val_loss_cls: 0.2039  val_loss_box_reg: 0.3242  val_loss_mask: 0.3312  val_loss_rpn_cls: 0.01707  val_loss_rpn_loc: 0.01452  time: 0.8826  data_time: 0.0069  lr: 0.001998  max_mem: 4747M
[32m[04/05 00:40:10 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:54 (0.8827 s / it)
[32m[04/05 00:40:10 d2.engine.hooks]: [0mTotal training time: 0:04:10 (0:01:15 on hooks)
[32m[04/05 00:40:10 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:40:10 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:40:10 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:40:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/05 00:40:10 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/05 00:40:11 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:40:11 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:40:11 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/05 00:40:11 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/05 00:40:15 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2338 s / img. ETA=0:14:41
[32m[04/05 00:40:20 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2324 s / img. ETA=0:14:30
[32m[04/05 00:40:25 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2329 s / img. ETA=0:14:16
[32m[04/05 00:40:30 d2.evaluation.evaluator]: [0mInference done 73/3489. 0.2329 s / img. ETA=0:14:05
[32m[04/05 00:40:35 d2.evaluation.evaluator]: [0mInference done 93/3489. 0.2333 s / img. ETA=0:14:06
[32m[04/05 00:40:40 d2.evaluation.evaluator]: [0mInference done 111/3489. 0.2341 s / img. ETA=0:14:18
[32m[04/05 00:40:45 d2.evaluation.evaluator]: [0mInference done 128/3489. 0.2365 s / img. ETA=0:14:38
[32m[04/05 00:40:51 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2388 s / img. ETA=0:15:02
[32m[04/05 00:40:56 d2.evaluation.evaluator]: [0mInference done 159/3489. 0.2408 s / img. ETA=0:15:19
[32m[04/05 00:41:01 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2422 s / img. ETA=0:15:31
[32m[04/05 00:41:06 d2.evaluation.evaluator]: [0mInference done 192/3489. 0.2430 s / img. ETA=0:15:34
[32m[04/05 00:41:11 d2.evaluation.evaluator]: [0mInference done 211/3489. 0.2424 s / img. ETA=0:15:23
[32m[04/05 00:41:17 d2.evaluation.evaluator]: [0mInference done 231/3489. 0.2417 s / img. ETA=0:15:11
[32m[04/05 00:41:22 d2.evaluation.evaluator]: [0mInference done 250/3489. 0.2416 s / img. ETA=0:15:05
[32m[04/05 00:41:27 d2.evaluation.evaluator]: [0mInference done 269/3489. 0.2414 s / img. ETA=0:14:58
[32m[04/05 00:41:32 d2.evaluation.evaluator]: [0mInference done 287/3489. 0.2415 s / img. ETA=0:14:55
[32m[04/05 00:41:37 d2.evaluation.evaluator]: [0mInference done 306/3489. 0.2415 s / img. ETA=0:14:49
[32m[04/05 00:41:43 d2.evaluation.evaluator]: [0mInference done 324/3489. 0.2415 s / img. ETA=0:14:45
[32m[04/05 00:41:48 d2.evaluation.evaluator]: [0mInference done 342/3489. 0.2416 s / img. ETA=0:14:42
[32m[04/05 00:41:53 d2.evaluation.evaluator]: [0mInference done 360/3489. 0.2418 s / img. ETA=0:14:38
[32m[04/05 00:41:58 d2.evaluation.evaluator]: [0mInference done 378/3489. 0.2419 s / img. ETA=0:14:34
[32m[04/05 00:42:03 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2418 s / img. ETA=0:14:29
[32m[04/05 00:42:08 d2.evaluation.evaluator]: [0mInference done 414/3489. 0.2418 s / img. ETA=0:14:25
[32m[04/05 00:42:14 d2.evaluation.evaluator]: [0mInference done 434/3489. 0.2415 s / img. ETA=0:14:16
[32m[04/05 00:42:19 d2.evaluation.evaluator]: [0mInference done 455/3489. 0.2411 s / img. ETA=0:14:05
[32m[04/05 00:42:24 d2.evaluation.evaluator]: [0mInference done 475/3489. 0.2409 s / img. ETA=0:13:56
[32m[04/05 00:42:29 d2.evaluation.evaluator]: [0mInference done 496/3489. 0.2406 s / img. ETA=0:13:46
[32m[04/05 00:42:34 d2.evaluation.evaluator]: [0mInference done 516/3489. 0.2406 s / img. ETA=0:13:38
[32m[04/05 00:42:39 d2.evaluation.evaluator]: [0mInference done 538/3489. 0.2401 s / img. ETA=0:13:27
[32m[04/05 00:42:44 d2.evaluation.evaluator]: [0mInference done 558/3489. 0.2399 s / img. ETA=0:13:20
[32m[04/05 00:42:49 d2.evaluation.evaluator]: [0mInference done 577/3489. 0.2399 s / img. ETA=0:13:14
[32m[04/05 00:42:54 d2.evaluation.evaluator]: [0mInference done 594/3489. 0.2401 s / img. ETA=0:13:11
[32m[04/05 00:43:00 d2.evaluation.evaluator]: [0mInference done 613/3489. 0.2401 s / img. ETA=0:13:06
[32m[04/05 00:43:05 d2.evaluation.evaluator]: [0mInference done 631/3489. 0.2402 s / img. ETA=0:13:02
[32m[04/05 00:43:10 d2.evaluation.evaluator]: [0mInference done 650/3489. 0.2402 s / img. ETA=0:12:57
[32m[04/05 00:43:15 d2.evaluation.evaluator]: [0mInference done 669/3489. 0.2401 s / img. ETA=0:12:51
[32m[04/05 00:43:20 d2.evaluation.evaluator]: [0mInference done 689/3489. 0.2400 s / img. ETA=0:12:44
[32m[04/05 00:43:25 d2.evaluation.evaluator]: [0mInference done 710/3489. 0.2398 s / img. ETA=0:12:36
[32m[04/05 00:43:30 d2.evaluation.evaluator]: [0mInference done 730/3489. 0.2396 s / img. ETA=0:12:29
[32m[04/05 00:43:35 d2.evaluation.evaluator]: [0mInference done 750/3489. 0.2394 s / img. ETA=0:12:22
[32m[04/05 00:43:40 d2.evaluation.evaluator]: [0mInference done 771/3489. 0.2392 s / img. ETA=0:12:14
[32m[04/05 00:43:45 d2.evaluation.evaluator]: [0mInference done 792/3489. 0.2390 s / img. ETA=0:12:06
[32m[04/05 00:43:50 d2.evaluation.evaluator]: [0mInference done 813/3489. 0.2388 s / img. ETA=0:11:58
[32m[04/05 00:43:56 d2.evaluation.evaluator]: [0mInference done 835/3489. 0.2385 s / img. ETA=0:11:50
[32m[04/05 00:44:01 d2.evaluation.evaluator]: [0mInference done 856/3489. 0.2383 s / img. ETA=0:11:43
[32m[04/05 00:44:06 d2.evaluation.evaluator]: [0mInference done 877/3489. 0.2381 s / img. ETA=0:11:36
[32m[04/05 00:44:11 d2.evaluation.evaluator]: [0mInference done 899/3489. 0.2379 s / img. ETA=0:11:28
[32m[04/05 00:44:16 d2.evaluation.evaluator]: [0mInference done 916/3489. 0.2381 s / img. ETA=0:11:25
[32m[04/05 00:44:21 d2.evaluation.evaluator]: [0mInference done 933/3489. 0.2384 s / img. ETA=0:11:23
[32m[04/05 00:44:26 d2.evaluation.evaluator]: [0mInference done 949/3489. 0.2387 s / img. ETA=0:11:20
[32m[04/05 00:44:32 d2.evaluation.evaluator]: [0mInference done 966/3489. 0.2389 s / img. ETA=0:11:18
[32m[04/05 00:44:37 d2.evaluation.evaluator]: [0mInference done 982/3489. 0.2392 s / img. ETA=0:11:16
[32m[04/05 00:44:42 d2.evaluation.evaluator]: [0mInference done 998/3489. 0.2395 s / img. ETA=0:11:14
[32m[04/05 00:44:47 d2.evaluation.evaluator]: [0mInference done 1014/3489. 0.2398 s / img. ETA=0:11:12
[32m[04/05 00:44:53 d2.evaluation.evaluator]: [0mInference done 1030/3489. 0.2400 s / img. ETA=0:11:10
[32m[04/05 00:44:58 d2.evaluation.evaluator]: [0mInference done 1046/3489. 0.2403 s / img. ETA=0:11:07
[32m[04/05 00:45:03 d2.evaluation.evaluator]: [0mInference done 1061/3489. 0.2406 s / img. ETA=0:11:05
[32m[04/05 00:45:08 d2.evaluation.evaluator]: [0mInference done 1077/3489. 0.2408 s / img. ETA=0:11:03
[32m[04/05 00:45:13 d2.evaluation.evaluator]: [0mInference done 1095/3489. 0.2409 s / img. ETA=0:10:58
[32m[04/05 00:45:19 d2.evaluation.evaluator]: [0mInference done 1114/3489. 0.2408 s / img. ETA=0:10:53
[32m[04/05 00:45:24 d2.evaluation.evaluator]: [0mInference done 1130/3489. 0.2410 s / img. ETA=0:10:50
[32m[04/05 00:45:29 d2.evaluation.evaluator]: [0mInference done 1146/3489. 0.2412 s / img. ETA=0:10:47
[32m[04/05 00:45:34 d2.evaluation.evaluator]: [0mInference done 1162/3489. 0.2414 s / img. ETA=0:10:44
[32m[04/05 00:45:39 d2.evaluation.evaluator]: [0mInference done 1178/3489. 0.2416 s / img. ETA=0:10:41
[32m[04/05 00:45:44 d2.evaluation.evaluator]: [0mInference done 1195/3489. 0.2417 s / img. ETA=0:10:37
[32m[04/05 00:45:49 d2.evaluation.evaluator]: [0mInference done 1212/3489. 0.2418 s / img. ETA=0:10:33
[32m[04/05 00:45:54 d2.evaluation.evaluator]: [0mInference done 1229/3489. 0.2419 s / img. ETA=0:10:29
[32m[04/05 00:45:59 d2.evaluation.evaluator]: [0mInference done 1246/3489. 0.2419 s / img. ETA=0:10:25
[32m[04/05 00:46:04 d2.evaluation.evaluator]: [0mInference done 1266/3489. 0.2418 s / img. ETA=0:10:19
[32m[04/05 00:46:10 d2.evaluation.evaluator]: [0mInference done 1288/3489. 0.2416 s / img. ETA=0:10:11
[32m[04/05 00:46:15 d2.evaluation.evaluator]: [0mInference done 1310/3489. 0.2414 s / img. ETA=0:10:03
[32m[04/05 00:46:20 d2.evaluation.evaluator]: [0mInference done 1331/3489. 0.2412 s / img. ETA=0:09:56
[32m[04/05 00:46:25 d2.evaluation.evaluator]: [0mInference done 1352/3489. 0.2410 s / img. ETA=0:09:49
[32m[04/05 00:46:30 d2.evaluation.evaluator]: [0mInference done 1373/3489. 0.2409 s / img. ETA=0:09:42
[32m[04/05 00:46:35 d2.evaluation.evaluator]: [0mInference done 1394/3489. 0.2408 s / img. ETA=0:09:35
[32m[04/05 00:46:40 d2.evaluation.evaluator]: [0mInference done 1415/3489. 0.2407 s / img. ETA=0:09:29
[32m[04/05 00:46:45 d2.evaluation.evaluator]: [0mInference done 1435/3489. 0.2406 s / img. ETA=0:09:23
[32m[04/05 00:46:51 d2.evaluation.evaluator]: [0mInference done 1456/3489. 0.2405 s / img. ETA=0:09:16
[32m[04/05 00:46:56 d2.evaluation.evaluator]: [0mInference done 1477/3489. 0.2403 s / img. ETA=0:09:09
[32m[04/05 00:47:01 d2.evaluation.evaluator]: [0mInference done 1498/3489. 0.2402 s / img. ETA=0:09:03
[32m[04/05 00:47:06 d2.evaluation.evaluator]: [0mInference done 1519/3489. 0.2401 s / img. ETA=0:08:56
[32m[04/05 00:47:11 d2.evaluation.evaluator]: [0mInference done 1540/3489. 0.2400 s / img. ETA=0:08:50
[32m[04/05 00:47:16 d2.evaluation.evaluator]: [0mInference done 1561/3489. 0.2399 s / img. ETA=0:08:43
[32m[04/05 00:47:21 d2.evaluation.evaluator]: [0mInference done 1582/3489. 0.2398 s / img. ETA=0:08:37
[32m[04/05 00:47:26 d2.evaluation.evaluator]: [0mInference done 1602/3489. 0.2397 s / img. ETA=0:08:31
[32m[04/05 00:47:32 d2.evaluation.evaluator]: [0mInference done 1621/3489. 0.2397 s / img. ETA=0:08:26
[32m[04/05 00:47:37 d2.evaluation.evaluator]: [0mInference done 1639/3489. 0.2397 s / img. ETA=0:08:22
[32m[04/05 00:47:42 d2.evaluation.evaluator]: [0mInference done 1658/3489. 0.2397 s / img. ETA=0:08:16
[32m[04/05 00:47:47 d2.evaluation.evaluator]: [0mInference done 1676/3489. 0.2398 s / img. ETA=0:08:12
[32m[04/05 00:47:52 d2.evaluation.evaluator]: [0mInference done 1692/3489. 0.2399 s / img. ETA=0:08:08
[32m[04/05 00:47:57 d2.evaluation.evaluator]: [0mInference done 1709/3489. 0.2400 s / img. ETA=0:08:04
[32m[04/05 00:48:02 d2.evaluation.evaluator]: [0mInference done 1725/3489. 0.2402 s / img. ETA=0:08:01
[32m[04/05 00:48:08 d2.evaluation.evaluator]: [0mInference done 1742/3489. 0.2403 s / img. ETA=0:07:57
[32m[04/05 00:48:13 d2.evaluation.evaluator]: [0mInference done 1758/3489. 0.2404 s / img. ETA=0:07:53
[32m[04/05 00:48:18 d2.evaluation.evaluator]: [0mInference done 1773/3489. 0.2406 s / img. ETA=0:07:50
[32m[04/05 00:48:23 d2.evaluation.evaluator]: [0mInference done 1788/3489. 0.2407 s / img. ETA=0:07:47
[32m[04/05 00:48:28 d2.evaluation.evaluator]: [0mInference done 1803/3489. 0.2409 s / img. ETA=0:07:43
[32m[04/05 00:48:33 d2.evaluation.evaluator]: [0mInference done 1818/3489. 0.2411 s / img. ETA=0:07:40
[32m[04/05 00:48:38 d2.evaluation.evaluator]: [0mInference done 1833/3489. 0.2412 s / img. ETA=0:07:37
[32m[04/05 00:48:43 d2.evaluation.evaluator]: [0mInference done 1848/3489. 0.2414 s / img. ETA=0:07:33
[32m[04/05 00:48:48 d2.evaluation.evaluator]: [0mInference done 1864/3489. 0.2415 s / img. ETA=0:07:30
[32m[04/05 00:48:54 d2.evaluation.evaluator]: [0mInference done 1880/3489. 0.2416 s / img. ETA=0:07:26
[32m[04/05 00:48:59 d2.evaluation.evaluator]: [0mInference done 1896/3489. 0.2418 s / img. ETA=0:07:22
[32m[04/05 00:49:04 d2.evaluation.evaluator]: [0mInference done 1911/3489. 0.2419 s / img. ETA=0:07:19
[32m[04/05 00:49:09 d2.evaluation.evaluator]: [0mInference done 1927/3489. 0.2420 s / img. ETA=0:07:15
[32m[04/05 00:49:15 d2.evaluation.evaluator]: [0mInference done 1943/3489. 0.2421 s / img. ETA=0:07:11
[32m[04/05 00:49:20 d2.evaluation.evaluator]: [0mInference done 1958/3489. 0.2423 s / img. ETA=0:07:08
[32m[04/05 00:49:25 d2.evaluation.evaluator]: [0mInference done 1974/3489. 0.2424 s / img. ETA=0:07:04
[32m[04/05 00:49:30 d2.evaluation.evaluator]: [0mInference done 1990/3489. 0.2425 s / img. ETA=0:07:00
[32m[04/05 00:49:35 d2.evaluation.evaluator]: [0mInference done 2008/3489. 0.2425 s / img. ETA=0:06:55
[32m[04/05 00:49:40 d2.evaluation.evaluator]: [0mInference done 2025/3489. 0.2425 s / img. ETA=0:06:50
[32m[04/05 00:49:46 d2.evaluation.evaluator]: [0mInference done 2042/3489. 0.2426 s / img. ETA=0:06:46
[32m[04/05 00:49:51 d2.evaluation.evaluator]: [0mInference done 2058/3489. 0.2427 s / img. ETA=0:06:42
[32m[04/05 00:49:56 d2.evaluation.evaluator]: [0mInference done 2074/3489. 0.2428 s / img. ETA=0:06:38
[32m[04/05 00:50:01 d2.evaluation.evaluator]: [0mInference done 2089/3489. 0.2429 s / img. ETA=0:06:34
[32m[04/05 00:50:06 d2.evaluation.evaluator]: [0mInference done 2104/3489. 0.2430 s / img. ETA=0:06:31
[32m[04/05 00:50:11 d2.evaluation.evaluator]: [0mInference done 2120/3489. 0.2431 s / img. ETA=0:06:27
[32m[04/05 00:50:16 d2.evaluation.evaluator]: [0mInference done 2135/3489. 0.2432 s / img. ETA=0:06:23
[32m[04/05 00:50:21 d2.evaluation.evaluator]: [0mInference done 2150/3489. 0.2434 s / img. ETA=0:06:19
[32m[04/05 00:50:27 d2.evaluation.evaluator]: [0mInference done 2165/3489. 0.2435 s / img. ETA=0:06:15
[32m[04/05 00:50:32 d2.evaluation.evaluator]: [0mInference done 2180/3489. 0.2436 s / img. ETA=0:06:12
[32m[04/05 00:50:37 d2.evaluation.evaluator]: [0mInference done 2195/3489. 0.2437 s / img. ETA=0:06:08
[32m[04/05 00:50:42 d2.evaluation.evaluator]: [0mInference done 2210/3489. 0.2438 s / img. ETA=0:06:04
[32m[04/05 00:50:47 d2.evaluation.evaluator]: [0mInference done 2226/3489. 0.2438 s / img. ETA=0:06:00
[32m[04/05 00:50:52 d2.evaluation.evaluator]: [0mInference done 2242/3489. 0.2439 s / img. ETA=0:05:55
[32m[04/05 00:50:57 d2.evaluation.evaluator]: [0mInference done 2259/3489. 0.2439 s / img. ETA=0:05:51
[32m[04/05 00:51:02 d2.evaluation.evaluator]: [0mInference done 2276/3489. 0.2440 s / img. ETA=0:05:46
[32m[04/05 00:51:07 d2.evaluation.evaluator]: [0mInference done 2293/3489. 0.2441 s / img. ETA=0:05:41
[32m[04/05 00:51:13 d2.evaluation.evaluator]: [0mInference done 2309/3489. 0.2441 s / img. ETA=0:05:37
[32m[04/05 00:51:18 d2.evaluation.evaluator]: [0mInference done 2325/3489. 0.2441 s / img. ETA=0:05:33
[32m[04/05 00:51:23 d2.evaluation.evaluator]: [0mInference done 2341/3489. 0.2442 s / img. ETA=0:05:28
[32m[04/05 00:51:28 d2.evaluation.evaluator]: [0mInference done 2357/3489. 0.2443 s / img. ETA=0:05:24
[32m[04/05 00:51:33 d2.evaluation.evaluator]: [0mInference done 2375/3489. 0.2443 s / img. ETA=0:05:19
[32m[04/05 00:51:38 d2.evaluation.evaluator]: [0mInference done 2394/3489. 0.2442 s / img. ETA=0:05:13
[32m[04/05 00:51:43 d2.evaluation.evaluator]: [0mInference done 2412/3489. 0.2442 s / img. ETA=0:05:08
[32m[04/05 00:51:48 d2.evaluation.evaluator]: [0mInference done 2430/3489. 0.2442 s / img. ETA=0:05:03
[32m[04/05 00:51:53 d2.evaluation.evaluator]: [0mInference done 2447/3489. 0.2442 s / img. ETA=0:04:58
[32m[04/05 00:51:59 d2.evaluation.evaluator]: [0mInference done 2464/3489. 0.2443 s / img. ETA=0:04:53
[32m[04/05 00:52:04 d2.evaluation.evaluator]: [0mInference done 2480/3489. 0.2444 s / img. ETA=0:04:49
[32m[04/05 00:52:09 d2.evaluation.evaluator]: [0mInference done 2499/3489. 0.2443 s / img. ETA=0:04:44
[32m[04/05 00:52:14 d2.evaluation.evaluator]: [0mInference done 2519/3489. 0.2442 s / img. ETA=0:04:38
[32m[04/05 00:52:19 d2.evaluation.evaluator]: [0mInference done 2539/3489. 0.2442 s / img. ETA=0:04:32
[32m[04/05 00:52:25 d2.evaluation.evaluator]: [0mInference done 2559/3489. 0.2442 s / img. ETA=0:04:26
[32m[04/05 00:52:30 d2.evaluation.evaluator]: [0mInference done 2579/3489. 0.2441 s / img. ETA=0:04:20
[32m[04/05 00:52:35 d2.evaluation.evaluator]: [0mInference done 2599/3489. 0.2440 s / img. ETA=0:04:14
[32m[04/05 00:52:40 d2.evaluation.evaluator]: [0mInference done 2619/3489. 0.2440 s / img. ETA=0:04:08
[32m[04/05 00:52:45 d2.evaluation.evaluator]: [0mInference done 2640/3489. 0.2439 s / img. ETA=0:04:02
[32m[04/05 00:52:50 d2.evaluation.evaluator]: [0mInference done 2661/3489. 0.2438 s / img. ETA=0:03:55
[32m[04/05 00:52:55 d2.evaluation.evaluator]: [0mInference done 2681/3489. 0.2437 s / img. ETA=0:03:50
[32m[04/05 00:53:01 d2.evaluation.evaluator]: [0mInference done 2701/3489. 0.2437 s / img. ETA=0:03:44
[32m[04/05 00:53:06 d2.evaluation.evaluator]: [0mInference done 2721/3489. 0.2436 s / img. ETA=0:03:38
[32m[04/05 00:53:11 d2.evaluation.evaluator]: [0mInference done 2741/3489. 0.2435 s / img. ETA=0:03:32
[32m[04/05 00:53:16 d2.evaluation.evaluator]: [0mInference done 2761/3489. 0.2435 s / img. ETA=0:03:26
[32m[04/05 00:53:21 d2.evaluation.evaluator]: [0mInference done 2781/3489. 0.2434 s / img. ETA=0:03:20
[32m[04/05 00:53:26 d2.evaluation.evaluator]: [0mInference done 2801/3489. 0.2433 s / img. ETA=0:03:15
[32m[04/05 00:53:31 d2.evaluation.evaluator]: [0mInference done 2821/3489. 0.2433 s / img. ETA=0:03:09
[32m[04/05 00:53:36 d2.evaluation.evaluator]: [0mInference done 2840/3489. 0.2432 s / img. ETA=0:03:03
[32m[04/05 00:53:42 d2.evaluation.evaluator]: [0mInference done 2860/3489. 0.2431 s / img. ETA=0:02:58
[32m[04/05 00:53:47 d2.evaluation.evaluator]: [0mInference done 2880/3489. 0.2431 s / img. ETA=0:02:52
[32m[04/05 00:53:52 d2.evaluation.evaluator]: [0mInference done 2901/3489. 0.2430 s / img. ETA=0:02:46
[32m[04/05 00:53:57 d2.evaluation.evaluator]: [0mInference done 2922/3489. 0.2429 s / img. ETA=0:02:40
[32m[04/05 00:54:02 d2.evaluation.evaluator]: [0mInference done 2943/3489. 0.2429 s / img. ETA=0:02:34
[32m[04/05 00:54:07 d2.evaluation.evaluator]: [0mInference done 2964/3489. 0.2428 s / img. ETA=0:02:27
[32m[04/05 00:54:13 d2.evaluation.evaluator]: [0mInference done 2985/3489. 0.2427 s / img. ETA=0:02:21
[32m[04/05 00:54:18 d2.evaluation.evaluator]: [0mInference done 3004/3489. 0.2427 s / img. ETA=0:02:16
[32m[04/05 00:54:23 d2.evaluation.evaluator]: [0mInference done 3024/3489. 0.2426 s / img. ETA=0:02:10
[32m[04/05 00:54:28 d2.evaluation.evaluator]: [0mInference done 3044/3489. 0.2426 s / img. ETA=0:02:05
[32m[04/05 00:54:33 d2.evaluation.evaluator]: [0mInference done 3064/3489. 0.2425 s / img. ETA=0:01:59
[32m[04/05 00:54:38 d2.evaluation.evaluator]: [0mInference done 3083/3489. 0.2425 s / img. ETA=0:01:54
[32m[04/05 00:54:43 d2.evaluation.evaluator]: [0mInference done 3103/3489. 0.2424 s / img. ETA=0:01:48
[32m[04/05 00:54:48 d2.evaluation.evaluator]: [0mInference done 3123/3489. 0.2424 s / img. ETA=0:01:42
[32m[04/05 00:54:54 d2.evaluation.evaluator]: [0mInference done 3143/3489. 0.2424 s / img. ETA=0:01:37
[32m[04/05 00:54:59 d2.evaluation.evaluator]: [0mInference done 3163/3489. 0.2423 s / img. ETA=0:01:31
[32m[04/05 00:55:04 d2.evaluation.evaluator]: [0mInference done 3183/3489. 0.2423 s / img. ETA=0:01:25
[32m[04/05 00:55:09 d2.evaluation.evaluator]: [0mInference done 3203/3489. 0.2422 s / img. ETA=0:01:20
[32m[04/05 00:55:14 d2.evaluation.evaluator]: [0mInference done 3223/3489. 0.2422 s / img. ETA=0:01:14
[32m[04/05 00:55:19 d2.evaluation.evaluator]: [0mInference done 3243/3489. 0.2421 s / img. ETA=0:01:08
[32m[04/05 00:55:24 d2.evaluation.evaluator]: [0mInference done 3264/3489. 0.2420 s / img. ETA=0:01:02
[32m[04/05 00:55:30 d2.evaluation.evaluator]: [0mInference done 3285/3489. 0.2420 s / img. ETA=0:00:56
[32m[04/05 00:55:35 d2.evaluation.evaluator]: [0mInference done 3307/3489. 0.2419 s / img. ETA=0:00:50
[32m[04/05 00:55:40 d2.evaluation.evaluator]: [0mInference done 3329/3489. 0.2418 s / img. ETA=0:00:44
[32m[04/05 00:55:45 d2.evaluation.evaluator]: [0mInference done 3351/3489. 0.2418 s / img. ETA=0:00:38
[32m[04/05 00:55:50 d2.evaluation.evaluator]: [0mInference done 3372/3489. 0.2417 s / img. ETA=0:00:32
[32m[04/05 00:55:55 d2.evaluation.evaluator]: [0mInference done 3393/3489. 0.2416 s / img. ETA=0:00:26
[32m[04/05 00:56:00 d2.evaluation.evaluator]: [0mInference done 3414/3489. 0.2416 s / img. ETA=0:00:20
[32m[04/05 00:56:06 d2.evaluation.evaluator]: [0mInference done 3435/3489. 0.2415 s / img. ETA=0:00:14
[32m[04/05 00:56:11 d2.evaluation.evaluator]: [0mInference done 3456/3489. 0.2415 s / img. ETA=0:00:09
[32m[04/05 00:56:16 d2.evaluation.evaluator]: [0mInference done 3476/3489. 0.2414 s / img. ETA=0:00:03
[32m[04/05 00:56:19 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:06.122923 (0.277303 s / img per device, on 1 devices)
[32m[04/05 00:56:19 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:01 (0.241399 s / img per device, on 1 devices)
[32m[04/05 00:56:21 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 00:56:21 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_5/coco_instances_results.json
[32m[04/05 00:56:23 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.53 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
[32m[04/05 00:56:25 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.747 | 76.864 | 36.581 | 28.691 | 48.178 | 51.271 |
[32m[04/05 00:56:25 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 59.954 | Pedestrian | 23.539 |
Loading and preparing results...
DONE (t=2.20s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.30 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725
[32m[04/05 00:56:35 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.336 | 73.485 | 38.440 | 23.649 | 50.180 | 64.165 |
[32m[04/05 00:56:35 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.963 | Pedestrian | 20.709 |
[32m[04/05 00:56:35 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: 41.7468,76.8638,36.5805,28.6909,48.1776,51.2713
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 00:56:35 d2.evaluation.testing]: [0mcopypaste: 42.3359,73.4855,38.4403,23.6487,50.1800,64.1646
evaluated
Test [6][['res4', 'res5']]
[32m[04/05 00:56:36 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/05 00:56:36 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/05 00:56:36 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:56:36 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:56:36 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/05 00:56:36 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/05 00:56:36 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/05 00:56:37 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 00:56:37 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 00:56:37 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/05 00:56:37 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/05 00:56:37 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/05 00:57:02 d2.utils.events]: [0m eta: 0:02:36  iter: 19  total_loss: 1.989  loss_cls: 0.8894  loss_box_reg: 0.3809  loss_mask: 0.661  loss_rpn_cls: 0.01891  loss_rpn_loc: 0.008372  total_val_loss: 1.988  val_loss_cls: 0.7994  val_loss_box_reg: 0.4033  val_loss_mask: 0.6729  val_loss_rpn_cls: 0.04285  val_loss_rpn_loc: 0.0128  time: 0.8756  data_time: 0.0281  lr: 0.00019981  max_mem: 4747M
[32m[04/05 00:57:27 d2.utils.events]: [0m eta: 0:02:19  iter: 39  total_loss: 1.018  loss_cls: 0.2066  loss_box_reg: 0.3859  loss_mask: 0.3619  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.01308  total_val_loss: 1.457  val_loss_cls: 0.3202  val_loss_box_reg: 0.5034  val_loss_mask: 0.582  val_loss_rpn_cls: 0.03619  val_loss_rpn_loc: 0.0178  time: 0.8796  data_time: 0.0088  lr: 0.00039961  max_mem: 4747M
[32m[04/05 00:57:52 d2.utils.events]: [0m eta: 0:02:02  iter: 59  total_loss: 0.6613  loss_cls: 0.09814  loss_box_reg: 0.3262  loss_mask: 0.2128  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.005498  total_val_loss: 0.9294  val_loss_cls: 0.16  val_loss_box_reg: 0.459  val_loss_mask: 0.3256  val_loss_rpn_cls: 0.02202  val_loss_rpn_loc: 0.01301  time: 0.8831  data_time: 0.0079  lr: 0.00059941  max_mem: 4747M
[32m[04/05 00:58:17 d2.utils.events]: [0m eta: 0:01:45  iter: 79  total_loss: 0.6939  loss_cls: 0.06791  loss_box_reg: 0.2533  loss_mask: 0.1549  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.008276  total_val_loss: 1.136  val_loss_cls: 0.2637  val_loss_box_reg: 0.3348  val_loss_mask: 0.3897  val_loss_rpn_cls: 0.03382  val_loss_rpn_loc: 0.01379  time: 0.8848  data_time: 0.0084  lr: 0.00079921  max_mem: 4747M
[32m[04/05 00:58:42 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 00:58:42 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 00:58:42 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 00:58:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 00:58:43 d2.utils.events]: [0m eta: 0:01:28  iter: 99  total_loss: 0.3771  loss_cls: 0.04785  loss_box_reg: 0.0955  loss_mask: 0.1679  loss_rpn_cls: 0.005494  loss_rpn_loc: 0.004051  total_val_loss: 0.9724  val_loss_cls: 0.2393  val_loss_box_reg: 0.3273  val_loss_mask: 0.3686  val_loss_rpn_cls: 0.02134  val_loss_rpn_loc: 0.01366  time: 0.8853  data_time: 0.0082  lr: 0.00099901  max_mem: 4747M
[32m[04/05 00:59:08 d2.utils.events]: [0m eta: 0:01:10  iter: 119  total_loss: 0.382  loss_cls: 0.05893  loss_box_reg: 0.1265  loss_mask: 0.1588  loss_rpn_cls: 0.009403  loss_rpn_loc: 0.01001  total_val_loss: 0.5521  val_loss_cls: 0.111  val_loss_box_reg: 0.1641  val_loss_mask: 0.2874  val_loss_rpn_cls: 0.02055  val_loss_rpn_loc: 0.009722  time: 0.8865  data_time: 0.0097  lr: 0.0011988  max_mem: 4747M
[32m[04/05 00:59:32 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.3136  loss_cls: 0.0448  loss_box_reg: 0.08039  loss_mask: 0.1399  loss_rpn_cls: 0.004644  loss_rpn_loc: 0.007902  total_val_loss: 0.7332  val_loss_cls: 0.1303  val_loss_box_reg: 0.1737  val_loss_mask: 0.3003  val_loss_rpn_cls: 0.01525  val_loss_rpn_loc: 0.01189  time: 0.8851  data_time: 0.0075  lr: 0.0013986  max_mem: 4747M
[32m[04/05 00:59:57 d2.utils.events]: [0m eta: 0:00:35  iter: 159  total_loss: 0.3308  loss_cls: 0.05716  loss_box_reg: 0.1015  loss_mask: 0.1577  loss_rpn_cls: 0.005732  loss_rpn_loc: 0.008542  total_val_loss: 0.9562  val_loss_cls: 0.218  val_loss_box_reg: 0.3374  val_loss_mask: 0.3065  val_loss_rpn_cls: 0.01936  val_loss_rpn_loc: 0.01664  time: 0.8851  data_time: 0.0079  lr: 0.0015984  max_mem: 4747M
[32m[04/05 01:00:22 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3351  loss_cls: 0.05122  loss_box_reg: 0.1077  loss_mask: 0.1585  loss_rpn_cls: 0.006673  loss_rpn_loc: 0.00794  total_val_loss: 0.7052  val_loss_cls: 0.1385  val_loss_box_reg: 0.2617  val_loss_mask: 0.2469  val_loss_rpn_cls: 0.02247  val_loss_rpn_loc: 0.01458  time: 0.8846  data_time: 0.0077  lr: 0.0017982  max_mem: 4747M
[32m[04/05 01:00:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:00:48 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:00:48 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:00:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 01:00:48 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3671  loss_cls: 0.0501  loss_box_reg: 0.1227  loss_mask: 0.1725  loss_rpn_cls: 0.007156  loss_rpn_loc: 0.01113  total_val_loss: 0.6969  val_loss_cls: 0.1258  val_loss_box_reg: 0.2273  val_loss_mask: 0.297  val_loss_rpn_cls: 0.01608  val_loss_rpn_loc: 0.01314  time: 0.8847  data_time: 0.0080  lr: 0.001998  max_mem: 4747M
[32m[04/05 01:00:48 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:55 (0.8847 s / it)
[32m[04/05 01:00:48 d2.engine.hooks]: [0mTotal training time: 0:04:08 (0:01:13 on hooks)
[32m[04/05 01:00:49 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:00:49 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:00:49 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:00:49 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/05 01:00:49 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/05 01:00:50 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:00:50 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:00:50 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/05 01:00:50 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/05 01:00:53 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2337 s / img. ETA=0:14:51
[32m[04/05 01:00:58 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2316 s / img. ETA=0:14:28
[32m[04/05 01:01:03 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2316 s / img. ETA=0:14:15
[32m[04/05 01:01:09 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2308 s / img. ETA=0:14:02
[32m[04/05 01:01:14 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2318 s / img. ETA=0:14:07
[32m[04/05 01:01:19 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2333 s / img. ETA=0:14:19
[32m[04/05 01:01:24 d2.evaluation.evaluator]: [0mInference done 129/3489. 0.2352 s / img. ETA=0:14:39
[32m[04/05 01:01:29 d2.evaluation.evaluator]: [0mInference done 145/3489. 0.2376 s / img. ETA=0:15:01
[32m[04/05 01:01:34 d2.evaluation.evaluator]: [0mInference done 160/3489. 0.2399 s / img. ETA=0:15:20
[32m[04/05 01:01:40 d2.evaluation.evaluator]: [0mInference done 176/3489. 0.2416 s / img. ETA=0:15:33
[32m[04/05 01:01:45 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2422 s / img. ETA=0:15:36
[32m[04/05 01:01:50 d2.evaluation.evaluator]: [0mInference done 212/3489. 0.2417 s / img. ETA=0:15:25
[32m[04/05 01:01:55 d2.evaluation.evaluator]: [0mInference done 231/3489. 0.2413 s / img. ETA=0:15:15
[32m[04/05 01:02:00 d2.evaluation.evaluator]: [0mInference done 249/3489. 0.2412 s / img. ETA=0:15:09
[32m[04/05 01:02:05 d2.evaluation.evaluator]: [0mInference done 267/3489. 0.2412 s / img. ETA=0:15:04
[32m[04/05 01:02:10 d2.evaluation.evaluator]: [0mInference done 285/3489. 0.2412 s / img. ETA=0:14:59
[32m[04/05 01:02:15 d2.evaluation.evaluator]: [0mInference done 303/3489. 0.2412 s / img. ETA=0:14:54
[32m[04/05 01:02:20 d2.evaluation.evaluator]: [0mInference done 320/3489. 0.2414 s / img. ETA=0:14:52
[32m[04/05 01:02:25 d2.evaluation.evaluator]: [0mInference done 338/3489. 0.2416 s / img. ETA=0:14:49
[32m[04/05 01:02:31 d2.evaluation.evaluator]: [0mInference done 355/3489. 0.2420 s / img. ETA=0:14:47
[32m[04/05 01:02:36 d2.evaluation.evaluator]: [0mInference done 373/3489. 0.2421 s / img. ETA=0:14:43
[32m[04/05 01:02:41 d2.evaluation.evaluator]: [0mInference done 391/3489. 0.2423 s / img. ETA=0:14:39
[32m[04/05 01:02:46 d2.evaluation.evaluator]: [0mInference done 409/3489. 0.2424 s / img. ETA=0:14:34
[32m[04/05 01:02:51 d2.evaluation.evaluator]: [0mInference done 427/3489. 0.2424 s / img. ETA=0:14:29
[32m[04/05 01:02:57 d2.evaluation.evaluator]: [0mInference done 448/3489. 0.2420 s / img. ETA=0:14:18
[32m[04/05 01:03:02 d2.evaluation.evaluator]: [0mInference done 468/3489. 0.2417 s / img. ETA=0:14:08
[32m[04/05 01:03:07 d2.evaluation.evaluator]: [0mInference done 488/3489. 0.2413 s / img. ETA=0:13:59
[32m[04/05 01:03:12 d2.evaluation.evaluator]: [0mInference done 509/3489. 0.2409 s / img. ETA=0:13:49
[32m[04/05 01:03:17 d2.evaluation.evaluator]: [0mInference done 530/3489. 0.2406 s / img. ETA=0:13:39
[32m[04/05 01:03:22 d2.evaluation.evaluator]: [0mInference done 551/3489. 0.2403 s / img. ETA=0:13:30
[32m[04/05 01:03:27 d2.evaluation.evaluator]: [0mInference done 570/3489. 0.2403 s / img. ETA=0:13:24
[32m[04/05 01:03:33 d2.evaluation.evaluator]: [0mInference done 588/3489. 0.2404 s / img. ETA=0:13:21
[32m[04/05 01:03:38 d2.evaluation.evaluator]: [0mInference done 606/3489. 0.2405 s / img. ETA=0:13:16
[32m[04/05 01:03:43 d2.evaluation.evaluator]: [0mInference done 624/3489. 0.2405 s / img. ETA=0:13:12
[32m[04/05 01:03:48 d2.evaluation.evaluator]: [0mInference done 642/3489. 0.2406 s / img. ETA=0:13:08
[32m[04/05 01:03:53 d2.evaluation.evaluator]: [0mInference done 661/3489. 0.2406 s / img. ETA=0:13:03
[32m[04/05 01:03:58 d2.evaluation.evaluator]: [0mInference done 681/3489. 0.2405 s / img. ETA=0:12:56
[32m[04/05 01:04:03 d2.evaluation.evaluator]: [0mInference done 701/3489. 0.2404 s / img. ETA=0:12:48
[32m[04/05 01:04:09 d2.evaluation.evaluator]: [0mInference done 721/3489. 0.2402 s / img. ETA=0:12:41
[32m[04/05 01:04:14 d2.evaluation.evaluator]: [0mInference done 741/3489. 0.2400 s / img. ETA=0:12:34
[32m[04/05 01:04:19 d2.evaluation.evaluator]: [0mInference done 762/3489. 0.2398 s / img. ETA=0:12:26
[32m[04/05 01:04:24 d2.evaluation.evaluator]: [0mInference done 783/3489. 0.2395 s / img. ETA=0:12:18
[32m[04/05 01:04:29 d2.evaluation.evaluator]: [0mInference done 804/3489. 0.2394 s / img. ETA=0:12:10
[32m[04/05 01:04:34 d2.evaluation.evaluator]: [0mInference done 826/3489. 0.2391 s / img. ETA=0:12:01
[32m[04/05 01:04:39 d2.evaluation.evaluator]: [0mInference done 847/3489. 0.2389 s / img. ETA=0:11:54
[32m[04/05 01:04:44 d2.evaluation.evaluator]: [0mInference done 868/3489. 0.2388 s / img. ETA=0:11:47
[32m[04/05 01:04:50 d2.evaluation.evaluator]: [0mInference done 890/3489. 0.2385 s / img. ETA=0:11:39
[32m[04/05 01:04:55 d2.evaluation.evaluator]: [0mInference done 909/3489. 0.2386 s / img. ETA=0:11:34
[32m[04/05 01:05:00 d2.evaluation.evaluator]: [0mInference done 925/3489. 0.2389 s / img. ETA=0:11:32
[32m[04/05 01:05:05 d2.evaluation.evaluator]: [0mInference done 941/3489. 0.2391 s / img. ETA=0:11:29
[32m[04/05 01:05:10 d2.evaluation.evaluator]: [0mInference done 958/3489. 0.2393 s / img. ETA=0:11:27
[32m[04/05 01:05:15 d2.evaluation.evaluator]: [0mInference done 974/3489. 0.2396 s / img. ETA=0:11:25
[32m[04/05 01:05:21 d2.evaluation.evaluator]: [0mInference done 990/3489. 0.2399 s / img. ETA=0:11:23
[32m[04/05 01:05:26 d2.evaluation.evaluator]: [0mInference done 1006/3489. 0.2402 s / img. ETA=0:11:20
[32m[04/05 01:05:31 d2.evaluation.evaluator]: [0mInference done 1022/3489. 0.2404 s / img. ETA=0:11:18
[32m[04/05 01:05:37 d2.evaluation.evaluator]: [0mInference done 1038/3489. 0.2407 s / img. ETA=0:11:16
[32m[04/05 01:05:42 d2.evaluation.evaluator]: [0mInference done 1054/3489. 0.2410 s / img. ETA=0:11:13
[32m[04/05 01:05:47 d2.evaluation.evaluator]: [0mInference done 1070/3489. 0.2412 s / img. ETA=0:11:11
[32m[04/05 01:05:52 d2.evaluation.evaluator]: [0mInference done 1087/3489. 0.2413 s / img. ETA=0:11:07
[32m[04/05 01:05:57 d2.evaluation.evaluator]: [0mInference done 1105/3489. 0.2414 s / img. ETA=0:11:02
[32m[04/05 01:06:02 d2.evaluation.evaluator]: [0mInference done 1123/3489. 0.2414 s / img. ETA=0:10:57
[32m[04/05 01:06:08 d2.evaluation.evaluator]: [0mInference done 1140/3489. 0.2415 s / img. ETA=0:10:54
[32m[04/05 01:06:13 d2.evaluation.evaluator]: [0mInference done 1157/3489. 0.2417 s / img. ETA=0:10:50
[32m[04/05 01:06:18 d2.evaluation.evaluator]: [0mInference done 1173/3489. 0.2418 s / img. ETA=0:10:47
[32m[04/05 01:06:23 d2.evaluation.evaluator]: [0mInference done 1190/3489. 0.2419 s / img. ETA=0:10:43
[32m[04/05 01:06:28 d2.evaluation.evaluator]: [0mInference done 1207/3489. 0.2420 s / img. ETA=0:10:38
[32m[04/05 01:06:33 d2.evaluation.evaluator]: [0mInference done 1225/3489. 0.2420 s / img. ETA=0:10:34
[32m[04/05 01:06:38 d2.evaluation.evaluator]: [0mInference done 1243/3489. 0.2420 s / img. ETA=0:10:29
[32m[04/05 01:06:43 d2.evaluation.evaluator]: [0mInference done 1263/3489. 0.2418 s / img. ETA=0:10:22
[32m[04/05 01:06:49 d2.evaluation.evaluator]: [0mInference done 1285/3489. 0.2416 s / img. ETA=0:10:14
[32m[04/05 01:06:54 d2.evaluation.evaluator]: [0mInference done 1306/3489. 0.2414 s / img. ETA=0:10:07
[32m[04/05 01:06:59 d2.evaluation.evaluator]: [0mInference done 1327/3489. 0.2413 s / img. ETA=0:10:00
[32m[04/05 01:07:04 d2.evaluation.evaluator]: [0mInference done 1348/3489. 0.2411 s / img. ETA=0:09:53
[32m[04/05 01:07:09 d2.evaluation.evaluator]: [0mInference done 1369/3489. 0.2410 s / img. ETA=0:09:46
[32m[04/05 01:07:14 d2.evaluation.evaluator]: [0mInference done 1390/3489. 0.2408 s / img. ETA=0:09:39
[32m[04/05 01:07:19 d2.evaluation.evaluator]: [0mInference done 1411/3489. 0.2407 s / img. ETA=0:09:32
[32m[04/05 01:07:24 d2.evaluation.evaluator]: [0mInference done 1431/3489. 0.2406 s / img. ETA=0:09:26
[32m[04/05 01:07:29 d2.evaluation.evaluator]: [0mInference done 1452/3489. 0.2405 s / img. ETA=0:09:20
[32m[04/05 01:07:35 d2.evaluation.evaluator]: [0mInference done 1473/3489. 0.2404 s / img. ETA=0:09:13
[32m[04/05 01:07:40 d2.evaluation.evaluator]: [0mInference done 1494/3489. 0.2403 s / img. ETA=0:09:06
[32m[04/05 01:07:45 d2.evaluation.evaluator]: [0mInference done 1515/3489. 0.2402 s / img. ETA=0:09:00
[32m[04/05 01:07:50 d2.evaluation.evaluator]: [0mInference done 1536/3489. 0.2400 s / img. ETA=0:08:53
[32m[04/05 01:07:55 d2.evaluation.evaluator]: [0mInference done 1557/3489. 0.2399 s / img. ETA=0:08:47
[32m[04/05 01:08:00 d2.evaluation.evaluator]: [0mInference done 1577/3489. 0.2399 s / img. ETA=0:08:41
[32m[04/05 01:08:05 d2.evaluation.evaluator]: [0mInference done 1597/3489. 0.2398 s / img. ETA=0:08:35
[32m[04/05 01:08:10 d2.evaluation.evaluator]: [0mInference done 1615/3489. 0.2399 s / img. ETA=0:08:30
[32m[04/05 01:08:16 d2.evaluation.evaluator]: [0mInference done 1633/3489. 0.2399 s / img. ETA=0:08:26
[32m[04/05 01:08:21 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2399 s / img. ETA=0:08:21
[32m[04/05 01:08:26 d2.evaluation.evaluator]: [0mInference done 1670/3489. 0.2400 s / img. ETA=0:08:16
[32m[04/05 01:08:31 d2.evaluation.evaluator]: [0mInference done 1687/3489. 0.2400 s / img. ETA=0:08:12
[32m[04/05 01:08:36 d2.evaluation.evaluator]: [0mInference done 1703/3489. 0.2402 s / img. ETA=0:08:08
[32m[04/05 01:08:42 d2.evaluation.evaluator]: [0mInference done 1720/3489. 0.2403 s / img. ETA=0:08:04
[32m[04/05 01:08:47 d2.evaluation.evaluator]: [0mInference done 1736/3489. 0.2404 s / img. ETA=0:08:01
[32m[04/05 01:08:52 d2.evaluation.evaluator]: [0mInference done 1752/3489. 0.2405 s / img. ETA=0:07:57
[32m[04/05 01:08:57 d2.evaluation.evaluator]: [0mInference done 1767/3489. 0.2407 s / img. ETA=0:07:54
[32m[04/05 01:09:02 d2.evaluation.evaluator]: [0mInference done 1783/3489. 0.2408 s / img. ETA=0:07:51
[32m[04/05 01:09:07 d2.evaluation.evaluator]: [0mInference done 1798/3489. 0.2410 s / img. ETA=0:07:47
[32m[04/05 01:09:12 d2.evaluation.evaluator]: [0mInference done 1813/3489. 0.2411 s / img. ETA=0:07:44
[32m[04/05 01:09:18 d2.evaluation.evaluator]: [0mInference done 1828/3489. 0.2412 s / img. ETA=0:07:41
[32m[04/05 01:09:23 d2.evaluation.evaluator]: [0mInference done 1843/3489. 0.2414 s / img. ETA=0:07:37
[32m[04/05 01:09:28 d2.evaluation.evaluator]: [0mInference done 1858/3489. 0.2415 s / img. ETA=0:07:34
[32m[04/05 01:09:33 d2.evaluation.evaluator]: [0mInference done 1873/3489. 0.2417 s / img. ETA=0:07:30
[32m[04/05 01:09:38 d2.evaluation.evaluator]: [0mInference done 1888/3489. 0.2418 s / img. ETA=0:07:27
[32m[04/05 01:09:43 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2419 s / img. ETA=0:07:23
[32m[04/05 01:09:48 d2.evaluation.evaluator]: [0mInference done 1918/3489. 0.2421 s / img. ETA=0:07:20
[32m[04/05 01:09:53 d2.evaluation.evaluator]: [0mInference done 1934/3489. 0.2422 s / img. ETA=0:07:16
[32m[04/05 01:09:58 d2.evaluation.evaluator]: [0mInference done 1949/3489. 0.2423 s / img. ETA=0:07:12
[32m[04/05 01:10:03 d2.evaluation.evaluator]: [0mInference done 1964/3489. 0.2424 s / img. ETA=0:07:09
[32m[04/05 01:10:08 d2.evaluation.evaluator]: [0mInference done 1979/3489. 0.2425 s / img. ETA=0:07:05
[32m[04/05 01:10:13 d2.evaluation.evaluator]: [0mInference done 1995/3489. 0.2426 s / img. ETA=0:07:01
[32m[04/05 01:10:18 d2.evaluation.evaluator]: [0mInference done 2013/3489. 0.2426 s / img. ETA=0:06:56
[32m[04/05 01:10:23 d2.evaluation.evaluator]: [0mInference done 2030/3489. 0.2426 s / img. ETA=0:06:52
[32m[04/05 01:10:29 d2.evaluation.evaluator]: [0mInference done 2047/3489. 0.2427 s / img. ETA=0:06:47
[32m[04/05 01:10:34 d2.evaluation.evaluator]: [0mInference done 2063/3489. 0.2428 s / img. ETA=0:06:43
[32m[04/05 01:10:39 d2.evaluation.evaluator]: [0mInference done 2079/3489. 0.2429 s / img. ETA=0:06:39
[32m[04/05 01:10:44 d2.evaluation.evaluator]: [0mInference done 2094/3489. 0.2430 s / img. ETA=0:06:35
[32m[04/05 01:10:49 d2.evaluation.evaluator]: [0mInference done 2109/3489. 0.2431 s / img. ETA=0:06:31
[32m[04/05 01:10:54 d2.evaluation.evaluator]: [0mInference done 2125/3489. 0.2432 s / img. ETA=0:06:27
[32m[04/05 01:11:00 d2.evaluation.evaluator]: [0mInference done 2140/3489. 0.2435 s / img. ETA=0:06:24
[32m[04/05 01:11:05 d2.evaluation.evaluator]: [0mInference done 2155/3489. 0.2436 s / img. ETA=0:06:20
[32m[04/05 01:11:10 d2.evaluation.evaluator]: [0mInference done 2170/3489. 0.2437 s / img. ETA=0:06:16
[32m[04/05 01:11:15 d2.evaluation.evaluator]: [0mInference done 2185/3489. 0.2438 s / img. ETA=0:06:12
[32m[04/05 01:11:20 d2.evaluation.evaluator]: [0mInference done 2200/3489. 0.2439 s / img. ETA=0:06:08
[32m[04/05 01:11:25 d2.evaluation.evaluator]: [0mInference done 2216/3489. 0.2440 s / img. ETA=0:06:04
[32m[04/05 01:11:30 d2.evaluation.evaluator]: [0mInference done 2232/3489. 0.2441 s / img. ETA=0:06:00
[32m[04/05 01:11:35 d2.evaluation.evaluator]: [0mInference done 2248/3489. 0.2441 s / img. ETA=0:05:56
[32m[04/05 01:11:41 d2.evaluation.evaluator]: [0mInference done 2264/3489. 0.2442 s / img. ETA=0:05:51
[32m[04/05 01:11:46 d2.evaluation.evaluator]: [0mInference done 2281/3489. 0.2442 s / img. ETA=0:05:47
[32m[04/05 01:11:51 d2.evaluation.evaluator]: [0mInference done 2297/3489. 0.2443 s / img. ETA=0:05:42
[32m[04/05 01:11:56 d2.evaluation.evaluator]: [0mInference done 2313/3489. 0.2444 s / img. ETA=0:05:38
[32m[04/05 01:12:01 d2.evaluation.evaluator]: [0mInference done 2329/3489. 0.2445 s / img. ETA=0:05:34
[32m[04/05 01:12:07 d2.evaluation.evaluator]: [0mInference done 2345/3489. 0.2445 s / img. ETA=0:05:29
[32m[04/05 01:12:12 d2.evaluation.evaluator]: [0mInference done 2362/3489. 0.2446 s / img. ETA=0:05:25
[32m[04/05 01:12:17 d2.evaluation.evaluator]: [0mInference done 2381/3489. 0.2445 s / img. ETA=0:05:19
[32m[04/05 01:12:22 d2.evaluation.evaluator]: [0mInference done 2400/3489. 0.2445 s / img. ETA=0:05:14
[32m[04/05 01:12:28 d2.evaluation.evaluator]: [0mInference done 2418/3489. 0.2445 s / img. ETA=0:05:08
[32m[04/05 01:12:33 d2.evaluation.evaluator]: [0mInference done 2436/3489. 0.2445 s / img. ETA=0:05:03
[32m[04/05 01:12:38 d2.evaluation.evaluator]: [0mInference done 2453/3489. 0.2445 s / img. ETA=0:04:58
[32m[04/05 01:12:43 d2.evaluation.evaluator]: [0mInference done 2469/3489. 0.2446 s / img. ETA=0:04:54
[32m[04/05 01:12:48 d2.evaluation.evaluator]: [0mInference done 2485/3489. 0.2446 s / img. ETA=0:04:49
[32m[04/05 01:12:53 d2.evaluation.evaluator]: [0mInference done 2505/3489. 0.2446 s / img. ETA=0:04:43
[32m[04/05 01:12:58 d2.evaluation.evaluator]: [0mInference done 2525/3489. 0.2445 s / img. ETA=0:04:37
[32m[04/05 01:13:03 d2.evaluation.evaluator]: [0mInference done 2545/3489. 0.2444 s / img. ETA=0:04:31
[32m[04/05 01:13:08 d2.evaluation.evaluator]: [0mInference done 2565/3489. 0.2443 s / img. ETA=0:04:25
[32m[04/05 01:13:14 d2.evaluation.evaluator]: [0mInference done 2586/3489. 0.2442 s / img. ETA=0:04:19
[32m[04/05 01:13:19 d2.evaluation.evaluator]: [0mInference done 2606/3489. 0.2442 s / img. ETA=0:04:13
[32m[04/05 01:13:24 d2.evaluation.evaluator]: [0mInference done 2627/3489. 0.2441 s / img. ETA=0:04:07
[32m[04/05 01:13:29 d2.evaluation.evaluator]: [0mInference done 2648/3489. 0.2439 s / img. ETA=0:04:01
[32m[04/05 01:13:34 d2.evaluation.evaluator]: [0mInference done 2668/3489. 0.2439 s / img. ETA=0:03:55
[32m[04/05 01:13:39 d2.evaluation.evaluator]: [0mInference done 2687/3489. 0.2439 s / img. ETA=0:03:49
[32m[04/05 01:13:44 d2.evaluation.evaluator]: [0mInference done 2707/3489. 0.2438 s / img. ETA=0:03:43
[32m[04/05 01:13:50 d2.evaluation.evaluator]: [0mInference done 2727/3489. 0.2437 s / img. ETA=0:03:37
[32m[04/05 01:13:55 d2.evaluation.evaluator]: [0mInference done 2747/3489. 0.2437 s / img. ETA=0:03:31
[32m[04/05 01:14:00 d2.evaluation.evaluator]: [0mInference done 2767/3489. 0.2436 s / img. ETA=0:03:26
[32m[04/05 01:14:05 d2.evaluation.evaluator]: [0mInference done 2787/3489. 0.2435 s / img. ETA=0:03:20
[32m[04/05 01:14:10 d2.evaluation.evaluator]: [0mInference done 2807/3489. 0.2435 s / img. ETA=0:03:14
[32m[04/05 01:14:16 d2.evaluation.evaluator]: [0mInference done 2827/3489. 0.2434 s / img. ETA=0:03:08
[32m[04/05 01:14:21 d2.evaluation.evaluator]: [0mInference done 2847/3489. 0.2434 s / img. ETA=0:03:02
[32m[04/05 01:14:26 d2.evaluation.evaluator]: [0mInference done 2867/3489. 0.2433 s / img. ETA=0:02:56
[32m[04/05 01:14:31 d2.evaluation.evaluator]: [0mInference done 2887/3489. 0.2432 s / img. ETA=0:02:51
[32m[04/05 01:14:36 d2.evaluation.evaluator]: [0mInference done 2908/3489. 0.2432 s / img. ETA=0:02:45
[32m[04/05 01:14:41 d2.evaluation.evaluator]: [0mInference done 2929/3489. 0.2431 s / img. ETA=0:02:38
[32m[04/05 01:14:46 d2.evaluation.evaluator]: [0mInference done 2950/3489. 0.2430 s / img. ETA=0:02:32
[32m[04/05 01:14:52 d2.evaluation.evaluator]: [0mInference done 2971/3489. 0.2429 s / img. ETA=0:02:26
[32m[04/05 01:14:57 d2.evaluation.evaluator]: [0mInference done 2991/3489. 0.2428 s / img. ETA=0:02:20
[32m[04/05 01:15:02 d2.evaluation.evaluator]: [0mInference done 3010/3489. 0.2428 s / img. ETA=0:02:15
[32m[04/05 01:15:07 d2.evaluation.evaluator]: [0mInference done 3030/3489. 0.2427 s / img. ETA=0:02:09
[32m[04/05 01:15:12 d2.evaluation.evaluator]: [0mInference done 3050/3489. 0.2427 s / img. ETA=0:02:04
[32m[04/05 01:15:17 d2.evaluation.evaluator]: [0mInference done 3070/3489. 0.2426 s / img. ETA=0:01:58
[32m[04/05 01:15:22 d2.evaluation.evaluator]: [0mInference done 3089/3489. 0.2426 s / img. ETA=0:01:52
[32m[04/05 01:15:27 d2.evaluation.evaluator]: [0mInference done 3108/3489. 0.2425 s / img. ETA=0:01:47
[32m[04/05 01:15:32 d2.evaluation.evaluator]: [0mInference done 3127/3489. 0.2425 s / img. ETA=0:01:42
[32m[04/05 01:15:37 d2.evaluation.evaluator]: [0mInference done 3146/3489. 0.2425 s / img. ETA=0:01:36
[32m[04/05 01:15:43 d2.evaluation.evaluator]: [0mInference done 3166/3489. 0.2424 s / img. ETA=0:01:31
[32m[04/05 01:15:48 d2.evaluation.evaluator]: [0mInference done 3187/3489. 0.2424 s / img. ETA=0:01:25
[32m[04/05 01:15:53 d2.evaluation.evaluator]: [0mInference done 3207/3489. 0.2423 s / img. ETA=0:01:19
[32m[04/05 01:15:58 d2.evaluation.evaluator]: [0mInference done 3227/3489. 0.2423 s / img. ETA=0:01:13
[32m[04/05 01:16:03 d2.evaluation.evaluator]: [0mInference done 3247/3489. 0.2422 s / img. ETA=0:01:08
[32m[04/05 01:16:09 d2.evaluation.evaluator]: [0mInference done 3268/3489. 0.2421 s / img. ETA=0:01:02
[32m[04/05 01:16:14 d2.evaluation.evaluator]: [0mInference done 3289/3489. 0.2421 s / img. ETA=0:00:56
[32m[04/05 01:16:19 d2.evaluation.evaluator]: [0mInference done 3311/3489. 0.2420 s / img. ETA=0:00:49
[32m[04/05 01:16:24 d2.evaluation.evaluator]: [0mInference done 3333/3489. 0.2419 s / img. ETA=0:00:43
[32m[04/05 01:16:29 d2.evaluation.evaluator]: [0mInference done 3355/3489. 0.2419 s / img. ETA=0:00:37
[32m[04/05 01:16:34 d2.evaluation.evaluator]: [0mInference done 3376/3489. 0.2418 s / img. ETA=0:00:31
[32m[04/05 01:16:40 d2.evaluation.evaluator]: [0mInference done 3397/3489. 0.2418 s / img. ETA=0:00:25
[32m[04/05 01:16:45 d2.evaluation.evaluator]: [0mInference done 3418/3489. 0.2417 s / img. ETA=0:00:19
[32m[04/05 01:16:50 d2.evaluation.evaluator]: [0mInference done 3439/3489. 0.2416 s / img. ETA=0:00:13
[32m[04/05 01:16:55 d2.evaluation.evaluator]: [0mInference done 3459/3489. 0.2416 s / img. ETA=0:00:08
[32m[04/05 01:17:00 d2.evaluation.evaluator]: [0mInference done 3479/3489. 0.2415 s / img. ETA=0:00:02
[32m[04/05 01:17:03 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:11.370351 (0.278809 s / img per device, on 1 devices)
[32m[04/05 01:17:03 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:01 (0.241514 s / img per device, on 1 devices)
[32m[04/05 01:17:05 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 01:17:05 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_6/coco_instances_results.json
[32m[04/05 01:17:06 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.59 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.56 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[32m[04/05 01:17:09 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.660 | 76.129 | 38.972 | 29.274 | 51.055 | 56.815 |
[32m[04/05 01:17:09 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 64.456 | Pedestrian | 22.864 |
Loading and preparing results...
DONE (t=2.35s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.47 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754
[32m[04/05 01:17:19 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.384 | 71.066 | 38.186 | 21.520 | 48.032 | 67.511 |
[32m[04/05 01:17:19 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.998 | Pedestrian | 17.769 |
[32m[04/05 01:17:19 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: 43.6598,76.1292,38.9724,29.2744,51.0551,56.8151
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:17:19 d2.evaluation.testing]: [0mcopypaste: 40.3836,71.0661,38.1857,21.5196,48.0318,67.5115
evaluated
Test [7][['res2', 'res3', 'res4']]
[32m[04/05 01:17:20 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/05 01:17:20 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/05 01:17:20 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 01:17:20 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 01:17:20 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/05 01:17:20 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/05 01:17:21 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/05 01:17:21 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 01:17:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 01:17:21 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/05 01:17:21 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/05 01:17:21 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/05 01:17:47 d2.utils.events]: [0m eta: 0:02:34  iter: 19  total_loss: 1.723  loss_cls: 0.7554  loss_box_reg: 0.3003  loss_mask: 0.6724  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.007573  total_val_loss: 1.99  val_loss_cls: 0.71  val_loss_box_reg: 0.4993  val_loss_mask: 0.6815  val_loss_rpn_cls: 0.04333  val_loss_rpn_loc: 0.01591  time: 0.8698  data_time: 0.0296  lr: 0.00019981  max_mem: 4747M
[32m[04/05 01:18:11 d2.utils.events]: [0m eta: 0:02:18  iter: 39  total_loss: 0.8344  loss_cls: 0.1781  loss_box_reg: 0.271  loss_mask: 0.3569  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.004749  total_val_loss: 1.227  val_loss_cls: 0.2512  val_loss_box_reg: 0.457  val_loss_mask: 0.5103  val_loss_rpn_cls: 0.04601  val_loss_rpn_loc: 0.01214  time: 0.8703  data_time: 0.0076  lr: 0.00039961  max_mem: 4747M
[32m[04/05 01:18:36 d2.utils.events]: [0m eta: 0:02:01  iter: 59  total_loss: 0.7623  loss_cls: 0.1023  loss_box_reg: 0.3961  loss_mask: 0.2154  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.01133  total_val_loss: 1.234  val_loss_cls: 0.2607  val_loss_box_reg: 0.4962  val_loss_mask: 0.4009  val_loss_rpn_cls: 0.03202  val_loss_rpn_loc: 0.0155  time: 0.8740  data_time: 0.0078  lr: 0.00059941  max_mem: 4747M
[32m[04/05 01:19:01 d2.utils.events]: [0m eta: 0:01:44  iter: 79  total_loss: 0.6063  loss_cls: 0.07436  loss_box_reg: 0.2875  loss_mask: 0.1645  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.009424  total_val_loss: 0.8363  val_loss_cls: 0.154  val_loss_box_reg: 0.3937  val_loss_mask: 0.3726  val_loss_rpn_cls: 0.02414  val_loss_rpn_loc: 0.009659  time: 0.8758  data_time: 0.0082  lr: 0.00079921  max_mem: 4747M
[32m[04/05 01:19:25 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:19:25 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:19:26 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:19:26 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 01:19:26 d2.utils.events]: [0m eta: 0:01:27  iter: 99  total_loss: 0.3365  loss_cls: 0.03629  loss_box_reg: 0.1042  loss_mask: 0.151  loss_rpn_cls: 0.006555  loss_rpn_loc: 0.006463  total_val_loss: 0.8729  val_loss_cls: 0.1795  val_loss_box_reg: 0.2913  val_loss_mask: 0.3338  val_loss_rpn_cls: 0.02553  val_loss_rpn_loc: 0.01639  time: 0.8756  data_time: 0.0070  lr: 0.00099901  max_mem: 4747M
[32m[04/05 01:19:51 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.3968  loss_cls: 0.06002  loss_box_reg: 0.1308  loss_mask: 0.1778  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.01194  total_val_loss: 1.011  val_loss_cls: 0.2377  val_loss_box_reg: 0.2521  val_loss_mask: 0.4057  val_loss_rpn_cls: 0.01691  val_loss_rpn_loc: 0.01459  time: 0.8766  data_time: 0.0069  lr: 0.0011988  max_mem: 4747M
[32m[04/05 01:20:15 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.2927  loss_cls: 0.04107  loss_box_reg: 0.07806  loss_mask: 0.1378  loss_rpn_cls: 0.007144  loss_rpn_loc: 0.007053  total_val_loss: 1.142  val_loss_cls: 0.2428  val_loss_box_reg: 0.3097  val_loss_mask: 0.4791  val_loss_rpn_cls: 0.02633  val_loss_rpn_loc: 0.01218  time: 0.8756  data_time: 0.0070  lr: 0.0013986  max_mem: 4747M
[32m[04/05 01:20:40 d2.utils.events]: [0m eta: 0:00:34  iter: 159  total_loss: 0.3135  loss_cls: 0.04772  loss_box_reg: 0.0837  loss_mask: 0.1502  loss_rpn_cls: 0.005091  loss_rpn_loc: 0.006416  total_val_loss: 0.7007  val_loss_cls: 0.1205  val_loss_box_reg: 0.1868  val_loss_mask: 0.399  val_loss_rpn_cls: 0.02172  val_loss_rpn_loc: 0.01406  time: 0.8745  data_time: 0.0068  lr: 0.0015984  max_mem: 4747M
[32m[04/05 01:21:05 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.2988  loss_cls: 0.04721  loss_box_reg: 0.1042  loss_mask: 0.165  loss_rpn_cls: 0.004463  loss_rpn_loc: 0.008177  total_val_loss: 0.6012  val_loss_cls: 0.1182  val_loss_box_reg: 0.203  val_loss_mask: 0.2383  val_loss_rpn_cls: 0.01865  val_loss_rpn_loc: 0.01272  time: 0.8749  data_time: 0.0079  lr: 0.0017982  max_mem: 4747M
[32m[04/05 01:21:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:21:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:21:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:21:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 01:21:31 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.3268  loss_cls: 0.05544  loss_box_reg: 0.1079  loss_mask: 0.1338  loss_rpn_cls: 0.0067  loss_rpn_loc: 0.01233  total_val_loss: 0.8649  val_loss_cls: 0.1806  val_loss_box_reg: 0.3112  val_loss_mask: 0.3173  val_loss_rpn_cls: 0.01669  val_loss_rpn_loc: 0.01453  time: 0.8753  data_time: 0.0085  lr: 0.001998  max_mem: 4747M
[32m[04/05 01:21:31 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:53 (0.8753 s / it)
[32m[04/05 01:21:31 d2.engine.hooks]: [0mTotal training time: 0:04:06 (0:01:13 on hooks)
[32m[04/05 01:21:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:21:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:21:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:21:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/05 01:21:31 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/05 01:21:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:21:32 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:21:32 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/05 01:21:32 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/05 01:21:35 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2380 s / img. ETA=0:14:56
[32m[04/05 01:21:40 d2.evaluation.evaluator]: [0mInference done 31/3489. 0.2343 s / img. ETA=0:14:37
[32m[04/05 01:21:46 d2.evaluation.evaluator]: [0mInference done 52/3489. 0.2326 s / img. ETA=0:14:20
[32m[04/05 01:21:51 d2.evaluation.evaluator]: [0mInference done 73/3489. 0.2324 s / img. ETA=0:14:10
[32m[04/05 01:21:56 d2.evaluation.evaluator]: [0mInference done 92/3489. 0.2337 s / img. ETA=0:14:23
[32m[04/05 01:22:01 d2.evaluation.evaluator]: [0mInference done 109/3489. 0.2360 s / img. ETA=0:14:46
[32m[04/05 01:22:06 d2.evaluation.evaluator]: [0mInference done 125/3489. 0.2383 s / img. ETA=0:15:07
[32m[04/05 01:22:11 d2.evaluation.evaluator]: [0mInference done 140/3489. 0.2405 s / img. ETA=0:15:27
[32m[04/05 01:22:17 d2.evaluation.evaluator]: [0mInference done 155/3489. 0.2427 s / img. ETA=0:15:47
[32m[04/05 01:22:22 d2.evaluation.evaluator]: [0mInference done 170/3489. 0.2442 s / img. ETA=0:15:59
[32m[04/05 01:22:27 d2.evaluation.evaluator]: [0mInference done 186/3489. 0.2450 s / img. ETA=0:16:03
[32m[04/05 01:22:32 d2.evaluation.evaluator]: [0mInference done 203/3489. 0.2451 s / img. ETA=0:16:00
[32m[04/05 01:22:37 d2.evaluation.evaluator]: [0mInference done 222/3489. 0.2446 s / img. ETA=0:15:49
[32m[04/05 01:22:42 d2.evaluation.evaluator]: [0mInference done 240/3489. 0.2443 s / img. ETA=0:15:41
[32m[04/05 01:22:47 d2.evaluation.evaluator]: [0mInference done 257/3489. 0.2448 s / img. ETA=0:15:40
[32m[04/05 01:22:52 d2.evaluation.evaluator]: [0mInference done 274/3489. 0.2449 s / img. ETA=0:15:36
[32m[04/05 01:22:57 d2.evaluation.evaluator]: [0mInference done 291/3489. 0.2450 s / img. ETA=0:15:33
[32m[04/05 01:23:03 d2.evaluation.evaluator]: [0mInference done 308/3489. 0.2452 s / img. ETA=0:15:31
[32m[04/05 01:23:08 d2.evaluation.evaluator]: [0mInference done 325/3489. 0.2454 s / img. ETA=0:15:29
[32m[04/05 01:23:13 d2.evaluation.evaluator]: [0mInference done 341/3489. 0.2458 s / img. ETA=0:15:29
[32m[04/05 01:23:18 d2.evaluation.evaluator]: [0mInference done 357/3489. 0.2462 s / img. ETA=0:15:27
[32m[04/05 01:23:23 d2.evaluation.evaluator]: [0mInference done 373/3489. 0.2465 s / img. ETA=0:15:25
[32m[04/05 01:23:28 d2.evaluation.evaluator]: [0mInference done 389/3489. 0.2467 s / img. ETA=0:15:23
[32m[04/05 01:23:33 d2.evaluation.evaluator]: [0mInference done 407/3489. 0.2466 s / img. ETA=0:15:16
[32m[04/05 01:23:39 d2.evaluation.evaluator]: [0mInference done 424/3489. 0.2467 s / img. ETA=0:15:12
[32m[04/05 01:23:44 d2.evaluation.evaluator]: [0mInference done 444/3489. 0.2461 s / img. ETA=0:15:00
[32m[04/05 01:23:49 d2.evaluation.evaluator]: [0mInference done 464/3489. 0.2456 s / img. ETA=0:14:48
[32m[04/05 01:23:54 d2.evaluation.evaluator]: [0mInference done 484/3489. 0.2451 s / img. ETA=0:14:37
[32m[04/05 01:23:59 d2.evaluation.evaluator]: [0mInference done 505/3489. 0.2445 s / img. ETA=0:14:25
[32m[04/05 01:24:04 d2.evaluation.evaluator]: [0mInference done 525/3489. 0.2443 s / img. ETA=0:14:15
[32m[04/05 01:24:09 d2.evaluation.evaluator]: [0mInference done 546/3489. 0.2437 s / img. ETA=0:14:03
[32m[04/05 01:24:14 d2.evaluation.evaluator]: [0mInference done 565/3489. 0.2435 s / img. ETA=0:13:56
[32m[04/05 01:24:19 d2.evaluation.evaluator]: [0mInference done 583/3489. 0.2436 s / img. ETA=0:13:51
[32m[04/05 01:24:24 d2.evaluation.evaluator]: [0mInference done 600/3489. 0.2437 s / img. ETA=0:13:47
[32m[04/05 01:24:29 d2.evaluation.evaluator]: [0mInference done 618/3489. 0.2436 s / img. ETA=0:13:42
[32m[04/05 01:24:35 d2.evaluation.evaluator]: [0mInference done 635/3489. 0.2437 s / img. ETA=0:13:38
[32m[04/05 01:24:40 d2.evaluation.evaluator]: [0mInference done 653/3489. 0.2437 s / img. ETA=0:13:32
[32m[04/05 01:24:45 d2.evaluation.evaluator]: [0mInference done 672/3489. 0.2435 s / img. ETA=0:13:26
[32m[04/05 01:24:50 d2.evaluation.evaluator]: [0mInference done 692/3489. 0.2432 s / img. ETA=0:13:18
[32m[04/05 01:24:55 d2.evaluation.evaluator]: [0mInference done 712/3489. 0.2429 s / img. ETA=0:13:09
[32m[04/05 01:25:00 d2.evaluation.evaluator]: [0mInference done 732/3489. 0.2426 s / img. ETA=0:13:02
[32m[04/05 01:25:05 d2.evaluation.evaluator]: [0mInference done 752/3489. 0.2423 s / img. ETA=0:12:54
[32m[04/05 01:25:10 d2.evaluation.evaluator]: [0mInference done 772/3489. 0.2421 s / img. ETA=0:12:46
[32m[04/05 01:25:15 d2.evaluation.evaluator]: [0mInference done 792/3489. 0.2419 s / img. ETA=0:12:38
[32m[04/05 01:25:20 d2.evaluation.evaluator]: [0mInference done 813/3489. 0.2416 s / img. ETA=0:12:30
[32m[04/05 01:25:25 d2.evaluation.evaluator]: [0mInference done 834/3489. 0.2413 s / img. ETA=0:12:21
[32m[04/05 01:25:31 d2.evaluation.evaluator]: [0mInference done 855/3489. 0.2411 s / img. ETA=0:12:13
[32m[04/05 01:25:36 d2.evaluation.evaluator]: [0mInference done 876/3489. 0.2408 s / img. ETA=0:12:05
[32m[04/05 01:25:41 d2.evaluation.evaluator]: [0mInference done 897/3489. 0.2406 s / img. ETA=0:11:57
[32m[04/05 01:25:46 d2.evaluation.evaluator]: [0mInference done 914/3489. 0.2408 s / img. ETA=0:11:54
[32m[04/05 01:25:51 d2.evaluation.evaluator]: [0mInference done 930/3489. 0.2411 s / img. ETA=0:11:51
[32m[04/05 01:25:56 d2.evaluation.evaluator]: [0mInference done 946/3489. 0.2413 s / img. ETA=0:11:49
[32m[04/05 01:26:02 d2.evaluation.evaluator]: [0mInference done 962/3489. 0.2416 s / img. ETA=0:11:47
[32m[04/05 01:26:07 d2.evaluation.evaluator]: [0mInference done 978/3489. 0.2419 s / img. ETA=0:11:44
[32m[04/05 01:26:12 d2.evaluation.evaluator]: [0mInference done 994/3489. 0.2421 s / img. ETA=0:11:42
[32m[04/05 01:26:17 d2.evaluation.evaluator]: [0mInference done 1009/3489. 0.2424 s / img. ETA=0:11:40
[32m[04/05 01:26:23 d2.evaluation.evaluator]: [0mInference done 1025/3489. 0.2426 s / img. ETA=0:11:37
[32m[04/05 01:26:28 d2.evaluation.evaluator]: [0mInference done 1041/3489. 0.2428 s / img. ETA=0:11:34
[32m[04/05 01:26:33 d2.evaluation.evaluator]: [0mInference done 1057/3489. 0.2430 s / img. ETA=0:11:31
[32m[04/05 01:26:38 d2.evaluation.evaluator]: [0mInference done 1073/3489. 0.2432 s / img. ETA=0:11:28
[32m[04/05 01:26:44 d2.evaluation.evaluator]: [0mInference done 1090/3489. 0.2433 s / img. ETA=0:11:24
[32m[04/05 01:26:49 d2.evaluation.evaluator]: [0mInference done 1109/3489. 0.2432 s / img. ETA=0:11:18
[32m[04/05 01:26:54 d2.evaluation.evaluator]: [0mInference done 1126/3489. 0.2433 s / img. ETA=0:11:14
[32m[04/05 01:26:59 d2.evaluation.evaluator]: [0mInference done 1142/3489. 0.2435 s / img. ETA=0:11:11
[32m[04/05 01:27:04 d2.evaluation.evaluator]: [0mInference done 1158/3489. 0.2437 s / img. ETA=0:11:08
[32m[04/05 01:27:10 d2.evaluation.evaluator]: [0mInference done 1174/3489. 0.2438 s / img. ETA=0:11:04
[32m[04/05 01:27:15 d2.evaluation.evaluator]: [0mInference done 1191/3489. 0.2439 s / img. ETA=0:11:00
[32m[04/05 01:27:20 d2.evaluation.evaluator]: [0mInference done 1208/3489. 0.2440 s / img. ETA=0:10:56
[32m[04/05 01:27:25 d2.evaluation.evaluator]: [0mInference done 1225/3489. 0.2441 s / img. ETA=0:10:51
[32m[04/05 01:27:30 d2.evaluation.evaluator]: [0mInference done 1242/3489. 0.2441 s / img. ETA=0:10:46
[32m[04/05 01:27:35 d2.evaluation.evaluator]: [0mInference done 1261/3489. 0.2440 s / img. ETA=0:10:40
[32m[04/05 01:27:40 d2.evaluation.evaluator]: [0mInference done 1283/3489. 0.2438 s / img. ETA=0:10:32
[32m[04/05 01:27:45 d2.evaluation.evaluator]: [0mInference done 1305/3489. 0.2435 s / img. ETA=0:10:24
[32m[04/05 01:27:51 d2.evaluation.evaluator]: [0mInference done 1327/3489. 0.2432 s / img. ETA=0:10:16
[32m[04/05 01:27:56 d2.evaluation.evaluator]: [0mInference done 1348/3489. 0.2430 s / img. ETA=0:10:08
[32m[04/05 01:28:01 d2.evaluation.evaluator]: [0mInference done 1369/3489. 0.2428 s / img. ETA=0:10:01
[32m[04/05 01:28:06 d2.evaluation.evaluator]: [0mInference done 1390/3489. 0.2427 s / img. ETA=0:09:53
[32m[04/05 01:28:11 d2.evaluation.evaluator]: [0mInference done 1411/3489. 0.2425 s / img. ETA=0:09:46
[32m[04/05 01:28:16 d2.evaluation.evaluator]: [0mInference done 1432/3489. 0.2423 s / img. ETA=0:09:39
[32m[04/05 01:28:21 d2.evaluation.evaluator]: [0mInference done 1453/3489. 0.2421 s / img. ETA=0:09:32
[32m[04/05 01:28:26 d2.evaluation.evaluator]: [0mInference done 1474/3489. 0.2420 s / img. ETA=0:09:25
[32m[04/05 01:28:31 d2.evaluation.evaluator]: [0mInference done 1495/3489. 0.2418 s / img. ETA=0:09:18
[32m[04/05 01:28:36 d2.evaluation.evaluator]: [0mInference done 1516/3489. 0.2417 s / img. ETA=0:09:11
[32m[04/05 01:28:41 d2.evaluation.evaluator]: [0mInference done 1537/3489. 0.2415 s / img. ETA=0:09:04
[32m[04/05 01:28:47 d2.evaluation.evaluator]: [0mInference done 1558/3489. 0.2414 s / img. ETA=0:08:57
[32m[04/05 01:28:52 d2.evaluation.evaluator]: [0mInference done 1579/3489. 0.2413 s / img. ETA=0:08:51
[32m[04/05 01:28:57 d2.evaluation.evaluator]: [0mInference done 1599/3489. 0.2412 s / img. ETA=0:08:45
[32m[04/05 01:29:02 d2.evaluation.evaluator]: [0mInference done 1617/3489. 0.2412 s / img. ETA=0:08:40
[32m[04/05 01:29:07 d2.evaluation.evaluator]: [0mInference done 1634/3489. 0.2413 s / img. ETA=0:08:36
[32m[04/05 01:29:13 d2.evaluation.evaluator]: [0mInference done 1652/3489. 0.2414 s / img. ETA=0:08:31
[32m[04/05 01:29:18 d2.evaluation.evaluator]: [0mInference done 1669/3489. 0.2415 s / img. ETA=0:08:27
[32m[04/05 01:29:23 d2.evaluation.evaluator]: [0mInference done 1685/3489. 0.2416 s / img. ETA=0:08:23
[32m[04/05 01:29:28 d2.evaluation.evaluator]: [0mInference done 1701/3489. 0.2417 s / img. ETA=0:08:20
[32m[04/05 01:29:34 d2.evaluation.evaluator]: [0mInference done 1717/3489. 0.2418 s / img. ETA=0:08:16
[32m[04/05 01:29:39 d2.evaluation.evaluator]: [0mInference done 1733/3489. 0.2420 s / img. ETA=0:08:12
[32m[04/05 01:29:44 d2.evaluation.evaluator]: [0mInference done 1749/3489. 0.2421 s / img. ETA=0:08:09
[32m[04/05 01:29:49 d2.evaluation.evaluator]: [0mInference done 1764/3489. 0.2422 s / img. ETA=0:08:05
[32m[04/05 01:29:55 d2.evaluation.evaluator]: [0mInference done 1780/3489. 0.2424 s / img. ETA=0:08:02
[32m[04/05 01:30:00 d2.evaluation.evaluator]: [0mInference done 1796/3489. 0.2425 s / img. ETA=0:07:58
[32m[04/05 01:30:05 d2.evaluation.evaluator]: [0mInference done 1811/3489. 0.2426 s / img. ETA=0:07:54
[32m[04/05 01:30:10 d2.evaluation.evaluator]: [0mInference done 1827/3489. 0.2428 s / img. ETA=0:07:51
[32m[04/05 01:30:15 d2.evaluation.evaluator]: [0mInference done 1842/3489. 0.2429 s / img. ETA=0:07:47
[32m[04/05 01:30:20 d2.evaluation.evaluator]: [0mInference done 1857/3489. 0.2431 s / img. ETA=0:07:43
[32m[04/05 01:30:25 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2432 s / img. ETA=0:07:40
[32m[04/05 01:30:30 d2.evaluation.evaluator]: [0mInference done 1887/3489. 0.2433 s / img. ETA=0:07:36
[32m[04/05 01:30:36 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2434 s / img. ETA=0:07:32
[32m[04/05 01:30:41 d2.evaluation.evaluator]: [0mInference done 1918/3489. 0.2435 s / img. ETA=0:07:29
[32m[04/05 01:30:46 d2.evaluation.evaluator]: [0mInference done 1934/3489. 0.2437 s / img. ETA=0:07:25
[32m[04/05 01:30:51 d2.evaluation.evaluator]: [0mInference done 1949/3489. 0.2438 s / img. ETA=0:07:21
[32m[04/05 01:30:56 d2.evaluation.evaluator]: [0mInference done 1965/3489. 0.2439 s / img. ETA=0:07:17
[32m[04/05 01:31:01 d2.evaluation.evaluator]: [0mInference done 1980/3489. 0.2440 s / img. ETA=0:07:13
[32m[04/05 01:31:07 d2.evaluation.evaluator]: [0mInference done 1996/3489. 0.2441 s / img. ETA=0:07:09
[32m[04/05 01:31:12 d2.evaluation.evaluator]: [0mInference done 2013/3489. 0.2441 s / img. ETA=0:07:04
[32m[04/05 01:31:17 d2.evaluation.evaluator]: [0mInference done 2029/3489. 0.2442 s / img. ETA=0:07:00
[32m[04/05 01:31:22 d2.evaluation.evaluator]: [0mInference done 2045/3489. 0.2443 s / img. ETA=0:06:56
[32m[04/05 01:31:28 d2.evaluation.evaluator]: [0mInference done 2061/3489. 0.2444 s / img. ETA=0:06:52
[32m[04/05 01:31:33 d2.evaluation.evaluator]: [0mInference done 2076/3489. 0.2445 s / img. ETA=0:06:48
[32m[04/05 01:31:38 d2.evaluation.evaluator]: [0mInference done 2091/3489. 0.2446 s / img. ETA=0:06:44
[32m[04/05 01:31:43 d2.evaluation.evaluator]: [0mInference done 2106/3489. 0.2447 s / img. ETA=0:06:40
[32m[04/05 01:31:48 d2.evaluation.evaluator]: [0mInference done 2121/3489. 0.2448 s / img. ETA=0:06:37
[32m[04/05 01:31:53 d2.evaluation.evaluator]: [0mInference done 2137/3489. 0.2449 s / img. ETA=0:06:32
[32m[04/05 01:31:58 d2.evaluation.evaluator]: [0mInference done 2152/3489. 0.2450 s / img. ETA=0:06:28
[32m[04/05 01:32:04 d2.evaluation.evaluator]: [0mInference done 2168/3489. 0.2451 s / img. ETA=0:06:24
[32m[04/05 01:32:09 d2.evaluation.evaluator]: [0mInference done 2183/3489. 0.2452 s / img. ETA=0:06:20
[32m[04/05 01:32:14 d2.evaluation.evaluator]: [0mInference done 2198/3489. 0.2453 s / img. ETA=0:06:16
[32m[04/05 01:32:19 d2.evaluation.evaluator]: [0mInference done 2213/3489. 0.2454 s / img. ETA=0:06:12
[32m[04/05 01:32:24 d2.evaluation.evaluator]: [0mInference done 2228/3489. 0.2455 s / img. ETA=0:06:08
[32m[04/05 01:32:29 d2.evaluation.evaluator]: [0mInference done 2243/3489. 0.2456 s / img. ETA=0:06:04
[32m[04/05 01:32:34 d2.evaluation.evaluator]: [0mInference done 2259/3489. 0.2456 s / img. ETA=0:06:00
[32m[04/05 01:32:39 d2.evaluation.evaluator]: [0mInference done 2275/3489. 0.2457 s / img. ETA=0:05:55
[32m[04/05 01:32:45 d2.evaluation.evaluator]: [0mInference done 2291/3489. 0.2458 s / img. ETA=0:05:51
[32m[04/05 01:32:50 d2.evaluation.evaluator]: [0mInference done 2307/3489. 0.2459 s / img. ETA=0:05:47
[32m[04/05 01:32:55 d2.evaluation.evaluator]: [0mInference done 2323/3489. 0.2459 s / img. ETA=0:05:42
[32m[04/05 01:33:00 d2.evaluation.evaluator]: [0mInference done 2338/3489. 0.2460 s / img. ETA=0:05:38
[32m[04/05 01:33:06 d2.evaluation.evaluator]: [0mInference done 2354/3489. 0.2461 s / img. ETA=0:05:34
[32m[04/05 01:33:11 d2.evaluation.evaluator]: [0mInference done 2371/3489. 0.2461 s / img. ETA=0:05:29
[32m[04/05 01:33:16 d2.evaluation.evaluator]: [0mInference done 2389/3489. 0.2461 s / img. ETA=0:05:23
[32m[04/05 01:33:21 d2.evaluation.evaluator]: [0mInference done 2406/3489. 0.2461 s / img. ETA=0:05:18
[32m[04/05 01:33:26 d2.evaluation.evaluator]: [0mInference done 2423/3489. 0.2461 s / img. ETA=0:05:13
[32m[04/05 01:33:31 d2.evaluation.evaluator]: [0mInference done 2440/3489. 0.2461 s / img. ETA=0:05:08
[32m[04/05 01:33:36 d2.evaluation.evaluator]: [0mInference done 2456/3489. 0.2462 s / img. ETA=0:05:04
[32m[04/05 01:33:42 d2.evaluation.evaluator]: [0mInference done 2472/3489. 0.2462 s / img. ETA=0:05:00
[32m[04/05 01:33:47 d2.evaluation.evaluator]: [0mInference done 2487/3489. 0.2463 s / img. ETA=0:04:55
[32m[04/05 01:33:52 d2.evaluation.evaluator]: [0mInference done 2506/3489. 0.2464 s / img. ETA=0:04:50
[32m[04/05 01:33:57 d2.evaluation.evaluator]: [0mInference done 2525/3489. 0.2463 s / img. ETA=0:04:44
[32m[04/05 01:34:02 d2.evaluation.evaluator]: [0mInference done 2544/3489. 0.2462 s / img. ETA=0:04:38
[32m[04/05 01:34:07 d2.evaluation.evaluator]: [0mInference done 2563/3489. 0.2462 s / img. ETA=0:04:32
[32m[04/05 01:34:12 d2.evaluation.evaluator]: [0mInference done 2582/3489. 0.2461 s / img. ETA=0:04:26
[32m[04/05 01:34:18 d2.evaluation.evaluator]: [0mInference done 2602/3489. 0.2461 s / img. ETA=0:04:20
[32m[04/05 01:34:23 d2.evaluation.evaluator]: [0mInference done 2622/3489. 0.2460 s / img. ETA=0:04:14
[32m[04/05 01:34:28 d2.evaluation.evaluator]: [0mInference done 2643/3489. 0.2459 s / img. ETA=0:04:08
[32m[04/05 01:34:33 d2.evaluation.evaluator]: [0mInference done 2664/3489. 0.2458 s / img. ETA=0:04:01
[32m[04/05 01:34:38 d2.evaluation.evaluator]: [0mInference done 2684/3489. 0.2457 s / img. ETA=0:03:55
[32m[04/05 01:34:43 d2.evaluation.evaluator]: [0mInference done 2704/3489. 0.2456 s / img. ETA=0:03:49
[32m[04/05 01:34:48 d2.evaluation.evaluator]: [0mInference done 2724/3489. 0.2455 s / img. ETA=0:03:43
[32m[04/05 01:34:53 d2.evaluation.evaluator]: [0mInference done 2744/3489. 0.2454 s / img. ETA=0:03:37
[32m[04/05 01:34:58 d2.evaluation.evaluator]: [0mInference done 2764/3489. 0.2453 s / img. ETA=0:03:31
[32m[04/05 01:35:04 d2.evaluation.evaluator]: [0mInference done 2784/3489. 0.2452 s / img. ETA=0:03:25
[32m[04/05 01:35:09 d2.evaluation.evaluator]: [0mInference done 2804/3489. 0.2451 s / img. ETA=0:03:19
[32m[04/05 01:35:14 d2.evaluation.evaluator]: [0mInference done 2824/3489. 0.2450 s / img. ETA=0:03:13
[32m[04/05 01:35:19 d2.evaluation.evaluator]: [0mInference done 2844/3489. 0.2449 s / img. ETA=0:03:07
[32m[04/05 01:35:24 d2.evaluation.evaluator]: [0mInference done 2864/3489. 0.2449 s / img. ETA=0:03:01
[32m[04/05 01:35:29 d2.evaluation.evaluator]: [0mInference done 2884/3489. 0.2448 s / img. ETA=0:02:55
[32m[04/05 01:35:34 d2.evaluation.evaluator]: [0mInference done 2904/3489. 0.2447 s / img. ETA=0:02:49
[32m[04/05 01:35:39 d2.evaluation.evaluator]: [0mInference done 2925/3489. 0.2446 s / img. ETA=0:02:43
[32m[04/05 01:35:44 d2.evaluation.evaluator]: [0mInference done 2946/3489. 0.2445 s / img. ETA=0:02:37
[32m[04/05 01:35:49 d2.evaluation.evaluator]: [0mInference done 2967/3489. 0.2445 s / img. ETA=0:02:30
[32m[04/05 01:35:55 d2.evaluation.evaluator]: [0mInference done 2988/3489. 0.2444 s / img. ETA=0:02:24
[32m[04/05 01:36:00 d2.evaluation.evaluator]: [0mInference done 3008/3489. 0.2443 s / img. ETA=0:02:18
[32m[04/05 01:36:05 d2.evaluation.evaluator]: [0mInference done 3028/3489. 0.2442 s / img. ETA=0:02:12
[32m[04/05 01:36:10 d2.evaluation.evaluator]: [0mInference done 3049/3489. 0.2441 s / img. ETA=0:02:06
[32m[04/05 01:36:15 d2.evaluation.evaluator]: [0mInference done 3069/3489. 0.2440 s / img. ETA=0:02:00
[32m[04/05 01:36:20 d2.evaluation.evaluator]: [0mInference done 3089/3489. 0.2440 s / img. ETA=0:01:54
[32m[04/05 01:36:25 d2.evaluation.evaluator]: [0mInference done 3109/3489. 0.2439 s / img. ETA=0:01:49
[32m[04/05 01:36:30 d2.evaluation.evaluator]: [0mInference done 3129/3489. 0.2439 s / img. ETA=0:01:43
[32m[04/05 01:36:36 d2.evaluation.evaluator]: [0mInference done 3149/3489. 0.2438 s / img. ETA=0:01:37
[32m[04/05 01:36:41 d2.evaluation.evaluator]: [0mInference done 3169/3489. 0.2437 s / img. ETA=0:01:31
[32m[04/05 01:36:46 d2.evaluation.evaluator]: [0mInference done 3190/3489. 0.2437 s / img. ETA=0:01:25
[32m[04/05 01:36:51 d2.evaluation.evaluator]: [0mInference done 3211/3489. 0.2436 s / img. ETA=0:01:19
[32m[04/05 01:36:56 d2.evaluation.evaluator]: [0mInference done 3231/3489. 0.2435 s / img. ETA=0:01:13
[32m[04/05 01:37:01 d2.evaluation.evaluator]: [0mInference done 3251/3489. 0.2435 s / img. ETA=0:01:08
[32m[04/05 01:37:06 d2.evaluation.evaluator]: [0mInference done 3272/3489. 0.2434 s / img. ETA=0:01:01
[32m[04/05 01:37:12 d2.evaluation.evaluator]: [0mInference done 3293/3489. 0.2433 s / img. ETA=0:00:55
[32m[04/05 01:37:17 d2.evaluation.evaluator]: [0mInference done 3315/3489. 0.2432 s / img. ETA=0:00:49
[32m[04/05 01:37:22 d2.evaluation.evaluator]: [0mInference done 3337/3489. 0.2431 s / img. ETA=0:00:43
[32m[04/05 01:37:27 d2.evaluation.evaluator]: [0mInference done 3358/3489. 0.2431 s / img. ETA=0:00:37
[32m[04/05 01:37:32 d2.evaluation.evaluator]: [0mInference done 3379/3489. 0.2430 s / img. ETA=0:00:31
[32m[04/05 01:37:37 d2.evaluation.evaluator]: [0mInference done 3400/3489. 0.2429 s / img. ETA=0:00:25
[32m[04/05 01:37:42 d2.evaluation.evaluator]: [0mInference done 3421/3489. 0.2428 s / img. ETA=0:00:19
[32m[04/05 01:37:47 d2.evaluation.evaluator]: [0mInference done 3442/3489. 0.2428 s / img. ETA=0:00:13
[32m[04/05 01:37:52 d2.evaluation.evaluator]: [0mInference done 3462/3489. 0.2427 s / img. ETA=0:00:07
[32m[04/05 01:37:58 d2.evaluation.evaluator]: [0mInference done 3482/3489. 0.2426 s / img. ETA=0:00:01
[32m[04/05 01:37:59 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:25.585156 (0.282889 s / img per device, on 1 devices)
[32m[04/05 01:37:59 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:14:05 (0.242620 s / img per device, on 1 devices)
[32m[04/05 01:38:01 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 01:38:02 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_7/coco_instances_results.json
[32m[04/05 01:38:03 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.68 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.58 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[32m[04/05 01:38:06 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.365 | 78.451 | 46.156 | 31.125 | 54.442 | 51.492 |
[32m[04/05 01:38:06 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 58.052 | Pedestrian | 32.678 |
Loading and preparing results...
DONE (t=2.48s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.59 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.63 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[32m[04/05 01:38:17 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.384 | 75.627 | 43.572 | 24.159 | 53.751 | 71.611 |
[32m[04/05 01:38:17 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 63.982 | Pedestrian | 26.785 |
[32m[04/05 01:38:17 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: 45.3653,78.4505,46.1556,31.1247,54.4419,51.4918
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:38:17 d2.evaluation.testing]: [0mcopypaste: 45.3837,75.6271,43.5716,24.1592,53.7512,71.6111
evaluated
Test [8][['res2', 'res3', 'res4', 'res5']]
[32m[04/05 01:38:18 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=3, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[04/05 01:38:18 d2.data.build]: [0mRemoved 729 images with no usable annotations. 3790 images left.
[32m[04/05 01:38:18 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 01:38:18 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 01:38:18 d2.data.common]: [0mSerializing 3790 elements to byte tensors and concatenating them all ...
[32m[04/05 01:38:18 d2.data.common]: [0mSerialized dataset takes 5.51 MiB
[32m[04/05 01:38:19 d2.data.build]: [0mRemoved 117 images with no usable annotations. 3372 images left.
[32m[04/05 01:38:19 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/05 01:38:19 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/05 01:38:19 d2.data.common]: [0mSerializing 3372 elements to byte tensors and concatenating them all ...
[32m[04/05 01:38:19 d2.data.common]: [0mSerialized dataset takes 6.00 MiB
[32m[04/05 01:38:19 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/05 01:38:45 d2.utils.events]: [0m eta: 0:02:35  iter: 19  total_loss: 1.827  loss_cls: 0.802  loss_box_reg: 0.3551  loss_mask: 0.6567  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.01115  total_val_loss: 1.761  val_loss_cls: 0.7038  val_loss_box_reg: 0.448  val_loss_mask: 0.6763  val_loss_rpn_cls: 0.03183  val_loss_rpn_loc: 0.009956  time: 0.8697  data_time: 0.0326  lr: 0.00019981  max_mem: 4747M
[32m[04/05 01:39:10 d2.utils.events]: [0m eta: 0:02:19  iter: 39  total_loss: 0.9566  loss_cls: 0.1752  loss_box_reg: 0.3963  loss_mask: 0.3578  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.009549  total_val_loss: 1.21  val_loss_cls: 0.232  val_loss_box_reg: 0.448  val_loss_mask: 0.5498  val_loss_rpn_cls: 0.0365  val_loss_rpn_loc: 0.0138  time: 0.8776  data_time: 0.0074  lr: 0.00039961  max_mem: 4747M
[32m[04/05 01:39:34 d2.utils.events]: [0m eta: 0:02:02  iter: 59  total_loss: 0.5312  loss_cls: 0.06713  loss_box_reg: 0.222  loss_mask: 0.2027  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.004624  total_val_loss: 1.082  val_loss_cls: 0.2193  val_loss_box_reg: 0.3714  val_loss_mask: 0.4115  val_loss_rpn_cls: 0.02419  val_loss_rpn_loc: 0.01141  time: 0.8788  data_time: 0.0074  lr: 0.00059941  max_mem: 4747M
[32m[04/05 01:39:59 d2.utils.events]: [0m eta: 0:01:44  iter: 79  total_loss: 0.5244  loss_cls: 0.07088  loss_box_reg: 0.2627  loss_mask: 0.1612  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.009095  total_val_loss: 0.9609  val_loss_cls: 0.1598  val_loss_box_reg: 0.3782  val_loss_mask: 0.3332  val_loss_rpn_cls: 0.02433  val_loss_rpn_loc: 0.01235  time: 0.8805  data_time: 0.0079  lr: 0.00079921  max_mem: 4747M
[32m[04/05 01:40:24 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:40:24 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:40:24 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:40:24 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 01:40:24 d2.utils.events]: [0m eta: 0:01:27  iter: 99  total_loss: 0.4499  loss_cls: 0.05118  loss_box_reg: 0.1728  loss_mask: 0.1573  loss_rpn_cls: 0.009185  loss_rpn_loc: 0.007472  total_val_loss: 1.14  val_loss_cls: 0.2636  val_loss_box_reg: 0.3614  val_loss_mask: 0.4249  val_loss_rpn_cls: 0.02388  val_loss_rpn_loc: 0.01099  time: 0.8804  data_time: 0.0076  lr: 0.00099901  max_mem: 4747M
[32m[04/05 01:40:49 d2.utils.events]: [0m eta: 0:01:09  iter: 119  total_loss: 0.4646  loss_cls: 0.07897  loss_box_reg: 0.1529  loss_mask: 0.1639  loss_rpn_cls: 0.008267  loss_rpn_loc: 0.01009  total_val_loss: 0.6918  val_loss_cls: 0.1511  val_loss_box_reg: 0.1779  val_loss_mask: 0.3146  val_loss_rpn_cls: 0.01948  val_loss_rpn_loc: 0.01225  time: 0.8821  data_time: 0.0075  lr: 0.0011988  max_mem: 4747M
[32m[04/05 01:41:14 d2.utils.events]: [0m eta: 0:00:52  iter: 139  total_loss: 0.2807  loss_cls: 0.03797  loss_box_reg: 0.08006  loss_mask: 0.1295  loss_rpn_cls: 0.004495  loss_rpn_loc: 0.007833  total_val_loss: 0.7427  val_loss_cls: 0.1375  val_loss_box_reg: 0.1892  val_loss_mask: 0.3458  val_loss_rpn_cls: 0.01776  val_loss_rpn_loc: 0.01298  time: 0.8824  data_time: 0.0080  lr: 0.0013986  max_mem: 4747M
[32m[04/05 01:41:39 d2.utils.events]: [0m eta: 0:00:35  iter: 159  total_loss: 0.3029  loss_cls: 0.0455  loss_box_reg: 0.1054  loss_mask: 0.1252  loss_rpn_cls: 0.006133  loss_rpn_loc: 0.01181  total_val_loss: 0.6634  val_loss_cls: 0.1397  val_loss_box_reg: 0.2085  val_loss_mask: 0.2872  val_loss_rpn_cls: 0.01515  val_loss_rpn_loc: 0.01258  time: 0.8838  data_time: 0.0081  lr: 0.0015984  max_mem: 4747M
[32m[04/05 01:42:04 d2.utils.events]: [0m eta: 0:00:17  iter: 179  total_loss: 0.3095  loss_cls: 0.05063  loss_box_reg: 0.1052  loss_mask: 0.1341  loss_rpn_cls: 0.007591  loss_rpn_loc: 0.01027  total_val_loss: 1.001  val_loss_cls: 0.2253  val_loss_box_reg: 0.3261  val_loss_mask: 0.3437  val_loss_rpn_cls: 0.01712  val_loss_rpn_loc: 0.01405  time: 0.8840  data_time: 0.0076  lr: 0.0017982  max_mem: 4747M
[32m[04/05 01:42:30 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:42:30 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:42:30 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:42:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/05 01:42:31 d2.utils.events]: [0m eta: 0:00:00  iter: 199  total_loss: 0.2944  loss_cls: 0.03272  loss_box_reg: 0.06758  loss_mask: 0.1413  loss_rpn_cls: 0.005557  loss_rpn_loc: 0.00542  total_val_loss: 0.6451  val_loss_cls: 0.1205  val_loss_box_reg: 0.1705  val_loss_mask: 0.3022  val_loss_rpn_cls: 0.02321  val_loss_rpn_loc: 0.01453  time: 0.8844  data_time: 0.0086  lr: 0.001998  max_mem: 4747M
[32m[04/05 01:42:31 d2.engine.hooks]: [0mOverall training speed: 198 iterations in 0:02:55 (0.8844 s / it)
[32m[04/05 01:42:31 d2.engine.hooks]: [0mTotal training time: 0:04:08 (0:01:13 on hooks)
[32m[04/05 01:42:31 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:42:31 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:42:31 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[5m[31mWARNING[0m [32m[04/05 01:42:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[5m[31mWARNING[0m [32m[04/05 01:42:31 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly
[32m[04/05 01:42:32 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[04/05 01:42:32 d2.data.common]: [0mSerializing 3489 elements to byte tensors and concatenating them all ...
[32m[04/05 01:42:32 d2.data.common]: [0mSerialized dataset takes 6.03 MiB
[32m[04/05 01:42:32 d2.evaluation.evaluator]: [0mStart inference on 3489 images
[32m[04/05 01:42:35 d2.evaluation.evaluator]: [0mInference done 11/3489. 0.2344 s / img. ETA=0:14:32
[32m[04/05 01:42:40 d2.evaluation.evaluator]: [0mInference done 32/3489. 0.2312 s / img. ETA=0:14:15
[32m[04/05 01:42:45 d2.evaluation.evaluator]: [0mInference done 53/3489. 0.2303 s / img. ETA=0:14:00
[32m[04/05 01:42:51 d2.evaluation.evaluator]: [0mInference done 74/3489. 0.2305 s / img. ETA=0:13:54
[32m[04/05 01:42:56 d2.evaluation.evaluator]: [0mInference done 94/3489. 0.2310 s / img. ETA=0:13:57
[32m[04/05 01:43:01 d2.evaluation.evaluator]: [0mInference done 112/3489. 0.2329 s / img. ETA=0:14:12
[32m[04/05 01:43:06 d2.evaluation.evaluator]: [0mInference done 129/3489. 0.2348 s / img. ETA=0:14:32
[32m[04/05 01:43:11 d2.evaluation.evaluator]: [0mInference done 144/3489. 0.2372 s / img. ETA=0:14:57
[32m[04/05 01:43:16 d2.evaluation.evaluator]: [0mInference done 159/3489. 0.2394 s / img. ETA=0:15:16
[32m[04/05 01:43:21 d2.evaluation.evaluator]: [0mInference done 175/3489. 0.2408 s / img. ETA=0:15:27
[32m[04/05 01:43:27 d2.evaluation.evaluator]: [0mInference done 193/3489. 0.2411 s / img. ETA=0:15:27
[32m[04/05 01:43:32 d2.evaluation.evaluator]: [0mInference done 213/3489. 0.2404 s / img. ETA=0:15:15
[32m[04/05 01:43:37 d2.evaluation.evaluator]: [0mInference done 233/3489. 0.2400 s / img. ETA=0:15:03
[32m[04/05 01:43:42 d2.evaluation.evaluator]: [0mInference done 251/3489. 0.2401 s / img. ETA=0:14:59
[32m[04/05 01:43:47 d2.evaluation.evaluator]: [0mInference done 270/3489. 0.2397 s / img. ETA=0:14:52
[32m[04/05 01:43:52 d2.evaluation.evaluator]: [0mInference done 288/3489. 0.2398 s / img. ETA=0:14:48
[32m[04/05 01:43:57 d2.evaluation.evaluator]: [0mInference done 306/3489. 0.2400 s / img. ETA=0:14:44
[32m[04/05 01:44:03 d2.evaluation.evaluator]: [0mInference done 324/3489. 0.2402 s / img. ETA=0:14:41
[32m[04/05 01:44:08 d2.evaluation.evaluator]: [0mInference done 342/3489. 0.2404 s / img. ETA=0:14:39
[32m[04/05 01:44:13 d2.evaluation.evaluator]: [0mInference done 360/3489. 0.2406 s / img. ETA=0:14:36
[32m[04/05 01:44:18 d2.evaluation.evaluator]: [0mInference done 378/3489. 0.2407 s / img. ETA=0:14:32
[32m[04/05 01:44:23 d2.evaluation.evaluator]: [0mInference done 396/3489. 0.2408 s / img. ETA=0:14:27
[32m[04/05 01:44:29 d2.evaluation.evaluator]: [0mInference done 414/3489. 0.2409 s / img. ETA=0:14:23
[32m[04/05 01:44:34 d2.evaluation.evaluator]: [0mInference done 434/3489. 0.2405 s / img. ETA=0:14:14
[32m[04/05 01:44:39 d2.evaluation.evaluator]: [0mInference done 455/3489. 0.2401 s / img. ETA=0:14:03
[32m[04/05 01:44:44 d2.evaluation.evaluator]: [0mInference done 476/3489. 0.2398 s / img. ETA=0:13:53
[32m[04/05 01:44:49 d2.evaluation.evaluator]: [0mInference done 497/3489. 0.2396 s / img. ETA=0:13:44
[32m[04/05 01:44:54 d2.evaluation.evaluator]: [0mInference done 518/3489. 0.2391 s / img. ETA=0:13:34
[32m[04/05 01:45:00 d2.evaluation.evaluator]: [0mInference done 540/3489. 0.2386 s / img. ETA=0:13:23
[32m[04/05 01:45:05 d2.evaluation.evaluator]: [0mInference done 560/3489. 0.2386 s / img. ETA=0:13:17
[32m[04/05 01:45:10 d2.evaluation.evaluator]: [0mInference done 579/3489. 0.2386 s / img. ETA=0:13:11
[32m[04/05 01:45:15 d2.evaluation.evaluator]: [0mInference done 597/3489. 0.2387 s / img. ETA=0:13:08
[32m[04/05 01:45:20 d2.evaluation.evaluator]: [0mInference done 615/3489. 0.2388 s / img. ETA=0:13:03
[32m[04/05 01:45:25 d2.evaluation.evaluator]: [0mInference done 633/3489. 0.2391 s / img. ETA=0:13:00
[32m[04/05 01:45:31 d2.evaluation.evaluator]: [0mInference done 652/3489. 0.2391 s / img. ETA=0:12:55
[32m[04/05 01:45:36 d2.evaluation.evaluator]: [0mInference done 671/3489. 0.2391 s / img. ETA=0:12:49
[32m[04/05 01:45:41 d2.evaluation.evaluator]: [0mInference done 691/3489. 0.2390 s / img. ETA=0:12:42
[32m[04/05 01:45:46 d2.evaluation.evaluator]: [0mInference done 712/3489. 0.2388 s / img. ETA=0:12:34
[32m[04/05 01:45:51 d2.evaluation.evaluator]: [0mInference done 732/3489. 0.2386 s / img. ETA=0:12:27
[32m[04/05 01:45:56 d2.evaluation.evaluator]: [0mInference done 752/3489. 0.2385 s / img. ETA=0:12:20
[32m[04/05 01:46:01 d2.evaluation.evaluator]: [0mInference done 773/3489. 0.2382 s / img. ETA=0:12:12
[32m[04/05 01:46:06 d2.evaluation.evaluator]: [0mInference done 794/3489. 0.2381 s / img. ETA=0:12:05
[32m[04/05 01:46:11 d2.evaluation.evaluator]: [0mInference done 816/3489. 0.2378 s / img. ETA=0:11:56
[32m[04/05 01:46:16 d2.evaluation.evaluator]: [0mInference done 837/3489. 0.2377 s / img. ETA=0:11:49
[32m[04/05 01:46:22 d2.evaluation.evaluator]: [0mInference done 859/3489. 0.2374 s / img. ETA=0:11:41
[32m[04/05 01:46:27 d2.evaluation.evaluator]: [0mInference done 880/3489. 0.2372 s / img. ETA=0:11:34
[32m[04/05 01:46:32 d2.evaluation.evaluator]: [0mInference done 901/3489. 0.2370 s / img. ETA=0:11:27
[32m[04/05 01:46:37 d2.evaluation.evaluator]: [0mInference done 918/3489. 0.2372 s / img. ETA=0:11:24
[32m[04/05 01:46:42 d2.evaluation.evaluator]: [0mInference done 934/3489. 0.2375 s / img. ETA=0:11:22
[32m[04/05 01:46:47 d2.evaluation.evaluator]: [0mInference done 951/3489. 0.2378 s / img. ETA=0:11:19
[32m[04/05 01:46:52 d2.evaluation.evaluator]: [0mInference done 967/3489. 0.2381 s / img. ETA=0:11:17
[32m[04/05 01:46:57 d2.evaluation.evaluator]: [0mInference done 983/3489. 0.2383 s / img. ETA=0:11:15
[32m[04/05 01:47:03 d2.evaluation.evaluator]: [0mInference done 999/3489. 0.2387 s / img. ETA=0:11:13
[32m[04/05 01:47:08 d2.evaluation.evaluator]: [0mInference done 1015/3489. 0.2390 s / img. ETA=0:11:11
[32m[04/05 01:47:13 d2.evaluation.evaluator]: [0mInference done 1031/3489. 0.2392 s / img. ETA=0:11:09
[32m[04/05 01:47:18 d2.evaluation.evaluator]: [0mInference done 1047/3489. 0.2395 s / img. ETA=0:11:06
[32m[04/05 01:47:23 d2.evaluation.evaluator]: [0mInference done 1063/3489. 0.2397 s / img. ETA=0:11:04
[32m[04/05 01:47:29 d2.evaluation.evaluator]: [0mInference done 1080/3489. 0.2399 s / img. ETA=0:11:00
[32m[04/05 01:47:34 d2.evaluation.evaluator]: [0mInference done 1099/3489. 0.2399 s / img. ETA=0:10:55
[32m[04/05 01:47:39 d2.evaluation.evaluator]: [0mInference done 1117/3489. 0.2399 s / img. ETA=0:10:51
[32m[04/05 01:47:44 d2.evaluation.evaluator]: [0mInference done 1133/3489. 0.2401 s / img. ETA=0:10:48
[32m[04/05 01:47:49 d2.evaluation.evaluator]: [0mInference done 1149/3489. 0.2403 s / img. ETA=0:10:44
[32m[04/05 01:47:54 d2.evaluation.evaluator]: [0mInference done 1165/3489. 0.2405 s / img. ETA=0:10:41
[32m[04/05 01:47:59 d2.evaluation.evaluator]: [0mInference done 1181/3489. 0.2406 s / img. ETA=0:10:38
[32m[04/05 01:48:04 d2.evaluation.evaluator]: [0mInference done 1198/3489. 0.2407 s / img. ETA=0:10:34
[32m[04/05 01:48:09 d2.evaluation.evaluator]: [0mInference done 1215/3489. 0.2409 s / img. ETA=0:10:30
[32m[04/05 01:48:15 d2.evaluation.evaluator]: [0mInference done 1233/3489. 0.2409 s / img. ETA=0:10:26
[32m[04/05 01:48:20 d2.evaluation.evaluator]: [0mInference done 1251/3489. 0.2409 s / img. ETA=0:10:21
[32m[04/05 01:48:25 d2.evaluation.evaluator]: [0mInference done 1272/3489. 0.2407 s / img. ETA=0:10:14
[32m[04/05 01:48:30 d2.evaluation.evaluator]: [0mInference done 1294/3489. 0.2405 s / img. ETA=0:10:06
[32m[04/05 01:48:35 d2.evaluation.evaluator]: [0mInference done 1315/3489. 0.2404 s / img. ETA=0:09:59
[32m[04/05 01:48:40 d2.evaluation.evaluator]: [0mInference done 1336/3489. 0.2403 s / img. ETA=0:09:52
[32m[04/05 01:48:45 d2.evaluation.evaluator]: [0mInference done 1357/3489. 0.2401 s / img. ETA=0:09:45
[32m[04/05 01:48:50 d2.evaluation.evaluator]: [0mInference done 1378/3489. 0.2399 s / img. ETA=0:09:39
[32m[04/05 01:48:55 d2.evaluation.evaluator]: [0mInference done 1399/3489. 0.2398 s / img. ETA=0:09:32
[32m[04/05 01:49:01 d2.evaluation.evaluator]: [0mInference done 1420/3489. 0.2397 s / img. ETA=0:09:25
[32m[04/05 01:49:06 d2.evaluation.evaluator]: [0mInference done 1441/3489. 0.2396 s / img. ETA=0:09:19
[32m[04/05 01:49:11 d2.evaluation.evaluator]: [0mInference done 1462/3489. 0.2395 s / img. ETA=0:09:12
[32m[04/05 01:49:16 d2.evaluation.evaluator]: [0mInference done 1483/3489. 0.2394 s / img. ETA=0:09:06
[32m[04/05 01:49:21 d2.evaluation.evaluator]: [0mInference done 1504/3489. 0.2393 s / img. ETA=0:08:59
[32m[04/05 01:49:26 d2.evaluation.evaluator]: [0mInference done 1525/3489. 0.2391 s / img. ETA=0:08:53
[32m[04/05 01:49:31 d2.evaluation.evaluator]: [0mInference done 1546/3489. 0.2390 s / img. ETA=0:08:46
[32m[04/05 01:49:37 d2.evaluation.evaluator]: [0mInference done 1567/3489. 0.2389 s / img. ETA=0:08:40
[32m[04/05 01:49:42 d2.evaluation.evaluator]: [0mInference done 1588/3489. 0.2388 s / img. ETA=0:08:34
[32m[04/05 01:49:47 d2.evaluation.evaluator]: [0mInference done 1607/3489. 0.2388 s / img. ETA=0:08:28
[32m[04/05 01:49:52 d2.evaluation.evaluator]: [0mInference done 1626/3489. 0.2388 s / img. ETA=0:08:23
[32m[04/05 01:49:57 d2.evaluation.evaluator]: [0mInference done 1645/3489. 0.2388 s / img. ETA=0:08:18
[32m[04/05 01:50:03 d2.evaluation.evaluator]: [0mInference done 1664/3489. 0.2388 s / img. ETA=0:08:13
[32m[04/05 01:50:08 d2.evaluation.evaluator]: [0mInference done 1681/3489. 0.2389 s / img. ETA=0:08:09
[32m[04/05 01:50:13 d2.evaluation.evaluator]: [0mInference done 1698/3489. 0.2390 s / img. ETA=0:08:05
[32m[04/05 01:50:18 d2.evaluation.evaluator]: [0mInference done 1715/3489. 0.2391 s / img. ETA=0:08:01
[32m[04/05 01:50:23 d2.evaluation.evaluator]: [0mInference done 1731/3489. 0.2392 s / img. ETA=0:07:58
[32m[04/05 01:50:28 d2.evaluation.evaluator]: [0mInference done 1748/3489. 0.2393 s / img. ETA=0:07:54
[32m[04/05 01:50:34 d2.evaluation.evaluator]: [0mInference done 1763/3489. 0.2395 s / img. ETA=0:07:51
[32m[04/05 01:50:39 d2.evaluation.evaluator]: [0mInference done 1779/3489. 0.2396 s / img. ETA=0:07:47
[32m[04/05 01:50:44 d2.evaluation.evaluator]: [0mInference done 1794/3489. 0.2398 s / img. ETA=0:07:44
[32m[04/05 01:50:49 d2.evaluation.evaluator]: [0mInference done 1810/3489. 0.2399 s / img. ETA=0:07:41
[32m[04/05 01:50:54 d2.evaluation.evaluator]: [0mInference done 1825/3489. 0.2401 s / img. ETA=0:07:37
[32m[04/05 01:51:00 d2.evaluation.evaluator]: [0mInference done 1840/3489. 0.2403 s / img. ETA=0:07:34
[32m[04/05 01:51:05 d2.evaluation.evaluator]: [0mInference done 1856/3489. 0.2404 s / img. ETA=0:07:30
[32m[04/05 01:51:10 d2.evaluation.evaluator]: [0mInference done 1872/3489. 0.2405 s / img. ETA=0:07:27
[32m[04/05 01:51:15 d2.evaluation.evaluator]: [0mInference done 1888/3489. 0.2407 s / img. ETA=0:07:23
[32m[04/05 01:51:20 d2.evaluation.evaluator]: [0mInference done 1903/3489. 0.2408 s / img. ETA=0:07:20
[32m[04/05 01:51:26 d2.evaluation.evaluator]: [0mInference done 1919/3489. 0.2409 s / img. ETA=0:07:16
[32m[04/05 01:51:31 d2.evaluation.evaluator]: [0mInference done 1935/3489. 0.2411 s / img. ETA=0:07:12
[32m[04/05 01:51:36 d2.evaluation.evaluator]: [0mInference done 1951/3489. 0.2412 s / img. ETA=0:07:08
[32m[04/05 01:51:42 d2.evaluation.evaluator]: [0mInference done 1967/3489. 0.2413 s / img. ETA=0:07:05
[32m[04/05 01:51:47 d2.evaluation.evaluator]: [0mInference done 1982/3489. 0.2414 s / img. ETA=0:07:01
[32m[04/05 01:51:52 d2.evaluation.evaluator]: [0mInference done 1999/3489. 0.2415 s / img. ETA=0:06:56
[32m[04/05 01:51:57 d2.evaluation.evaluator]: [0mInference done 2017/3489. 0.2415 s / img. ETA=0:06:52
[32m[04/05 01:52:02 d2.evaluation.evaluator]: [0mInference done 2034/3489. 0.2415 s / img. ETA=0:06:47
[32m[04/05 01:52:07 d2.evaluation.evaluator]: [0mInference done 2051/3489. 0.2416 s / img. ETA=0:06:43
[32m[04/05 01:52:12 d2.evaluation.evaluator]: [0mInference done 2067/3489. 0.2417 s / img. ETA=0:06:38
[32m[04/05 01:52:18 d2.evaluation.evaluator]: [0mInference done 2083/3489. 0.2418 s / img. ETA=0:06:35
[32m[04/05 01:52:23 d2.evaluation.evaluator]: [0mInference done 2099/3489. 0.2419 s / img. ETA=0:06:31
[32m[04/05 01:52:28 d2.evaluation.evaluator]: [0mInference done 2115/3489. 0.2420 s / img. ETA=0:06:26
[32m[04/05 01:52:33 d2.evaluation.evaluator]: [0mInference done 2130/3489. 0.2421 s / img. ETA=0:06:23
[32m[04/05 01:52:38 d2.evaluation.evaluator]: [0mInference done 2145/3489. 0.2422 s / img. ETA=0:06:19
[32m[04/05 01:52:43 d2.evaluation.evaluator]: [0mInference done 2160/3489. 0.2423 s / img. ETA=0:06:15
[32m[04/05 01:52:48 d2.evaluation.evaluator]: [0mInference done 2175/3489. 0.2425 s / img. ETA=0:06:12
[32m[04/05 01:52:53 d2.evaluation.evaluator]: [0mInference done 2191/3489. 0.2426 s / img. ETA=0:06:07
[32m[04/05 01:52:58 d2.evaluation.evaluator]: [0mInference done 2206/3489. 0.2427 s / img. ETA=0:06:04
[32m[04/05 01:53:04 d2.evaluation.evaluator]: [0mInference done 2222/3489. 0.2427 s / img. ETA=0:05:59
[32m[04/05 01:53:09 d2.evaluation.evaluator]: [0mInference done 2238/3489. 0.2428 s / img. ETA=0:05:55
[32m[04/05 01:53:14 d2.evaluation.evaluator]: [0mInference done 2255/3489. 0.2429 s / img. ETA=0:05:51
[32m[04/05 01:53:19 d2.evaluation.evaluator]: [0mInference done 2272/3489. 0.2429 s / img. ETA=0:05:46
[32m[04/05 01:53:24 d2.evaluation.evaluator]: [0mInference done 2289/3489. 0.2429 s / img. ETA=0:05:41
[32m[04/05 01:53:29 d2.evaluation.evaluator]: [0mInference done 2305/3489. 0.2430 s / img. ETA=0:05:37
[32m[04/05 01:53:34 d2.evaluation.evaluator]: [0mInference done 2321/3489. 0.2431 s / img. ETA=0:05:33
[32m[04/05 01:53:40 d2.evaluation.evaluator]: [0mInference done 2337/3489. 0.2431 s / img. ETA=0:05:28
[32m[04/05 01:53:45 d2.evaluation.evaluator]: [0mInference done 2354/3489. 0.2432 s / img. ETA=0:05:24
[32m[04/05 01:53:50 d2.evaluation.evaluator]: [0mInference done 2372/3489. 0.2432 s / img. ETA=0:05:19
[32m[04/05 01:53:55 d2.evaluation.evaluator]: [0mInference done 2391/3489. 0.2431 s / img. ETA=0:05:13
[32m[04/05 01:54:00 d2.evaluation.evaluator]: [0mInference done 2409/3489. 0.2431 s / img. ETA=0:05:08
[32m[04/05 01:54:05 d2.evaluation.evaluator]: [0mInference done 2428/3489. 0.2431 s / img. ETA=0:05:02
[32m[04/05 01:54:10 d2.evaluation.evaluator]: [0mInference done 2445/3489. 0.2431 s / img. ETA=0:04:58
[32m[04/05 01:54:15 d2.evaluation.evaluator]: [0mInference done 2462/3489. 0.2431 s / img. ETA=0:04:53
[32m[04/05 01:54:21 d2.evaluation.evaluator]: [0mInference done 2479/3489. 0.2432 s / img. ETA=0:04:48
[32m[04/05 01:54:26 d2.evaluation.evaluator]: [0mInference done 2498/3489. 0.2432 s / img. ETA=0:04:43
[32m[04/05 01:54:31 d2.evaluation.evaluator]: [0mInference done 2519/3489. 0.2430 s / img. ETA=0:04:36
[32m[04/05 01:54:36 d2.evaluation.evaluator]: [0mInference done 2539/3489. 0.2430 s / img. ETA=0:04:30
[32m[04/05 01:54:41 d2.evaluation.evaluator]: [0mInference done 2559/3489. 0.2429 s / img. ETA=0:04:24
[32m[04/05 01:54:46 d2.evaluation.evaluator]: [0mInference done 2579/3489. 0.2428 s / img. ETA=0:04:19
[32m[04/05 01:54:52 d2.evaluation.evaluator]: [0mInference done 2600/3489. 0.2428 s / img. ETA=0:04:12
[32m[04/05 01:54:57 d2.evaluation.evaluator]: [0mInference done 2621/3489. 0.2427 s / img. ETA=0:04:06
[32m[04/05 01:55:02 d2.evaluation.evaluator]: [0mInference done 2642/3489. 0.2426 s / img. ETA=0:04:00
[32m[04/05 01:55:07 d2.evaluation.evaluator]: [0mInference done 2663/3489. 0.2425 s / img. ETA=0:03:54
[32m[04/05 01:55:12 d2.evaluation.evaluator]: [0mInference done 2683/3489. 0.2424 s / img. ETA=0:03:48
[32m[04/05 01:55:17 d2.evaluation.evaluator]: [0mInference done 2703/3489. 0.2424 s / img. ETA=0:03:42
[32m[04/05 01:55:23 d2.evaluation.evaluator]: [0mInference done 2723/3489. 0.2423 s / img. ETA=0:03:36
[32m[04/05 01:55:28 d2.evaluation.evaluator]: [0mInference done 2743/3489. 0.2422 s / img. ETA=0:03:30
[32m[04/05 01:55:33 d2.evaluation.evaluator]: [0mInference done 2763/3489. 0.2422 s / img. ETA=0:03:25
[32m[04/05 01:55:38 d2.evaluation.evaluator]: [0mInference done 2783/3489. 0.2421 s / img. ETA=0:03:19
[32m[04/05 01:55:43 d2.evaluation.evaluator]: [0mInference done 2803/3489. 0.2421 s / img. ETA=0:03:13
[32m[04/05 01:55:48 d2.evaluation.evaluator]: [0mInference done 2823/3489. 0.2420 s / img. ETA=0:03:07
[32m[04/05 01:55:53 d2.evaluation.evaluator]: [0mInference done 2843/3489. 0.2420 s / img. ETA=0:03:02
[32m[04/05 01:55:58 d2.evaluation.evaluator]: [0mInference done 2863/3489. 0.2419 s / img. ETA=0:02:56
[32m[04/05 01:56:03 d2.evaluation.evaluator]: [0mInference done 2883/3489. 0.2418 s / img. ETA=0:02:50
[32m[04/05 01:56:09 d2.evaluation.evaluator]: [0mInference done 2904/3489. 0.2418 s / img. ETA=0:02:44
[32m[04/05 01:56:14 d2.evaluation.evaluator]: [0mInference done 2925/3489. 0.2417 s / img. ETA=0:02:38
[32m[04/05 01:56:19 d2.evaluation.evaluator]: [0mInference done 2946/3489. 0.2416 s / img. ETA=0:02:32
[32m[04/05 01:56:24 d2.evaluation.evaluator]: [0mInference done 2967/3489. 0.2415 s / img. ETA=0:02:26
[32m[04/05 01:56:29 d2.evaluation.evaluator]: [0mInference done 2988/3489. 0.2414 s / img. ETA=0:02:20
[32m[04/05 01:56:34 d2.evaluation.evaluator]: [0mInference done 3008/3489. 0.2414 s / img. ETA=0:02:14
[32m[04/05 01:56:39 d2.evaluation.evaluator]: [0mInference done 3028/3489. 0.2414 s / img. ETA=0:02:08
[32m[04/05 01:56:45 d2.evaluation.evaluator]: [0mInference done 3049/3489. 0.2413 s / img. ETA=0:02:03
[32m[04/05 01:56:50 d2.evaluation.evaluator]: [0mInference done 3069/3489. 0.2412 s / img. ETA=0:01:57
[32m[04/05 01:56:55 d2.evaluation.evaluator]: [0mInference done 3089/3489. 0.2412 s / img. ETA=0:01:51
[32m[04/05 01:57:00 d2.evaluation.evaluator]: [0mInference done 3109/3489. 0.2411 s / img. ETA=0:01:46
[32m[04/05 01:57:05 d2.evaluation.evaluator]: [0mInference done 3129/3489. 0.2411 s / img. ETA=0:01:40
[32m[04/05 01:57:10 d2.evaluation.evaluator]: [0mInference done 3149/3489. 0.2410 s / img. ETA=0:01:34
[32m[04/05 01:57:16 d2.evaluation.evaluator]: [0mInference done 3169/3489. 0.2410 s / img. ETA=0:01:29
[32m[04/05 01:57:21 d2.evaluation.evaluator]: [0mInference done 3190/3489. 0.2409 s / img. ETA=0:01:23
[32m[04/05 01:57:26 d2.evaluation.evaluator]: [0mInference done 3210/3489. 0.2409 s / img. ETA=0:01:17
[32m[04/05 01:57:31 d2.evaluation.evaluator]: [0mInference done 3229/3489. 0.2409 s / img. ETA=0:01:12
[32m[04/05 01:57:36 d2.evaluation.evaluator]: [0mInference done 3249/3489. 0.2409 s / img. ETA=0:01:06
[32m[04/05 01:57:41 d2.evaluation.evaluator]: [0mInference done 3270/3489. 0.2408 s / img. ETA=0:01:00
[32m[04/05 01:57:46 d2.evaluation.evaluator]: [0mInference done 3291/3489. 0.2407 s / img. ETA=0:00:54
[32m[04/05 01:57:51 d2.evaluation.evaluator]: [0mInference done 3313/3489. 0.2407 s / img. ETA=0:00:48
[32m[04/05 01:57:57 d2.evaluation.evaluator]: [0mInference done 3335/3489. 0.2406 s / img. ETA=0:00:42
[32m[04/05 01:58:02 d2.evaluation.evaluator]: [0mInference done 3357/3489. 0.2405 s / img. ETA=0:00:36
[32m[04/05 01:58:07 d2.evaluation.evaluator]: [0mInference done 3378/3489. 0.2404 s / img. ETA=0:00:30
[32m[04/05 01:58:12 d2.evaluation.evaluator]: [0mInference done 3399/3489. 0.2404 s / img. ETA=0:00:24
[32m[04/05 01:58:17 d2.evaluation.evaluator]: [0mInference done 3420/3489. 0.2403 s / img. ETA=0:00:19
[32m[04/05 01:58:22 d2.evaluation.evaluator]: [0mInference done 3440/3489. 0.2403 s / img. ETA=0:00:13
[32m[04/05 01:58:27 d2.evaluation.evaluator]: [0mInference done 3460/3489. 0.2402 s / img. ETA=0:00:08
[32m[04/05 01:58:32 d2.evaluation.evaluator]: [0mInference done 3481/3489. 0.2402 s / img. ETA=0:00:02
[32m[04/05 01:58:34 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:00.659950 (0.275735 s / img per device, on 1 devices)
[32m[04/05 01:58:34 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:13:56 (0.240143 s / img per device, on 1 devices)
[32m[04/05 01:58:36 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/05 01:58:36 d2.evaluation.coco_evaluation]: [0mSaving results to ./output_8/coco_instances_results.json
[32m[04/05 01:58:37 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 1.50 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.51 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.405
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[32m[04/05 01:58:40 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.324 | 80.408 | 51.250 | 30.021 | 58.547 | 61.770 |
[32m[04/05 01:58:40 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 59.102 | Pedestrian | 39.546 |
Loading and preparing results...
DONE (t=2.18s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 2.30 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.55 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[32m[04/05 01:58:49 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.816 | 76.153 | 42.890 | 23.278 | 53.887 | 68.851 |
[32m[04/05 01:58:49 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| Cars       | 62.814 | Pedestrian | 26.818 |
[32m[04/05 01:58:49 d2.engine.defaults]: [0mEvaluation results for kittimots_val in csv format:
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: 49.3241,80.4084,51.2498,30.0208,58.5465,61.7703
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[04/05 01:58:49 d2.evaluation.testing]: [0mcopypaste: 44.8162,76.1532,42.8896,23.2782,53.8866,68.8514
evaluated
